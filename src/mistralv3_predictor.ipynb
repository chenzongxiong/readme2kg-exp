{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae8e1d9-35dd-4659-a5aa-9dd8d7303bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "sys.path.append('./readme2kg-exp/src/')\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from termcolor import colored\n",
    "from functools import partial, reduce\n",
    "import operator as op\n",
    "import hashlib\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "from predictor import BasePredictor, LABELS\n",
    "from webanno_tsv import webanno_tsv_read_file, Document, Annotation, Token\n",
    "import utils\n",
    "import cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3be4a1-90bb-4601-963f-7cfe19c501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'test_unlabeled'\n",
    "base_path = f'./readme2kg-exp/data/{phase}'\n",
    "file_names = [fp for fp in os.listdir(base_path) if os.path.isfile(os.path.join(base_path, fp)) and fp.endswith('.tsv')]\n",
    "model_name = 'Mistral-7B-Instruct-v0.3'\n",
    "output_folder = f'./readme2kg-exp/results/{model_name}/{phase}'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560ab781-056f-41fe-aad8-6acf457399c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_id = 0\n",
    "prompt_template_path = f'./readme2kg-exp/config/deepseek-chat-prompt-0.txt'\n",
    "if os.path.isfile(prompt_template_path):\n",
    "    with open(prompt_template_path, 'r') as fd:\n",
    "        prompt_template = fd.read()\n",
    "else:\n",
    "    prompt_template = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4901a66c-ff2d-4d40-a331-15ff80039bb6",
   "metadata": {},
   "source": [
    "# Load Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a3d58c-edbc-431f-8b96-48e919e4080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8346b7bf339941d6839bc2fbd8a3d8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ann/mistral_models/7B-Instruct-v0.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "mistral_models_path = Path.home().joinpath('mistral_models', '7B-Instruct-v0.3')\n",
    "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d75786-539a-4ee6-855b-784ddb994a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['```\\n# DejaVu\\n## Table of Contents =================\\n\\t* [Code](#code)\\n\\t* [Install Requirements](#install-requirements)\\n\\t* [Usage](#usage)\\n\\t* [Example](#example)\\n\\t* [Datasets](#datasets)\\n\\t* [Deployment and Failure Injection Scripts of Train-Ticket](#deployment-and-failure-injection-scripts-of-train-ticket)\\n\\t* [Citation](#citation)\\n\\t* [Supplementary details](#supplementary-details)\\n\\t## Paper\\n\\tA preprint version: <PUBLICATION>https://arxiv.org/abs/2207.09021</PUBLICATION>\\n\\t## Code\\n\\t### Install\\n\\t1.\\n```']\n"
     ]
    }
   ],
   "source": [
    "from mistral_inference.transformer import Transformer\n",
    "from mistral_inference.generate import generate\n",
    "\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "\n",
    "tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\n",
    "model = Transformer.from_folder(mistral_models_path)\n",
    "\n",
    "# unit test code\n",
    "sentence_text = \"\"\"# DejaVu ## Table of Contents =================    * [Code](#code)     * [Install Requirements](#install-requirements)     * [Usage](#usage)     * [Example](#example)   * [Datasets](#datasets)   * [Deployment and Failure Injection Scripts of Train-Ticket](#deployment-and-failure-injection-scripts-of-train-ticket)   * [Citation](#citation)   * [Supplementary details](#supplementary-details)    ## Paper A preprint version: https://arxiv.org/abs/2207.09021 ## Code ### Install 1.\"\"\"\n",
    "prompt = prompt_template.replace('{input_text}', sentence_text)\n",
    "\n",
    "# original code\n",
    "#prompt = prompt_template.replace('{input_text}', sentence.text)\n",
    "\n",
    "'''\n",
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful NER annotator\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "'''\n",
    "completion_request = ChatCompletionRequest(messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful NER annotator\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    ")\n",
    "\n",
    "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "\n",
    "out_tokens, _ = generate([tokens], model, max_tokens=1000, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
    "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1bc1ba-089a-4cb9-95ae-4f691968fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(sentence, tokens, sid_path):\n",
    "    try:\n",
    "        #print(f\"Process-{os.getpid()} processing {colored(sentence.text, 'red')} ...\")\n",
    "        prompt = prompt_template.replace('{input_text}', sentence.text)\n",
    "\n",
    "        messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful NER annotator\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "        \n",
    "        completion_request = ChatCompletionRequest(messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful NER annotator\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ])\n",
    "        tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "\n",
    "        out_tokens, _ = generate([tokens], model, max_tokens=255, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
    "        result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
    "        \n",
    "        #print(f\"Process-{os.getpid()} predict {colored(sentence.text, 'cyan')} successfully\")\n",
    "        with open(sid_path, 'w') as file:\n",
    "            file.write(result)\n",
    "    except Exception as ex:\n",
    "        logging.error(f'[do_prediction] got exception: {ex}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78fc7e9-36b5-4505-ae93-b6472540e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotation_labels_if_possible(predicted_text):\n",
    "    label_to_text_list = defaultdict(list)\n",
    "    acc_adjusted_pos = 0\n",
    "    for label in LABELS:\n",
    "        regex = f'<{label}>(.*?)</{label}>'\n",
    "        matches = re.finditer(regex, predicted_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        for m in matches:\n",
    "            adjusted_pos = len(label) + 2\n",
    "            label_to_text_list[label].append({\n",
    "                'text': m.group(1),\n",
    "                'start': m.start(1) - adjusted_pos - acc_adjusted_pos,\n",
    "                'end': m.end(1) - adjusted_pos - acc_adjusted_pos,\n",
    "            })\n",
    "            acc_adjusted_pos += adjusted_pos * 2 + 1\n",
    "    return label_to_text_list\n",
    "\n",
    "\n",
    "\n",
    "def post_process(predicted_text, tokens):\n",
    "    cleaned_text = cleaner.Cleaner(predicted_text).clean()\n",
    "    label_to_text_list = extract_annotation_labels_if_possible(cleaned_text)\n",
    "    return label_to_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aefcdd39-2572-4a1e-bc6b-4f5651cb88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, tokens):\n",
    "    path = f'./readme2kg-exp/results/{model_name}/prompt-{prompt_id}/zzz_{file_name}' # NOTE: prefix zzz for directory sorting, non-sense\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    sid = hashlib.sha256(sentence.text.encode()).hexdigest()[:8]\n",
    "    #if not os.path.isfile(f'{path}/{sid}.txt'):   # original code\n",
    "    if os.path.isdir(f'{path}'):\n",
    "        do_prediction(sentence, tokens, f'{path}/{sid}.txt')\n",
    "\n",
    "    with open(f'{path}/{sid}.txt', 'r') as fd:\n",
    "        predicted_text = fd.read()\n",
    "\n",
    "    label_to_text_list = post_process(predicted_text, tokens)\n",
    "    # NOTE: sanity checking\n",
    "    for label, text_list in label_to_text_list.items():\n",
    "        for text in text_list:\n",
    "            if text['text'] != sentence.text[text['start']:text['end']]:\n",
    "                prompt = prompt_template.replace('{input_text}', sentence.text)\n",
    "                #logging.warning(f\"BUG? The predicted text is not exact the same as the original text. \\n\\nPrompt: {prompt}\\nOriginal: {colored(sentence.text, 'green')}\\nGenerated: {colored(text['text'], 'red')}\\n--------------------------------------------------------------------------------\")\n",
    "\n",
    "    span_tokens_to_label_list = []\n",
    "    for label, text_list in label_to_text_list.items():\n",
    "        for text in text_list:\n",
    "            span_tokens_to_label_list.append({\n",
    "                'span_tokens': utils.make_span_tokens(tokens, text['start'], text['end']),\n",
    "                'label': label\n",
    "            })\n",
    "    return span_tokens_to_label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0045624d-f168-44cf-a4c9-f94413793290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_serial(doc: Document):\n",
    "    annotations = []\n",
    "    for sent in doc.sentences:\n",
    "        tokens = doc.sentence_tokens(sent)\n",
    "        span_tokens_to_label_list = predict(sentence=sent, tokens=tokens)\n",
    "        \n",
    "        # create the annotation instances\n",
    "        for span_tokens_to_label in span_tokens_to_label_list:\n",
    "            span_tokens = span_tokens_to_label['span_tokens']\n",
    "            label = span_tokens_to_label['label']\n",
    "            if span_tokens is None:\n",
    "                continue\n",
    "\n",
    "            annotation = utils.make_annotation(tokens=span_tokens, label=label)\n",
    "            annotations.append(annotation)\n",
    "\n",
    "    result = utils.replace_webanno_annotations(doc, annotations=annotations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5349e6-b4b2-49f8-bd0e-a5fc25f83a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 7 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 0 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 3 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 3 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 4 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 6 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 0 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 3 annotations\n",
      "WARNING:root:Predicted 3 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 0 annotations\n",
      "WARNING:root:Predicted 7 annotations\n",
      "WARNING:root:Predicted 2 annotations\n",
      "WARNING:root:Predicted 6 annotations\n",
      "WARNING:root:Predicted 0 annotations\n",
      "WARNING:root:Predicted 3 annotations\n",
      "WARNING:root:Predicted 4 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 5 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 1 annotations\n",
      "WARNING:root:Predicted 0 annotations\n"
     ]
    }
   ],
   "source": [
    "for file_name in file_names:\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    ref_doc = webanno_tsv_read_file(file_path)\n",
    "    predicted_doc = call_serial(ref_doc)\n",
    "    # Verify\n",
    "    if ref_doc.text != predicted_doc.text:\n",
    "        #logging.warning('content changed')\n",
    "        pass\n",
    "    if len(ref_doc.sentences) == len(predicted_doc.sentences):\n",
    "        #logging.warning('sentences changed')\n",
    "        pass\n",
    "    if len(ref_doc.tokens) == len(predicted_doc.tokens):\n",
    "        #logging.warning('tokens changed')\n",
    "        pass\n",
    "    for s1, s2 in zip(ref_doc.sentences, predicted_doc.sentences):\n",
    "        if s1 == s2:\n",
    "            #logging.warning(f'sentence changed, \\n{s1}\\n{s2}')\n",
    "            pass\n",
    "\n",
    "    for t1, t2 in zip(ref_doc.tokens, predicted_doc.tokens):\n",
    "        if t1 == t2:\n",
    "            #logging.warning(f'token changed: \\n{t1}\\n{t2}')\n",
    "            pass\n",
    "\n",
    "    logging.warning(f\"Predicted {len(predicted_doc.annotations)} annotations\")\n",
    "    prediction_path = os.path.join(output_folder, file_name)\n",
    "    with open(prediction_path, 'w') as fd:\n",
    "        fd.write(predicted_doc.tsv())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
