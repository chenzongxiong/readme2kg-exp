{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32b07bf",
   "metadata": {},
   "source": [
    "# Entity-Level Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac5bf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script is downloaded from GSAP-NER: https://github.com/ottowg/gsap-ner/blob/emnlp_submission/evaluation/evaluation_methods.py\n",
    "from bisect import bisect_left, bisect_right\n",
    "import pandas as pd\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "def calc_scores(gold, prediction):\n",
    "    scores = prec_recall(gold, prediction, \"precision\")\\\n",
    "                .join(prec_recall(gold, prediction, \"recall\"))\n",
    "    add_f1(scores)\n",
    "    return scores\n",
    "\n",
    "def prec_recall(gold, prediction, score_name):\n",
    "    if score_name == \"recall\":\n",
    "        prediction, gold = gold, prediction\n",
    "    elif score_name != \"precision\":\n",
    "        raise Exception(\"no valid score\")\n",
    "    scores_interim = remap_annos_best_match_many_documents(gold,\n",
    "                                                prediction)\n",
    "    scores_interim = pd.DataFrame(scores_interim)\n",
    "    label_p = scores_interim.label.value_counts()\n",
    "    p = label_p.sum()\n",
    "    scores_interim[\"partial_tp\"] = scores_interim.label == scores_interim.label_mapped\n",
    "    scores_interim[\"exact_tp\"] = (scores_interim.label == scores_interim.label_mapped)\\\n",
    "                                 & (scores_interim.match_type == \"exact_match\")\n",
    "    partial_score = (scores_interim.groupby(\"label\").partial_tp.sum() /\\\n",
    "                     label_p).rename(f\"partial_{score_name}\")\n",
    "    partial_score.loc[\"all\"] = scores_interim.partial_tp.sum() / p\n",
    "    exact_score = (scores_interim.groupby(\"label\").exact_tp.sum() / label_p)\\\n",
    "                        .rename(f\"exact_{score_name}\")\n",
    "    exact_score.loc[\"all\"] = scores_interim.exact_tp.sum() / p\n",
    "    score = partial_score.to_frame().join(exact_score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def remap_annos_best_match_df(doc_annos, exact=False):\n",
    "    gold = doc_annos.gold\n",
    "    pred = doc_annos.pred\n",
    "    result = remap_annos_best_match_many_documents(gold, pred, exact=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "def remap_annos_best_match_many_documents(gold, pred, exact=False):\n",
    "    \"\"\"\n",
    "    each annotation (gold and prediction) need to contain: \"begin\", \"end\"\n",
    "    The documents will be grouped by \"id\" before matching.\n",
    "    Each \"id\" represents one document.\n",
    "    \"\"\"\n",
    "    document_annos = get_document_dict(gold, pred)\n",
    "    all_annos = []\n",
    "    for doc, annos in document_annos.items():\n",
    "        #print(doc)\n",
    "        #print(len(annos[\"gold\"]))\n",
    "        #print(len(annos[\"prediction\"]))\n",
    "        remaped = remap_annos_best_match(annos[\"gold\"], annos[\"prediction\"], exact=exact)\n",
    "        all_annos.extend(remaped)\n",
    "    return all_annos\n",
    "    \n",
    "def get_document_dict(gold, pred):\n",
    "    idents = {g[\"doc_id\"] for g in gold}\n",
    "    idents |= {p[\"doc_id\"] for p in pred}\n",
    "    print(\"n_documents:\", len(idents))\n",
    "    by_ident = {ident: dict(gold=[], prediction=[])\n",
    "                for ident in idents}\n",
    "    for g in gold:\n",
    "        by_ident[g[\"doc_id\"]][\"gold\"].append(g)\n",
    "    for p in pred:\n",
    "        by_ident[p[\"doc_id\"]][\"prediction\"].append(p)\n",
    "    return by_ident\n",
    "    \n",
    "    \n",
    "def remap_annos_best_match(gold, pred, exact=False):\n",
    "    pred_remapped = []\n",
    "    for idx, g in enumerate(gold):\n",
    "        g[\"index\"] = idx\n",
    "    gold_begin = sorted(gold, key=lambda x:x[\"begin\"])\n",
    "    gold_end = sorted(gold, key=lambda x:x[\"end\"])\n",
    "    for p in pred:\n",
    "        overlaps = get_overlapping(p, gold_begin, gold_end)\n",
    "        overlaps = [gold[idx] for idx in overlaps]\n",
    "        # find perfect match\n",
    "        match_type = \"no_match\"\n",
    "        matched = []\n",
    "        # find perfect match\n",
    "        if not matched:\n",
    "            overlaps_selected = [o for o in overlaps if o[\"label\"] == p[\"label\"]\n",
    "                                 and (o[\"begin\"] == p[\"begin\"] and o[\"end\"] == p[\"end\"])\n",
    "                                ]\n",
    "            if overlaps_selected:\n",
    "                matched = overlaps_selected\n",
    "                match_type = \"exact_match\"\n",
    "        if not matched and not exact:\n",
    "            # find same label but only overlapping span\n",
    "            overlaps_selected = [o for o in overlaps if o[\"label\"] == p[\"label\"]\n",
    "                        and (o[\"begin\"] != p[\"begin\"] or o[\"end\"] != p[\"end\"])\n",
    "                       ]\n",
    "            if overlaps_selected:\n",
    "                matched = overlaps_selected\n",
    "                match_type = \"partly_match\"\n",
    "        if not matched:\n",
    "            # find different label but same span\n",
    "            overlaps_selected = [o for o in overlaps if o[\"label\"] != p[\"label\"]\n",
    "                        and (o[\"begin\"] == p[\"begin\"] and o[\"end\"] == p[\"end\"])\n",
    "                       ]\n",
    "            if overlaps_selected:\n",
    "                matched = overlaps_selected\n",
    "                match_type = \"exact_span_match\"\n",
    "        if not matched and not exact:\n",
    "            # find different label and different overlapping span\n",
    "            overlaps_selected = [o for o in overlaps if o[\"label\"] != p[\"label\"]\n",
    "                        and (o[\"begin\"] != p[\"begin\"] or o[\"end\"] != p[\"end\"])\n",
    "                       ]\n",
    "            if overlaps_selected:\n",
    "                matched = overlaps_selected\n",
    "                match_type = \"partly_span_match\"\n",
    "        match = {} if not matched else matched[0]\n",
    "        match = {k:v for k, v in match.items()}\n",
    "        labels = sorted(list(set([a[\"label\"] for a in matched])))\n",
    "        labels = \" \".join(labels)\n",
    "        p = {k:v for k, v in p.items()}\n",
    "        p[\"text_mapped\"] = match.get(\"text\")\n",
    "        p[\"begin_mapped\"] = match.get(\"begin\")\n",
    "        p[\"end_mapped\"] = match.get(\"end\")\n",
    "        p[\"label_mapped\"] = match.get(\"label\", \"not_found\")\n",
    "        p[\"labels_mapped\"] = labels if labels else \"not_found\"\n",
    "        p[\"n_matched\"] = len(matched)\n",
    "        p[\"match_type\"] = match_type\n",
    "        pred_remapped.append(p)\n",
    "    return pred_remapped\n",
    "\n",
    "def get_overlapping(anno, annos_begin, annos_end):\n",
    "    # all annos with smaller end as begining of query anno\n",
    "    anno_idx_end_max = bisect_right(annos_end, anno[\"begin\"], key=lambda x:x[\"end\"])\n",
    "    # all annos with smaller beginning as ending of query anno\n",
    "    anno_idx_begin_min = bisect_left(annos_begin, anno[\"end\"], key=lambda x:x[\"begin\"])\n",
    "    #anno_idx_begin_min, anno_idx_end_max\n",
    "\n",
    "    matches = {a[\"index\"] for a in annos_end[anno_idx_end_max:]} &\\\n",
    "              {a[\"index\"] for a in annos_begin[:anno_idx_begin_min]}\n",
    "    return matches\n",
    "\n",
    "def add_f1(scores):\n",
    "    for t in [\"partial\", \"exact\"]:\n",
    "        scores[f\"{t}_f1\"] = 2 * (scores[f\"{t}_precision\"] * scores[f\"{t}_recall\"]) /\\\n",
    "                                (scores[f\"{t}_precision\"] + scores[f\"{t}_recall\"])\n",
    "\n",
    "\n",
    "def print_annos(annos):\n",
    "    for a in annos:\n",
    "        print(\"\\t\", end=\"\")\n",
    "        print_anno(a)\n",
    "\n",
    "def print_anno(anno):\n",
    "    print(f'{anno[\"begin\"]} {anno[\"end\"]} {anno[\"label\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6659e5d",
   "metadata": {},
   "source": [
    "# Consider our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8bb2c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from webanno_tsv import webanno_tsv_read_file\n",
    "\n",
    "def convert_to_gold_annos(tsv_path):\n",
    "    document = webanno_tsv_read_file(tsv_path)\n",
    "    gold_annos = []\n",
    "    doc_id = os.path.splitext(os.path.basename(tsv_path))[0]\n",
    "\n",
    "    for anno in document.annotations:\n",
    "        tokens = anno.tokens\n",
    "        begin = tokens[0].start\n",
    "        end = tokens[-1].end\n",
    "        text = ' '.join([token.text for token in tokens])\n",
    "        gold_anno = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"begin\": begin,\n",
    "            \"end\": end,\n",
    "            \"label\": anno.label,\n",
    "            \"text\": text\n",
    "        }\n",
    "        gold_annos.append(gold_anno)\n",
    "    \n",
    "    return gold_annos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05055337",
   "metadata": {},
   "source": [
    "## deepseek-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5189c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_documents: 40\n",
      "n_documents: 40\n",
      "\n",
      "=== Evaluation Result ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partial_precision</th>\n",
       "      <th>exact_precision</th>\n",
       "      <th>partial_recall</th>\n",
       "      <th>exact_recall</th>\n",
       "      <th>partial_f1</th>\n",
       "      <th>exact_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONFERENCE</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATASET</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVALMETRIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LICENSE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROGLANG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUBLICATION</th>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.111959</td>\n",
       "      <td>0.030534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOFTWARE</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.011574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORKSHOP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.033872</td>\n",
       "      <td>0.011310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             partial_precision  exact_precision  partial_recall  exact_recall  \\\n",
       "label                                                                           \n",
       "CONFERENCE            0.500000         0.250000        0.015385      0.005128   \n",
       "DATASET               0.200000         0.000000        0.007605      0.000000   \n",
       "EVALMETRIC            0.000000         0.000000        0.000000      0.000000   \n",
       "LICENSE               0.000000         0.000000        0.000000      0.000000   \n",
       "PROGLANG              0.000000         0.000000        0.000000      0.000000   \n",
       "PROJECT               0.000000         0.000000        0.000000      0.000000   \n",
       "PUBLICATION           0.709677         0.193548        0.060773      0.016575   \n",
       "SOFTWARE              0.200000         0.125000        0.009709      0.006068   \n",
       "WORKSHOP              1.000000         0.000000        0.027027      0.000000   \n",
       "all                   0.275591         0.094488        0.018045      0.006015   \n",
       "\n",
       "             partial_f1  exact_f1  \n",
       "label                              \n",
       "CONFERENCE     0.029851  0.010050  \n",
       "DATASET        0.014652       NaN  \n",
       "EVALMETRIC          NaN       NaN  \n",
       "LICENSE             NaN       NaN  \n",
       "PROGLANG            NaN       NaN  \n",
       "PROJECT             NaN       NaN  \n",
       "PUBLICATION    0.111959  0.030534  \n",
       "SOFTWARE       0.018519  0.011574  \n",
       "WORKSHOP       0.052632       NaN  \n",
       "all            0.033872  0.011310  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Directory paths\n",
    "ref_dir = '../data/test_labeled'\n",
    "src_dir_deepseek = '../results/deepseek-chat/test_unlabeled'\n",
    "\n",
    "# Process all TSV files in the reference directory\n",
    "all_gold_annos = []\n",
    "all_pred_annos = []\n",
    "\n",
    "# Get all TSV files in the reference directory\n",
    "ref_files = [f for f in os.listdir(ref_dir) if f.endswith('.tsv')]\n",
    "\n",
    "for ref_file in ref_files:\n",
    "    ref_path = os.path.join(ref_dir, ref_file)\n",
    "    src_path_deepseek = os.path.join(src_dir_deepseek, ref_file)\n",
    "    \n",
    "    # Process reference annotations\n",
    "    if os.path.exists(ref_path):\n",
    "        all_gold_annos.extend(convert_to_gold_annos(ref_path))\n",
    "    \n",
    "    # Process prediction annotations\n",
    "    if os.path.exists(src_path_deepseek):\n",
    "        all_pred_annos.extend(convert_to_gold_annos(src_path_deepseek))\n",
    "    \n",
    "scores = calc_scores(all_gold_annos, all_pred_annos)\n",
    "print(\"\\n=== Evaluation Result ===\")\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f39743c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to DataFrames\n",
    "# gold_df = pd.DataFrame(all_gold_annos)\n",
    "# pred_df = pd.DataFrame(all_pred_annos)\n",
    "\n",
    "# # Display the DataFrames\n",
    "# print(\"Gold Annotations:\")\n",
    "# print(gold_df.head())\n",
    "# print(\"\\nShape:\", gold_df.shape)\n",
    "\n",
    "# print(\"\\nPredicted Annotations:\")\n",
    "# print(pred_df.head())\n",
    "# print(\"\\nShape:\", pred_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95bbd8",
   "metadata": {},
   "source": [
    "## Meta-Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "821e039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_documents: 40\n",
      "n_documents: 40\n",
      "\n",
      "=== Evaluation Result ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partial_precision</th>\n",
       "      <th>exact_precision</th>\n",
       "      <th>partial_recall</th>\n",
       "      <th>exact_recall</th>\n",
       "      <th>partial_f1</th>\n",
       "      <th>exact_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATASET</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUBLICATION</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             partial_precision  exact_precision  partial_recall  exact_recall  \\\n",
       "label                                                                           \n",
       "DATASET               0.000000              0.0        0.000000           0.0   \n",
       "PUBLICATION           0.023256              0.0        0.002762           0.0   \n",
       "all                   0.013514              0.0        0.000501           0.0   \n",
       "\n",
       "             partial_f1  exact_f1  \n",
       "label                              \n",
       "DATASET             NaN       NaN  \n",
       "PUBLICATION    0.004938       NaN  \n",
       "all            0.000967       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Directory paths\n",
    "ref_dir = '../data/test_labeled'\n",
    "src_dir_deepseek = '../results/Meta-Llama-3-8B-Instruct/test_unlabeled'\n",
    "\n",
    "# Process all TSV files in the reference directory\n",
    "all_gold_annos = []\n",
    "all_pred_annos = []\n",
    "\n",
    "# Get all TSV files in the reference directory\n",
    "ref_files = [f for f in os.listdir(ref_dir) if f.endswith('.tsv')]\n",
    "\n",
    "for ref_file in ref_files:\n",
    "    ref_path = os.path.join(ref_dir, ref_file)\n",
    "    src_path_deepseek = os.path.join(src_dir_deepseek, ref_file)\n",
    "    \n",
    "    # Process reference annotations\n",
    "    if os.path.exists(ref_path):\n",
    "        all_gold_annos.extend(convert_to_gold_annos(ref_path))\n",
    "    \n",
    "    # Process prediction annotations\n",
    "    if os.path.exists(src_path_deepseek):\n",
    "        all_pred_annos.extend(convert_to_gold_annos(src_path_deepseek))\n",
    "    \n",
    "scores = calc_scores(all_gold_annos, all_pred_annos)\n",
    "print(\"\\n=== Evaluation Result ===\")\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecce60",
   "metadata": {},
   "source": [
    "## Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e523c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_documents: 40\n",
      "n_documents: 40\n",
      "\n",
      "=== Evaluation Result ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partial_precision</th>\n",
       "      <th>exact_precision</th>\n",
       "      <th>partial_recall</th>\n",
       "      <th>exact_recall</th>\n",
       "      <th>partial_f1</th>\n",
       "      <th>exact_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONFERENCE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATASET</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVALMETRIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LICENSE</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONTOLOGY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROGLANG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUBLICATION</th>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOFTWARE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORKSHOP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             partial_precision  exact_precision  partial_recall  exact_recall  \\\n",
       "label                                                                           \n",
       "CONFERENCE            0.000000         0.000000        0.000000      0.000000   \n",
       "DATASET               0.500000         0.000000        0.011407      0.000000   \n",
       "EVALMETRIC            0.000000         0.000000        0.000000      0.000000   \n",
       "LICENSE               0.250000         0.000000        0.038462      0.000000   \n",
       "ONTOLOGY              0.000000         0.000000        0.000000      0.000000   \n",
       "PROGLANG              0.000000         0.000000        0.000000      0.000000   \n",
       "PROJECT               0.000000         0.000000        0.000000      0.000000   \n",
       "PUBLICATION           0.391304         0.043478        0.024862      0.002762   \n",
       "SOFTWARE              0.000000         0.000000        0.000000      0.000000   \n",
       "WORKSHOP              0.000000         0.000000        0.000000      0.000000   \n",
       "all                   0.191176         0.014706        0.006516      0.000501   \n",
       "\n",
       "             partial_f1  exact_f1  \n",
       "label                              \n",
       "CONFERENCE          NaN       NaN  \n",
       "DATASET        0.022305       NaN  \n",
       "EVALMETRIC          NaN       NaN  \n",
       "LICENSE        0.066667       NaN  \n",
       "ONTOLOGY            NaN       NaN  \n",
       "PROGLANG            NaN       NaN  \n",
       "PROJECT             NaN       NaN  \n",
       "PUBLICATION    0.046753  0.005195  \n",
       "SOFTWARE            NaN       NaN  \n",
       "WORKSHOP            NaN       NaN  \n",
       "all            0.012603  0.000969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Directory paths\n",
    "ref_dir = '../data/test_labeled'\n",
    "src_dir_deepseek = '../results/Mistral-7B-Instruct-v0.3/test_unlabeled'\n",
    "\n",
    "# Process all TSV files in the reference directory\n",
    "all_gold_annos = []\n",
    "all_pred_annos = []\n",
    "\n",
    "# Get all TSV files in the reference directory\n",
    "ref_files = [f for f in os.listdir(ref_dir) if f.endswith('.tsv')]\n",
    "\n",
    "for ref_file in ref_files:\n",
    "    ref_path = os.path.join(ref_dir, ref_file)\n",
    "    src_path_deepseek = os.path.join(src_dir_deepseek, ref_file)\n",
    "    \n",
    "    # Process reference annotations\n",
    "    if os.path.exists(ref_path):\n",
    "        all_gold_annos.extend(convert_to_gold_annos(ref_path))\n",
    "    \n",
    "    # Process prediction annotations\n",
    "    if os.path.exists(src_path_deepseek):\n",
    "        all_pred_annos.extend(convert_to_gold_annos(src_path_deepseek))\n",
    "    \n",
    "scores = calc_scores(all_gold_annos, all_pred_annos)\n",
    "print(\"\\n=== Evaluation Result ===\")\n",
    "display(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
