sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
4,Download KILT wikipedia knowledge base [here](https://github.com/facebookresearch/KILT) and put it under a kb directory like /raw_kb/  \ 2.,Download <DATASET>KILT</DATASET> wikipedia knowledge base [here](https://github.com/facebookresearch/KILT) and put it under a kb directory like /raw_kb/  \ 2.,Download `KILT wikipedia knowledge base` [here](https://github.com/facebookresearch/KILT) and put it under a kb directory like /raw_kb/  \ 2.,Download `<DATASET>KILT wikipedia knowledge base</DATASET>` [here](https://github.com/<PROJECT>facebookresearch</PROJECT>/<PROJECT>KILT</PROJECT>) and put it under a kb directory like /raw_kb/  \ 2.,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\aff14cc4.txt,0.9928571428571429
13,usp=sharing).  2.,usp=sharing).  2.,usp=sharing) 3.,usp=sharing) 3.,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\fbba97df.txt,0.8125
15,It takes up 36G GPU memory for the main GPU and 32G GPU memory for the other GPU. ### Reader Local Evaluation 1.,It takes up 36G GPU memory for the main GPU and 32G GPU memory for the other GPU. ### Reader Local Evaluation 1.,It takes up 36G GPU memory for the main GPU and 32G GPU memory for the other GPU. ### `Reader Local Evaluation` 1.,It takes up 36G GPU memory for the main GPU and 32G GPU memory for the other GPU. ### `<EVALMETRIC>Reader Local Evaluation</EVALMETRIC>` 1.,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\798f3018.txt,0.9911504424778761
17,usp=sharing) 2.,usp=sharing) 2.,usp=sharing) 3.,usp=sharing) 3.,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\fbba97df.txt,0.9333333333333333
21,"Use the above reader training scripts and set `--epochs` to be 0 for evaluation.  ### Reader Results  |   val F1  |  test F1  |  val Recall |  test Recall |  val Precision  |  test Precision  | |:-----------:|:-----------:|:-------------:|:--------------:|:-----------------:|:------------------:| |   87.32%  |   84.4%  |   90.23%    |    87.0%    |     84.6%      |      81.96%      |  ## GERBIL evaluation Our GERBIL evaluation steps follow [here](https://github.com/dalab/end2end_neural_el), specifically: 1.","Use the above reader training scripts and set `--epochs` to be 0 for evaluation.  ### Reader Results  |   val <EVALMETRIC>F1</EVALMETRIC>  |  test <EVALMETRIC>F1</EVALMETRIC>  |  val <EVALMETRIC>Recall</EVALMETRIC> |  test <EVALMETRIC>Recall</EVALMETRIC> |  val <EVALMETRIC>Precision</EVALMETRIC>  |  test <EVALMETRIC>Precision</EVALMETRIC>  | |:-----------:|:-----------:|:-------------:|:--------------:|:-----------------:|:------------------:| |   87.32%  |   84.4%  |   90.23%    |    87.0%    |     84.6%      |      81.96%      |  ## GERBIL evaluation Our GERBIL evaluation steps follow [here](https://github.com/dalab/end2end_neural_el), specifically: 1.","Use the above reader training scripts and set `--epochs` to be 0 for evaluation.  ### Reader Results  |   val `F1`  |  test `F1`  |  val `Recall` |  test `Recall` |  val `Precision`  |  test `Precision`  | |:-----------:|:-----------:|:-------------:|:--------------:|:-----------------:|:------------------:| |   87.32%  |   84.4%  |   90.23%    |    87.0%    |     84.6%      |      81.96%      |  ## `GERBIL` evaluation Our `GERBIL` evaluation steps follow [here](https://github.com/dalab/end2end_neural_el), specifically: 1.","Use the above reader training scripts and set `--epochs` to be 0 for evaluation.  ### Reader Results  |   val `<EVALMETRIC>F1</EVALMETRIC>`  |  test `<EVALMETRIC>F1</EVALMETRIC>`  |  val `<EVALMETRIC>Recall</EVALMETRIC>` |  test `<EVALMETRIC>Recall</EVALMETRIC>` |  val `<EVALMETRIC>Precision</EVALMETRIC>`  |  test `<EVALMETRIC>Precision</EVALMETRIC>`  | |:-----------:|:-----------:|:-------------:|:--------------:|:-----------------:|:------------------:| |   87.32%  |   84.4%  |   90.23%    |    87.0%    |     84.6%      |      81.96%      |  ## `<SOFTWARE>GERBIL</SOFTWARE>` evaluation Our `<SOFTWARE>GERBIL</SOFTWARE>` evaluation steps follow [here](https://github.com/dalab/end2end_neural_el), specifically: 1.",../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\069c0b70.txt,0.8961538461538462
26,usp=sharing) 2.,usp=sharing) 2.,usp=sharing) 3.,usp=sharing) 3.,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\fbba97df.txt,0.9333333333333333
29,On another terminal/screen run: ``` cd gerbil-SpotWrapNifWS4Test/ mvn clean -Dmaven.tomcat.port=1235 tomcat:run  ``` 4.,On another <SOFTWARE>terminal</SOFTWARE>/screen run: ``` cd gerbil-SpotWrapNifWS4Test/ mvn clean -Dmaven.tomcat.port=1235 tomcat:run  ``` 4.,```On another terminal/screen run: ``` cd gerbil-SpotWrapNifWS4Test/ mvn clean -Dmaven.tomcat.port=1235 tomcat:run  ``` 4.```,```On another terminal/screen run: ``` cd gerbil-SpotWrapNifWS4Test/ <PROGLANG>mvn</PROGLANG> clean -Dmaven.tomcat.port=1235 tomcat:run  ``` 4.```,../results/deepseek-chat/prompt-0/zzz_wenzhengzhang_entqa_main_README.md.tsv\ce34869e.txt,0.9754098360655737
