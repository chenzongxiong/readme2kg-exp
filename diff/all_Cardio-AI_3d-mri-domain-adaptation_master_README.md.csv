sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,# 3D CMR-Domain-Adaptation  This repo contains code to train a deep learning model for **Unsupervised Domain Adaptation (UDA)** of 3D cardiac magnetic resonance (CMR) cine images to **transform from axial to short-axis orientation**.,# <PROJECT>3D CMR-Domain-Adaptation</PROJECT>  This repo contains code to train a deep learning model for **Unsupervised Domain Adaptation (UDA)** of 3D cardiac magnetic resonance (CMR) cine images to **transform from axial to short-axis orientation**.,# 3D CMR-Domain-Adaptation This repo contains code to train a deep learning model for **Unsupervised Domain Adaptation (UDA)** of 3D cardiac magnetic resonance (CMR) cine images to **transform from axial to short-axis orientation**.,# <PROJECT>3D CMR-Domain-Adaptation</PROJECT> This repo contains code to train a deep learning model for **Unsupervised Domain Adaptation (UDA)** of 3D cardiac magnetic resonance (CMR) cine images to **transform from axial to short-axis orientation**.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6675849a.txt,0.9978494623655914
2,"The task associated to the domain adaptation is to perform a **segmentation task via a pre-trained fixed network**, and the results are leveraged to guide the transformation process (rigid transform via spatial transformer networks).","The task associated to the domain adaptation is to perform a **segmentation task via a pre-trained fixed network**, and the results are leveraged to guide the transformation process (rigid transform via spatial transformer networks).","The task associated to the domain adaptation is to perform a **segmentation task via a pre-trained fixed network**, and the results are leveraged to guide the transformation process (rigid transform via spatial transformer networks).","The task associated to the domain adaptation is to perform a **segmentation task via a pre-trained fixed network**, and the results are leveraged to guide the transformation process (rigid transform via spatial transformer networks).",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6e1a3d96.txt,1.0
3,The trained model is able to transform an axial (AX) CMR into the patient specific short-axis (SAX) direction.,The trained model is able to transform an axial (AX) CMR into the patient specific short-axis (SAX) direction.,The trained model is able to transform an axial (AX) CMR into the patient specific short-axis (SAX) direction.,The trained model is able to transform an axial (AX) CMR into the patient specific short-axis (SAX) direction.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\537ed903.txt,1.0
4,The model learns from paired AX/SAX CMR image pairs and a pre-trained SAX segmentation model.,The model learns from paired AX/SAX CMR image pairs and a pre-trained SAX segmentation model.,The model learns from paired AX/SAX CMR image pairs and a pre-trained SAX segmentation model.,The model learns from paired AX/SAX CMR image pairs and a pre-trained SAX segmentation model.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\bb7d4cfa.txt,1.0
5,The following gif exemplary visualizes the learning progress of this model.,The following gif exemplary visualizes the learning progress of this model.,The following gif exemplary visualizes the learning progress of this model.,The following gif exemplary visualizes the learning progress of this model.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\5517ac68.txt,1.0
6,Slices along z-direction are shown horizontally.   !,Slices along z-direction are shown horizontally.   !,Slices along z-direction are shown horizontally.   !,Slices along z-direction are shown horizontally.   !,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\39dd960f.txt,1.0
7,"[Unsupervised Domain adaptation learning](https://github.com/Cardio-AI/3d-mri-domain-adaption/blob/master/reports/ax_sax_learning_example.gif ""learning progress"")   Each temporal frame shows the AX2SAX prediction of the model after successive epochs.","[Unsupervised Domain adaptation learning](https://github.com/Cardio-AI/3d-mri-domain-adaption/blob/master/reports/ax_sax_learning_example.gif ""learning progress"")   Each temporal frame shows the AX2SAX prediction of the model after successive epochs.","`[Unsupervised Domain adaptation learning](https://github.com/Cardio-AI/3d-mri-domain-adaption/blob/master/reports/ax_sax_learning_example.gif ""learning progress"")   Each temporal frame shows the AX2SAX prediction of the model after successive epochs.`","`[<PROJECT>Unsupervised Domain adaptation learning</PROJECT>](https://github.com/<PROJECT>Cardio-AI</PROJECT>/<PROJECT>3d-mri-domain-adaption</PROJECT>/blob/master/reports/ax_sax_learning_example.gif ""learning progress"")   Each temporal frame shows the AX2SAX prediction of the model after successive epochs.`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6129b73d.txt,0.9960159362549801
8,"At the end of the learning process, the model is able to transform the data set such that it corresponds to a short-axis view, which can be segmented more reliably by the pre-trained short-axis segmentation module.","At the end of the learning process, the model is able to transform the data set such that it corresponds to a short-axis view, which can be segmented more reliably by the pre-trained short-axis segmentation module.","At the end of the learning process, the model is able to transform the `data set` such that it corresponds to a short-axis view, which can be segmented more reliably by the pre-trained short-axis segmentation module.","At the end of the learning process, the model is able to transform the `<DATASET>data set</DATASET>` such that it corresponds to a short-axis view, which can be segmented more reliably by the pre-trained short-axis segmentation module.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\683284c7.txt,0.958139534883721
9,"Finally the inverse transformation could be applied to the segmentation, which results in a automatically segmented AX CMR.","Finally the inverse transformation could be applied to the segmentation, which results in a automatically segmented AX CMR.","Finally the inverse transformation could be applied to the segmentation, which results in a automatically segmented AX CMR.","Finally the inverse transformation could be applied to the segmentation, which results in a automatically segmented AX CMR.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\4c98185b.txt,1.0
10,"For the training of this transformation model, neither AX nor SAX ground truth segmentations are required.","For the training of this transformation model, neither AX nor SAX ground truth segmentations are required.","For the training of this transformation model, neither AX nor SAX ground truth segmentations are required.","For the training of this transformation model, neither AX nor SAX ground truth segmentations are required.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\1d3be747.txt,1.0
11,A special **Euler2Affine Layer** was implemented to restrict the transform of the spatial transformer network to be rigid and invertible,A special **Euler2Affine Layer** was implemented to restrict the transform of the spatial transformer network to be rigid and invertible,A special Euler2Affine Layer was implemented to restrict the transform of the spatial transformer network to be rigid and invertible,A special <SOFTWARE>Euler2Affine Layer</SOFTWARE> was implemented to restrict the transform of the spatial transformer network to be rigid and invertible,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\f3f46aa6.txt,0.9850746268656716
12,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
13,# Overview  - The repository dependencies are saved as conda environment (environment.yaml) file,# Overview  - The repository dependencies are saved as <SOFTWARE>conda</SOFTWARE> environment (environment.yaml) file,# Overview  - The repository dependencies are saved as conda environment (environment.yaml) file,# Overview  - The repository dependencies are saved as conda environment (environment.yaml) file,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\acacc094.txt,1.0
14,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
15,- The Deep Learning models/layers are build with TF 2.X. - Setup instruction for the repository are given here: [Install requirements](https://github.com/Cardio-AI/3d-mri-domain-adaptation#setup-instructions-tested-with-osx-and-ubuntu) - An overview of all files and there usage is given here: [Repository Structure](https://github.com/Cardio-AI/3d-mri-domain-adaptation#repository-structure)  # Paper:  Please cite the following paper if you use/modify or adapt part of the code from this repository:  S.,- The Deep Learning models/layers are build with <SOFTWARE>TF 2.X</SOFTWARE>. - Setup instruction for the repository are given here: [Install requirements](https://github.com/Cardio-AI/<PROJECT>3d-mri-domain-adaptation</PROJECT>#setup-instructions-tested-with-osx-and-ubuntu) - An overview of all files and there usage is given here: [Repository Structure](https://github.com/Cardio-AI/3d-mri-domain-adaptation#repository-structure)  # Paper:  Please cite the following paper if you use/modify or adapt part of the code from this repository:  S.,- The Deep Learning models/layers are build with TF 2.X. - Setup instruction for the repository are given here: [Install requirements](https://github.com/Cardio-AI/3d-mri-domain-adaptation#setup-instructions-tested-with-osx-and-ubuntu) - An overview of all files and there usage is given here: [Repository Structure](https://github.com/Cardio-AI/3d-mri-domain-adaptation#repository-structure)  # Paper:  Please cite the following paper if you use/modify or adapt part of the code from this repository:  S.,- The Deep Learning models/layers are build with <PROGLANG>TF 2.X</PROGLANG>. - Setup instruction for the repository are given here: [Install requirements](https://github.com/<PROJECT>Cardio-AI</PROJECT>/3d-mri-domain-adaptation#setup-instructions-tested-with-osx-and-ubuntu) - An overview of all files and there usage is given here: [Repository Structure](https://github.com/<PROJECT>Cardio-AI</PROJECT>/3d-mri-domain-adaptation#repository-structure)  # Paper:  Please cite the following paper if you use/modify or adapt part of the code from this repository:  S.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\bf9943d4.txt,1.0
16,"Koehler, T.","Koehler, T.","`Koehler, T.`","`<PUBLICATION>Koehler, T.</PUBLICATION>`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\5217cae2.txt,0.9166666666666666
17,"Hussain, Z.","Hussain, Z.","Hussain, Z.","Hussain, Z.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\725ba0d3.txt,1.0
18,"Blair, T.","Blair, T.","Blair, T.","Blair, T.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\60523108.txt,1.0
19,"Huffaker, F.","Huffaker, F.","`Huffaker, F.`","`<PUBLICATION>Huffaker, F.</PUBLICATION>`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\f1c277d7.txt,0.9230769230769231
20,"Ritzmann, A.","Ritzmann, A.","`Ritzmann, A.`","`Ritzmann, A.`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\779757c6.txt,0.9230769230769231
21,"Tandon, T.","Tandon, T.","Tandon, T.","<PUBLICATION>Tandon, T.</PUBLICATION>",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\ffa3dbc0.txt,1.0
22,"Pickardt, S.","Pickardt, S.","Pickardt, S.","Pickardt, S.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\66db4d53.txt,1.0
23,"Sarikouch, H.","Sarikouch, H.","`Sarikouch, H.`","`Sarikouch, H.`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\adabc75f.txt,0.9285714285714286
24,"Latus, G.","Latus, G.","Latus, G.","<PUBLICATION>Latus, G.</PUBLICATION>",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\a093549e.txt,1.0
25,"Greil, I.","Greil, I.","Greil, I.","Greil, I.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\10259d8c.txt,1.0
26,"Wolf, S.","Wolf, S.","Wolf, S.","<PUBLICATION>Wolf, S.</PUBLICATION>",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\2bf600c5.txt,1.0
27,"Engelhardt, ""Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks,"" in IEEE Transactions on Medical Imaging (TMI), early access, doi: 10.1109/TMI.2021.3052972","Engelhardt, ""<PUBLICATION>Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks</PUBLICATION>,"" in <PUBLICATION>IEEE Transactions on Medical Imaging</PUBLICATION> (<PUBLICATION>TMI</PUBLICATION>), early access, doi: 10.1109/<PUBLICATION>TMI</PUBLICATION>.2021.3052972","Engelhardt, ""Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks,"" in IEEE Transactions on Medical Imaging (TMI), early access, doi: 10.1109/TMI.2021.3052972","Engelhardt, ""<PUBLICATION>Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks</PUBLICATION>,"" in <PUBLICATION>IEEE Transactions on Medical Imaging (TMI)</PUBLICATION>, early access, doi: 10.1109/TMI.2021.3052972",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6f977e20.txt,1.0
28,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
29,"- Link to original paper: [IEEE TMI paper link](https://ieeexplore.ieee.org/document/9328840) (accepted 13.1.2021) - A pre-print version is available here: [arxiv-Preprint](http://arxiv.org/abs/2101.07653)  Bibtex:  >@article{Koehler_2021, <br> >   title={Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks},<br> >   ISSN={1558-254X},<br> >   url={http://dx.doi.org/10.1109/TMI.2021.3052972},<br> >   DOI={10.1109/tmi.2021.3052972},<br> >   journal={IEEE Transactions on Medical Imaging},<br> >   publisher={Institute of Electrical and Electronics Engineers (IEEE)},<br> >   author={Koehler, Sven and Hussain, Tarique and Blair, Zach and Huffaker, Tyler and Ritzmann, Florian and Tandon, Animesh and Pickardt, Thomas and Sarikouch, Samir and Sarikouch, Samir and Latus, Heiner and Greil, Gerald and Wolf, Ivo and Engelhardt, Sandy}, >   year={2021},<br> >   pages={1–1}<br> >}   # Institutions:  >- [Heidelberg University Hospital, Artificial Intelligence in Cardiovascular Medicine (AICM) Group](https://www.klinikum.uni-heidelberg.de/chirurgische-klinik-zentrum/herzchirurgie/forschung/ag-artificial-intelligence-in-cardiovascular-medicine) >- [German Competence network for Congenital heart defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/) >- [UT Southwestern Medical Center, Pediatric Cardiology](https://www.utsouthwestern.edu/education/medical-school/departments/pediatrics/divisions/cardiology/) >- [Department of Computer Science, University Of Applied Science Mannheim](https://www.informatik.hs-mannheim.de/wir/menschen/professoren/prof-dr-ivo-wolf.html)   # How to use:  This repository splits the source code into:  - interactive notebooks (/notebooks),  - python source modules (/src) and  - the experiment related files such as the experiment configs (/reports) or trained models (/models).","- Link to original paper: [<PUBLICATION>IEEE TMI</PUBLICATION> paper link](https://ieeexplore.ieee.org/document/9328840) (accepted 13.1.2021) - A pre-print version is available here: [arxiv-Preprint](http://arxiv.org/abs/2101.07653)  Bibtex:  >@article{Koehler_2021, <br> >   title={<PUBLICATION>Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks</PUBLICATION>},<br> >   ISSN={1558-254X},<br> >   url={http://dx.doi.org/10.1109/<PUBLICATION>TMI</PUBLICATION>.2021.3052972},<br> >   DOI={10.1109/tmi.2021.3052972},<br> >   journal={<PUBLICATION>IEEE Transactions on Medical Imaging</PUBLICATION>},<br> >   publisher={Institute of Electrical and Electronics Engineers (IEEE)},<br> >   author={Koehler, Sven and Hussain, Tarique and Blair, Zach and Huffaker, Tyler and Ritzmann, Florian and Tandon, Animesh and Pickardt, Thomas and Sarikouch, Samir and Sarikouch, Samir and Latus, Heiner and Greil, Gerald and Wolf, Ivo and Engelhardt, Sandy}, >   year={2021},<br> >   pages={1–1}<br> >}   # Institutions:  >- [Heidelberg University Hospital, Artificial Intelligence in Cardiovascular Medicine (AICM) Group](https://www.klinikum.uni-heidelberg.de/chirurgische-klinik-zentrum/herzchirurgie/forschung/ag-artificial-intelligence-in-cardiovascular-medicine) >- [German Competence network for Congenital heart defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/) >- [UT Southwestern Medical Center, Pediatric Cardiology](https://www.utsouthwestern.edu/education/medical-school/departments/pediatrics/divisions/cardiology/) >- [Department of Computer Science, University Of Applied Science Mannheim](https://www.informatik.hs-mannheim.de/wir/menschen/professoren/prof-dr-ivo-wolf.html)   # How to use:  This repository splits the source code into:  - interactive notebooks (/notebooks),  - <SOFTWARE>python</SOFTWARE> source modules (/src) and  - the experiment related files such as the experiment configs (/reports) or trained models (/models).","- Link to original paper: [IEEE TMI paper link](https://ieeexplore.ieee.org/document/9328840) (accepted 13.1.2021) - A pre-print version is available here: [arxiv-Preprint](http://arxiv.org/abs/2101.07653)  Bibtex:  >@article{Koehler_2021, <br> >   title={Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks},<br> >   ISSN={1558-254X},<br> >   url={http://dx.doi.org/10.1109/TMI.2021.3052972},<br> >   DOI={10.1109/tmi.2021.3052972},<br> >   journal={IEEE Transactions on Medical Imaging},<br> >   publisher={Institute of Electrical and Electronics Engineers (IEEE)},<br> >   author={Koehler, Sven and Hussain, Tarique and Blair, Zach and Huffaker, Tyler and Ritzmann, Florian and Tandon, Animesh and Pickardt, Thomas and Sarikouch, Samir and Sarikouch, Samir and Latus, Heiner and Greil, Gerald and Wolf, Ivo and Engelhardt, Sandy}, >   year={2021},<br> >   pages={1–1}<br> >}   # Institutions:  >- [Heidelberg University Hospital, Artificial Intelligence in Cardiovascular Medicine (AICM) Group](https://www.klinikum.uni-heidelberg.de/chirurgische-klinik-zentrum/herzchirurgie/forschung/ag-artificial-intelligence-in-cardiovascular-medicine) >- [German Competence network for Congenital heart defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/) >- [UT Southwestern Medical Center, Pediatric Cardiology](https://www.utsouthwestern.edu/education/medical-school/departments/pediatrics/divisions/cardiology/) >- [Department of Computer Science, University Of Applied Science Mannheim](https://www.informatik.hs-mannheim.de/wir/menschen/professoren/prof-dr-ivo-wolf.html)   # How to use:  This repository splits the source code into:  - interactive notebooks (/notebooks),  - python source modules (/src) and  - the experiment related files such as the experiment configs (/reports) or trained models (/models).","- Link to original paper: [<PUBLICATION>IEEE TMI paper</PUBLICATION> link](https://ieeexplore.ieee.org/document/9328840) (accepted 13.1.2021) - A pre-print version is available here: [<PUBLICATION>arxiv-Preprint</PUBLICATION>](http://arxiv.org/abs/2101.07653)  Bibtex:  >@article{Koehler_2021, <br> >   title={Unsupervised Domain Adaptation from Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks},<br> >   ISSN={1558-254X},<br> >   url={http://dx.doi.org/10.1109/TMI.2021.3052972},<br> >   DOI={10.1109/tmi.2021.3052972},<br> >   journal={<PUBLICATION>IEEE Transactions on Medical Imaging</PUBLICATION>},<br> >   publisher={<PROJECT>Institute of Electrical and Electronics Engineers (IEEE)</PROJECT>},<br> >   author={Koehler, Sven and Hussain, Tarique and Blair, Zach and Huffaker, Tyler and Ritzmann, Florian and Tandon, Animesh and Pickardt, Thomas and Sarikouch, Samir and Sarikouch, Samir and Latus, Heiner and Greil, Gerald and Wolf, Ivo and Engelhardt, Sandy}, >   year={2021},<br> >   pages={1–1}<br> >}   # Institutions:  >- [<PROJECT>Heidelberg University Hospital, Artificial Intelligence in Cardiovascular Medicine (AICM) Group</PROJECT>](https://www.klinikum.uni-heidelberg.de/chirurgische-klinik-zentrum/herzchirurgie/forschung/ag-artificial-intelligence-in-cardiovascular-medicine) >- [<PROJECT>German Competence network for Congenital heart defects</PROJECT>](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/) >- [<PROJECT>UT Southwestern Medical Center, Pediatric Cardiology</PROJECT>](https://www.utsouthwestern.edu/education/medical-school/departments/pediatrics/divisions/cardiology/) >- [<PROJECT>Department of Computer Science, University Of Applied Science Mannheim</PROJECT>](https://www.informatik.hs-mannheim.de/wir/menschen/professoren/prof-dr-ivo-wolf.html)   # How to use:  This repository splits the source code into:  - interactive notebooks (/notebooks),  - <PROGLANG>python</PROGLANG> source modules (/src) and  - the experiment related files such as the experiment configs (/reports) or trained models (/models).",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\08aeb255.txt,1.0
30,"Each experiment includes the following artefacts: - One config file, which represents all experimental hyper-parameters which are neccessary to reproduce the experiment or to load it for later predictions - Three tensorboard logfiles per training to keep track of the trainings, evaluation and visual output progress","Each experiment includes the following artefacts: - One config file, which represents all experimental hyper-parameters which are neccessary to reproduce the experiment or to load it for later predictions - Three <SOFTWARE>tensorboard</SOFTWARE> logfiles per training to keep track of the trainings, evaluation and visual output progress","Each experiment includes the following artefacts: - One config file, which represents all experimental hyper-parameters which are neccessary to reproduce the experiment or to load it for later predictions - Three `tensorboard` logfiles per training to keep track of the trainings, evaluation and visual output progress","Each experiment includes the following artefacts: - One config file, which represents all experimental hyper-parameters which are neccessary to reproduce the experiment or to load it for later predictions - Three `<SOFTWARE>tensorboard</SOFTWARE>` logfiles per training to keep track of the trainings, evaluation and visual output progress",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\08f2c19a.txt,0.9968454258675079
31,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
32,- One dataframe which orchestrates the nrrd files with the metadata and the experiment splitting,- One dataframe which orchestrates the nrrd files with the metadata and the experiment splitting,- One dataframe which orchestrates the `nrrd` files with the metadata and the experiment splitting,- One dataframe which orchestrates the `<DATASET>nrrd</DATASET>` files with the metadata and the experiment splitting,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\3685e47e.txt,0.9896907216494846
33,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
34,- Model graph description either as json or tensorflow protobuf file and the corresponding model weights as h5 file.,- Model graph description either as json or <SOFTWARE>tensorflow</SOFTWARE> protobuf file and the corresponding model weights as h5 file.,- Model graph description either as `json` or `tensorflow` protobuf file and the corresponding model weights as `h5` file.,- Model graph description either as `<PROGLANG>json</PROGLANG>` or `<PROGLANG>tensorflow</PROGLANG>` protobuf file and the corresponding model weights as `<PROGLANG>h5</PROGLANG>` file.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\546dc695.txt,0.9747899159663865
35,The tensorflow model and layer definitions are within /src/models.,The <SOFTWARE>tensorflow</SOFTWARE> model and layer definitions are within /src/models.,The tensorflow model and layer definitions are within /src/models.,The <SOFTWARE>tensorflow</SOFTWARE> model and layer definitions are within /src/models.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\e8c06960.txt,1.0
36,"The transformation layer is built on the neuron project, which is also part of the current Voxelmorph approach (https://github.com/voxelmorph/voxelmorph).","The transformation layer is built on the <PROJECT>neuron</PROJECT> project, which is also part of the current Voxelmorph approach (https://github.com/voxelmorph/voxelmorph).","The transformation layer is built on the `neuron` project, which is also part of the current `Voxelmorph` approach (https://github.com/voxelmorph/voxelmorph).","The transformation layer is built on the `<PROJECT>neuron</PROJECT>` project, which is also part of the current `<SOFTWARE>Voxelmorph</SOFTWARE>` approach (https://github.com/<SOFTWARE>voxelmorph</SOFTWARE>/<SOFTWARE>voxelmorph</SOFTWARE>).",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\2eb2d8b9.txt,0.9871794871794872
37,"Use the Notebooks to interact (train, predict or evaluate) with the python functions.   ## Repository Structure      ├── LICENSE     ├── Makefile           <- Makefile with commands like 'make environment'     ├── README.md          <- The top-level README for developers using this project.     ├── data     │   ├── metadata       <- Excel and csv files with additional metadata are stored here     │   ├── interim        <- Intermediate data that has been transformed","Use the Notebooks to interact (train, predict or evaluate) with the python functions.   ## Repository Structure      ├── LICENSE     ├── Makefile           <- Makefile with commands like 'make environment'     ├── README.md          <- The top-level README for developers using this project.     ├── data     │   ├── metadata       <- Excel and csv files with additional metadata are stored here     │   ├── interim        <- Intermediate data that has been transformed","Use the Notebooks to interact (train, predict or evaluate) with the python functions.   ## Repository Structure      ├── LICENSE     ├── Makefile           <- Makefile with commands like 'make environment'     ├── README.md          <- The top-level README for developers using this project.     ├── data     │   ├── metadata       <- Excel and csv files with additional metadata are stored here     │   ├── interim        <- Intermediate data that has been transformed","Use the Notebooks to interact (train, predict or evaluate) with the <PROGLANG>python</PROGLANG> functions.   ## Repository Structure      ├── <LICENSE>LICENSE</LICENSE>     ├── Makefile           <- Makefile with commands like 'make environment'     ├── README.md          <- The top-level README for developers using this project.     ├── data     │   ├── metadata       <- Excel and csv files with additional metadata are stored here     │   ├── interim        <- Intermediate data that has been transformed",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\904cb03a.txt,1.0
38,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
39,"│   ├── predicted      <- Model predictions, will be used for the evaluation scripts     │   └── raw            <- The original, immutable data dump","│   ├── predicted      <- Model predictions, will be used for the evaluation scripts     │   └── raw            <- The original, immutable data dump","│   ├── predicted      <- Model predictions, will be used for the evaluation scripts     │   └── raw            <- The original, immutable data dump","│   ├── predicted      <- Model predictions, will be used for the evaluation scripts     │   └── raw            <- The original, immutable data dump",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\47c4e6e4.txt,1.0
40,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
41,│     ├── models             <- Trained and serialized model definitions and weights     │     ├── notebooks          <- Jupyter notebooks,│     ├── models             <- Trained and serialized model definitions and weights     │     ├── notebooks          <- Jupyter notebooks,│     ├── models             <- Trained and serialized model definitions and weights     │     ├── Jupyter notebooks,│     ├── models             <- Trained and serialized model definitions and weights     │     ├── <PROGLANG>Jupyter</PROGLANG> notebooks,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cb213373.txt,0.9133858267716536
42,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
43,"│   ├── Dataset        <- Create, map, split or pre-process the dataset     │   ├── Evaluate       <- Evaluate the model predictions, create dataframes and plots     │   ├── Predict        <- Load an experiment config and a pre-trained model,      │   │                     transform AX CMR into the SAX domain, apply the task network,      │   │                     transform the predicted mask back into the AX domain,      │   │                     undo the generator steps and save the prediction to disk        │   └── Train          <- Inspect the generators, define an experiment config,     │                              load and inject a task network, build the graph and train a new AX2SAX model     │     ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc","│   ├── Dataset        <- Create, map, split or pre-process the dataset     │   ├── Evaluate       <- Evaluate the model predictions, create dataframes and plots     │   ├── Predict        <- Load an experiment config and a pre-trained model,      │   │                     transform AX CMR into the SAX domain, apply the task network,      │   │                     transform the predicted mask back into the AX domain,      │   │                     undo the generator steps and save the prediction to disk        │   └── Train          <- Inspect the generators, define an experiment config,     │                              load and inject a task network, build the graph and train a new AX2SAX model     │     ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc","│   ├── Dataset        <- Create, map, split or pre-process the dataset     │   ├── Evaluate       <- Evaluate the model predictions, create dataframes and plots     │   ├── Predict        <- Load an experiment config and a pre-trained model,      │   │                     transform AX CMR into the SAX domain, apply the task network,      │   │                     transform the predicted mask back into the AX domain,      │   │                     undo the generator steps and save the prediction to disk        │   └── Train          <- Inspect the generators, define an experiment config,     │                              load and inject a task network, build the graph and train a new AX2SAX model     │     ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc","│   ├── <DATASET>Dataset</DATASET>        <- Create, map, split or pre-process the <DATASET>dataset</DATASET>     │   ├── Evaluate       <- Evaluate the model predictions, create dataframes and plots     │   ├── Predict        <- Load an experiment config and a pre-trained model,      │   │                     transform AX CMR into the SAX domain, apply the task network,      │   │                     transform the predicted mask back into the AX domain,      │   │                     undo the generator steps and save the prediction to disk        │   └── Train          <- Inspect the generators, define an experiment config,     │                              load and inject a task network, build the graph and train a new AX2SAX model     │     ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\473b31e3.txt,1.0
44,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
45,│   ├── configs        <- Experiment config files as json with all hyperparameters and paths     │   ├── figures        <- Generated graphics and figures to be used in reporting     │   ├── history        <- Tensorboard trainings history files     │   └── tensorboard_logs  <- Trainings-scalars and images of the intermediate predictions     │     ├── environment.yaml   <- Conda requirements file.,│   ├── configs        <- Experiment config files as json with all hyperparameters and paths     │   ├── figures        <- Generated graphics and figures to be used in reporting     │   ├── history        <- <SOFTWARE>Tensorboard</SOFTWARE> trainings history files     │   └── <SOFTWARE>tensorboard</SOFTWARE>_logs  <- Trainings-scalars and images of the intermediate predictions     │     ├── environment.yaml   <- Conda requirements file.,│   ├── configs        <- Experiment config files as json with all hyperparameters and paths     │   ├── figures        <- Generated graphics and figures to be used in reporting     │   ├── history        <- Tensorboard trainings history files     │   └── tensorboard_logs  <- Trainings-scalars and images of the intermediate predictions     │     ├── environment.yaml   <- Conda requirements file.,│   ├── configs        <- Experiment config files as json with all hyperparameters and paths     │   ├── figures        <- Generated graphics and figures to be used in reporting     │   ├── history        <- Tensorboard trainings history files     │   └── tensorboard_logs  <- Trainings-scalars and images of the intermediate predictions     │     ├── <SOFTWARE>environment.yaml</SOFTWARE>   <- Conda requirements file.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\5fa351bc.txt,1.0
46,"Generated with `conda env export > environment.yml`     │     ├── setup.py           <- Makes project pip installable (pip install -e .) so src can be imported     ├── src                <- Python modules with classes and functions that will be orchestrated in the notebooks.         ├── data           <- Python modules - Generators, preprocess and postprocess functions         ├── models         <- Python modules - TF.keras 2.X Model and Layer definition         ├── utils          <- Python modules - Metrics, losses, prediction, evaluation code, TF-callbacks and io-utils         └── visualization  <- Python modules - Plot functions for the evaluation and data description  ## Dataset For this work a multi-centric heterogeneous cine-SSFPs CMR TOF data set from the [German Competence Network for Congenital Heart Defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/)) was used (study identifier: NCT00266188, title: Non-invasive Imaging and Exercise Tolerance Tests in Post-repair Tetralogy of Fallot -Intervention and Course in Patients Over 8 Years Old).","Generated with `conda env export > environment.yml`     │     ├── setup.py           <- Makes project pip installable (pip install -e .) so src can be imported     ├── src                <- <PROGLANG>Python</PROGLANG> modules with classes and functions that will be orchestrated in the notebooks.         ├── data           <- <PROGLANG>Python</PROGLANG> modules - Generators, preprocess and postprocess functions         ├── models         <- <PROGLANG>Python</PROGLANG> modules - TF.keras 2.X Model and Layer definition         ├── utils          <- <PROGLANG>Python</PROGLANG> modules - Metrics, losses, prediction, evaluation code, TF-callbacks and io-utils         └── visualization  <- <PROGLANG>Python</PROGLANG> modules - Plot functions for the evaluation and data description  ## Dataset For this work a <DATASET>multi-centric heterogeneous cine-SSFPs CMR TOF</DATASET> data set from the [German Competence Network for Congenital Heart Defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/)) was used (study identifier: NCT00266188, title: <PUBLICATION>Non-invasive Imaging and Exercise Tolerance Tests in Post-repair Tetralogy of Fallot -Intervention and Course in Patients Over 8 Years Old</PUBLICATION>).","Generated with `conda env export > environment.yml`     │     ├── setup.py           <- Makes project pip installable (pip install -e .) so src can be imported     ├── src                <- Python modules with classes and functions that will be orchestrated in the notebooks.         ├── data           <- Python modules - Generators, preprocess and postprocess functions         ├── models         <- Python modules - TF.keras 2.X Model and Layer definition         ├── utils          <- Python modules - Metrics, losses, prediction, evaluation code, TF-callbacks and io-utils         └── visualization  <- Python modules - Plot functions for the evaluation and data description  ## Dataset For this work a multi-centric heterogeneous cine-SSFPs CMR TOF data set from the [German Competence Network for Congenital Heart Defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/)) was used (study identifier: NCT00266188, title: Non-invasive Imaging and Exercise Tolerance Tests in Post-repair Tetralogy of Fallot -Intervention and Course in Patients Over 8 Years Old).","Generated with `<PROGLANG>conda</PROGLANG> env export > environment.yml`     │     ├── setup.py           <- Makes project pip installable (pip install -e .) so src can be imported     ├── src                <- <PROGLANG>Python</PROGLANG> modules with classes and functions that will be orchestrated in the notebooks.         ├── data           <- <PROGLANG>Python</PROGLANG> modules - Generators, preprocess and postprocess functions         ├── models         <- <PROGLANG>Python</PROGLANG> modules - TF.keras 2.X Model and Layer definition         ├── utils          <- <PROGLANG>Python</PROGLANG> modules - Metrics, losses, prediction, evaluation code, TF-callbacks and io-utils         └── visualization  <- <PROGLANG>Python</PROGLANG> modules - Plot functions for the evaluation and data description  ## <DATASET>Dataset</DATASET> For this work a multi-centric heterogeneous cine-SSFPs CMR TOF <DATASET>data set</DATASET> from the [German Competence Network for Congenital Heart Defects](https://www.kompetenznetz-ahf.de/en/about-us/competence-network/)) was used (study identifier: NCT00266188, title: Non-invasive Imaging and Exercise Tolerance Tests in Post-repair Tetralogy of Fallot -Intervention and Course in Patients Over 8 Years Old).",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\74acd026.txt,1.0
47,This TOF dataset constitutes one of the largest compiled data set of this pathology to date.,This <DATASET>TOF</DATASET> dataset constitutes one of the largest compiled data set of this pathology to date.,This TOF dataset constitutes one of the largest compiled data set of this pathology to date.,This <DATASET>TOF</DATASET> dataset constitutes one of the largest compiled data set of this pathology to date.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\02e9ab6d.txt,1.0
48,"The data was acquired at 14 different German sites between 2005-2008 on 1.5T and 3T machines;  further descriptions can be found in [original study](https://www.ahajournals.org/doi/epub/10.1161/CIRCIMAGING.111.963637), [eprint previous work](https://arxiv.org/abs/2002.04392) [1],[2]","The data was acquired at 14 different German sites between 2005-2008 on 1.5T and 3T machines;  further descriptions can be found in [original study](https://www.ahajournals.org/doi/epub/10.1161/CIRCIMAGING.111.963637), [eprint previous work](https://arxiv.org/abs/2002.04392) [1],[2]","The data was acquired at 14 different German sites between 2005-2008 on 1.5T and 3T machines;  further descriptions can be found in [original study](https://www.ahajournals.org/doi/epub/10.1161/CIRCIMAGING.111.963637), [eprint previous work](https://arxiv.org/abs/2002.04392) [1],[2]","The data was acquired at 14 different German sites between 2005-2008 on 1.5T and 3T machines;  further descriptions can be found in [original study](https://www.ahajournals.org/doi/epub/10.1161/CIRCIMAGING.111.963637), [<PUBLICATION>eprint previous work</PUBLICATION>](https://arxiv.org/abs/2002.04392) [1],[2]",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\f64ed439.txt,1.0
49,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
50,"[1] Sarikouch S, Koerperich H, Dubowy KO, Boethig D, Boettler P, Mir TS, Peters B, Kuehne T, Beerbaum P; German Competence Network for Congenital Heart Defects Investigators.","[1] Sarikouch S, Koerperich H, Dubowy KO, Boethig D, Boettler P, Mir TS, Peters B, Kuehne T, Beerbaum P; German Competence Network for Congenital Heart Defects Investigators.","[1] Sarikouch S, Koerperich H, Dubowy KO, Boethig D, Boettler P, Mir TS, Peters B, Kuehne T, Beerbaum P; `German Competence Network for Congenital Heart Defects Investigators`.","[1] Sarikouch S, Koerperich H, Dubowy KO, Boethig D, Boettler P, Mir TS, Peters B, Kuehne T, Beerbaum P; `<PROJECT>German Competence Network for Congenital Heart Defects Investigators</PROJECT>`.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\9a8d4e4b.txt,0.9942857142857143
51,Impact of gender and age on cardiovascular function late after repair of tetralogy of Fallot: percentiles based on cardiac magnetic resonance.,<PUBLICATION>Impact of gender and age on cardiovascular function late after repair of tetralogy of Fallot: percentiles based on cardiac magnetic resonance</PUBLICATION>.,"`Impact of gender and age on cardiovascular function late after repair of tetralogy of Fallot: percentiles based on cardiac magnetic resonance.`  

*Note: No entities were identified in the given text based on the provided guidelines.*","`Impact of gender and age on cardiovascular function late after repair of tetralogy of Fallot: percentiles based on cardiac magnetic resonance.`  

*Note: No entities were identified in the given text based on the provided guidelines.*",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\2be9e8fa.txt,0.753315649867374
52,Circ Cardiovasc Imaging. 2011 Nov;4(6):703-11. doi: 10.1161/CIRCIMAGING.111.963637.,Circ Cardiovasc Imaging. 2011 Nov;4(6):703-11. doi: 10.1161/CIRCIMAGING.111.963637.,`Circ Cardiovasc Imaging. 2011 Nov;4(6):703-11. doi: 10.1161/CIRCIMAGING.111.963637.`,`<PUBLICATION>Circ Cardiovasc Imaging</PUBLICATION>. 2011 Nov;4(6):703-11. doi: 10.1161/CIRCIMAGING.111.963637.`,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\964433dc.txt,0.9880952380952381
53,Epub 2011 Sep 9.,Epub 2011 Sep 9.,`Epub 2011 Sep 9.`,`Epub 2011 Sep 9.`,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6f8882f0.txt,0.9411764705882353
54,PMID: 21908707,PMID: 21908707,PMID: 21908707,PMID: 21908707,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\675188fa.txt,1.0
55,.,.,.,.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\cdb4ee2a.txt,1.0
56,"[2] Köhler, Sven, Animesh Tandon, Tarique Hussain, H.","[2] Köhler, Sven, Animesh Tandon, Tarique Hussain, H.","[2] Köhler, Sven, Animesh Tandon, Tarique Hussain, H.","[2] Köhler, Sven, Animesh Tandon, Tarique Hussain, H.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\aca1d230.txt,1.0
57,"Latus, T.","Latus, T.","`Latus, T.`","`Latus, T.`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\0ec9e760.txt,0.9
58,"Pickardt, S.","Pickardt, S.","Pickardt, S.","Pickardt, S.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\66db4d53.txt,1.0
59,"Sarikouch, P.","Sarikouch, P.","`Sarikouch, P.`","`Sarikouch, P.`",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\a1371164.txt,0.9285714285714286
60,"Beerbaum, G.","Beerbaum, G.","Beerbaum, G.","Beerbaum, G.",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\6fdca1a8.txt,1.0
61,"Greil, S.","Greil, S.","Greil, S.","<PUBLICATION>Greil, S.</PUBLICATION>",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\f53682ca.txt,1.0
62,Engelhardt and Ivo Wolf.,Engelhardt and Ivo Wolf.,Engelhardt and Ivo Wolf.,Engelhardt and Ivo Wolf.,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\83aebb96.txt,1.0
63,“How well do U-Net-based segmentation trained on adult cardiac magnetic resonance imaging data generalise to rare congenital heart diseases for surgical planning?”,“<PUBLICATION>How well do U-Net-based segmentation trained on adult cardiac magnetic resonance imaging data generalise to rare congenital heart diseases for surgical planning?</PUBLICATION>”,“How well do U-Net-based segmentation trained on adult cardiac magnetic resonance imaging data generalise to rare congenital heart diseases for surgical planning?”,“How well do <SOFTWARE>U-Net</SOFTWARE>-based segmentation trained on adult cardiac magnetic resonance imaging data generalise to rare congenital heart diseases for surgical planning?”,../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\23222a70.txt,1.0
64,"Medical Imaging: Image-Guided Procedures (2020).  ## Setup instructions (Ubuntu)  ### Preconditions:  - Python 3.6 locally installed  (e.g.:  <a target=""_blank"" href=""https://www.anaconda.com/download/#macos"">Anaconda</a>) - Installed nvidia drivers, cuda and cudnn  (e.g.:  <a target=""_blank"" href=""https://www.tensorflow.org/install/gpu"">Tensorflow</a>)  ### Local setup Clone repository ``` git clone %repo-name% cd %repo-name% ``` Create a conda environment from environment.yaml (environment name will be ax2sax) ``` conda env create --file environment.yaml ```  Activate environment ``` conda activate ax2sax ``` Install a helper to automatically change the working directory to the project root directory ``` pip install --extra-index-url https://test.pypi.org/simple/ ProjectRoot ``` Create a jupyter kernel from the activated environment, this kernel will be visible in the jupyter lab ``` python -m ipykernel install --user --name ax2sax --display-name ""ax2sax kernel"" ```   ### Enable interactive widgets in Jupyterlab  Pre-condition: nodejs installed globally or into the conda environment. e.g.: ``` conda install -c conda-forge nodejs ``` Install the jupyterlab-manager which enables the use of interactive widgets ``` jupyter labextension install @jupyter-widgets/jupyterlab-manager ```  Further infos on how to enable the jupyterlab-extensions: [JupyterLab](https://ipywidgets.readthedocs.io/en/latest/user_install.html#installing-the-jupyterlab-extension)","Medical Imaging: Image-Guided Procedures (2020).  ## Setup instructions (Ubuntu)  ### Preconditions:  - <SOFTWARE>Python 3.6</SOFTWARE> locally installed  (e.g.:  <a target=""_blank"" href=""https://www.<SOFTWARE>anaconda</SOFTWARE>.com/download/#macos""><SOFTWARE>Anaconda</SOFTWARE></a>) - Installed <SOFTWARE>nvidia drivers</SOFTWARE>, <SOFTWARE>cuda</SOFTWARE> and <SOFTWARE>cudnn</SOFTWARE>  (e.g.:  <a target=""_blank"" href=""https://www.<SOFTWARE>tensorflow</SOFTWARE>.org/install/gpu""><SOFTWARE>Tensorflow</SOFTWARE></a>)  ### Local setup Clone repository ``` <SOFTWARE>git</SOFTWARE> clone %repo-name% cd %repo-name% ``` Create a <SOFTWARE>conda</SOFTWARE> environment from environment.yaml (environment name will be ax2sax) ``` <SOFTWARE>conda</SOFTWARE> env create --file environment.yaml ```  Activate environment ``` <SOFTWARE>conda</SOFTWARE> activate ax2sax ``` Install a helper to automatically change the working directory to the project root directory ``` <SOFTWARE>pip</SOFTWARE> install --extra-index-url https://test.pypi.org/simple/ ProjectRoot ``` Create a jupyter kernel from the activated environment, this kernel will be visible in the <SOFTWARE>jupyter lab</SOFTWARE> ``` <SOFTWARE>python</SOFTWARE> -m ipykernel install --user --name ax2sax --display-name ""ax2sax kernel"" ```   ### Enable interactive widgets in Jupyterlab  Pre-condition: <SOFTWARE>nodejs</SOFTWARE> installed globally or into the <SOFTWARE>conda</SOFTWARE> environment. e.g.: ``` <SOFTWARE>conda</SOFTWARE> install -c conda-forge <SOFTWARE>nodejs</SOFTWARE> ``` Install the <SOFTWARE>jupyterlab-manager</SOFTWARE> which enables the use of interactive widgets ``` <SOFTWARE>jupyter</SOFTWARE> labextension install @<SOFTWARE>jupyter-widgets/jupyterlab-manager</SOFTWARE> ```  Further infos on how to enable the <SOFTWARE>jupyterlab</SOFTWARE>-extensions: [<SOFTWARE>JupyterLab</SOFTWARE>](https://ipywidgets.readthedocs.io/en/latest/user_install.html#installing-the-<SOFTWARE>jupyterlab</SOFTWARE>-extension)","Medical Imaging: Image-Guided Procedures (2020).  ## Setup instructions (Ubuntu)  ### Preconditions:  - Python 3.6 locally installed  (e.g.:  <a target=""_blank"" href=""https://www.anaconda.com/download/#macos"">Anaconda</a>) - Installed nvidia drivers, cuda and cudnn  (e.g.:  <a target=""_blank"" href=""https://www.tensorflow.org/install/gpu"">Tensorflow</a>)  ### Local setup Clone repository ``` git clone %repo-name% cd %repo-name% ``` Create a conda environment from environment.yaml (environment name will be ax2sax) ``` conda env create --file environment.yaml ```  Activate environment ``` conda activate ax2sax ``` Install a helper to automatically change the working directory to the project root directory ``` pip install --extra-index-url https://test.pypi.org/simple/ ProjectRoot ``` Create a jupyter kernel from the activated environment, this kernel will be visible in the jupyter lab ``` python -m ipykernel install --user --name ax2sax --display-name ""ax2sax kernel"" ```   ### Enable interactive widgets in Jupyterlab  Pre-condition: nodejs installed globally or into the conda environment. e.g.: ``` conda install -c conda-forge nodejs ``` Install the jupyterlab-manager which enables the use of interactive widgets ``` jupyter labextension install @jupyter-widgets/jupyterlab-manager ```  Further infos on how to enable the jupyterlab-extensions: [JupyterLab](https://ipywidgets.readthedocs.io/en/latest/user_install.html#installing-the-jupyterlab-extension)","<PUBLICATION>Medical Imaging: Image-Guided Procedures (2020)</PUBLICATION>.  ## Setup instructions (Ubuntu)  ### Preconditions:  - <PROGLANG>Python 3.6</PROGLANG> locally installed  (e.g.:  <a target=""_blank"" href=""https://www.anaconda.com/download/#macos""><SOFTWARE>Anaconda</SOFTWARE></a>) - Installed nvidia drivers, cuda and cudnn  (e.g.:  <a target=""_blank"" href=""https://www.tensorflow.org/install/gpu""><SOFTWARE>Tensorflow</SOFTWARE></a>)  ### Local setup Clone repository ``` git clone %repo-name% cd %repo-name% ``` Create a conda environment from environment.yaml (environment name will be ax2sax) ``` conda env create --file environment.yaml ```  Activate environment ``` conda activate ax2sax ``` Install a helper to automatically change the working directory to the project root directory ``` pip install --extra-index-url https://test.pypi.org/simple/ <SOFTWARE>ProjectRoot</SOFTWARE> ``` Create a jupyter kernel from the activated environment, this kernel will be visible in the jupyter lab ``` python -m ipykernel install --user --name ax2sax --display-name ""ax2sax kernel"" ```   ### Enable interactive widgets in Jupyterlab  Pre-condition: <SOFTWARE>nodejs</SOFTWARE> installed globally or into the conda environment. e.g.: ``` conda install -c conda-forge <SOFTWARE>nodejs</SOFTWARE> ``` Install the jupyterlab-manager which enables the use of interactive widgets ``` jupyter labextension install @jupyter-widgets/jupyterlab-manager ```  Further infos on how to enable the jupyterlab-extensions: [<SOFTWARE>JupyterLab</SOFTWARE>](https://ipywidgets.readthedocs.io/en/latest/user_install.html#installing-the-jupyterlab-extension)",../results/deepseek-chat/prompt-0/zzz_Cardio-AI_3d-mri-domain-adaptation_master_README.md.tsv\036c3f3c.txt,1.0
