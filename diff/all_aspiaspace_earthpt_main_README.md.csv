sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,"<p align=""center"">     <img src=""assets/emoji.png"" alt=""earthPT"" width=""150""/> </p>  # EarthPT  <p align=""center"">     <img src=""assets/timeseries.png"" alt=""prediction"" width=""600""/> </p>  A simple repository for training time series large observation models.","<p align=""center"">     <img src=""assets/emoji.png"" alt=""earthPT"" width=""150""/> </p>  # EarthPT  <p align=""center"">     <img src=""assets/timeseries.png"" alt=""prediction"" width=""600""/> </p>  A simple repository for training time series large observation models.","<p align=""center"">     <img src=""assets/emoji.png"" alt=""earthPT"" width=""150""/> </p>  # EarthPT  <p align=""center"">     <img src=""assets/timeseries.png"" alt=""prediction"" width=""600""/> </p>  A simple repository for training time series large observation models.","<p align=""center"">     <img src=""assets/emoji.png"" alt=""earthPT"" width=""150""/> </p>  # <PROJECT>EarthPT</PROJECT>  <p align=""center"">     <img src=""assets/timeseries.png"" alt=""prediction"" width=""600""/> </p>  A simple repository for training time series large observation models.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\28904dd4.txt,1.0
2,"This repository began its life as Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT), and has been altered so that it is usable for time series data.","This repository began its life as Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT), and has been altered so that it is usable for time series data.","This repository began its life as Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT), and has been altered so that it is usable for time series data.","This repository began its life as Andrej Karpathy's [<SOFTWARE>nanoGPT</SOFTWARE>](https://github.com/karpathy/<SOFTWARE>nanoGPT</SOFTWARE>), and has been altered so that it is usable for time series data.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\4805cc8c.txt,1.0
3,`train.py` reproduces [EarthPT-700M](https://arxiv.org/abs/2309.07207) when trained on 14B time series 'tokens' of ClearSky EO data within the TL UK National Grid tile.,`train.py` reproduces [EarthPT-700M](https://arxiv.org/abs/2309.07207) when trained on 14B time series 'tokens' of ClearSky EO data within the TL UK National Grid tile.,`train.py` reproduces [EarthPT-700M](https://arxiv.org/abs/2309.07207) when trained on 14B time series 'tokens' of ClearSky EO data within the TL UK National Grid tile.,`<SOFTWARE>train.py</SOFTWARE>` reproduces [<PUBLICATION>EarthPT-700M</PUBLICATION>](https://arxiv.org/abs/2309.07207) when trained on 14B time series 'tokens' of ClearSky EO data within the TL UK National Grid tile.,../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\e46f59c6.txt,1.0
4,"When run, `train.py` takes ~5 days to achieve Chinchilla üê≠  completion on a single 8xA100 40GB node.","When run, `train.py` takes ~5 days to achieve Chinchilla üê≠  completion on a single 8xA100 40GB node.","When run, `train.py` takes ~5 days to achieve Chinchilla üê≠  completion on a single 8xA100 40GB node.","When run, `<SOFTWARE>train.py</SOFTWARE>` takes ~5 days to achieve Chinchilla üê≠  completion on a single 8xA100 40GB node.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\16079e5c.txt,1.0
5,Within `train.py` you will find a ~300-line boilerplate training loop and within `model.py` you will find a ~300-line GPT model definition with an MLP tokeniser and a regressive loss.,Within `train.py` you will find a ~300-line boilerplate training loop and within `model.py` you will find a ~300-line GPT model definition with an MLP tokeniser and a regressive loss.,Within `train.py` you will find a ~300-line boilerplate training loop and within `model.py` you will find a ~300-line `GPT` model definition with an `MLP` tokeniser and a regressive loss.,Within `<PROGLANG>train.py</PROGLANG>` you will find a ~300-line boilerplate training loop and within `<PROGLANG>model.py</PROGLANG>` you will find a ~300-line `<SOFTWARE>GPT</SOFTWARE>` model definition with an `<SOFTWARE>MLP</SOFTWARE>` tokeniser and a regressive loss.,../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\a88cb5c8.txt,0.9891891891891892
6,We have purposefully kept the code as simple and hackable as possible so that it is easy for all to hack this base to their needs.,We have purposefully kept the code as simple and hackable as possible so that it is easy for all to hack this base to their needs.,We have purposefully kept the code as simple and hackable as possible so that it is easy for all to hack this base to their needs.,We have purposefully kept the code as simple and hackable as possible so that it is easy for all to hack this base to their needs.,../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\c63f3a68.txt,1.0
7,"We release this code under the MIT licence in the hope that it will prove useful to others working on EO and timeseries large observation models.  ## install  Dependencies:  - `pip install -r requirements.txt`  ## results  Our EarthPT-700M model is able to predict future satellite passes well into the future, and also learns semantically meaningful information about the timeseries that it is fed:  <p align=""center"">     <img src=""assets/3d.gif"" alt=""embeddings"" width=""400""/> </p>  You can find a plot with less angular momentum and further results in our paper [here](https://arxiv.org/abs/2309.07207).  ## pretrained weights  You can find our weights for all the EarthPT models on [HuggingFace](https://doi.org/10.57967/hf/1598) ü§ó .  ## citation  If you find EarthPT useful in your work please do drop us a cite:  ```bibtex @article{ref_smith2023,     author = {Smith, M.","We release this code under the <LICENSE>MIT</LICENSE> licence in the hope that it will prove useful to others working on EO and timeseries large observation models.  ## install  Dependencies:  - `pip install -r requirements.txt`  ## results  Our EarthPT-700M model is able to predict future satellite passes well into the future, and also learns semantically meaningful information about the timeseries that it is fed:  <p align=""center"">     <img src=""assets/3d.gif"" alt=""embeddings"" width=""400""/> </p>  You can find a plot with less angular momentum and further results in our paper [here](https://arxiv.org/abs/2309.07207).  ## pretrained weights  You can find our weights for all the EarthPT models on [HuggingFace](https://doi.org/10.57967/hf/1598) ü§ó .  ## citation  If you find EarthPT useful in your work please do drop us a cite:  ```bibtex @article{ref_smith2023,     author = {Smith, M.","We release this code under the MIT licence in the hope that it will prove useful to others working on EO and timeseries large observation models.  ## install  Dependencies:  - `pip install -r requirements.txt`  ## results  Our EarthPT-700M model is able to predict future satellite passes well into the future, and also learns semantically meaningful information about the timeseries that it is fed:  <p align=""center"">     <img src=""assets/3d.gif"" alt=""embeddings"" width=""400""/> </p>  You can find a plot with less angular momentum and further results in our paper [here](https://arxiv.org/abs/2309.07207).  ## pretrained weights  You can find our weights for all the EarthPT models on [HuggingFace](https://doi.org/10.57967/hf/1598) ü§ó .  ## citation  If you find EarthPT useful in your work please do drop us a cite:  ```bibtex @article{ref_smith2023,     author = {Smith, M.","We release this code under the <LICENSE>MIT</LICENSE> licence in the hope that it will prove useful to others working on EO and timeseries large observation models.  ## install  Dependencies:  - `pip install -r requirements.txt`  ## results  Our <PROJECT>EarthPT-700M</PROJECT> model is able to predict future satellite passes well into the future, and also learns semantically meaningful information about the timeseries that it is fed:  <p align=""center"">     <img src=""assets/3d.gif"" alt=""embeddings"" width=""400""/> </p>  You can find a plot with less angular momentum and further results in our <PUBLICATION>paper</PUBLICATION> [here](https://arxiv.org/abs/2309.07207).  ## pretrained weights  You can find our weights for all the <PROJECT>EarthPT</PROJECT> models on [<PROJECT>HuggingFace</PROJECT>](https://doi.org/10.57967/hf/1598) ü§ó .  ## citation  If you find <PROJECT>EarthPT</PROJECT> useful in your work please do drop us a cite:  ```bibtex @article{ref_smith2023,     author = {Smith, M.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\8af654d7.txt,1.0
8,"J. and Fleming, L. and Geach, J.","J. and Fleming, L. and Geach, J.","J. and Fleming, L. and Geach, J.","J. and Fleming, L. and Geach, J.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\8098404e.txt,1.0
9,"E.},     title = {{EarthPT: a time series foundation model for Earth Observation}},     journal = {arXiv},     year = {2023},     eprint = {2309.07207},     doi = {10.48550/arXiv.2309.07207} } ```  This work is also in the [proceedings](https://www.climatechange.ai/papers/neurips2023/2) of the 2023 CCAI NeurIPS workshop.","E.},     title = {{<PUBLICATION>EarthPT: a time series foundation model for Earth Observation</PUBLICATION>}},     journal = {arXiv},     year = {2023},     eprint = {2309.07207},     doi = {10.48550/arXiv.2309.07207} } ```  This work is also in the [proceedings](https://www.climatechange.ai/papers/<CONFERENCE>neurips2023</CONFERENCE>/2) of the <WORKSHOP>2023 CCAI NeurIPS workshop</WORKSHOP><CONFERENCE>NeurIPS</CONFERENCE> workshop.","E.},     title = {{EarthPT: a time series foundation model for Earth Observation}},     journal = {arXiv},     year = {2023},     eprint = {2309.07207},     doi = {10.48550/arXiv.2309.07207} } ```  This work is also in the [proceedings](https://www.climatechange.ai/papers/neurips2023/2) of the 2023 CCAI NeurIPS workshop.","E.},     title = {{<PROJECT>EarthPT</PROJECT>: a time series foundation model for Earth Observation}},     journal = {<PUBLICATION>arXiv</PUBLICATION>},     year = {2023},     eprint = {2309.07207},     doi = {10.48550/arXiv.2309.07207} } ```  This work is also in the [proceedings](https://www.climatechange.ai/papers/neurips2023/2) of the <CONFERENCE>2023 CCAI NeurIPS workshop</CONFERENCE>.",../results/deepseek-chat/prompt-0/zzz_aspiaspace_earthpt_main_README.md.tsv\0448e652.txt,1.0
