sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,# MLLM-Bench MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria <center>  !,# <PROJECT>MLLM-Bench</PROJECT> <PUBLICATION>MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria</PUBLICATION> <center>  !,"# MLLM-Bench MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria <center>  !
","# <PUBLICATION>MLLM-Bench MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria</PUBLICATION> <center>  !
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\b1df7b0d.txt,0.9943502824858758
2,[Python 3.9+](https://img.shields.io/badge/Python-3.9+-lightblue) !,[<PROGLANG>Python 3.9+</PROGLANG>](https://img.shields.io/badge/<PROGLANG>Python-3.9+</PROGLANG>-lightblue) !,[Python 3.9+](https://img.shields.io/badge/Python-3.9+-lightblue) !,[<PROGLANG>Python 3.9+</PROGLANG>](https://img.shields.io/badge/<PROGLANG>Python</PROGLANG>-3.9+-lightblue) !,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\7f970348.txt,1.0
3,[Pytorch 2.0](https://img.shields.io/badge/PyTorch-2.0+-lightblue) !,[<SOFTWARE>Pytorch 2.0</SOFTWARE>](https://img.shields.io/badge/<SOFTWARE>PyTorch-2.0</SOFTWARE>+-lightblue) !,"[Pytorch 2.0](https://img.shields.io/badge/PyTorch-2.0+-lightblue) !
","[<SOFTWARE>Pytorch 2.0</SOFTWARE>](https://img.shields.io/badge/<SOFTWARE>PyTorch</SOFTWARE>-2.0+-lightblue) !
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\955bf424.txt,0.9927007299270073
4,[transformers](https://img.shields.io/badge/transformers-4.36.0.dev0%2B-lightblue) !,[<SOFTWARE>transformers</SOFTWARE>](https://img.shields.io/badge/<SOFTWARE>transformers-4.36.0.dev0</SOFTWARE>%2B-lightblue) !,"[transformers](https://img.shields.io/badge/transformers-4.36.0.dev0%2B-lightblue) !
","[<SOFTWARE>transformers</SOFTWARE>](https://img.shields.io/badge/<SOFTWARE>transformers</SOFTWARE>-4.36.0.dev0%2B-lightblue) !
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\f3e49da7.txt,0.9940828402366864
5,"[accelerate](https://img.shields.io/badge/accelerate-0.22+-lightblue) </center>  <p align=""center"">    üìÉ  <a href=""https://arxiv.org/abs/2311.13951"" target=""_blank"">Paper</a> ‚Ä¢ üåê  <a href=""https://mllm-bench.llmzoo.com/"" target=""_blank"">Website</a> ‚Ä¢ ü§ó  <a href=""huggingface.com"" target=""_blank"">HuggingFace</a>    <p align=""center""> <img src="".","[<SOFTWARE>accelerate</SOFTWARE>](https://img.shields.io/badge/<SOFTWARE>accelerate-0.22</SOFTWARE>+-lightblue) </center>  <p align=""center"">    üìÉ  <a href=""https://arxiv.org/abs/2311.13951"" target=""_blank"">Paper</a> ‚Ä¢ üåê  <a href=""https://mllm-bench.llmzoo.com/"" target=""_blank"">Website</a> ‚Ä¢ ü§ó  <a href=""huggingface.com"" target=""_blank"">HuggingFace</a>    <p align=""center""> <img src="".","[accelerate](https://img.shields.io/badge/accelerate-0.22+-lightblue) </center>  <p align=""center"">    üìÉ  <a href=""https://arxiv.org/abs/2311.13951"" target=""_blank"">Paper</a> ‚Ä¢ üåê  <a href=""https://mllm-bench.llmzoo.com/"" target=""_blank"">Website</a> ‚Ä¢ ü§ó  <a href=""huggingface.com"" target=""_blank"">HuggingFace</a>    <p align=""center""> <img src="".
","[<SOFTWARE>accelerate</SOFTWARE>](https://img.shields.io/badge/accelerate-0.22+-lightblue) </center>  <p align=""center"">    üìÉ  <a href=""https://arxiv.org/abs/2311.13951"" target=""_blank""><PUBLICATION>Paper</PUBLICATION></a> ‚Ä¢ üåê  <a href=""https://<PROJECT>mllm-bench</PROJECT>.<SOFTWARE>llmzoo</SOFTWARE>.com/"" target=""_blank"">Website</a> ‚Ä¢ ü§ó  <a href=""<SOFTWARE>huggingface</SOFTWARE>.com"" target=""_blank""><SOFTWARE>HuggingFace</SOFTWARE></a>    <p align=""center""> <img src="".
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\430b2d82.txt,0.9985528219971056
6,"/image.png"" alt=""Data Composition"" width=""550"" height=""550"">   ## üåà  Update * **[2024.4.27]** V3 data, benchmark reuslts, leaderboard and arxiv paper are updated.","/image.png"" alt=""Data Composition"" width=""550"" height=""550"">   ## üåà  Update * **[2024.4.27]** V3 data, benchmark reuslts, leaderboard and arxiv paper are updated.","/image.png"" alt=""Data Composition"" width=""550"" height=""550"">   ## üåà  Update * **[2024.4.27]** V3 data, benchmark reuslts, leaderboard and arxiv paper are updated.
","/image.png"" alt=""Data Composition"" width=""550"" height=""550"">   ## üåà  Update * **[2024.4.27]** V3 <DATASET>data</DATASET>, benchmark reuslts, leaderboard and arxiv <PUBLICATION>paper</PUBLICATION> are updated.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\e1483134.txt,0.9969230769230769
8,"However, we provide  <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">a submission entry</a>  for FREE evaluations.","However, we provide  <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">a submission entry</a>  for FREE evaluations.","However, we provide  <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">a submission entry</a>  for FREE evaluations.","However, we provide  <a href=""https://<PROJECT>mllm-bench</PROJECT>.<SOFTWARE>llmzoo</SOFTWARE>.com/static/submit.html"" target=""_blank"">a submission entry</a>  for FREE evaluations.",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\3f7c3d5e.txt,1.0
10,"* **[2024.1.7]** V2 data, reuslts and leaderboard are updated","* **[2024.1.7]** V2 data, reuslts and leaderboard are updated","* **[2024.1.7]** V2 data, reuslts and leaderboard are updated
","* **[2024.1.7]** <DATASET>V2</DATASET> data, reuslts and leaderboard are updated
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\62556810.txt,0.991869918699187
11,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
15,See more results of different evaluation protocols and anchors in our  [paper](https://arxiv.org/abs/2311.13951).,See more results of different evaluation protocols and anchors in our  [paper](https://arxiv.org/abs/2311.13951).,See more results of different evaluation protocols and anchors in our  [paper](https://arxiv.org/abs/2311.13951).,See more results of different evaluation protocols and anchors in our  [<PUBLICATION>paper</PUBLICATION>](https://arxiv.org/abs/2311.13951).,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\278f214f.txt,1.0
17,/Model_cards.md),/Model_cards.md),"/workers/model_workers.py).
","/workers/<SOFTWARE>model_workers.py</SOFTWARE>).
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\33cd6637.txt,0.45454545454545453
18,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
19,| **Rank** | **Models**       | **Perception**  | **Understanding** | **Applying** | **Analyzing** | **Evaluation** | **Creation** | **Win Rates over LLaVA-v1.5-13B** | |------|-----------------------|-------------|---------------|----------|-----------|------------|----------|-----------------------| | üèÖÔ∏è   | GPT-4o             | 64/5/1     | 98/11/1        | 50/8/2  | 86/9/5   | 40/0/0     | 38/1/1   | 0.90                  | | ü•à   | Claude-3              | 56/13/1     | 98/9/3        | 45/11/4  | 83/14/3   | 33/5/2     | 33/6/1   | 0.83                  | | ü•â   | GPT-4V                | 56/10/4     | 101/6/3       | 29/12/19 | 73/22/5   | 33/2/5     | 2/0/38   | 0.70                  | | 4  | LLaVA-v1.6-34B        | 46/17/7     | 78/22/10      | 36/15/9  | 61/28/11  | 33/3/4     | 24/10/6  | 0.66                  | | 5    | LLaVA-v1.6-Vicuna-13B | 40/21/9     | 65/33/12      | 35/19/6  | 51/26/23  | 33/5/2     | 27/9/4   | 0.60                  | | 6   | LLaVA-v1.6-Vicuna-7B  | 31/25/14    | 56/37/17      | 26/23/11 | 40/31/29  | 22/10/8    | 19/10/11 | 0.46                  | | 7    | ALLaVA-3B-Longer      | 22/21/27    | 57/30/23      | 23/17/20 | 44/30/26  | 16/10/14   | 17/12/11 | 0.43                  | | 8    | Gemini-1.0-Pro        | 45/10/15    | 36/35/39      | 24/19/17 | 33/28/39  | 9/8/23     | 16/8/16  | 0.39                  | | 9    | Qwen-VL-Chat          | 34/22/14    | 38/36/36      | 26/18/16 | 35/29/36  | 15/6/19    | 9/12/19  | 0.37                  | | 10    | LVIS                  | 22/28/20    | 32/39/39      | 11/27/22 | 33/36/31  | 14/9/17    | 9/16/15  | 0.29                  | | 11   | mPLUG-Owl2            | 16/24/30    | 30/34/46      | 17/17/26 | 23/38/39  | 15/8/17    | 11/14/15 | 0.27                  | | 12   | LLaVA-v1.5-7B         | 19/22/29    | 27/47/36      | 13/29/18 | 21/43/36  | 9/14/17    | 8/13/19  | 0.23                  | | 13   | MiniGPT-v2            | 12/25/33    | 24/32/54      | 11/25/24 | 17/38/45  | 9/9/22     | 6/6/28   | 0.19                  | | 14   | InstructBLIP          | 15/16/39    | 13/36/61      | 6/23/31  | 13/29/58  | 10/7/23    | 4/9/27   | 0.15                  | | 15   | Cheetor               | 12/20/38    | 7/27/76       | 10/22/28 | 16/23/61  | 4/4/32     | 3/4/33   | 0.12                  | | 16   | SEED-LLaMA            | 16/15/39    | 5/25/80       | 10/21/29 | 7/25/68   | 3/7/30     | 3/3/34   | 0.10                  | | 17   | kosmos2               | 6/22/42     | 6/18/86       | 6/15/39  | 10/20/70  | 1/4/35     | 2/3/35   | 0.07                  | | 18   | Yi-VL-6B              | 4/17/49     | 8/22/80       | 5/27/28  | 5/29/66   | 3/9/28     | 3/9/28   | 0.07                  | | 19   | Fuyu-8B               | 7/19/44     | 7/27/76       | 6/14/40  | 4/22/74   | 3/7/30     | 0/6/34   | 0.06                  | | 20   | LWM                   | 2/18/50     | 5/15/90       | 4/21/35  | 2/18/80   | 3/2/35     | 2/6/32   | 0.04                  | | 21   | OpenFlamingo          | 8/13/49     | 2/8/100       | 3/14/43  | 2/21/77   | 1/2/37     | 1/5/34   | 0.04                  | | 22   | BLIP2                 | 3/13/54     | 2/15/93       | 6/8/46   | 0/22/78   | 0/1/39     | 0/2/38   | 0.03                  |    ## Usage ### Environment Setup <details><summary>Click to expand</summary>     Install required packages: ```bash pip install -r requirements.txt ``` Update `transformers` (we used `4.36.0.dev0`): ```bash pip install git+https://github.com/huggingface/transformers ```  </details>    ### Answer Generation <details><summary>Click to expand</summary>  - Configurate `accelerate` settings.,| **Rank** | **Models**       | **<EVALMETRIC>Perception</EVALMETRIC>**  | **<EVALMETRIC>Understanding</EVALMETRIC>** | **<EVALMETRIC>Applying</EVALMETRIC>** | **<EVALMETRIC>Analyzing</EVALMETRIC>** | **<EVALMETRIC>Evaluation</EVALMETRIC>** | **<EVALMETRIC>Creation</EVALMETRIC>** | **<EVALMETRIC>Win Rates over LLaVA-v1.5-13B</EVALMETRIC><SOFTWARE>LLaVA-v1.5-13B</SOFTWARE>** | |------|-----------------------|-------------|---------------|----------|-----------|------------|----------|-----------------------| | üèÖÔ∏è   | <SOFTWARE>GPT-4o</SOFTWARE>             | 64/5/1     | 98/11/1        | 50/8/2  | 86/9/5   | 40/0/0     | 38/1/1   | 0.90                  | | ü•à   | <SOFTWARE>Claude-3</SOFTWARE>              | 56/13/1     | 98/9/3        | 45/11/4  | 83/14/3   | 33/5/2     | 33/6/1   | 0.83                  | | ü•â   | <SOFTWARE>GPT-4V</SOFTWARE>                | 56/10/4     | 101/6/3       | 29/12/19 | 73/22/5   | 33/2/5     | 2/0/38   | 0.70                  | | 4  | <SOFTWARE>LLaVA-v1.6-34B</SOFTWARE>        | 46/17/7     | 78/22/10      | 36/15/9  | 61/28/11  | 33/3/4     | 24/10/6  | 0.66                  | | 5    | <SOFTWARE>LLaVA-v1.6-Vicuna-13B</SOFTWARE> | 40/21/9     | 65/33/12      | 35/19/6  | 51/26/23  | 33/5/2     | 27/9/4   | 0.60                  | | 6   | <SOFTWARE>LLaVA-v1.6-Vicuna-7B</SOFTWARE>  | 31/25/14    | 56/37/17      | 26/23/11 | 40/31/29  | 22/10/8    | 19/10/11 | 0.46                  | | 7    | <SOFTWARE>ALLaVA-3B-Longer</SOFTWARE>      | 22/21/27    | 57/30/23      | 23/17/20 | 44/30/26  | 16/10/14   | 17/12/11 | 0.43                  | | 8    | <SOFTWARE>Gemini-1.0-Pro</SOFTWARE>        | 45/10/15    | 36/35/39      | 24/19/17 | 33/28/39  | 9/8/23     | 16/8/16  | 0.39                  | | 9    | <SOFTWARE>Qwen-VL-Chat</SOFTWARE>          | 34/22/14    | 38/36/36      | 26/18/16 | 35/29/36  | 15/6/19    | 9/12/19  | 0.37                  | | 10    | <SOFTWARE>LVIS</SOFTWARE>                  | 22/28/20    | 32/39/39      | 11/27/22 | 33/36/31  | 14/9/17    | 9/16/15  | 0.29                  | | 11   | <SOFTWARE>mPLUG-Owl2</SOFTWARE>            | 16/24/30    | 30/34/46      | 17/17/26 | 23/38/39  | 15/8/17    | 11/14/15 | 0.27                  | | 12   | <SOFTWARE>LLaVA-v1.5-7B</SOFTWARE>         | 19/22/29    | 27/47/36      | 13/29/18 | 21/43/36  | 9/14/17    | 8/13/19  | 0.23                  | | 13   | <SOFTWARE>MiniGPT-v2</SOFTWARE>            | 12/25/33    | 24/32/54      | 11/25/24 | 17/38/45  | 9/9/22     | 6/6/28   | 0.19                  | | 14   | <SOFTWARE>InstructBLIP</SOFTWARE>          | 15/16/39    | 13/36/61      | 6/23/31  | 13/29/58  | 10/7/23    | 4/9/27   | 0.15                  | | 15   | <SOFTWARE>Cheetor</SOFTWARE>               | 12/20/38    | 7/27/76       | 10/22/28 | 16/23/61  | 4/4/32     | 3/4/33   | 0.12                  | | 16   | <SOFTWARE>SEED-LLaMA</SOFTWARE>            | 16/15/39    | 5/25/80       | 10/21/29 | 7/25/68   | 3/7/30     | 3/3/34   | 0.10                  | | 17   | <SOFTWARE>kosmos2</SOFTWARE>               | 6/22/42     | 6/18/86       | 6/15/39  | 10/20/70  | 1/4/35     | 2/3/35   | 0.07                  | | 18   | <SOFTWARE>Yi-VL-6B</SOFTWARE>              | 4/17/49     | 8/22/80       | 5/27/28  | 5/29/66   | 3/9/28     | 3/9/28   | 0.07                  | | 19   | <SOFTWARE>Fuyu-8B</SOFTWARE>               | 7/19/44     | 7/27/76       | 6/14/40  | 4/22/74   | 3/7/30     | 0/6/34   | 0.06                  | | 20   | <SOFTWARE>LWM</SOFTWARE>                   | 2/18/50     | 5/15/90       | 4/21/35  | 2/18/80   | 3/2/35     | 2/6/32   | 0.04                  | | 21   | <SOFTWARE>OpenFlamingo</SOFTWARE>          | 8/13/49     | 2/8/100       | 3/14/43  | 2/21/77   | 1/2/37     | 1/5/34   | 0.04                  | | 22   | <SOFTWARE>BLIP2</SOFTWARE>                 | 3/13/54     | 2/15/93       | 6/8/46   | 0/22/78   | 0/1/39     | 0/2/38   | 0.03                  |    ## Usage ### Environment Setup <details><summary>Click to expand</summary>     Install required packages: ```<SOFTWARE>bash</SOFTWARE> <SOFTWARE>pip</SOFTWARE> install -r requirements.txt ``` Update `<SOFTWARE>transformers</SOFTWARE>` (we used `4.36.0.dev0`): ```<SOFTWARE>bash</SOFTWARE> <SOFTWARE>pip</SOFTWARE> install <SOFTWARE>git</SOFTWARE>+https://github.com/huggingface/<SOFTWARE>transformers</SOFTWARE> ```  </details>    ### Answer Generation <details><summary>Click to expand</summary>  - Configurate `<SOFTWARE>accelerate</SOFTWARE>` settings.,"| **Rank** | **Models**       | **Perception**  | **Understanding** | **Applying** | **Analyzing** | **Evaluation** | **Creation** | **Win Rates over LLaVA-v1.5-13B** | |------|-----------------------|-------------|---------------|----------|-----------|------------|----------|-----------------------| | üèÖÔ∏è   | GPT-4o             | 64/5/1     | 98/11/1        | 50/8/2  | 86/9/5   | 40/0/0     | 38/1/1   | 0.90                  | | ü•à   | Claude-3              | 56/13/1     | 98/9/3        | 45/11/4  | 83/14/3   | 33/5/2     | 33/6/1   | 0.83                  | | ü•â   | GPT-4V                | 56/10/4     | 101/6/3       | 29/12/19 | 73/22/5   | 33/2/5     | 2/0/38   | 0.70                  | | 4  | LLaVA-v1.6-34B        | 46/17/7     | 78/22/10      | 36/15/9  | 61/28/11  | 33/3/4     | 24/10/6  | 0.66                  | | 5    | LLaVA-v1.6-Vicuna-13B | 40/21/9     | 65/33/12      | 35/19/6  | 51/26/23  | 33/5/2     | 27/9/4   | 0.60                  | | 6   | LLaVA-v1.6-Vicuna-7B  | 31/25/14    | 56/37/17      | 26/23/11 | 40/31/29  | 22/10/8    | 19/10/11 | 0.46                  | | 7    | ALLaVA-3B-Longer      | 22/21/27    | 57/30/23      | 23/17/20 | 44/30/26  | 16/10/14   | 17/12/11 | 0.43                  | | 8    | Gemini-1.0-Pro        | 45/10/15    | 36/35/39      | 24/19/17 | 33/28/39  | 9/8/23     | 16/8/16  | 0.39                  | | 9    | Qwen-VL-Chat          | 34/22/14    | 38/36/36      | 26/18/16 | 35/29/36  | 15/6/19    | 9/12/19  | 0.37                  | | 10    | LVIS                  | 22/28/20    | 32/39/39      | 11/27/22 | 33/36/31  | 14/9/17    | 9/16/15  | 0.29                  | | 11   | mPLUG-Owl2            | 16/24/30    | 30/34/46      | 17/17/26 | 23/38/39  | 15/8/17    | 11/14/15 | 0.27                  | | 12   | LLaVA-v1.5-7B         | 19/22/29    | 27/47/36      | 13/29/18 | 21/43/36  | 9/14/17    | 8/13/19  | 0.23                  | | 13   | MiniGPT-v2            | 12/25/33    | 24/32/54      | 11/25/24 | 17/38/45  | 9/9/22     | 6/6/28   | 0.19                  | | 14   | InstructBLIP          | 15/16/39    | 13/36/61      | 6/23/31  | 13/29/58  | 10/7/23    | 4/9/27   | 0.15                  | | 15   | Cheetor               | 12/20/38    | 7/27/76       | 10/22/28 | 16/23/61  | 4/4/32     | 3/4/33   | 0.12                  | | 16   | SEED-LLaMA            | 16/15/39    | 5/25/80       | 10/21/29 | 7/25/68   | 3/7/30     | 3/3/34   | 0.10                  | | 17   | kosmos2               | 6/22/42     | 6/18/86       | 6/15/39  | 10/20/70  | 1/4/35     | 2/3/35   | 0.07                  | | 18   | Yi-VL-6B              | 4/17/49     | 8/22/80       | 5/27/28  | 5/29/66   | 3/9/28     | 3/9/28   | 0.07                  | | 19   | Fuyu-8B               | 7/19/44     | 7/27/76       | 6/14/40  | 4/22/74   | 3/7/30     | 0/6/34   | 0.06                  | | 20   | LWM                   | 2/18/50     | 5/15/90       | 4/21/35  | 2/18/80   | 3/2/35     | 2/6/32   | 0.04                  | | 21   | OpenFlamingo          | 8/13/49     | 2/8/100       | 3/14/43  | 2/21/77   | 1/2/37     | 1/5/34   | 0.04                  | | 22   | BLIP2                 | 3/13/54     | 2/15/93       | 6/8/46   | 0/22/78   | 0/1/39     | 0/2/38   | 0.03                  |    ## Usage ### Environment Setup <details><summary>Click to expand</summary>     Install required packages: bash pip install -r requirements.txt  Update transformers (we used 4.36.0.dev0): bash pip install git+https://github.com/huggingface/transformers   </details>    ### Answer Generation <details><summary>Click to expand</summary>  - Configurate accelerate settings.
","| **Rank** | **Models**       | **Perception**  | **Understanding** | **Applying** | **Analyzing** | **Evaluation** | **Creation** | **Win Rates over <SOFTWARE>LLaVA-v1.5-13B</SOFTWARE>** | |------|-----------------------|-------------|---------------|----------|-----------|------------|----------|-----------------------| | üèÖÔ∏è   | <SOFTWARE>GPT-4o</SOFTWARE>             | 64/5/1     | 98/11/1        | 50/8/2  | 86/9/5   | 40/0/0     | 38/1/1   | 0.90                  | | ü•à   | <SOFTWARE>Claude-3</SOFTWARE>              | 56/13/1     | 98/9/3        | 45/11/4  | 83/14/3   | 33/5/2     | 33/6/1   | 0.83                  | | ü•â   | <SOFTWARE>GPT-4V</SOFTWARE>                | 56/10/4     | 101/6/3       | 29/12/19 | 73/22/5   | 33/2/5     | 2/0/38   | 0.70                  | | 4  | <SOFTWARE>LLaVA-v1.6-34B</SOFTWARE>        | 46/17/7     | 78/22/10      | 36/15/9  | 61/28/11  | 33/3/4     | 24/10/6  | 0.66                  | | 5    | <SOFTWARE>LLaVA-v1.6-Vicuna-13B</SOFTWARE> | 40/21/9     | 65/33/12      | 35/19/6  | 51/26/23  | 33/5/2     | 27/9/4   | 0.60                  | | 6   | <SOFTWARE>LLaVA-v1.6-Vicuna-7B</SOFTWARE>  | 31/25/14    | 56/37/17      | 26/23/11 | 40/31/29  | 22/10/8    | 19/10/11 | 0.46                  | | 7    | <SOFTWARE>ALLaVA-3B-Longer</SOFTWARE>      | 22/21/27    | 57/30/23      | 23/17/20 | 44/30/26  | 16/10/14   | 17/12/11 | 0.43                  | | 8    | <SOFTWARE>Gemini-1.0-Pro</SOFTWARE>        | 45/10/15    | 36/35/39      | 24/19/17 | 33/28/39  | 9/8/23     | 16/8/16  | 0.39                  | | 9    | <SOFTWARE>Qwen-VL-Chat</SOFTWARE>          | 34/22/14    | 38/36/36      | 26/18/16 | 35/29/36  | 15/6/19    | 9/12/19  | 0.37                  | | 10    | <SOFTWARE>LVIS</SOFTWARE>                  | 22/28/20    | 32/39/39      | 11/27/22 | 33/36/31  | 14/9/17    | 9/16/15  | 0.29                  | | 11   | <SOFTWARE>mPLUG-Owl2</SOFTWARE>            | 16/24/30    | 30/34/46      | 17/17/26 | 23/38/39  | 15/8/17    | 11/14/15 | 0.27                  | | 12   | <SOFTWARE>LLaVA-v1.5-7B</SOFTWARE>         | 19/22/29    | 27/47/36      | 13/29/18 | 21/43/36  | 9/14/17    | 8/13/19  | 0.23                  | | 13   | <SOFTWARE>MiniGPT-v2</SOFTWARE>            | 12/25/33    | 24/32/54      | 11/25/24 | 17/38/45  | 9/9/22     | 6/6/28   | 0.19                  | | 14   | <SOFTWARE>InstructBLIP</SOFTWARE>          | 15/16/39    | 13/36/61      | 6/23/31  | 13/29/58  | 10/7/23    | 4/9/27   | 0.15                  | | 15   | <SOFTWARE>Cheetor</SOFTWARE>               | 12/20/38    | 7/27/76       | 10/22/28 | 16/23/61  | 4/4/32     | 3/4/33   | 0.12                  | | 16   | <SOFTWARE>SEED-LLaMA</SOFTWARE>            | 16/15/39    | 5/25/80       | 10/21/29 | 7/25/68   | 3/7/30     | 3/3/34   | 0.10                  | | 17   | <SOFTWARE>kosmos2</SOFTWARE>               | 6/22/42     | 6/18/86       | 6/15/39  | 10/20/70  | 1/4/35     | 2/3/35   | 0.07                  | | 18   | <SOFTWARE>Yi-VL-6B</SOFTWARE>              | 4/17/49     | 8/22/80       | 5/27/28  | 5/29/66   | 3/9/28     | 3/9/28   | 0.07                  | | 19   | <SOFTWARE>Fuyu-8B</SOFTWARE>               | 7/19/44     | 7/27/76       | 6/14/40  | 4/22/74   | 3/7/30     | 0/6/34   | 0.06                  | | 20   | <SOFTWARE>LWM</SOFTWARE>                   | 2/18/50     | 5/15/90       | 4/21/35  | 2/18/80   | 3/2/35     | 2/6/32   | 0.04                  | | 21   | <SOFTWARE>OpenFlamingo</SOFTWARE>          | 8/13/49     | 2/8/100       | 3/14/43  | 2/21/77   | 1/2/37     | 1/5/34   | 0.04                  | | 22   | <SOFTWARE>BLIP2</SOFTWARE>                 | 3/13/54     | 2/15/93       | 6/8/46   | 0/22/78   | 0/1/39     | 0/2/38   | 0.03                  |    ## Usage ### Environment Setup <details><summary>Click to expand</summary>     Install required packages: bash pip install -r requirements.txt  Update <SOFTWARE>transformers</SOFTWARE> (we used 4.36.0.dev0): bash pip install git+https://github.com/huggingface/transformers   </details>    ### Answer Generation <details><summary>Click to expand</summary>  - Configurate <SOFTWARE>accelerate</SOFTWARE> settings.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\32bc3ea0.txt,0.9973782254726093
20,We use `bf16` inference by default.,We use `bf16` inference by default.,We use bf16 inference by default.,We use <PROGLANG>bf16</PROGLANG> inference by default.,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\043d0266.txt,0.9705882352941176
21,"If this is not supported by your device, set `downcast_bf16` to `false` and `mixed_precision` to `fp16`","If this is not supported by your device, set `downcast_bf16` to `false` and `mixed_precision` to `fp16`","If this is not supported by your device, set downcast_bf16 to false and mixed_precision to fp16","If this is not supported by your device, set <PROGLANG>downcast_bf16</PROGLANG> to <PROGLANG>false</PROGLANG> and <PROGLANG>mixed_precision</PROGLANG> to <PROGLANG>fp16</PROGLANG>",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\c8772b4f.txt,0.9595959595959596
22,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
23,- Add model information in [configs/model_configs.yaml](.,- Add model information in [configs/model_configs.yaml](.,"- Add model information in [configs/model_configs.yaml](.
","- Add model information in [configs/<SOFTWARE>model_configs</SOFTWARE>.yaml](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\22418f56.txt,0.991304347826087
24,/configs/model_configs.yaml)  - Create a model worker in [workers/model_workers.py](.,/configs/model_configs.yaml)  - Create a model worker in [workers/model_workers.py](.,"/configs/model_configs.yaml)  - Create a model worker in [workers/model_workers.py](.
","/configs/<SOFTWARE>model_configs.yaml</SOFTWARE>)  - Create a model worker in [workers/<SOFTWARE>model_workers.py</SOFTWARE>](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\90a74e53.txt,0.9941520467836257
25,/workers/model_workers.py).,/workers/model_workers.py).,"/workers/model_workers.py).
","/workers/<SOFTWARE>model_workers.py</SOFTWARE>).
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\33cd6637.txt,0.9818181818181818
26,The worker should inherit `BaseWorker`.,The worker should inherit `BaseWorker`.,The worker should inherit BaseWorker.,The worker should inherit <PROGLANG>BaseWorker</PROGLANG>.,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\9930269f.txt,0.9736842105263158
27,Rewrite `init_components()` and `forward()` method.,Rewrite `init_components()` and `forward()` method.,Rewrite init_components() and forward() method.,Rewrite <PROGLANG>init_components()</PROGLANG> and <PROGLANG>forward()</PROGLANG> method.,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\559ed056.txt,0.9591836734693877
28,Explanations of parameters and outputs of the two methods are in [workers/baseworker.py](.,Explanations of parameters and outputs of the two methods are in [workers/baseworker.py](.,"Explanations of parameters and outputs of the two methods are in [workers/baseworker.py](.
","Explanations of parameters and outputs of the two methods are in [workers/<SOFTWARE>baseworker</SOFTWARE>.py](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\1ef104fe.txt,0.994475138121547
29,/workers/baseworker.py),/workers/baseworker.py),"/workers/baseworker.py)
","/workers/<SOFTWARE>baseworker.py</SOFTWARE>)
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\6b7bcbbe.txt,0.9787234042553191
30,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
31,- Run `bash generate.sh`.,- Run `<SOFTWARE>bash</SOFTWARE> generate.sh`.,"- Run bash generate.sh.
","- Run <PROGLANG>bash</PROGLANG> generate.sh.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\495f915c.txt,0.9387755102040817
32,</details>  ### Self-Evaluation <details><summary>Click to expand</summary>  - Prepare the data in the format as shown in [data/anchor.json](.,</details>  ### Self-Evaluation <details><summary>Click to expand</summary>  - Prepare the data in the format as shown in [data/anchor.json](.,"</details>  ### Self-Evaluation <details><summary>Click to expand</summary>  - Prepare the data in the format as shown in [data/anchor.json](.
","</details>  ### Self-Evaluation <details><summary>Click to expand</summary>  - Prepare the data in the format as shown in [data/<DATASET>anchor.json</DATASET>](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\649357ba.txt,0.9964912280701754
33,"/data/anchor.json), note that the key ""unique_idx"", ""gen_model_id"", and ""answer"" are required.","/data/anchor.json), note that the key ""unique_idx"", ""gen_model_id"", and ""answer"" are required.","/data/anchor.json), note that the key ""unique_idx"", ""gen_model_id"", and ""answer"" are required.","/data/<DATASET>anchor.json</DATASET>), note that the key ""unique_idx"", ""gen_model_id"", and ""answer"" are required.",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\92f0c4cb.txt,1.0
34,Move your data under [data](.,Move your data under [data](.,"Move your data under [data](.
","Move your data under [<DATASET>data</DATASET>](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\c5528aef.txt,0.9830508474576272
36,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
37,- Modify the parameters in [evaluate.sh](.,- Modify the parameters in [evaluate.sh](.,"- Modify the parameters in [evaluate.sh](.
","- Modify the parameters in [<SOFTWARE>evaluate.sh</SOFTWARE>](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\1395cb4e.txt,0.9882352941176471
38,"/evaluate.sh), especially ""model_name"" and ""model2_path""","/evaluate.sh), especially ""model_name"" and ""model2_path""","/evaluate.sh), especially ""model_name"" and ""model2_path""","/evaluate.sh), especially ""<SOFTWARE>model_name</SOFTWARE>"" and ""<SOFTWARE>model2_path</SOFTWARE>""",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\9322f640.txt,1.0
39,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
40,- Put your OpenAI API key in [evaluate.py](.,- Put your OpenAI API key in [evaluate.py](.,"- Put your OpenAI API key in [evaluate.py](.
","- Put your OpenAI API key in [<SOFTWARE>evaluate.py</SOFTWARE>](.
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\103830d1.txt,0.9887640449438202
41,"/scripts/evaluate.py), please make sure you have access to model ""gpt-4-vision-preview""","/scripts/evaluate.py), please make sure you have access to model ""gpt-4-vision-preview""","/scripts/evaluate.py), please make sure you have access to model ""gpt-4-vision-preview""
","/scripts/<SOFTWARE>evaluate.py</SOFTWARE>), please make sure you have access to model ""gpt-4-vision-preview""
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\d604181f.txt,0.9942857142857143
42,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
43,- Run `bash evaluate.sh`,- Run `<SOFTWARE>bash</SOFTWARE> evaluate.sh`,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.9361702127659575
44,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
45,- Run `cd scripts & bash evaluate4elo.sh` for elo rating,- Run `cd scripts & <SOFTWARE>bash</SOFTWARE> evaluate4elo.sh` for elo rating,"- Run cd scripts & bash evaluate4elo.sh for elo rating
","- Run cd scripts & bash <SOFTWARE>evaluate4elo.sh</SOFTWARE> for elo rating
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\80e8606c.txt,0.972972972972973
46,.,.,"- Run bash evaluate.sh
","- Run bash <PROGLANG>evaluate.sh</PROGLANG>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\55ddd912.txt,0.08333333333333333
47,- NOTE: The per sample criteria are not provided for self-evaluate and this self-evaluation process is just used for your reference.,- NOTE: The per sample criteria are not provided for self-evaluate and this self-evaluation process is just used for your reference.,- NOTE: The per sample criteria are not provided for self-evaluate and this self-evaluation process is just used for your reference.,- NOTE: The per sample criteria are not provided for <SOFTWARE>self-evaluate</SOFTWARE> and this <SOFTWARE>self-evaluation</SOFTWARE> process is just used for your reference.,../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\1038ad48.txt,1.0
49,"</details>  ### Submission for Leaderboard Refer to instructions <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">here</a>.   ## Citation ```angular2 @misc{ge2024mllmbench,       title={MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria},        author={Wentao Ge and Shunian Chen and Guiming Hardy Chen and Zhihong Chen and Junying Chen and Shuo Yan and Chenghao Zhu and Ziyue Lin and Wenya Xie and Xinyi Zhang and Yichen Chai and Xiaoyu Liu and Nuo Chen and Dingjie Song and Xidong Wang and Anningzhe Gao and Zhiyi Zhang and Jianquan Li and Xiang Wan and Benyou Wang},       year={2024},       eprint={2311.13951},       archivePrefix={arXiv},       primaryClass={cs.CL} } ```   ## Star History  <a href=""https://star-history.com/#FreedomIntelligence/MLLM-Bench&Date"">   <picture>     <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?","</details>  ### Submission for Leaderboard Refer to instructions <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">here</a>.   ## Citation ```angular2 @misc{ge2024mllmbench,       title={<PUBLICATION>MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria</PUBLICATION>},        author={Wentao Ge and Shunian Chen and Guiming Hardy Chen and Zhihong Chen and Junying Chen and Shuo Yan and Chenghao Zhu and Ziyue Lin and Wenya Xie and Xinyi Zhang and Yichen Chai and Xiaoyu Liu and Nuo Chen and Dingjie Song and Xidong Wang and Anningzhe Gao and Zhiyi Zhang and Jianquan Li and Xiang Wan and Benyou Wang},       year={2024},       eprint={2311.13951},       archivePrefix={arXiv},       primaryClass={cs.CL} } ```   ## Star History  <a href=""https://star-history.com/#FreedomIntelligence/MLLM-Bench&Date"">   <picture>     <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?","</details>  ### Submission for Leaderboard Refer to instructions <a href=""https://mllm-bench.llmzoo.com/static/submit.html"" target=""_blank"">here</a>.   ## Citation angular2 @misc{ge2024mllmbench,       title={MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria},        author={Wentao Ge and Shunian Chen and Guiming Hardy Chen and Zhihong Chen and Junying Chen and Shuo Yan and Chenghao Zhu and Ziyue Lin and Wenya Xie and Xinyi Zhang and Yichen Chai and Xiaoyu Liu and Nuo Chen and Dingjie Song and Xidong Wang and Anningzhe Gao and Zhiyi Zhang and Jianquan Li and Xiang Wan and Benyou Wang},       year={2024},       eprint={2311.13951},       archivePrefix={arXiv},       primaryClass={cs.CL} }    ## Star History  <a href=""https://star-history.com/#FreedomIntelligence/MLLM-Bench&Date"">   <picture>     <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?
","</details>  ### Submission for Leaderboard Refer to instructions <a href=""https://<PROJECT>mllm-bench</PROJECT>.<SOFTWARE>llmzoo</SOFTWARE>.com/static/submit.html"" target=""_blank"">here</a>.   ## Citation angular2 @misc{ge2024<PUBLICATION>mllmbench</PUBLICATION>,       title={<PUBLICATION>MLLM-Bench: Evaluating Multimodal LLMs with Per-sample Criteria</PUBLICATION>},        author={Wentao Ge and Shunian Chen and Guiming Hardy Chen and Zhihong Chen and Junying Chen and Shuo Yan and Chenghao Zhu and Ziyue Lin and Wenya Xie and Xinyi Zhang and Yichen Chai and Xiaoyu Liu and Nuo Chen and Dingjie Song and Xidong Wang and Anningzhe Gao and Zhiyi Zhang and Jianquan Li and Xiang Wan and Benyou Wang},       year={2024},       eprint={2311.13951},       archivePrefix={<PUBLICATION>arXiv</PUBLICATION>},       primaryClass={<PROGLANG>cs.CL</PROGLANG>} }    ## Star History  <a href=""https://<PROJECT>star-history</PROJECT>.com/#<PROJECT>FreedomIntelligence</PROJECT>/<PROJECT>MLLM-Bench</PROJECT>&Date"">   <picture>     <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.<PROJECT>star-history</PROJECT>.com/svg?
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\34abf8b1.txt,0.9961517317207257
50,"repos=FreedomIntelligence/MLLM-Bench&type=Date&theme=dark"" />     <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?","repos=FreedomIntelligence/MLLM-Bench&type=Date&theme=dark"" />     <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?","repos=FreedomIntelligence/MLLM-Bench&type=Date&theme=dark"" />     <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?
","repos=<PROJECT>FreedomIntelligence/MLLM-Bench</PROJECT>&type=Date&theme=dark"" />     <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\ae83dcf2.txt,0.996742671009772
51,"repos=FreedomIntelligence/MLLM-Bench&type=Date"" />     <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?","repos=FreedomIntelligence/MLLM-Bench&type=Date"" />     <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?","repos=FreedomIntelligence/MLLM-Bench&type=Date"" />     <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?
","repos=<PROJECT>FreedomIntelligence/MLLM-Bench</PROJECT>&type=Date"" />     <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\040d85d5.txt,0.9959514170040485
52,"repos=FreedomIntelligence/MLLM-Bench&type=Date"" />   </picture> </a>","repos=FreedomIntelligence/MLLM-Bench&type=Date"" />   </picture> </a>","repos=FreedomIntelligence/MLLM-Bench&type=Date"" />   </picture> </a>
","repos=<PROJECT>FreedomIntelligence/MLLM-Bench</PROJECT>&type=Date"" />   </picture> </a>
",../results/deepseek-chat/prompt-0/zzz_freedomintelligence_mllm-bench_main_README.md.tsv\580fbea4.txt,0.9927007299270073
