sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,# Awesome PrivEx: Privacy-Preserving Explainable AI (PPXAI)  [!,# Awesome PrivEx: Privacy-Preserving Explainable AI (PPXAI)  [!,"# Awesome PrivEx: Privacy-Preserving Explainable AI (PPXAI)  [!
","# <PROJECT>Awesome PrivEx</PROJECT>: Privacy-Preserving Explainable AI (PPXAI)  [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\5c22020a.txt,0.9921259842519685
2,[Awesome](https://awesome.re/badge.svg)](https://awesome.re) [!,[Awesome](https://awesome.re/badge.svg)](https://awesome.re) [!,"[Awesome](https://awesome.re/badge.svg)](https://awesome.re) [!
","[<PROJECT>Awesome</PROJECT>](https://<PROJECT>awesome</PROJECT>.re/badge.svg)](https://<PROJECT>awesome</PROJECT>.re) [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\d98ed6c7.txt,0.9921259842519685
3,[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673) [!,[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673) [!,"[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673) [!
","[<PUBLICATION>arXiv</PUBLICATION>](https://img.shields.io/badge/<PUBLICATION>arXiv</PUBLICATION>-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673) [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\67e18e90.txt,0.9951690821256038
4,[Website](https://img.shields.io/website?,[Website](https://img.shields.io/website?,"[Website](https://img.shields.io/website?
","[Website](https://img.shields.io/website?
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\cc9c34dc.txt,0.9879518072289156
5,down_color=lightgrey&down_message=offline&label=Official%20Website&up_color=green&up_message=online&url=https%3A%2F%2Fawesome-privex.github.io%2F)](https://awesome-privex.github.io/) !,down_color=lightgrey&down_message=offline&label=Official%20Website&up_color=green&up_message=online&url=https%3A%2F%2Fawesome-privex.github.io%2F)](https://awesome-privex.github.io/) !,"down_color=lightgrey&down_message=offline&label=Official%20Website&up_color=green&up_message=online&url=https%3A%2F%2Fawesome-privex.github.io%2F)](https://awesome-privex.github.io/) !
","down_color=lightgrey&down_message=offline&label=Official%20Website&up_color=green&up_message=online&url=https%3A%2F%2F<PROJECT>awesome-privex</PROJECT>.github.io%2F)](https://<PROJECT>awesome-privex</PROJECT>.github.io/) !
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\dd62efc9.txt,0.997289972899729
6,[GitHub stars](https://img.shields.io/github/stars/tamlhp/awesome-privex?,[GitHub stars](https://img.shields.io/github/stars/tamlhp/awesome-privex?,[GitHub stars](https://img.shields.io/github/stars/tamlhp/awesome-privex?,[GitHub stars](https://img.shields.io/github/stars/<PROJECT>tamlhp</PROJECT>/<PROJECT>awesome-privex</PROJECT>?,../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\7f209fab.txt,1.0
7,color=yellow&label=Stars) [!,color=yellow&label=Stars) [!,"The given input text does not contain any identifiable entities based on the provided guidelines. Here is the text as-is:


color=yellow&label=Stars) [!
","The given input text does not contain any identifiable entities based on the provided guidelines. Here is the text as-is:


color=yellow&label=Stars) [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\fbb44669.txt,0.30939226519337015
8,[Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?,[Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?,"[Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?
","[Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\05e8c616.txt,0.9917355371900827
9,"url=https%3A%2F%2Fgithub.com%2Ftamlhp%2Fawesome-privex%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com) <img src=""https://img.shields.io/badge/Contributions-Welcome-278ea5"" alt=""Contrib""/>    A collection of academic articles, published methodology, and datasets on the subject of **Privacy-Preserving Explainable AI**","url=https%3A%2F%2Fgithub.com%2Ftamlhp%2Fawesome-privex%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com) <img src=""https://img.shields.io/badge/Contributions-Welcome-278ea5"" alt=""Contrib""/>    A collection of academic articles, published methodology, and datasets on the subject of **Privacy-Preserving Explainable AI**","url=https%3A%2F%2Fgithub.com%2Ftamlhp%2Fawesome-privex%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com) <img src=""https://img.shields.io/badge/Contributions-Welcome-278ea5"" alt=""Contrib""/>    A collection of academic articles, published methodology, and datasets on the subject of **Privacy-Preserving Explainable AI**
","url=https%3A%2F%2Fgithub.com%2Ftamlhp%2F<PROJECT>awesome-privex</PROJECT>%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com) <img src=""https://img.shields.io/badge/Contributions-Welcome-278ea5"" alt=""Contrib""/>    A collection of academic <PUBLICATION>articles</PUBLICATION>, published <PUBLICATION>methodology</PUBLICATION>, and <DATASET>datasets</DATASET> on the subject of **Privacy-Preserving Explainable AI**
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\d31b3306.txt,0.9987357774968394
10,.,.,"page_id=tamlhp.awesome-privex)
","page_id=<PROJECT>tamlhp.awesome-privex</PROJECT>)
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0895d13e.txt,0.0625
11,"- [A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](#awesome-privex)   - [Existing Surveys](#existing-surveys)   - [Taxonomy](#taxonomy)   - [Approaches](#approaches)   - [Datasets](#datasets)     - [Type: Image](#type-image)     - [Type: Tabular](#type-tabular)     - [Type: Graph](#type-graph)     - [Type: Text](#type-text)   - [Evaluation Metrics](#evaluation-metrics)  A sortable version is available here: https://awesome-privex.github.io/  ## üîñ  News!!!","- [<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>](#awesome-privex)   - [Existing Surveys](#existing-surveys)   - [Taxonomy](#taxonomy)   - [Approaches](#approaches)   - [Datasets](#datasets)     - [Type: Image](#type-image)     - [Type: Tabular](#type-tabular)     - [Type: Graph](#type-graph)     - [Type: Text](#type-text)   - [Evaluation Metrics](#evaluation-metrics)  A sortable version is available here: https://awesome-privex.github.io/  ## üîñ  News!!!","- [A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](#awesome-privex)   - [Existing Surveys](#existing-surveys)   - [Taxonomy](#taxonomy)   - [Approaches](#approaches)   - [Datasets](#datasets)     - [Type: Image](#type-image)     - [Type: Tabular](#type-tabular)     - [Type: Graph](#type-graph)     - [Type: Text](#type-text)   - [Evaluation Metrics](#evaluation-metrics)  A sortable version is available here: https://awesome-privex.github.io/  ## üîñ  News!!!
","- [<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>](#awesome-privex)   - [Existing Surveys](#existing-surveys)   - [Taxonomy](#taxonomy)   - [Approaches](#approaches)   - [<DATASET>Datasets</DATASET>](#datasets)     - [Type: Image](#type-image)     - [Type: Tabular](#type-tabular)     - [Type: Graph](#type-graph)     - [Type: Text](#type-text)   - [<EVALMETRIC>Evaluation Metrics</EVALMETRIC>](#evaluation-metrics)  A sortable version is available here: https://<PROJECT>awesome-privex</PROJECT>.github.io/  ## üîñ  News!!!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\af2336a4.txt,0.9990147783251232
14,.,.,"page_id=tamlhp.awesome-privex)
","page_id=<PROJECT>tamlhp.awesome-privex</PROJECT>)
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0895d13e.txt,0.0625
15,"üì∞  2024-06-27: Our paper **A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures** has been revised into version 2 with new methods and dicussions.  ## üîç  Citation  If you find this work helpful in your research, welcome to cite the paper and give a ‚≠ê.","üì∞  2024-06-27: Our paper **<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>** has been revised into version 2 with new methods and dicussions.  ## üîç  Citation  If you find this work helpful in your research, welcome to cite the paper and give a ‚≠ê.","üì∞  2024-06-27: Our paper **A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures** has been revised into version 2 with new methods and dicussions.  ## üîç  Citation  If you find this work helpful in your research, welcome to cite the paper and give a ‚≠ê.
","üì∞  2024-06-27: Our paper **<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>** has been revised into version 2 with new methods and dicussions.  ## üîç  Citation  If you find this work helpful in your research, welcome to cite the paper and give a ‚≠ê.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\6a6ed5e1.txt,0.9982964224872232
16,Please read and cite our paper: [!,Please read and cite our paper: [!,"Please read and cite our paper: [!
","Please read and cite our paper: [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\bbb6ea22.txt,0.9855072463768116
17,"[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673)  >Nguyen, T.T., Huynh, T.T., Ren, Z., Nguyen, T.T., Nguyen, P.L., Yin, H. and Nguyen, Q.V.H., 2024.","[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673)  >Nguyen, T.T., Huynh, T.T., Ren, Z., Nguyen, T.T., Nguyen, P.L., Yin, H. and Nguyen, Q.V.H., 2024.","[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673)  >Nguyen, T.T., Huynh, T.T., Ren, Z., Nguyen, T.T., Nguyen, P.L., Yin, H. and Nguyen, Q.V.H., 2024.
","[arXiv](https://img.shields.io/badge/arXiv-2404.00673-b31b1b.svg)](https://arxiv.org/abs/2404.00673)  ><PUBLICATION>Nguyen, T.T., Huynh, T.T., Ren, Z., Nguyen, T.T., Nguyen, P.L., Yin, H. and Nguyen, Q.V.H., 2024.</PUBLICATION>
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\55f65171.txt,0.9975062344139651
18,"A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures. arXiv preprint arXiv:2404.00673.  ``` @article{nguyen2024survey,   title={A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures},   author={Nguyen, Thanh Tam and Huynh, Thanh Trung and Ren, Zhao and Nguyen, Thanh Toan and Nguyen, Phi Le and Yin, Hongzhi and Nguyen, Quoc Viet Hung},   journal={arXiv preprint arXiv:2404.00673},   year={2024} } ```  ----------  ## Existing Surveys | **Paper Title** | **Venue** | **Year** |  | --------------- | ---- | ---- |  | [Privacy-Preserving Explainable AI: A Survey](https://www.sciengine.com/SCIS/doi/10.1007/s11432-024-4123-4) | _SCIS_ | 2024 | | [Adversarial attacks and defenses in explainable artificial intelligence: A survey](https://www.sciencedirect.com/science/article/pii/S1566253524000812) | _Information Fusion_ | 2024 | | [A Survey of Privacy Attacks in Machine Learning](https://dl.acm.org/doi/full/10.1145/3624010) | _CSUR_ | 2023 | | [SoK: Taming the Triangle -- On the Interplays between Fairness, Interpretability and Privacy in Machine Learning](https://arxiv.org/abs/2312.16191) | _arXiv_ | 2023 | | [When Machine Learning Meets Privacy: A Survey and Outlook](https://dl.acm.org/doi/abs/10.1145/3436755) | _CSUR_ | 2021 | | [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://ieeexplore.ieee.org/abstract/document/8631448/) | _DSAA_ | 2018 | | [A Survey of Methods for Explaining Black Box Models](https://dl.acm.org/doi/abs/10.1145/3236009) | _CSUR_ | 2018 | | [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://dl.acm.org/doi/abs/10.1145/3243734.3264418) | _CCS_ | 2018 |  ----------  ## Taxonomy  [!","<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>. arXiv preprint arXiv:2404.00673.  ``` @article{nguyen2024survey,   title={<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>},   author={Nguyen, Thanh Tam and Huynh, Thanh Trung and Ren, Zhao and Nguyen, Thanh Toan and Nguyen, Phi Le and Yin, Hongzhi and Nguyen, Quoc Viet Hung},   journal={arXiv preprint arXiv:2404.00673},   year={2024} } ```  ----------  ## Existing Surveys | **Paper Title** | **Venue** | **Year** |  | --------------- | ---- | ---- |  | [<PUBLICATION>Privacy-Preserving Explainable AI: A Survey</PUBLICATION>](https://www.sciengine.com/SCIS/doi/10.1007/s11432-024-4123-4) | _SCIS_ | 2024 | | [<PUBLICATION>Adversarial attacks and defenses in explainable artificial intelligence: A survey</PUBLICATION>](https://www.sciencedirect.com/science/article/pii/S1566253524000812) | _Information Fusion_ | 2024 | | [<PUBLICATION>A Survey of Privacy Attacks in Machine Learning</PUBLICATION>](https://dl.acm.org/doi/full/10.1145/3624010) | _CSUR_ | 2023 | | [<PUBLICATION>SoK: Taming the Triangle -- On the Interplays between Fairness, Interpretability and Privacy in Machine Learning</PUBLICATION>](https://arxiv.org/abs/2312.16191) | _arXiv_ | 2023 | | [<PUBLICATION>When Machine Learning Meets Privacy: A Survey and Outlook</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3436755) | _CSUR_ | 2021 | | [<PUBLICATION>Explaining Explanations: An Overview of Interpretability of Machine Learning</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/8631448/) | _<CONFERENCE>DSAA</CONFERENCE>_ | 2018 | | [<PUBLICATION>A Survey of Methods for Explaining Black Box Models</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3236009) | _CSUR_ | 2018 | | [<PUBLICATION>Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3243734.3264418) | _<CONFERENCE>CCS</CONFERENCE>_ | 2018 |  ----------  ## Taxonomy  [!","A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures. arXiv preprint arXiv:2404.00673.   @article{nguyen2024survey,   title={A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures},   author={Nguyen, Thanh Tam and Huynh, Thanh Trung and Ren, Zhao and Nguyen, Thanh Toan and Nguyen, Phi Le and Yin, Hongzhi and Nguyen, Quoc Viet Hung},   journal={arXiv preprint arXiv:2404.00673},   year={2024} }   ----------  ## Existing Surveys | **Paper Title** | **Venue** | **Year** |  | --------------- | ---- | ---- |  | [Privacy-Preserving Explainable AI: A Survey](https://www.sciengine.com/SCIS/doi/10.1007/s11432-024-4123-4) | _SCIS_ | 2024 | | [Adversarial attacks and defenses in explainable artificial intelligence: A survey](https://www.sciencedirect.com/science/article/pii/S1566253524000812) | _Information Fusion_ | 2024 | | [A Survey of Privacy Attacks in Machine Learning](https://dl.acm.org/doi/full/10.1145/3624010) | _CSUR_ | 2023 | | [SoK: Taming the Triangle -- On the Interplays between Fairness, Interpretability and Privacy in Machine Learning](https://arxiv.org/abs/2312.16191) | _arXiv_ | 2023 | | [When Machine Learning Meets Privacy: A Survey and Outlook](https://dl.acm.org/doi/abs/10.1145/3436755) | _CSUR_ | 2021 | | [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://ieeexplore.ieee.org/abstract/document/8631448/) | _DSAA_ | 2018 | | [A Survey of Methods for Explaining Black Box Models](https://dl.acm.org/doi/abs/10.1145/3236009) | _CSUR_ | 2018 | | [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://dl.acm.org/doi/abs/10.1145/3243734.3264418) | _CCS_ | 2018 |  ----------  ## Taxonomy  [!
","<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>. <PUBLICATION>arXiv preprint arXiv:2404.00673</PUBLICATION>.   @article{nguyen2024survey,   title={<PUBLICATION>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</PUBLICATION>},   author={Nguyen, Thanh Tam and Huynh, Thanh Trung and Ren, Zhao and Nguyen, Thanh Toan and Nguyen, Phi Le and Yin, Hongzhi and Nguyen, Quoc Viet Hung},   journal={<PUBLICATION>arXiv preprint arXiv:2404.00673</PUBLICATION>},   year={2024} }   ----------  ## Existing Surveys | **Paper Title** | **Venue** | **Year** |  | --------------- | ---- | ---- |  | [<PUBLICATION>Privacy-Preserving Explainable AI: A Survey</PUBLICATION>](https://www.sciengine.com/SCIS/doi/10.1007/s11432-024-4123-4) | _<CONFERENCE>SCIS</CONFERENCE>_ | 2024 | | [<PUBLICATION>Adversarial attacks and defenses in explainable artificial intelligence: A survey</PUBLICATION>](https://www.sciencedirect.com/science/article/pii/S1566253524000812) | _<PUBLICATION>Information Fusion</PUBLICATION>_ | 2024 | | [<PUBLICATION>A Survey of Privacy Attacks in Machine Learning</PUBLICATION>](https://dl.acm.org/doi/full/10.1145/3624010) | _<CONFERENCE>CSUR</CONFERENCE>_ | 2023 | | [<PUBLICATION>SoK: Taming the Triangle -- On the Interplays between Fairness, Interpretability and Privacy in Machine Learning</PUBLICATION>](https://arxiv.org/abs/2312.16191) | _<PUBLICATION>arXiv</PUBLICATION>_ | 2023 | | [<PUBLICATION>When Machine Learning Meets Privacy: A Survey and Outlook</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3436755) | _<CONFERENCE>CSUR</CONFERENCE>_ | 2021 | | [<PUBLICATION>Explaining Explanations: An Overview of Interpretability of Machine Learning</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/8631448/) | _<CONFERENCE>DSAA</CONFERENCE>_ | 2018 | | [<PUBLICATION>A Survey of Methods for Explaining Black Box Models</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3236009) | _<CONFERENCE>CSUR</CONFERENCE>_ | 2018 | | [<PUBLICATION>Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3243734.3264418) | _<CONFERENCE>CCS</CONFERENCE>_ | 2018 |  ----------  ## Taxonomy  [!
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\1adc68df.txt,0.9980164352507792
19,"[taxonomy](taxonomy1.png)](https://arxiv.org/abs/2404.00673)  ----------  ## Approaches  | **Title** | **Year** | **Venue** | **Target Explanations** | **Attacks** | **Defenses** | **Code** | | --------------- | :----: | ---- | :----: | :----: | :----: | :----: | | [Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack](https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG) | 2024 | _SP_ | Feature-based | Membership Inference | Differential Privacy, Privacy-Preserving Models, DP-SGD | - | | [Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks](https://arxiv.org/abs/2404.07139) | 2024 | _arXiv_ | Feature-based | Membership Inference | Game Theory | - | | [On the Privacy Risks of Algorithmic Recourse](https://proceedings.mlr.press/v206/pawelczyk23a.html) | 2023 | _AISTATS_ | Counterfactual | Membership Inference | Differential Privacy | - | | [The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks](https://dl.acm.org/doi/full/10.1145/3608482) | 2023 | _TIST_ | Counterfactual | Linkage | Anonymisaion | - | | [Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations](https://dl.acm.org/doi/abs/10.1145/3580305.3599343) | 2023 | _KDD_ | Counterfactual | - | Perturbation | [[Code]](https://github.com/isVy08/L2C/) | | [Private Graph Extraction via Feature Explanations](https://petsymposium.org/popets/2023/popets-2023-0041.pdf) | 2023 | _PETS_ | Feature-based | Graph Extraction | Perturbation | [[Code]](https://github.com/iyempissy/graph-stealing-attacks-with-explanation) | | [Privacy-Preserving Algorithmic Recourse](https://arxiv.org/abs/2311.14137) | 2023 | _ICAIF_ |  Counterfactual | - | Differential Privacy | - | | [Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage](https://arxiv.org/abs/2308.04341) | 2023 | _ICML-Workshop_ | Counterfactual | Membership Inference | Differential Privacy | - | | [Probabilistic Dataset Reconstruction from Interpretable Models](https://arxiv.org/abs/2308.15099) | 2023 | _arXiv_ | Interpretable Surrogates | Data Reconstruction | - | [[Code]](https://github.com/ferryjul/ProbabilisticDatasetsReconstruction) | | [DeepFixCX: Explainable privacy-preserving image compression for medical image analysis](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495) | 2023 | _WIREs-DMKD_ | Case-based | Identity recognition | Anonymisation | [[Code]](https://github.com/adgaudio/DeepFixCX) | | [XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models](https://eprint.iacr.org/2023/1859) | 2023 | _Preprint_ | Shapley | - | Multi-party Computation | - | | DP-XAI | 2023 | _Github_ | ALE plot | - | Differential Privacy | [[Code]](https://github.com/lange-martin/dp-global-xai) | | [Inferring Sensitive Attributes from Model Explanations](https://dl.acm.org/doi/abs/10.1145/3511808.3557362) | 2022 | _CIKM_ | Gradient-based, Perturbation-based | Attribute Inference | - | [[Code]](https://github.com/vasishtduddu/AttInfExplanations) | | [Model explanations with differential privacy](https://dl.acm.org/doi/abs/10.1145/3531146.3533235) | 2022 | _FAccT_ | Feature-based | - | Differential Privacy | - | | [DualCF: Efficient Model Extraction Attack from Counterfactual Explanations](https://dl.acm.org/doi/10.1145/3531146.3533188) | 2022 | _FAccT_ | Counterfactual | Model Extraction | - | - | | [Feature Inference Attack on Shapley Values](https://dl.acm.org/doi/abs/10.1145/3548606.3560573) | 2022 | _CCS_ | Shapley | Attribute/Feature Inference | Low-dimensional | - | | [Evaluating the privacy exposure of interpretable global explainers](https://ieeexplore.ieee.org/abstract/document/10063510/), [Privacy Risk of Global Explainers](https://ebooks.iospress.nl/doi/10.3233/FAIA220206) | 2022 | _CogMI_ | Interpretable Surrogates | Membership Inference | - | - | | [Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy](https://ieeexplore.ieee.org/document/9729808/) | 2022 | _IEEE Access_ | Example-based | - | Anonymisation | - | | [On the amplification of security and privacy risks by post-hoc explanations in machine learning models](https://arxiv.org/abs/2206.14004) | 2022 | _arXiv_ | Feature-based | Membership Inference | - | - | | [Differentially Private Counterfactuals via Functional Mechanism](https://arxiv.org/abs/2208.02878) | 2022 | _arXiv_ | Counterfactual | - | Differential Privacy | - | | [Differentially Private Shapley Values for Data Evaluation](https://arxiv.org/abs/2206.00511) | 2022 | _arXiv_ | Shapley | - | Differential Privacy | [[Code]](https://github.com/amiratag/DataShapley) | | [Exploiting Explanations for Model Inversion Attacks](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html) | 2021 | _ICCV_ | Gradient-based, Interpretable Surrogates | Model Inversion | - | - | | [On the Privacy Risks of Model Explanations](https://dl.acm.org/doi/abs/10.1145/3461702.3462533) | 2021 | AIES | Feature-based, Shapley, Counterfactual | Membership Inference | - | - | | [Adversarial XAI Methods in Cybersecurity](https://ieeexplore.ieee.org/abstract/document/9555622) | 2021 | TIFS | Counterfactual | Membership Inference | - | - | | [MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI](https://arxiv.org/abs/2107.08909) | 2021 | _arXiv_ | Gradient-based | Model Extraction | - | [[Code]](https://github.com/cake-lab/datafree-model-extraction) | | [Robust Counterfactual Explanations for Privacy-Preserving SVM](https://www.diva-portal.org/smash/record.jsf?","[taxonomy](taxonomy1.png)](https://arxiv.org/abs/2404.00673)  ----------  ## Approaches  | **Title** | **Year** | **Venue** | **Target Explanations** | **Attacks** | **Defenses** | **Code** | | --------------- | :----: | ---- | :----: | :----: | :----: | :----: | | [<PUBLICATION>Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack</PUBLICATION>](https://www.computer.org/csdl/proceedings-article/<CONFERENCE>sp</CONFERENCE>/2024/313000a120/1Ub23teQ7PG) | 2024 | _<CONFERENCE>SP</CONFERENCE>_ | Feature-based | Membership Inference | Differential Privacy, Privacy-Preserving Models, DP-SGD | - | | [<PUBLICATION>Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks</PUBLICATION>](https://arxiv.org/abs/2404.07139) | 2024 | _arXiv_ | Feature-based | Membership Inference | Game Theory | - | | [<PUBLICATION>On the Privacy Risks of Algorithmic Recourse</PUBLICATION>](https://proceedings.mlr.press/v206/pawelczyk23a.html) | 2023 | _<CONFERENCE>AISTATS</CONFERENCE>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks</PUBLICATION>](https://dl.acm.org/doi/full/10.1145/3608482) | 2023 | _TIST_ | Counterfactual | Linkage | Anonymisaion | - | | [<PUBLICATION>Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3580305.3599343) | 2023 | _<CONFERENCE>KDD</CONFERENCE>_ | Counterfactual | - | Perturbation | [[Code]](https://github.com/isVy08/L2C/) | | [<PUBLICATION>Private Graph Extraction via Feature Explanations</PUBLICATION>](https://petsymposium.org/popets/2023/popets-2023-0041.pdf) | 2023 | _<CONFERENCE>PETS</CONFERENCE>_ | Feature-based | Graph Extraction | Perturbation | [[Code]](https://github.com/iyempissy/graph-stealing-attacks-with-explanation) | | [<PUBLICATION>Privacy-Preserving Algorithmic Recourse</PUBLICATION>](https://arxiv.org/abs/2311.14137) | 2023 | _<CONFERENCE>ICAIF</CONFERENCE>_ |  Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</PUBLICATION>](https://arxiv.org/abs/2308.04341) | 2023 | _<WORKSHOP>ICML-Workshop</WORKSHOP>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>Probabilistic Dataset Reconstruction from Interpretable Models</PUBLICATION>](https://arxiv.org/abs/2308.15099) | 2023 | _arXiv_ | Interpretable Surrogates | Data Reconstruction | - | [[Code]](https://github.com/ferryjul/ProbabilisticDatasetsReconstruction) | | [<PUBLICATION>DeepFixCX: Explainable privacy-preserving image compression for medical image analysis</PUBLICATION>](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495) | 2023 | _WIREs-DMKD_ | Case-based | Identity recognition | Anonymisation | [[Code]](https://github.com/adgaudio/DeepFixCX) | | [<PUBLICATION>XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models</PUBLICATION>](https://eprint.iacr.org/2023/1859) | 2023 | _Preprint_ | Shapley | - | Multi-party Computation | - | | DP-XAI | 2023 | _Github_ | ALE plot | - | Differential Privacy | [[Code]](https://github.com/lange-martin/dp-global-xai) | | [<PUBLICATION>Inferring Sensitive Attributes from Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3511808.3557362) | 2022 | _<CONFERENCE>CIKM</CONFERENCE>_ | Gradient-based, Perturbation-based | Attribute Inference | - | [[Code]](https://github.com/vasishtduddu/AttInfExplanations) | | [<PUBLICATION>Model explanations with differential privacy</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3531146.3533235) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Feature-based | - | Differential Privacy | - | | [<PUBLICATION>DualCF: Efficient Model Extraction Attack from Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/10.1145/3531146.3533188) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Counterfactual | Model Extraction | - | - | | [<PUBLICATION>Feature Inference Attack on Shapley Values</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3548606.3560573) | 2022 | _<CONFERENCE>CCS</CONFERENCE>_ | Shapley | Attribute/Feature Inference | Low-dimensional | - | | [<PUBLICATION>Evaluating the privacy exposure of interpretable global explainers</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/10063510/), [Privacy Risk of Global Explainers](https://ebooks.iospress.nl/doi/10.3233/FAIA220206) | 2022 | _<CONFERENCE>CogMI</CONFERENCE>_ | Interpretable Surrogates | Membership Inference | - | - | | [<PUBLICATION>Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy</PUBLICATION>](https://ieeexplore.ieee.org/document/9729808/) | 2022 | _IEEE Access_ | Example-based | - | Anonymisation | - | | [<PUBLICATION>On the amplification of security and privacy risks by post-hoc explanations in machine learning models</PUBLICATION>](https://arxiv.org/abs/2206.14004) | 2022 | _arXiv_ | Feature-based | Membership Inference | - | - | | [<PUBLICATION>Differentially Private Counterfactuals via Functional Mechanism</PUBLICATION>](https://arxiv.org/abs/2208.02878) | 2022 | _arXiv_ | Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Differentially Private Shapley Values for Data Evaluation</PUBLICATION>](https://arxiv.org/abs/2206.00511) | 2022 | _arXiv_ | Shapley | - | Differential Privacy | [[Code]](https://github.com/amiratag/DataShapley) | | [<PUBLICATION>Exploiting Explanations for Model Inversion Attacks</PUBLICATION>](https://openaccess.thecvf.com/content/<CONFERENCE>ICCV2021</CONFERENCE>/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_<CONFERENCE>ICCV_2021</CONFERENCE>_paper.html) | 2021 | _<CONFERENCE>ICCV</CONFERENCE>_ | Gradient-based, Interpretable Surrogates | Model Inversion | - | - | | [<PUBLICATION>On the Privacy Risks of Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3461702.3462533) | 2021 | <CONFERENCE>AIES</CONFERENCE> | Feature-based, Shapley, Counterfactual | Membership Inference | - | - | | [<PUBLICATION>Adversarial XAI Methods in Cybersecurity</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/9555622) | 2021 | TIFS | Counterfactual | Membership Inference | - | - | | [<PUBLICATION>MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</PUBLICATION>](https://arxiv.org/abs/2107.08909) | 2021 | _arXiv_ | Gradient-based | Model Extraction | - | [[Code]](https://github.com/cake-lab/datafree-model-extraction) | | [<PUBLICATION>Robust Counterfactual Explanations for Privacy-Preserving SVM</PUBLICATION>](https://www.diva-portal.org/smash/record.jsf?","[taxonomy](taxonomy1.png)](https://arxiv.org/abs/2404.00673)  ----------  ## Approaches  | **Title** | **Year** | **Venue** | **Target Explanations** | **Attacks** | **Defenses** | **Code** | | --------------- | :----: | ---- | :----: | :----: | :----: | :----: | | [Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack](https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG) | 2024 | _SP_ | Feature-based | Membership Inference | Differential Privacy, Privacy-Preserving Models, DP-SGD | - | | [Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks](https://arxiv.org/abs/2404.07139) | 2024 | _arXiv_ | Feature-based | Membership Inference | Game Theory | - | | [On the Privacy Risks of Algorithmic Recourse](https://proceedings.mlr.press/v206/pawelczyk23a.html) | 2023 | _AISTATS_ | Counterfactual | Membership Inference | Differential Privacy | - | | [The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks](https://dl.acm.org/doi/full/10.1145/3608482) | 2023 | _TIST_ | Counterfactual | Linkage | Anonymisaion | - | | [Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations](https://dl.acm.org/doi/abs/10.1145/3580305.3599343) | 2023 | _KDD_ | Counterfactual | - | Perturbation | [[Code]](https://github.com/isVy08/L2C/) | | [Private Graph Extraction via Feature Explanations](https://petsymposium.org/popets/2023/popets-2023-0041.pdf) | 2023 | _PETS_ | Feature-based | Graph Extraction | Perturbation | [[Code]](https://github.com/iyempissy/graph-stealing-attacks-with-explanation) | | [Privacy-Preserving Algorithmic Recourse](https://arxiv.org/abs/2311.14137) | 2023 | _ICAIF_ |  Counterfactual | - | Differential Privacy | - | | [Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage](https://arxiv.org/abs/2308.04341) | 2023 | _ICML-Workshop_ | Counterfactual | Membership Inference | Differential Privacy | - | | [Probabilistic Dataset Reconstruction from Interpretable Models](https://arxiv.org/abs/2308.15099) | 2023 | _arXiv_ | Interpretable Surrogates | Data Reconstruction | - | [[Code]](https://github.com/ferryjul/ProbabilisticDatasetsReconstruction) | | [DeepFixCX: Explainable privacy-preserving image compression for medical image analysis](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495) | 2023 | _WIREs-DMKD_ | Case-based | Identity recognition | Anonymisation | [[Code]](https://github.com/adgaudio/DeepFixCX) | | [XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models](https://eprint.iacr.org/2023/1859) | 2023 | _Preprint_ | Shapley | - | Multi-party Computation | - | | DP-XAI | 2023 | _Github_ | ALE plot | - | Differential Privacy | [[Code]](https://github.com/lange-martin/dp-global-xai) | | [Inferring Sensitive Attributes from Model Explanations](https://dl.acm.org/doi/abs/10.1145/3511808.3557362) | 2022 | _CIKM_ | Gradient-based, Perturbation-based | Attribute Inference | - | [[Code]](https://github.com/vasishtduddu/AttInfExplanations) | | [Model explanations with differential privacy](https://dl.acm.org/doi/abs/10.1145/3531146.3533235) | 2022 | _FAccT_ | Feature-based | - | Differential Privacy | - | | [DualCF: Efficient Model Extraction Attack from Counterfactual Explanations](https://dl.acm.org/doi/10.1145/3531146.3533188) | 2022 | _FAccT_ | Counterfactual | Model Extraction | - | - | | [Feature Inference Attack on Shapley Values](https://dl.acm.org/doi/abs/10.1145/3548606.3560573) | 2022 | _CCS_ | Shapley | Attribute/Feature Inference | Low-dimensional | - | | [Evaluating the privacy exposure of interpretable global explainers](https://ieeexplore.ieee.org/abstract/document/10063510/), [Privacy Risk of Global Explainers](https://ebooks.iospress.nl/doi/10.3233/FAIA220206) | 2022 | _CogMI_ | Interpretable Surrogates | Membership Inference | - | - | | [Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy](https://ieeexplore.ieee.org/document/9729808/) | 2022 | _IEEE Access_ | Example-based | - | Anonymisation | - | | [On the amplification of security and privacy risks by post-hoc explanations in machine learning models](https://arxiv.org/abs/2206.14004) | 2022 | _arXiv_ | Feature-based | Membership Inference | - | - | | [Differentially Private Counterfactuals via Functional Mechanism](https://arxiv.org/abs/2208.02878) | 2022 | _arXiv_ | Counterfactual | - | Differential Privacy | - | | [Differentially Private Shapley Values for Data Evaluation](https://arxiv.org/abs/2206.00511) | 2022 | _arXiv_ | Shapley | - | Differential Privacy | [[Code]](https://github.com/amiratag/DataShapley) | | [Exploiting Explanations for Model Inversion Attacks](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html) | 2021 | _ICCV_ | Gradient-based, Interpretable Surrogates | Model Inversion | - | - | | [On the Privacy Risks of Model Explanations](https://dl.acm.org/doi/abs/10.1145/3461702.3462533) | 2021 | AIES | Feature-based, Shapley, Counterfactual | Membership Inference | - | - | | [Adversarial XAI Methods in Cybersecurity](https://ieeexplore.ieee.org/abstract/document/9555622) | 2021 | TIFS | Counterfactual | Membership Inference | - | - | | [MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI](https://arxiv.org/abs/2107.08909) | 2021 | _arXiv_ | Gradient-based | Model Extraction | - | [[Code]](https://github.com/cake-lab/datafree-model-extraction) | | [Robust Counterfactual Explanations for Privacy-Preserving SVM](https://www.diva-portal.org/smash/record.jsf?
","[taxonomy](taxonomy1.png)](https://arxiv.org/abs/2404.00673)  ----------  ## Approaches  | **Title** | **Year** | **Venue** | **Target Explanations** | **Attacks** | **Defenses** | **Code** | | --------------- | :----: | ---- | :----: | :----: | :----: | :----: | | [<PUBLICATION>Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack</PUBLICATION>](https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG) | 2024 | _<CONFERENCE>SP</CONFERENCE>_ | Feature-based | Membership Inference | Differential Privacy, Privacy-Preserving Models, DP-SGD | - | | [<PUBLICATION>Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks</PUBLICATION>](https://arxiv.org/abs/2404.07139) | 2024 | _<CONFERENCE>arXiv</CONFERENCE>_ | Feature-based | Membership Inference | Game Theory | - | | [<PUBLICATION>On the Privacy Risks of Algorithmic Recourse</PUBLICATION>](https://proceedings.mlr.press/v206/pawelczyk23a.html) | 2023 | _<CONFERENCE>AISTATS</CONFERENCE>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks</PUBLICATION>](https://dl.acm.org/doi/full/10.1145/3608482) | 2023 | _<CONFERENCE>TIST</CONFERENCE>_ | Counterfactual | Linkage | Anonymisaion | - | | [<PUBLICATION>Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3580305.3599343) | 2023 | _<CONFERENCE>KDD</CONFERENCE>_ | Counterfactual | - | Perturbation | [[Code]](https://github.com/isVy08/<SOFTWARE>L2C</SOFTWARE>/) | | [<PUBLICATION>Private Graph Extraction via Feature Explanations</PUBLICATION>](https://petsymposium.org/popets/2023/popets-2023-0041.pdf) | 2023 | _<CONFERENCE>PETS</CONFERENCE>_ | Feature-based | Graph Extraction | Perturbation | [[Code]](https://github.com/iyempissy/<SOFTWARE>graph-stealing-attacks-with-explanation</SOFTWARE>) | | [<PUBLICATION>Privacy-Preserving Algorithmic Recourse</PUBLICATION>](https://arxiv.org/abs/2311.14137) | 2023 | _<CONFERENCE>ICAIF</CONFERENCE>_ |  Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</PUBLICATION>](https://arxiv.org/abs/2308.04341) | 2023 | _<WORKSHOP>ICML-Workshop</WORKSHOP>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>Probabilistic Dataset Reconstruction from Interpretable Models</PUBLICATION>](https://arxiv.org/abs/2308.15099) | 2023 | _<CONFERENCE>arXiv</CONFERENCE>_ | Interpretable Surrogates | Data Reconstruction | - | [[Code]](https://github.com/ferryjul/<SOFTWARE>ProbabilisticDatasetsReconstruction</SOFTWARE>) | | [<PUBLICATION>DeepFixCX: Explainable privacy-preserving image compression for medical image analysis</PUBLICATION>](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495) | 2023 | _<CONFERENCE>WIREs-DMKD</CONFERENCE>_ | Case-based | Identity recognition | Anonymisation | [[Code]](https://github.com/adgaudio/<SOFTWARE>DeepFixCX</SOFTWARE>) | | [<PUBLICATION>XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models</PUBLICATION>](https://eprint.iacr.org/2023/1859) | 2023 | _<CONFERENCE>Preprint</CONFERENCE>_ | Shapley | - | Multi-party Computation | - | | DP-XAI | 2023 | _<SOFTWARE>Github</SOFTWARE>_ | ALE plot | - | Differential Privacy | [[Code]](https://github.com/lange-martin/<SOFTWARE>dp-global-xai</SOFTWARE>) | | [<PUBLICATION>Inferring Sensitive Attributes from Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3511808.3557362) | 2022 | _<CONFERENCE>CIKM</CONFERENCE>_ | Gradient-based, Perturbation-based | Attribute Inference | - | [[Code]](https://github.com/vasishtduddu/<SOFTWARE>AttInfExplanations</SOFTWARE>) | | [<PUBLICATION>Model explanations with differential privacy</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3531146.3533235) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Feature-based | - | Differential Privacy | - | | [<PUBLICATION>DualCF: Efficient Model Extraction Attack from Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/10.1145/3531146.3533188) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Counterfactual | Model Extraction | - | - | | [<PUBLICATION>Feature Inference Attack on Shapley Values</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3548606.3560573) | 2022 | _<CONFERENCE>CCS</CONFERENCE>_ | Shapley | Attribute/Feature Inference | Low-dimensional | - | | [<PUBLICATION>Evaluating the privacy exposure of interpretable global explainers</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/10063510/), [<PUBLICATION>Privacy Risk of Global Explainers</PUBLICATION>](https://ebooks.iospress.nl/doi/10.3233/FAIA220206) | 2022 | _<CONFERENCE>CogMI</CONFERENCE>_ | Interpretable Surrogates | Membership Inference | - | - | | [<PUBLICATION>Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy</PUBLICATION>](https://ieeexplore.ieee.org/document/9729808/) | 2022 | _<CONFERENCE>IEEE Access</CONFERENCE>_ | Example-based | - | Anonymisation | - | | [<PUBLICATION>On the amplification of security and privacy risks by post-hoc explanations in machine learning models</PUBLICATION>](https://arxiv.org/abs/2206.14004) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Feature-based | Membership Inference | - | - | | [<PUBLICATION>Differentially Private Counterfactuals via Functional Mechanism</PUBLICATION>](https://arxiv.org/abs/2208.02878) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Differentially Private Shapley Values for Data Evaluation</PUBLICATION>](https://arxiv.org/abs/2206.00511) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Shapley | - | Differential Privacy | [[Code]](https://github.com/amiratag/<SOFTWARE>DataShapley</SOFTWARE>) | | [<PUBLICATION>Exploiting Explanations for Model Inversion Attacks</PUBLICATION>](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html) | 2021 | _<CONFERENCE>ICCV</CONFERENCE>_ | Gradient-based, Interpretable Surrogates | Model Inversion | - | - | | [<PUBLICATION>On the Privacy Risks of Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3461702.3462533) | 2021 | <CONFERENCE>AIES</CONFERENCE> | Feature-based, Shapley, Counterfactual | Membership Inference | - | - | | [<PUBLICATION>Adversarial XAI Methods in Cybersecurity</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/9555622) | 2021 | <CONFERENCE>TIFS</CONFERENCE> | Counterfactual | Membership Inference | - | - | | [<PUBLICATION>MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</PUBLICATION>](https://arxiv.org/abs/2107.08909) | 2021 | _<CONFERENCE>arXiv</CONFERENCE>_ | Gradient-based | Model Extraction | - | [[Code]](https://github.com/cake-lab/<SOFTWARE>datafree-model-extraction</SOFTWARE>) | | [<PUBLICATION>Robust Counterfactual Explanations for Privacy-Preserving SVM</PUBLICATION>](https://www.diva-portal.org/smash/record.jsf?
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\6e4b7d03.txt,0.999912579770959
20,"pid=diva2%3A1581005&dswid=5229), [Robust Explanations for Private Support Vector Machines](https://arxiv.org/abs/2102.03785) | 2021 | _ICML-Workshop_ | Counterfactual | - |  Private SVM | [[Code]](https://github.com/rami-mochaourab/robust-explanation-SVM) | | [When Differential Privacy Meets Interpretability: A Case Study](https://arxiv.org/abs/2106.13203) | 2021 | _RCV-CVPR_ | Interpretable Models | - | Differential Privacy | - | | [Differentially Private Quantiles](https://proceedings.mlr.press/v139/gillenwater21a.html) | 2021 | _ICML_ | Quantiles | - | Differential Privacy | [[Code]](https://github.com/google-research/google-research/tree/master/dp_multiq) | | [FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media](https://ieeexplore.ieee.org/document/9647778) | 2021 | _PST_ | - | Attribute Inference | Privacy-Protecting Explanation | - | | [Privacy-preserving generative adversarial network for case-based explainability in medical image analysis](https://ieeexplore.ieee.org/abstract/document/9598877/) | 2021 | _IEEE Access_ | Example-based | - | Generative Anonymisation | - | | [Interpretable and Differentially Private Predictions](https://ojs.aaai.org/index.php/AAAI/article/view/5827) | 2020 | _AAAI_ | Locally linear maps | - | Differential Privacy | [[Code]](https://github.com/frhrdr/dp-llm) | | [Model extraction from counterfactual explanations](https://arxiv.org/abs/2009.01884) | 2020 | _arXiv_ | Counterfactual | Model Extraction | - | [[Code]](https://github.com/aivodji/mrce) | | [Model Reconstruction from Model Explanations](https://dl.acm.org/doi/10.1145/3287560.3287562) | 2019 | _FAT*_ | Gradient-based | Model Reconstruction, Model Extraction | - | - | | [Interpret Federated Learning with Shapley Values](https://arxiv.org/abs/1905.04519) | 2019 | __ |  Shapley | - | Federated | [[Code]](https://github.com/crownpku/federated_shap) | | [Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation](https://dl.acm.org/doi/10.1145/3308560.3317586) | 2019 | _WWW_ | Feature-based | - | Collaborative rule-based model | - | | [Model inversion attacks that exploit confidence information and basic countermeasures](https://dl.acm.org/doi/abs/10.1145/2810103.2813677) | 2015 | _CCS_ | Confidence scores | Reconstruction, Model Inversion | - | - |  ----------  ## Datasets  ### Type: Image | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [MNIST](www.kaggle.com/datasets/hojjatk/mnist-dataset) | 70K | 11MB | Counterfactuals, Gradient | 4 | | [CIFAR](www.cs.toronto.edu/~kriz/cifar.html) | 60K | 163MB | Gradient | 4 | | [SVHN](ufldl.stanford.edu/housenumbers/) | 600K | 400MB+ | Gradient | 1 | | [Food101](www.kaggle.com/datasets/dansbecker/food-101) | 100K+ | 10GB | Case-based | 1 | | [Flowers102](www.robots.ox.ac.uk/~vgg/data/flowers/102/) | 8K+ | 300MB+ | Case-based | 1 | | [Cervical](www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening) | 8K+ | 46GB+ | Case-based, Interpretable Models | 1 | | [CheXpert](stanfordmlgroup.github.io/competitions/chexpert/) | 220K+ | GBs | Black-box | 1 | | [Facial Expression](www.kaggle.com/datasets/msambare/fer2013) | 12K+ | 63MB | Gradient | 1 | | [Celeb](mmlab.ie.cuhk.edu.hk/projects/CelebA.html) | 200K | GBs | Counterfactuals, Shapley, Gradient, Perturbation | 1 |  ### Type: Tablular | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [Adult](archive.ics.uci.edu/ml/datasets/adult) | 48K+ | 10MB | Counterfactuals, Shapley | 10+ | | [COMPAS](www.kaggle.com/datasets/danofer/compass) | 7K+ | 25MB | Counterfactuals, Shapley | 2 | | [FICO](community.fico.com/s/explainable-machine-learning-challenge) | 10K+ | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [Boston Housing](www.kaggle.com/code/prasadperera/the-boston-housing-dataset) | 500+ | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [German Credit](archive.ics.uci.edu/dataset/144/statlog+german+credit+data) | 1K | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [Student Admission](www.kaggle.com/datasets/mohansacharya/graduate-admissions) | 500 | ‚â§ 1MB | Counterfactuals, Shapley, Gradient, Perturbation | 1 | | [Student Performance](www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression) | 10K | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [GMSC](www.kaggle.com/c/GiveMeSomeCredit/data) | 150K+ | 15MB | Interpretable models, Counterfactuals | 2 | | [Diabetes](archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) | 100K+ | 20MB | Feature-based | 5 | | [Breast Cancer](archive.ics.uci.edu/ml/datasets/breast+cancer) | 569 | < 1MB | Feature-based | 1 |  ### Type: Graph | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [Cora](relational.fit.cvut.cz/dataset/CORA) | 2K+ | 4.5MB | Feature-based | 1 | | [Bitcoin](snap.stanford.edu/data/soc-sign-bitcoin-alpha.html) | 30K | ‚â§ 1MB | Counterfactuals | 1 | | [CIC-IDS2017](www.unb.ca/cic/datasets/ids-2017.html) | 2.8M+ | 500MB | Black-box | 1 |  ### Type: Text | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [IMDB Review](ai.stanford.edu/~amaas/data/sentiment/) | 50K | 66MB | Black-box | 1 |  ---------- ## Evaluation Metrics  | **Category**           | **Evaluation Metrics**                    | **Formula/Description**    | **Usage**                | |-----------|-----------|---------|---------------| | **Explanation Utility** | Counterfactual validity | $\text{Pureness} = \frac{\text{no. value combinations with desired outcome}}{\text{no. value combinations}}$        |  <div style=""width:500px""> Assess the range of attribute values within k-anonymous counterfactual instances.","pid=diva2%3A1581005&dswid=5229), [<PUBLICATION>Robust Explanations for Private Support Vector Machines</PUBLICATION>](https://arxiv.org/abs/2102.03785) | 2021 | _<WORKSHOP>ICML-Workshop</WORKSHOP>_ | Counterfactual | - |  Private SVM | [[Code]](https://github.com/rami-mochaourab/robust-explanation-SVM) | | [<PUBLICATION>When Differential Privacy Meets Interpretability: A Case Study</PUBLICATION>](https://arxiv.org/abs/2106.13203) | 2021 | _<WORKSHOP>RCV-CVPR</WORKSHOP><CONFERENCE>CVPR</CONFERENCE>_ | Interpretable Models | - | Differential Privacy | - | | [<PUBLICATION>Differentially Private Quantiles</PUBLICATION>](https://proceedings.mlr.press/v139/gillenwater21a.html) | 2021 | _<CONFERENCE>ICML</CONFERENCE>_ | Quantiles | - | Differential Privacy | [[Code]](https://github.com/google-research/google-research/tree/master/dp_multiq) | | [<PUBLICATION>FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media</PUBLICATION>](https://ieeexplore.ieee.org/document/9647778) | 2021 | _PST_ | - | Attribute Inference | Privacy-Protecting Explanation | - | | [<PUBLICATION>Privacy-preserving generative adversarial network for case-based explainability in medical image analysis</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/9598877/) | 2021 | _IEEE Access_ | Example-based | - | Generative Anonymisation | - | | [<PUBLICATION>Interpretable and Differentially Private Predictions</PUBLICATION>](https://ojs.aaai.org/index.php/AAAI/article/view/5827) | 2020 | _<CONFERENCE>AAAI</CONFERENCE>_ | Locally linear maps | - | Differential Privacy | [[Code]](https://github.com/frhrdr/dp-llm) | | [<PUBLICATION>Model extraction from counterfactual explanations</PUBLICATION>](https://arxiv.org/abs/2009.01884) | 2020 | _arXiv_ | Counterfactual | Model Extraction | - | [[Code]](https://github.com/aivodji/mrce) | | [<PUBLICATION>Model Reconstruction from Model Explanations</PUBLICATION>](https://dl.acm.org/doi/10.1145/3287560.3287562) | 2019 | _<CONFERENCE>FAT*</CONFERENCE>_ | Gradient-based | Model Reconstruction, Model Extraction | - | - | | [<PUBLICATION>Interpret Federated Learning with Shapley Values</PUBLICATION>](https://arxiv.org/abs/1905.04519) | 2019 | __ |  Shapley | - | Federated | [[Code]](https://github.com/crownpku/federated_shap) | | [<PUBLICATION>Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation</PUBLICATION>](https://dl.acm.org/doi/10.1145/3308560.3317586) | 2019 | _<CONFERENCE>WWW</CONFERENCE>_ | Feature-based | - | Collaborative rule-based model | - | | [<PUBLICATION>Model inversion attacks that exploit confidence information and basic countermeasures</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/2810103.2813677) | 2015 | _<CONFERENCE>CCS</CONFERENCE>_ | Confidence scores | Reconstruction, Model Inversion | - | - |  ----------  ## Datasets  ### Type: Image | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>MNIST</DATASET>](www.kaggle.com/datasets/hojjatk/<DATASET>mnist</DATASET>-dataset) | 70K | 11MB | Counterfactuals, Gradient | 4 | | [<DATASET>CIFAR</DATASET>](www.cs.toronto.edu/~kriz/<DATASET>cifar</DATASET>.html) | 60K | 163MB | Gradient | 4 | | [<DATASET>SVHN</DATASET>](ufldl.stanford.edu/housenumbers/) | 600K | 400MB+ | Gradient | 1 | | [<DATASET>Food101</DATASET>](www.kaggle.com/datasets/dansbecker/<DATASET>food-101</DATASET>) | 100K+ | 10GB | Case-based | 1 | | [<DATASET>Flowers102</DATASET>](www.robots.ox.ac.uk/~vgg/data/flowers/102/) | 8K+ | 300MB+ | Case-based | 1 | | [<DATASET>Cervical</DATASET>](www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening) | 8K+ | 46GB+ | Case-based, Interpretable Models | 1 | | [<DATASET>CheXpert</DATASET>](stanfordmlgroup.github.io/competitions/<DATASET>chexpert</DATASET>/) | 220K+ | GBs | Black-box | 1 | | [<DATASET>Facial Expression</DATASET>](www.kaggle.com/datasets/msambare/<DATASET>fer2013</DATASET>) | 12K+ | 63MB | Gradient | 1 | | [<DATASET>Celeb</DATASET>](mmlab.ie.cuhk.edu.hk/projects/<DATASET>CelebA</DATASET>.html) | 200K | GBs | Counterfactuals, Shapley, Gradient, Perturbation | 1 |  ### Type: Tablular | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>Adult</DATASET>](archive.ics.uci.edu/ml/datasets/adult) | 48K+ | 10MB | Counterfactuals, Shapley | 10+ | | [<DATASET>COMPAS</DATASET>](www.kaggle.com/datasets/danofer/compass) | 7K+ | 25MB | Counterfactuals, Shapley | 2 | | [<DATASET>FICO</DATASET>](community.fico.com/s/explainable-machine-learning-challenge) | 10K+ | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [<DATASET>Boston Housing</DATASET>](www.kaggle.com/code/prasadperera/the-boston-housing-dataset) | 500+ | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [<DATASET>German Credit</DATASET>](archive.ics.uci.edu/dataset/144/statlog+german+credit+data) | 1K | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [<DATASET>Student Admission</DATASET>](www.kaggle.com/datasets/mohansacharya/graduate-admissions) | 500 | ‚â§ 1MB | Counterfactuals, Shapley, Gradient, Perturbation | 1 | | [<DATASET>Student Performance</DATASET>](www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression) | 10K | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [<DATASET>GMSC</DATASET>](www.kaggle.com/c/<DATASET>GiveMeSomeCredit</DATASET>/data) | 150K+ | 15MB | Interpretable models, Counterfactuals | 2 | | [<DATASET>Diabetes</DATASET>](archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) | 100K+ | 20MB | Feature-based | 5 | | [<DATASET>Breast Cancer</DATASET>](archive.ics.uci.edu/ml/datasets/breast+cancer) | 569 | < 1MB | Feature-based | 1 |  ### Type: Graph | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>Cora</DATASET>](relational.fit.cvut.cz/dataset/<DATASET>CORA</DATASET>) | 2K+ | 4.5MB | Feature-based | 1 | | [<DATASET>Bitcoin</DATASET>](snap.stanford.edu/data/soc-sign-bitcoin-alpha.html) | 30K | ‚â§ 1MB | Counterfactuals | 1 | | [<DATASET>CIC-IDS2017</DATASET>](www.unb.ca/cic/datasets/<DATASET>ids-2017</DATASET>.html) | 2.8M+ | 500MB | Black-box | 1 |  ### Type: Text | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>IMDB Review</DATASET>](ai.stanford.edu/~amaas/data/sentiment/) | 50K | 66MB | Black-box | 1 |  ---------- ## Evaluation Metrics  | **Category**           | **Evaluation Metrics**                    | **Formula/Description**    | **Usage**                | |-----------|-----------|---------|---------------| | **Explanation Utility** | <EVALMETRIC>Counterfactual validity</EVALMETRIC> | $\text{Pureness} = \frac{\text{no. value combinations with desired outcome}}{\text{no. value combinations}}$        |  <div style=""width:500px""> Assess the range of attribute values within k-anonymous counterfactual instances.","pid=diva2%3A1581005&dswid=5229), [Robust Explanations for Private Support Vector Machines](https://arxiv.org/abs/2102.03785) | 2021 | _ICML-Workshop_ | Counterfactual | - |  Private SVM | [[Code]](https://github.com/rami-mochaourab/robust-explanation-SVM) | | [When Differential Privacy Meets Interpretability: A Case Study](https://arxiv.org/abs/2106.13203) | 2021 | _RCV-CVPR_ | Interpretable Models | - | Differential Privacy | - | | [Differentially Private Quantiles](https://proceedings.mlr.press/v139/gillenwater21a.html) | 2021 | _ICML_ | Quantiles | - | Differential Privacy | [[Code]](https://github.com/google-research/google-research/tree/master/dp_multiq) | | [FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media](https://ieeexplore.ieee.org/document/9647778) | 2021 | _PST_ | - | Attribute Inference | Privacy-Protecting Explanation | - | | [Privacy-preserving generative adversarial network for case-based explainability in medical image analysis](https://ieeexplore.ieee.org/abstract/document/9598877/) | 2021 | _IEEE Access_ | Example-based | - | Generative Anonymisation | - | | [Interpretable and Differentially Private Predictions](https://ojs.aaai.org/index.php/AAAI/article/view/5827) | 2020 | _AAAI_ | Locally linear maps | - | Differential Privacy | [[Code]](https://github.com/frhrdr/dp-llm) | | [Model extraction from counterfactual explanations](https://arxiv.org/abs/2009.01884) | 2020 | _arXiv_ | Counterfactual | Model Extraction | - | [[Code]](https://github.com/aivodji/mrce) | | [Model Reconstruction from Model Explanations](https://dl.acm.org/doi/10.1145/3287560.3287562) | 2019 | _FAT*_ | Gradient-based | Model Reconstruction, Model Extraction | - | - | | [Interpret Federated Learning with Shapley Values](https://arxiv.org/abs/1905.04519) | 2019 | __ |  Shapley | - | Federated | [[Code]](https://github.com/crownpku/federated_shap) | | [Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation](https://dl.acm.org/doi/10.1145/3308560.3317586) | 2019 | _WWW_ | Feature-based | - | Collaborative rule-based model | - | | [Model inversion attacks that exploit confidence information and basic countermeasures](https://dl.acm.org/doi/abs/10.1145/2810103.2813677) | 2015 | _CCS_ | Confidence scores | Reconstruction, Model Inversion | - | - |  ----------  ## Datasets  ### Type: Image | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [MNIST](www.kaggle.com/datasets/hojjatk/mnist-dataset) | 70K | 11MB | Counterfactuals, Gradient | 4 | | [CIFAR](www.cs.toronto.edu/~kriz/cifar.html) | 60K | 163MB | Gradient | 4 | | [SVHN](ufldl.stanford.edu/housenumbers/) | 600K | 400MB+ | Gradient | 1 | | [Food101](www.kaggle.com/datasets/dansbecker/food-101) | 100K+ | 10GB | Case-based | 1 | | [Flowers102](www.robots.ox.ac.uk/~vgg/data/flowers/102/) | 8K+ | 300MB+ | Case-based | 1 | | [Cervical](www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening) | 8K+ | 46GB+ | Case-based, Interpretable Models | 1 | | [CheXpert](stanfordmlgroup.github.io/competitions/chexpert/) | 220K+ | GBs | Black-box | 1 | | [Facial Expression](www.kaggle.com/datasets/msambare/fer2013) | 12K+ | 63MB | Gradient | 1 | | [Celeb](mmlab.ie.cuhk.edu.hk/projects/CelebA.html) | 200K | GBs | Counterfactuals, Shapley, Gradient, Perturbation | 1 |  ### Type: Tablular | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [Adult](archive.ics.uci.edu/ml/datasets/adult) | 48K+ | 10MB | Counterfactuals, Shapley | 10+ | | [COMPAS](www.kaggle.com/datasets/danofer/compass) | 7K+ | 25MB | Counterfactuals, Shapley | 2 | | [FICO](community.fico.com/s/explainable-machine-learning-challenge) | 10K+ | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [Boston Housing](www.kaggle.com/code/prasadperera/the-boston-housing-dataset) | 500+ | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [German Credit](archive.ics.uci.edu/dataset/144/statlog+german+credit+data) | 1K | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [Student Admission](www.kaggle.com/datasets/mohansacharya/graduate-admissions) | 500 | ‚â§ 1MB | Counterfactuals, Shapley, Gradient, Perturbation | 1 | | [Student Performance](www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression) | 10K | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [GMSC](www.kaggle.com/c/GiveMeSomeCredit/data) | 150K+ | 15MB | Interpretable models, Counterfactuals | 2 | | [Diabetes](archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) | 100K+ | 20MB | Feature-based | 5 | | [Breast Cancer](archive.ics.uci.edu/ml/datasets/breast+cancer) | 569 | < 1MB | Feature-based | 1 |  ### Type: Graph | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [Cora](relational.fit.cvut.cz/dataset/CORA) | 2K+ | 4.5MB | Feature-based | 1 | | [Bitcoin](snap.stanford.edu/data/soc-sign-bitcoin-alpha.html) | 30K | ‚â§ 1MB | Counterfactuals | 1 | | [CIC-IDS2017](www.unb.ca/cic/datasets/ids-2017.html) | 2.8M+ | 500MB | Black-box | 1 |  ### Type: Text | Dataset | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [IMDB Review](ai.stanford.edu/~amaas/data/sentiment/) | 50K | 66MB | Black-box | 1 |  ---------- ## Evaluation Metrics  | **Category**           | **Evaluation Metrics**                    | **Formula/Description**    | **Usage**                | |-----------|-----------|---------|---------------| | **Explanation Utility** | Counterfactual validity | $\text{Pureness} = \frac{\text{no. value combinations with desired outcome}}{\text{no. value combinations}}$        |  <div style=""width:500px""> Assess the range of attribute values within k-anonymous counterfactual instances.
","pid=diva2%3A1581005&dswid=5229), [<PUBLICATION>Robust Explanations for Private Support Vector Machines</PUBLICATION>](https://arxiv.org/abs/2102.03785) | 2021 | _<WORKSHOP>ICML-Workshop</WORKSHOP>_ | Counterfactual | - |  Private SVM | [[<SOFTWARE>Code</SOFTWARE>]](https://github.com/rami-mochaourab/robust-explanation-SVM) | | [<PUBLICATION>When Differential Privacy Meets Interpretability: A Case Study</PUBLICATION>](https://arxiv.org/abs/2106.13203) | 2021 | _<CONFERENCE>RCV-CVPR</CONFERENCE>_ | Interpretable Models | - | Differential Privacy | - | | [<PUBLICATION>Differentially Private Quantiles</PUBLICATION>](https://proceedings.mlr.press/v139/gillenwater21a.html) | 2021 | _<CONFERENCE>ICML</CONFERENCE>_ | Quantiles | - | Differential Privacy | [[<SOFTWARE>Code</SOFTWARE>]](https://github.com/google-research/google-research/tree/master/dp_multiq) | | [<PUBLICATION>FOX: Fooling with Explanations : Privacy Protection with Adversarial Reactions in Social Media</PUBLICATION>](https://ieeexplore.ieee.org/document/9647778) | 2021 | _<CONFERENCE>PST</CONFERENCE>_ | - | Attribute Inference | Privacy-Protecting Explanation | - | | [<PUBLICATION>Privacy-preserving generative adversarial network for case-based explainability in medical image analysis</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/9598877/) | 2021 | _<PUBLICATION>IEEE Access</PUBLICATION>_ | Example-based | - | Generative Anonymisation | - | | [<PUBLICATION>Interpretable and Differentially Private Predictions</PUBLICATION>](https://ojs.aaai.org/index.php/AAAI/article/view/5827) | 2020 | _<CONFERENCE>AAAI</CONFERENCE>_ | Locally linear maps | - | Differential Privacy | [[<SOFTWARE>Code</SOFTWARE>]](https://github.com/frhrdr/dp-llm) | | [<PUBLICATION>Model extraction from counterfactual explanations</PUBLICATION>](https://arxiv.org/abs/2009.01884) | 2020 | _<PUBLICATION>arXiv</PUBLICATION>_ | Counterfactual | Model Extraction | - | [[<SOFTWARE>Code</SOFTWARE>]](https://github.com/aivodji/mrce) | | [<PUBLICATION>Model Reconstruction from Model Explanations</PUBLICATION>](https://dl.acm.org/doi/10.1145/3287560.3287562) | 2019 | _<CONFERENCE>FAT*</CONFERENCE>_ | Gradient-based | Model Reconstruction, Model Extraction | - | - | | [<PUBLICATION>Interpret Federated Learning with Shapley Values</PUBLICATION>](https://arxiv.org/abs/1905.04519) | 2019 | __ |  Shapley | - | Federated | [[<SOFTWARE>Code</SOFTWARE>]](https://github.com/crownpku/federated_shap) | | [<PUBLICATION>Collaborative Explanation of Deep Models with Limited Interaction for Trade Secret and Privacy Preservation</PUBLICATION>](https://dl.acm.org/doi/10.1145/3308560.3317586) | 2019 | _<CONFERENCE>WWW</CONFERENCE>_ | Feature-based | - | Collaborative rule-based model | - | | [<PUBLICATION>Model inversion attacks that exploit confidence information and basic countermeasures</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/2810103.2813677) | 2015 | _<CONFERENCE>CCS</CONFERENCE>_ | Confidence scores | Reconstruction, Model Inversion | - | - |  ----------  ## <DATASET>Datasets</DATASET>  ### Type: Image | <DATASET>Dataset</DATASET> | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>MNIST</DATASET>](www.kaggle.com/datasets/hojjatk/mnist-dataset) | 70K | 11MB | Counterfactuals, Gradient | 4 | | [<DATASET>CIFAR</DATASET>](www.cs.toronto.edu/~kriz/cifar.html) | 60K | 163MB | Gradient | 4 | | [<DATASET>SVHN</DATASET>](ufldl.stanford.edu/housenumbers/) | 600K | 400MB+ | Gradient | 1 | | [<DATASET>Food101</DATASET>](www.kaggle.com/datasets/dansbecker/food-101) | 100K+ | 10GB | Case-based | 1 | | [<DATASET>Flowers102</DATASET>](www.robots.ox.ac.uk/~vgg/data/flowers/102/) | 8K+ | 300MB+ | Case-based | 1 | | [<DATASET>Cervical</DATASET>](www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening) | 8K+ | 46GB+ | Case-based, Interpretable Models | 1 | | [<DATASET>CheXpert</DATASET>](stanfordmlgroup.github.io/competitions/chexpert/) | 220K+ | GBs | Black-box | 1 | | [<DATASET>Facial Expression</DATASET>](www.kaggle.com/datasets/msambare/fer2013) | 12K+ | 63MB | Gradient | 1 | | [<DATASET>Celeb</DATASET>](mmlab.ie.cuhk.edu.hk/projects/CelebA.html) | 200K | GBs | Counterfactuals, Shapley, Gradient, Perturbation | 1 |  ### Type: Tablular | <DATASET>Dataset</DATASET> | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>Adult</DATASET>](archive.ics.uci.edu/ml/datasets/adult) | 48K+ | 10MB | Counterfactuals, Shapley | 10+ | | [<DATASET>COMPAS</DATASET>](www.kaggle.com/datasets/danofer/compass) | 7K+ | 25MB | Counterfactuals, Shapley | 2 | | [<DATASET>FICO</DATASET>](community.fico.com/s/explainable-machine-learning-challenge) | 10K+ | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [<DATASET>Boston Housing</DATASET>](www.kaggle.com/code/prasadperera/the-boston-housing-dataset) | 500+ | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [<DATASET>German Credit</DATASET>](archive.ics.uci.edu/dataset/144/statlog+german+credit+data) | 1K | ‚â§ 1MB | Counterfactuals, Shapley | 4 | | [<DATASET>Student Admission</DATASET>](www.kaggle.com/datasets/mohansacharya/graduate-admissions) | 500 | ‚â§ 1MB | Counterfactuals, Shapley, Gradient, Perturbation | 1 | | [<DATASET>Student Performance</DATASET>](www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression) | 10K | ‚â§ 1MB | Counterfactuals, Shapley | 1 | | [<DATASET>GMSC</DATASET>](www.kaggle.com/c/GiveMeSomeCredit/data) | 150K+ | 15MB | Interpretable models, Counterfactuals | 2 | | [<DATASET>Diabetes</DATASET>](archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) | 100K+ | 20MB | Feature-based | 5 | | [<DATASET>Breast Cancer</DATASET>](archive.ics.uci.edu/ml/datasets/breast+cancer) | 569 | < 1MB | Feature-based | 1 |  ### Type: Graph | <DATASET>Dataset</DATASET> | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>Cora</DATASET>](relational.fit.cvut.cz/dataset/CORA) | 2K+ | 4.5MB | Feature-based | 1 | | [<DATASET>Bitcoin</DATASET>](snap.stanford.edu/data/soc-sign-bitcoin-alpha.html) | 30K | ‚â§ 1MB | Counterfactuals | 1 | | [<DATASET>CIC-IDS2017</DATASET>](www.unb.ca/cic/datasets/ids-2017.html) | 2.8M+ | 500MB | Black-box | 1 |  ### Type: Text | <DATASET>Dataset</DATASET> | #Items | Disk Size | Downstream Explanations | #Papers Used | | :-- | --- | --- | --- | --- | | [<DATASET>IMDB Review</DATASET>](ai.stanford.edu/~amaas/data/sentiment/) | 50K | 66MB | Black-box | 1 |  ---------- ## <EVALMETRIC>Evaluation Metrics</EVALMETRIC>  | **Category**           | **<EVALMETRIC>Evaluation Metrics</EVALMETRIC>**                    | **Formula/Description**    | **Usage**                | |-----------|-----------|---------|---------------| | **Explanation Utility** | <EVALMETRIC>Counterfactual validity</EVALMETRIC> | $\text{Pureness} = \frac{\text{no. value combinations with desired outcome}}{\text{no. value combinations}}$        |  <div style=""width:500px""> Assess the range of attribute values within k-anonymous counterfactual instances.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\d48ec8e4.txt,0.9999145372190411
21,"Consider all attributes, including those beyond quasi-identifiers  </div>                                                                     | |                        | Classification metric | $CM = \frac{\sum\limits_{i=1}^{N} \text{penalty}(tuple_i)}{N}$                                                             | <div style=""width:500px""> Assess equivalence classes within anonymized datasets, focusing on class label uniformity.","Consider all attributes, including those beyond quasi-identifiers  </div>                                                                     | |                        | <EVALMETRIC>Classification metric</EVALMETRIC> | $CM = \frac{\sum\limits_{i=1}^{N} \text{penalty}(tuple_i)}{N}$                                                             | <div style=""width:500px""> Assess equivalence classes within anonymized datasets, focusing on class label uniformity.","Consider all attributes, including those beyond quasi-identifiers  </div>                                                                     | |                        | Classification metric | $CM = \frac{\sum\limits_{i=1}^{N} \text{penalty}(tuple_i)}{N}$                                                             | <div style=""width:500px""> Assess equivalence classes within anonymized datasets, focusing on class label uniformity.","Consider all attributes, including those beyond quasi-identifiers  </div>                                                                     | |                        | Classification metric | $CM = \frac{\sum\limits_{i=1}^{N} \text{penalty}(tuple_i)}{N}$                                                             | <div style=""width:500px""> Assess equivalence classes within anonymized datasets, focusing on class label uniformity.",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\a10dc6b2.txt,1.0
22,"</div>                                        | |                        | Faithfulness </br> (RDT-Fidelity) | $\mathcal{F}(\mathcal{E}_X)$ (see our paper) | <div style=""width:500px""> Reflect how often the model's predictions are unchanged despite perturbations to the input, which would suggest that the explanation is effectively capturing the reasoning behind the model's predictions.","</div>                                        | |                        | <EVALMETRIC>Faithfulness</EVALMETRIC> </br> (<EVALMETRIC>RDT-Fidelity</EVALMETRIC>) | $\mathcal{F}(\mathcal{E}_X)$ (see our paper) | <div style=""width:500px""> Reflect how often the model's predictions are unchanged despite perturbations to the input, which would suggest that the explanation is effectively capturing the reasoning behind the model's predictions.","</div>                                        | |                        | Faithfulness </br> (RDT-Fidelity) | $\mathcal{F}(\mathcal{E}_X)$ (see our paper) | <div style=""width:500px""> Reflect how often the model's predictions are unchanged despite perturbations to the input, which would suggest that the explanation is effectively capturing the reasoning behind the model's predictions.
","</div>                                        | |                        | <EVALMETRIC>Faithfulness</EVALMETRIC> </br> (<EVALMETRIC>RDT-Fidelity</EVALMETRIC>) | $\mathcal{F}(\mathcal{E}_X)$ (see our paper) | <div style=""width:500px""> Reflect how often the model's predictions are unchanged despite perturbations to the input, which would suggest that the explanation is effectively capturing the reasoning behind the model's predictions.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\08ae9759.txt,0.9987096774193548
23,"</div>          | |                        | Sparsity | $H(p) = -\sum_{f \in M} p(f) \log p(f)$                                                                              | <div style=""width:500px""> A complete and faithful explanation to the model should inherently be sparse, focusing only on a select subset of features that are most predictive of the model's decision.","</div>          | |                        | <EVALMETRIC>Sparsity</EVALMETRIC> | $H(p) = -\sum_{f \in M} p(f) \log p(f)$                                                                              | <div style=""width:500px""> A complete and faithful explanation to the model should inherently be sparse, focusing only on a select subset of features that are most predictive of the model's decision.","</div>          | |                        | Sparsity | $H(p) = -\sum_{f \in M} p(f) \log p(f)$                                                                              | <div style=""width:500px""> A complete and faithful explanation to the model should inherently be sparse, focusing only on a select subset of features that are most predictive of the model's decision.
","</div>          | |                        | Sparsity | $H(p) = -\sum_{f \in M} p(f) \log p(f)$                                                                              | <div style=""width:500px""> A complete and faithful explanation to the model should inherently be sparse, focusing only on a select subset of features that are most predictive of the model's decision.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\f2af487e.txt,0.998661311914324
24,"</div>            | | **Information Loss**   | Normalised Certainty Penalty </br> (NCP) | $\text{NCP}(G) = \sum\limits_{i=1}^{d} w_i \cdot \text{NCP}_{A_i}(G)$                                                       | <div style=""width:500px""> Higher NCP values indicate a greater degree of generalization and more information loss.","</div>            | | **Information Loss**   | <EVALMETRIC>Normalised Certainty Penalty</EVALMETRIC> </br> (<EVALMETRIC>NCP</EVALMETRIC>) | $\text{<EVALMETRIC>NCP</EVALMETRIC>}(G) = \sum\limits_{i=1}^{d} w_i \cdot \text{<EVALMETRIC>NCP</EVALMETRIC>}_{A_i}(G)$                                                       | <div style=""width:500px""> Higher <EVALMETRIC>NCP</EVALMETRIC> values indicate a greater degree of generalization and more information loss.","</div>            | | **Information Loss**   | Normalised Certainty Penalty </br> (NCP) | $\text{NCP}(G) = \sum\limits_{i=1}^{d} w_i \cdot \text{NCP}_{A_i}(G)$                                                       | <div style=""width:500px""> Higher NCP values indicate a greater degree of generalization and more information loss.
","</div>            | | **Information Loss**   | Normalised Certainty Penalty </br> (NCP) | $\text{NCP}(G) = \sum\limits_{i=1}^{d} w_i \cdot \text{NCP}_{A_i}(G)$                                                       | <div style=""width:500px""> Higher <EVALMETRIC>NCP</EVALMETRIC> values indicate a greater degree of generalization and more information loss.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\493be6a1.txt,0.9984871406959153
27,"\|E\| \geq k} \|E\|^2 + \sum_{VE \,s.t.\, \|E\| < k} \|D\|\|E\|$ </div>                            | <div style=""width:500px""> Measure the penalties on tuples in a dataset after k-anonymization, reflecting how indistinguishable they are post-anonymization                                                  </div>                                        | |                        | Approximation Loss | <div style=""width:300px""> $\mathcal{E}(\hat{\phi}, \mathcal{Z}, f(X)) \triangleq \mathbb{E} [\mathcal{L}(\hat{\phi}, \mathcal{Z}, f(X)) - \mathcal{L}(\phi^*, \mathcal{Z}, f(X))].$  </div>         | <div style=""width:500px""> Measure the error caused by randomness added when minimizing the privacy loss as the expected deviation of the randomized explanation from the best local approximation                    </div>                               | |                        | Explanation Intersection | <div style=""width:300px""> The percentage of bits in the original explanation that is retained in the privatised explanation after using differential privacy </div> | <div style=""width:500px""> The higher the better but due to privacy-utility trade-off, this metric should not be 100%.","\|E\| \geq k} \|E\|^2 + \sum_{VE \,s.t.\, \|E\| < k} \|D\|\|E\|$ </div>                            | <div style=""width:500px""> Measure the penalties on tuples in a dataset after k-anonymization, reflecting how indistinguishable they are post-anonymization                                                  </div>                                        | |                        | Approximation Loss | <div style=""width:300px""> $\mathcal{E}(\hat{\phi}, \mathcal{Z}, f(X)) \triangleq \mathbb{E} [\mathcal{L}(\hat{\phi}, \mathcal{Z}, f(X)) - \mathcal{L}(\phi^*, \mathcal{Z}, f(X))].$  </div>         | <div style=""width:500px""> Measure the error caused by randomness added when minimizing the privacy loss as the expected deviation of the randomized explanation from the best local approximation                    </div>                               | |                        | Explanation Intersection | <div style=""width:300px""> The percentage of bits in the original explanation that is retained in the privatised explanation after using differential privacy </div> | <div style=""width:500px""> The higher the better but due to privacy-utility trade-off, this metric should not be 100%.","\|E\| \geq k} \|E\|^2 + \sum_{VE \,s.t.\, \|E\| < k} \|D\|\|E\|$ </div>                            | <div style=""width:500px""> Measure the penalties on tuples in a dataset after k-anonymization, reflecting how indistinguishable they are post-anonymization                                                  </div>                                        | |                        | Approximation Loss | <div style=""width:300px""> $\mathcal{E}(\hat{\phi}, \mathcal{Z}, f(X)) \triangleq \mathbb{E} [\mathcal{L}(\hat{\phi}, \mathcal{Z}, f(X)) - \mathcal{L}(\phi^*, \mathcal{Z}, f(X))].$  </div>         | <div style=""width:500px""> Measure the error caused by randomness added when minimizing the privacy loss as the expected deviation of the randomized explanation from the best local approximation                    </div>                               | |                        | Explanation Intersection | <div style=""width:300px""> The percentage of bits in the original explanation that is retained in the privatised explanation after using differential privacy </div> | <div style=""width:500px""> The higher the better but due to privacy-utility trade-off, this metric should not be 100%.
","\|E\| \geq k} \|E\|^2 + \sum_{VE \,s.t.\, \|E\| < k} \|D\|\|E\|$ </div>                            | <div style=""width:500px""> Measure the penalties on tuples in a <DATASET>dataset</DATASET> after k-anonymization, reflecting how indistinguishable they are post-anonymization                                                  </div>                                        | |                        | <EVALMETRIC>Approximation Loss</EVALMETRIC> | <div style=""width:300px""> $\mathcal{E}(\hat{\phi}, \mathcal{Z}, f(X)) \triangleq \mathbb{E} [\mathcal{L}(\hat{\phi}, \mathcal{Z}, f(X)) - \mathcal{L}(\phi^*, \mathcal{Z}, f(X))].$  </div>         | <div style=""width:500px""> Measure the error caused by randomness added when minimizing the privacy loss as the expected deviation of the randomized explanation from the best local approximation                    </div>                               | |                        | <EVALMETRIC>Explanation Intersection</EVALMETRIC> | <div style=""width:300px""> The percentage of bits in the original explanation that is retained in the privatised explanation after using differential privacy </div> | <div style=""width:500px""> The higher the better but due to privacy-utility trade-off, this metric should not be 100%.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\59380ed6.txt,0.9995793016407236
28,"</div>                                        | | **Privacy Degree**     | k-anonymity   | <div style=""width:300px""> A person's information is indistinguishable from at least k-1 other individuals.","</div>                                        | | **Privacy Degree**     | k-anonymity   | <div style=""width:300px""> A person's information is indistinguishable from at least k-1 other individuals.","</div>                                        | | **Privacy Degree**     | k-anonymity   | <div style=""width:300px""> A person's information is indistinguishable from at least k-1 other individuals.
","</div>                                        | | **Privacy Degree**     | k-anonymity   | <div style=""width:300px""> A person's information is indistinguishable from at least k-1 other individuals.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\43869eaa.txt,0.9974683544303797
29,"<div>                                    | <div style=""width:500px""> Refers to the number of individuals in the training dataset to whom a given explanation could potentially be linked.","<div>                                    | <div style=""width:500px""> Refers to the number of individuals in the training dataset to whom a given explanation could potentially be linked.","Refers to the number of individuals in the training dataset to whom a given explanation could potentially be linked.
","Refers to the number of individuals in the training <DATASET>dataset</DATASET> to whom a given explanation could potentially be linked.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\c26e79da.txt,0.7682119205298014
30,"</div>  | |                        | Information Leakage | <div style=""width:300px""> $Pr_{i=1..k}\hat{\phi}(\mathbf{z_i}, X, f_D(X)) \leq e^{\hat{\varepsilon}} \cdot Pr[\hat{\phi}(\mathbf{z_i}, X, f'_D(X)) : \forall i] + \hat{\delta}$     </div>          | <div style=""width:500px""> If an adversary can access model explanations, they would not gain any additional information that could help in inferring something about the training data beyond what could be learned from the model predictions alone.","</div>  | |                        | <EVALMETRIC>Information Leakage</EVALMETRIC> | <div style=""width:300px""> $Pr_{i=1..k}\hat{\phi}(\mathbf{z_i}, X, f_D(X)) \leq e^{\hat{\varepsilon}} \cdot Pr[\hat{\phi}(\mathbf{z_i}, X, f'_D(X)) : \forall i] + \hat{\delta}$     </div>          | <div style=""width:500px""> If an adversary can access model explanations, they would not gain any additional information that could help in inferring something about the training data beyond what could be learned from the model predictions alone.","</div>  | |                        | Information Leakage | <div style=""width:300px""> $Pr_{i=1..k}\hat{\phi}(\mathbf{z_i}, X, f_D(X)) \leq e^{\hat{\varepsilon}} \cdot Pr[\hat{\phi}(\mathbf{z_i}, X, f'_D(X)) : \forall i] + \hat{\delta}$     </div>          | <div style=""width:500px""> If an adversary can access model explanations, they would not gain any additional information that could help in inferring something about the training data beyond what could be learned from the model predictions alone.
","</div>  | |                        | Information Leakage | <div style=""width:300px""> $Pr_{i=1..k}\hat{\phi}(\mathbf{z_i}, X, f_D(X)) \leq e^{\hat{\varepsilon}} \cdot Pr[\hat{\phi}(\mathbf{z_i}, X, f'_D(X)) : \forall i] + \hat{\delta}$     </div>          | <div style=""width:500px""> If an adversary can access model explanations, they would not gain any additional information that could help in inferring something about the training data beyond what could be learned from the model predictions alone.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\3407174c.txt,0.9990049751243781
31,"</div> | |                        | Privacy Budget                           | The total privacy budget for all queries is fixed at $(\varepsilon, \delta)$","</div> | |                        | Privacy Budget                           | The total privacy budget for all queries is fixed at $(\varepsilon, \delta)$","</div> | |                        | Privacy Budget                           | The total privacy budget for all queries is fixed at $(\varepsilon, \delta)$
","</div> | |                        | Privacy Budget                           | The total privacy budget for all queries is fixed at $(\varepsilon, \delta)$
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\73432c61.txt,0.9967845659163987
32,.,.,"page_id=tamlhp.awesome-privex)
","page_id=<PROJECT>tamlhp.awesome-privex</PROJECT>)
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0895d13e.txt,0.0625
33,"| <div style=""width:500px""> The explanation algorithm must not exceed the overall budget across all queries.","| <div style=""width:500px""> The explanation algorithm must not exceed the overall budget across all queries.",The explanation algorithm must not exceed the overall budget across all queries.,The explanation algorithm must not exceed the overall budget across all queries.,../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\6f0f1dad.txt,0.851063829787234
35,"</div>                           | | **Attack Success**     | Precision/Recall/F1 | $Prec = \frac{TP}{TP+FP}$, </br> $Rec = \frac{TP}{TP+FN}$, </br> $F1 = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}$ | <div style=""width:500px""> Evaluate an attack's effectiveness in correctly and completely identifying the properties it is designed to infer.","</div>                           | | **Attack Success**     | <EVALMETRIC>Precision</EVALMETRIC>/<EVALMETRIC>Recall</EVALMETRIC>/<EVALMETRIC>F1</EVALMETRIC> | $Prec = \frac{TP}{TP+FP}$, </br> $Rec = \frac{TP}{TP+FN}$, </br> $<EVALMETRIC>F1</EVALMETRIC> = 2 \times \frac{\text{<EVALMETRIC>precision</EVALMETRIC>} \times \text{<EVALMETRIC>recall</EVALMETRIC>}}{\text{<EVALMETRIC>precision</EVALMETRIC>} + \text{<EVALMETRIC>recall</EVALMETRIC>}}$ | <div style=""width:500px""> Evaluate an attack's effectiveness in correctly and completely identifying the properties it is designed to infer.","</div>                           | | **Attack Success**     | Precision/Recall/F1 | $Prec = \frac{TP}{TP+FP}$, </br> $Rec = \frac{TP}{TP+FN}$, </br> $F1 = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}$ | <div style=""width:500px""> Evaluate an attack's effectiveness in correctly and completely identifying the properties it is designed to infer.
","</div>                           | | **Attack Success**     | <EVALMETRIC>Precision</EVALMETRIC>/<EVALMETRIC>Recall</EVALMETRIC>/<EVALMETRIC>F1</EVALMETRIC> | $Prec = \frac{TP}{TP+FP}$, </br> $Rec = \frac{TP}{TP+FN}$, </br> $F1 = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}$ | <div style=""width:500px""> Evaluate an attack's effectiveness in correctly and completely identifying the properties it is designed to infer.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\94c50fe4.txt,0.9987063389391979
36,"</div>                                                   | |                        | Balanced Accuracy | $BA = \frac{TPR + TNR}{2}$                                                                                         | <div style=""width:500px""> Measures the accuracy of attack (e.g., membership prediction in membership inference attacks), on a balanced dataset of members and non-members.","</div>                                                   | |                        | <EVALMETRIC>Balanced Accuracy</EVALMETRIC> | $<EVALMETRIC>BA</EVALMETRIC> = \frac{TPR + TNR}{2}$                                                                                         | <div style=""width:500px""> Measures the accuracy of attack (e.g., membership prediction in membership inference attacks), on a balanced dataset of members and non-members.","</div>                                                   | |                        | Balanced Accuracy | $BA = \frac{TPR + TNR}{2}$                                                                                         | <div style=""width:500px""> Measures the accuracy of attack (e.g., membership prediction in membership inference attacks), on a balanced dataset of members and non-members.
","</div>                                                   | |                        | <EVALMETRIC>Balanced Accuracy</EVALMETRIC> | $BA = \frac{TPR + TNR}{2}$                                                                                         | <div style=""width:500px""> Measures the accuracy of attack (e.g., membership prediction in membership inference attacks), on a balanced dataset of members and non-members.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\dbb3f8f2.txt,0.9987293519695044
37,"</div>                | |                        | ROC/AUC | <div style=""width:300px""> The ROC curve plots the true positive rate against the false positive rate at various threshold settings.","</div>                | |                        | <EVALMETRIC>ROC</EVALMETRIC>/<EVALMETRIC>AUC</EVALMETRIC> | <div style=""width:300px""> The <EVALMETRIC>ROC</EVALMETRIC> curve plots the true positive rate against the false positive rate at various threshold settings.","</div>                | |                        | ROC/AUC | <div style=""width:300px""> The ROC curve plots the true positive rate against the false positive rate at various threshold settings.
","</div>                | |                        | <EVALMETRIC>ROC/AUC</EVALMETRIC> | <div style=""width:300px""> The ROC curve plots the true positive rate against the false positive rate at various threshold settings.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\c9e1ae33.txt,0.9974025974025974
39,"</div>                                    | |                        | TPR at Low FPR | Report TPR at a fixed FPR (e.g., 0.1%)","</div>                                    | |                        | <EVALMETRIC>TPR at Low FPR</EVALMETRIC> | Report <EVALMETRIC>TPR</EVALMETRIC> at a fixed <EVALMETRIC>FPR</EVALMETRIC> (e.g., 0.1%)","</div>                                    | |                        | TPR at Low FPR | Report TPR at a fixed FPR (e.g., 0.1%)","</div>                                    | |                        | <EVALMETRIC>TPR at Low FPR</EVALMETRIC> | Report <EVALMETRIC>TPR at a fixed FPR</EVALMETRIC> (e.g., 0.1%)",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0e5089f5.txt,1.0
40,.,.,"page_id=tamlhp.awesome-privex)
","page_id=<PROJECT>tamlhp.awesome-privex</PROJECT>)
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0895d13e.txt,0.0625
41,"| <div style=""width:500px""> If an attack can pinpoint even a minuscule fraction of the training dataset with high precision, then the attack ought to be deemed effective.","| <div style=""width:500px""> If an attack can pinpoint even a minuscule fraction of the training dataset with high precision, then the attack ought to be deemed effective.","| <div style=""width:500px""> If an attack can pinpoint even a minuscule fraction of the training dataset with high precision, then the attack ought to be deemed effective.","| <div style=""width:500px""> If an attack can pinpoint even a minuscule fraction of the <DATASET>training dataset</DATASET> with high precision, then the attack ought to be deemed effective.",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\6abb5ce1.txt,1.0
42,"</div>               | |                        | Mean Absolute Error (MAE) | $\ell_1 (\hat{x}, x) = \frac{1}{mn} \sum\limits_{j=1}^{m} \sum\limits_{i=1}^{n} \| \hat{x}_i^j - x_i^j \|,$                          | <div style=""width:500px""> Gives an overview of how accurately an attack can reconstruct private inputs by averaging the absolute differences across all samples and features.","</div>               | |                        | <EVALMETRIC>Mean Absolute Error</EVALMETRIC> (<EVALMETRIC>MAE</EVALMETRIC>) | $\ell_1 (\hat{x}, x) = \frac{1}{mn} \sum\limits_{j=1}^{m} \sum\limits_{i=1}^{n} \| \hat{x}_i^j - x_i^j \|,$                          | <div style=""width:500px""> Gives an overview of how accurately an attack can reconstruct private inputs by averaging the absolute differences across all samples and features.","</div>               | |                        | Mean Absolute Error (MAE) | $\ell_1 (\hat{x}, x) = \frac{1}{mn} \sum\limits_{j=1}^{m} \sum\limits_{i=1}^{n} \| \hat{x}_i^j - x_i^j \|,$                          | <div style=""width:500px""> Gives an overview of how accurately an attack can reconstruct private inputs by averaging the absolute differences across all samples and features.
","</div>               | |                        | <EVALMETRIC>Mean Absolute Error (MAE)</EVALMETRIC> | $\ell_1 (\hat{x}, x) = \frac{1}{mn} \sum\limits_{j=1}^{m} \sum\limits_{i=1}^{n} \| \hat{x}_i^j - x_i^j \|,$                          | <div style=""width:500px""> Gives an overview of how accurately an attack can reconstruct private inputs by averaging the absolute differences across all samples and features.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\35504570.txt,0.9987063389391979
43,"</div>                         | |                        | Success Rate (SR) | $SR = \frac{\|\hat{X}_{val} \neq \perp\|}{mn}$                                                                        | <div style=""width:500px""> The ratio of successfully reconstructed features to the total number of features across all samples                                                                                                    </div>                    | |                        | Model Agreement | $\text{Agreement} = \frac{1}{n} \sum\limits_{i=1}^{n} 1_{f_\theta(x_i) = h_\phi(x_i)}.$                                    | <div style=""width:500px""> A higher agreement indicates that the substitute model is more similar to the original model.","</div>                         | |                        | <EVALMETRIC>Success Rate</EVALMETRIC> (<EVALMETRIC>SR</EVALMETRIC>) | $<EVALMETRIC>SR</EVALMETRIC> = \frac{\|\hat{X}_{val} \neq \perp\|}{mn}$                                                                        | <div style=""width:500px""> The ratio of successfully reconstructed features to the total number of features across all samples                                                                                                    </div>                    | |                        | Model Agreement | $\text{Agreement} = \frac{1}{n} \sum\limits_{i=1}^{n} 1_{f_\theta(x_i) = h_\phi(x_i)}.$                                    | <div style=""width:500px""> A higher agreement indicates that the substitute model is more similar to the original model.","</div>                         | |                        | Success Rate (SR) | $SR = \frac{\|\hat{X}_{val} \neq \perp\|}{mn}$                                                                        | <div style=""width:500px""> The ratio of successfully reconstructed features to the total number of features across all samples                                                                                                    </div>                    | |                        | Model Agreement | $\text{Agreement} = \frac{1}{n} \sum\limits_{i=1}^{n} 1_{f_\theta(x_i) = h_\phi(x_i)}.$                                    | <div style=""width:500px""> A higher agreement indicates that the substitute model is more similar to the original model.
","</div>                         | |                        | <EVALMETRIC>Success Rate (SR)</EVALMETRIC> | $SR = \frac{\|\hat{X}_{val} \neq \perp\|}{mn}$                                                                        | <div style=""width:500px""> The ratio of successfully reconstructed features to the total number of features across all samples                                                                                                    </div>                    | |                        | <EVALMETRIC>Model Agreement</EVALMETRIC> | $\text{Agreement} = \frac{1}{n} \sum\limits_{i=1}^{n} 1_{f_\theta(x_i) = h_\phi(x_i)}.$                                    | <div style=""width:500px""> A higher agreement indicates that the substitute model is more similar to the original model.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\634cddab.txt,0.9993265993265993
45,"</div> | |                        | Average Uncertainty Reduction | $Dist(\mathcal{D}^M, \mathcal{D}^{Orig}) = \frac{1}{n \cdot d} \sum\limits_{i=1}^{n} \sum\limits_{k=1}^{d} \frac{H(\mathcal{D}^M_{i,k})}{H(\mathcal{D}_{i,k})}$ | <div style=""width:500px""> The degree to which a data reconstruction attack is accurate, measured by the reduction in uncertainty across all features of all samples in the dataset                       </div>                                               |    ---------- **Disclaimer**  Feel free to contact us if you have any queries or exciting news.","</div> | |                        | <EVALMETRIC>Average Uncertainty Reduction</EVALMETRIC> | $Dist(\mathcal{D}^M, \mathcal{D}^{Orig}) = \frac{1}{n \cdot d} \sum\limits_{i=1}^{n} \sum\limits_{k=1}^{d} \frac{H(\mathcal{D}^M_{i,k})}{H(\mathcal{D}_{i,k})}$ | <div style=""width:500px""> The degree to which a data reconstruction attack is accurate, measured by the reduction in uncertainty across all features of all samples in the dataset                       </div>                                               |    ---------- **Disclaimer**  Feel free to contact us if you have any queries or exciting news.","</div> | |                        | Average Uncertainty Reduction | $Dist(\mathcal{D}^M, \mathcal{D}^{Orig}) = \frac{1}{n \cdot d} \sum\limits_{i=1}^{n} \sum\limits_{k=1}^{d} \frac{H(\mathcal{D}^M_{i,k})}{H(\mathcal{D}_{i,k})}$ | <div style=""width:500px""> The degree to which a data reconstruction attack is accurate, measured by the reduction in uncertainty across all features of all samples in the dataset                       </div>                                               |    ---------- **Disclaimer**  Feel free to contact us if you have any queries or exciting news.
","</div> | |                        | <EVALMETRIC>Average Uncertainty Reduction</EVALMETRIC> | $Dist(\mathcal{D}^M, \mathcal{D}^{Orig}) = \frac{1}{n \cdot d} \sum\limits_{i=1}^{n} \sum\limits_{k=1}^{d} \frac{H(\mathcal{D}^M_{i,k})}{H(\mathcal{D}_{i,k})}$ | <div style=""width:500px""> The degree to which a data reconstruction attack is accurate, measured by the reduction in uncertainty across all features of all samples in the dataset                       </div>                                               |    ---------- **Disclaimer**  Feel free to contact us if you have any queries or exciting news.
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\3bb53470.txt,0.999140154772141
48,We will glady update the repos according to your suggestions.,We will glady update the repos according to your suggestions.,We will glady update the repos according to your suggestions.,We will glady update the <SOFTWARE>repos</SOFTWARE> according to your suggestions.,../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\086d32b3.txt,1.0
51,style=flat-square)](http://hits.dwyl.com/tamlhp/awesome-privex)  !,style=flat-square)](http://hits.dwyl.com/tamlhp/awesome-privex)  !,"style=flat-square)](http://hits.dwyl.com/tamlhp/awesome-privex)  !
","style=flat-square)](http://hits.dwyl.com/tamlhp/awesome-privex)  !
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\cd69aa91.txt,0.9924812030075187
52,[visitors](https://visitor-badge.laobi.icu/badge?,[visitors](https://visitor-badge.laobi.icu/badge?,"[visitors](https://visitor-badge.laobi.icu/badge?
","[visitors](https://visitor-badge.laobi.icu/badge?
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\090c9caa.txt,0.98989898989899
53,page_id=tamlhp.awesome-privex),page_id=tamlhp.awesome-privex),"page_id=tamlhp.awesome-privex)
","page_id=<PROJECT>tamlhp.awesome-privex</PROJECT>)
",../results/deepseek-chat/prompt-0/zzz_tamlhp_awesome-privex_main_README.md.tsv\0895d13e.txt,0.9836065573770492
