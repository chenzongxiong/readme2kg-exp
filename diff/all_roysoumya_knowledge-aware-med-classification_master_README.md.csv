sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,"# knowledge-aware-med-classification Contains the codebase for our paper **Knowledge-Aware Neural Networks for Medical Forum Question Classification** that is accepted for publication at the 30th ACM International Conference on Information and Knowledge Management (CIKM 2021) [arXiv](https://arxiv.org/abs/2109.13141), [DOI](https://dl.acm.org/doi/10.1145/3459637.3482128)  The codebase is based on huggingface transformers [Github codebase](https://github.com/huggingface/transformers).","# knowledge-aware-med-classification Contains the codebase for our paper **<PUBLICATION>Knowledge-Aware Neural Networks for Medical Forum Question Classification</PUBLICATION>** that is accepted for publication at the <CONFERENCE>30th ACM International Conference on Information and Knowledge Management</CONFERENCE> (<CONFERENCE>CIKM 2021</CONFERENCE>) [arXiv](https://arxiv.org/abs/2109.13141), [DOI](https://dl.acm.org/doi/10.1145/3459637.3482128)  The codebase is based on huggingface <SOFTWARE>transformers</SOFTWARE> [<SOFTWARE>Github</SOFTWARE> codebase](https://github.com/huggingface/<SOFTWARE>transformers</SOFTWARE>).","# knowledge-aware-med-classification Contains the codebase for our paper **Knowledge-Aware Neural Networks for Medical Forum Question Classification** that is accepted for publication at the 30th ACM International Conference on Information and Knowledge Management (CIKM 2021) [arXiv](https://arxiv.org/abs/2109.13141), [DOI](https://dl.acm.org/doi/10.1145/3459637.3482128)  The codebase is based on huggingface transformers [Github codebase](https://github.com/huggingface/transformers).","# knowledge-aware-med-classification Contains the codebase for our paper **<PUBLICATION>Knowledge-Aware Neural Networks for Medical Forum Question Classification</PUBLICATION>** that is accepted for publication at the <CONFERENCE>30th ACM International Conference on Information and Knowledge Management (CIKM 2021)</CONFERENCE> [arXiv](https://arxiv.org/abs/2109.13141), [DOI](https://dl.acm.org/doi/10.1145/3459637.3482128)  The codebase is based on <SOFTWARE>huggingface transformers</SOFTWARE> [Github codebase](https://github.com/huggingface/transformers).",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\aee2a594.txt,1.0
2,The LCF-BERT and LCF-associated codes is based on ABSA-Pytorch [Github codebase](https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/lcf_bert.py)  !,The LCF-BERT and LCF-associated codes is based on <SOFTWARE>ABSA-Pytorch</SOFTWARE> [<SOFTWARE>Github</SOFTWARE> codebase](https://github.com/songyouwei/<SOFTWARE>ABSA-PyTorch</SOFTWARE>/blob/master/models/lcf_bert.py)  !,The `LCF-BERT` and `LCF-associated codes` is based on `ABSA-Pytorch` [Github codebase](https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/lcf_bert.py)  !,The `<SOFTWARE>LCF-BERT</SOFTWARE>` and `<SOFTWARE>LCF-associated codes</SOFTWARE>` is based on `<SOFTWARE>ABSA-Pytorch</SOFTWARE>` [Github codebase](https://github.com/<SOFTWARE>songyouwei</SOFTWARE>/<SOFTWARE>ABSA-PyTorch</SOFTWARE>/blob/master/models/<SOFTWARE>lcf_bert</SOFTWARE>.py)  !,../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\d70ea764.txt,0.9813664596273292
3,"[Proposed Knowledge-aware BERT model](medbert-ichi.png)  ### Running Bert-plus models  The code files in the form of self-contained Jupyter notebooks is available at: **src/ProposedKnowledgeAwareModel/** Please go through the notebook, which produces at the end a 'run_ichi.py'.   ``` python .","[Proposed Knowledge-aware BERT model](medbert-ichi.png)  ### Running Bert-plus models  The code files in the form of self-contained <SOFTWARE>Jupyter</SOFTWARE> notebooks is available at: **src/ProposedKnowledgeAwareModel/** Please go through the notebook, which produces at the end a 'run_ichi.py'.   ``` <SOFTWARE>python</SOFTWARE> .","[Proposed Knowledge-aware BERT model](medbert-ichi.png)  ### Running Bert-plus models  The code files in the form of self-contained Jupyter notebooks is available at: **src/ProposedKnowledgeAwareModel/** Please go through the notebook, which produces at the end a 'run_ichi.py'.   ``` python .","[<PROJECT>Proposed Knowledge-aware BERT model</PROJECT>](medbert-ichi.png)  ### Running Bert-plus models  The code files in the form of self-contained Jupyter notebooks is available at: **src/<PROJECT>ProposedKnowledgeAwareModel</PROJECT>/** Please go through the notebook, which produces at the end a 'run_ichi.py'.   ``` <PROGLANG>python</PROGLANG> .",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\4823ac28.txt,1.0
4,/examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir .,/examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir .,`/examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir .`,`/examples/ichi/run_ichi.py --model_type bert --model_name_or_path <PROGLANG>bert-base-uncased</PROGLANG> --do_lower_case --do_train --do_eval --data_dir .`,../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\6c83c130.txt,0.9925373134328358
5,/data/ichi_dataset --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir .,/data/ichi_dataset --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir .,/data/ichi_dataset --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir .,/data/<DATASET>ichi_dataset</DATASET> --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir .,../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\87b11e3c.txt,1.0
6,"/tmp/ichi_bert_base_new --overwrite_output_dir ```  ### Experiments and Results The BERT and MedBERT models were trained and evaluated on two datasets: CADEC (multi-label) and ICHI (multi-class) (Datasets provided in the data directory).   ### Annotated CADEC, a multi-label medical forum question classificaton dataset We annotate CADEC as a multi-label multi-class dataset, for the task of ""Medical Forum Question Classification"".","/tmp/ichi_bert_base_new --overwrite_output_dir ```  ### Experiments and Results The <SOFTWARE>BERT</SOFTWARE> and <SOFTWARE>MedBERT</SOFTWARE> models were trained and evaluated on two datasets: <DATASET>CADEC</DATASET> (multi-label) and <DATASET>ICHI</DATASET> (multi-class) (Datasets provided in the data directory).   ### <DATASET>Annotated CADEC</DATASET>, a multi-label medical forum question classificaton dataset We annotate <DATASET>CADEC</DATASET> as a multi-label multi-class dataset, for the task of ""Medical Forum Question Classification"".","/tmp/ichi_bert_base_new --overwrite_output_dir ```  ### Experiments and Results The BERT and MedBERT models were trained and evaluated on two datasets: `CADEC` (multi-label) and `ICHI` (multi-class) (Datasets provided in the data directory).   ### Annotated `CADEC`, a multi-label medical forum question classificaton dataset We annotate `CADEC` as a multi-label multi-class dataset, for the task of ""Medical Forum Question Classification"".","/tmp/ichi_bert_base_new --overwrite_output_dir ```  ### Experiments and Results The BERT and MedBERT models were trained and evaluated on two datasets: `<DATASET>CADEC</DATASET>` (multi-label) and `<DATASET>ICHI</DATASET>` (multi-class) (Datasets provided in the data directory).   ### Annotated `<DATASET>CADEC</DATASET>`, a multi-label medical forum question classificaton dataset We annotate `<DATASET>CADEC</DATASET>` as a multi-label multi-class dataset, for the task of ""Medical Forum Question Classification"".",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\b3037516.txt,0.9908256880733946
7,"Each data point is annotated by 0 and 1, across five information need categories.","Each data point is annotated by 0 and 1, across five information need categories.","Each data point is annotated by 0 and 1, across five information need categories.","Each data point is annotated by 0 and 1, across five information need categories.",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\cce32655.txt,1.0
8,"We also have an additional column, containing the extracted medical concepts using QuickUMLS tool.","We also have an additional column, containing the extracted medical concepts using <SOFTWARE>QuickUMLS</SOFTWARE> tool.","We also have an additional column, containing the extracted medical concepts using QuickUMLS tool.","We also have an additional column, containing the extracted medical concepts using <SOFTWARE>QuickUMLS</SOFTWARE> tool.",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\6b221cc0.txt,1.0
9,"The annotated files can be found at **CADEC-Annotations/**  ### ICHI, a multi-class medical forum question classification dataset We obtain the ICHI data from rakshajalan/ECIR-2018 [Github codebase](https://github.com/rakshajalan/ECIR-2018/tree/master/ECIR-18_medical_question_classification/Dataset), and maintain the same train-test data split.  ## Citing MedBERT If you use the labeled CADEC dataset or use MedBERT model, please cite the paper:   ``` @inproceedings{10.1145/3459637.3482128, author = {Roy, Soumyadeep and Chakraborty, Sudip and Mandal, Aishik and Balde, Gunjan and Sharma, Prakhar and Natarajan, Anandhavelu and Khosla, Megha and Sural, Shamik and Ganguly, Niloy}, title = {Knowledge-Aware Neural Networks for Medical Forum Question Classification}, year = {2021}, isbn = {9781450384469}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3459637.3482128}, doi = {10.1145/3459637.3482128}, abstract = {Online medical forums have become a predominant platform for answering health-related information needs of consumers.","The annotated files can be found at **<DATASET>CADEC</DATASET>-Annotations/**  ### <DATASET>ICHI</DATASET>, a multi-class medical forum question classification dataset We obtain the <DATASET>ICHI</DATASET> data from rakshajalan/<CONFERENCE>ECIR-2018</CONFERENCE> [Github codebase](https://github.com/rakshajalan/<CONFERENCE>ECIR-2018</CONFERENCE>/tree/master/<CONFERENCE>ECIR-18</CONFERENCE>_medical_question_classification/Dataset), and maintain the same train-test data split.  ## Citing <SOFTWARE>MedBERT</SOFTWARE> If you use the labeled <DATASET>CADEC</DATASET> dataset or use <SOFTWARE>MedBERT</SOFTWARE> model, please cite the paper:   ``` @inproceedings{10.1145/3459637.3482128, author = {Roy, Soumyadeep and Chakraborty, Sudip and Mandal, Aishik and Balde, Gunjan and Sharma, Prakhar and Natarajan, Anandhavelu and Khosla, Megha and Sural, Shamik and Ganguly, Niloy}, title = {<PUBLICATION>Knowledge-Aware Neural Networks for Medical Forum Question Classification</PUBLICATION>}, year = {2021}, isbn = {9781450384469}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3459637.3482128}, doi = {10.1145/3459637.3482128}, abstract = {Online medical forums have become a predominant platform for answering health-related information needs of consumers.","The annotated files can be found at **CADEC-Annotations/**  ### ICHI, a multi-class medical forum question classification dataset We obtain the ICHI data from rakshajalan/ECIR-2018 [Github codebase](https://github.com/rakshajalan/ECIR-2018/tree/master/ECIR-18_medical_question_classification/Dataset), and maintain the same train-test data split.  ## Citing MedBERT If you use the labeled CADEC dataset or use MedBERT model, please cite the paper:   ``` @inproceedings{10.1145/3459637.3482128, author = {Roy, Soumyadeep and Chakraborty, Sudip and Mandal, Aishik and Balde, Gunjan and Sharma, Prakhar and Natarajan, Anandhavelu and Khosla, Megha and Sural, Shamik and Ganguly, Niloy}, title = {Knowledge-Aware Neural Networks for Medical Forum Question Classification}, year = {2021}, isbn = {9781450384469}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3459637.3482128}, doi = {10.1145/3459637.3482128}, abstract = {Online medical forums have become a predominant platform for answering health-related information needs of consumers.","The annotated files can be found at **<DATASET>CADEC-Annotations</DATASET>/**  ### <DATASET>ICHI</DATASET>, a multi-class medical forum question classification dataset We obtain the <DATASET>ICHI</DATASET> data from rakshajalan/<CONFERENCE>ECIR-2018</CONFERENCE> [Github codebase](https://github.com/rakshajalan/<CONFERENCE>ECIR-2018</CONFERENCE>/tree/master/<CONFERENCE>ECIR-18</CONFERENCE>_medical_question_classification/<DATASET>Dataset</DATASET>), and maintain the same train-test data split.  ## Citing <SOFTWARE>MedBERT</SOFTWARE> If you use the labeled <DATASET>CADEC</DATASET> dataset or use <SOFTWARE>MedBERT</SOFTWARE> model, please cite the paper:   ``` @inproceedings{10.1145/3459637.3482128, author = {Roy, Soumyadeep and Chakraborty, Sudip and Mandal, Aishik and Balde, Gunjan and Sharma, Prakhar and Natarajan, Anandhavelu and Khosla, Megha and Sural, Shamik and Ganguly, Niloy}, title = {Knowledge-Aware Neural Networks for Medical Forum Question Classification}, year = {2021}, isbn = {9781450384469}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3459637.3482128}, doi = {10.1145/3459637.3482128}, abstract = {Online medical forums have become a predominant platform for answering health-related information needs of consumers.",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\1dd8048b.txt,1.0
10,"However, with a significant rise in the number of queries and the limited availability of experts, it is necessary to automatically classify medical queries based on a consumer's intention, so that these questions may be directed to the right set of medical experts.","However, with a significant rise in the number of queries and the limited availability of experts, it is necessary to automatically classify medical queries based on a consumer's intention, so that these questions may be directed to the right set of medical experts.","However, with a significant rise in the number of queries and the limited availability of experts, it is necessary to automatically classify medical queries based on a consumer's intention, so that these questions may be directed to the right set of medical experts.","However, with a significant rise in the number of queries and the limited availability of experts, it is necessary to automatically classify medical queries based on a consumer's intention, so that these questions may be directed to the right set of medical experts.",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\e5acf013.txt,1.0
11,"Here, we develop a novel medical knowledge-aware BERT-based model (MedBERT) that explicitly gives more weightage to medical concept-bearing words, and utilize domain-specific side information obtained from a popular medical knowledge base.","Here, we develop a novel medical knowledge-aware BERT-based model (<SOFTWARE>MedBERT</SOFTWARE>) that explicitly gives more weightage to medical concept-bearing words, and utilize domain-specific side information obtained from a popular medical knowledge base.","Here, we develop a novel medical knowledge-aware BERT-based model (`MedBERT`) that explicitly gives more weightage to medical concept-bearing words, and utilize domain-specific side information obtained from a popular medical knowledge base.","Here, we develop a novel medical knowledge-aware BERT-based model (`<SOFTWARE>MedBERT</SOFTWARE>`) that explicitly gives more weightage to medical concept-bearing words, and utilize domain-specific side information obtained from a popular medical knowledge base.",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\c635f3c7.txt,0.9958333333333333
12,We also contribute a multi-label dataset for the Medical Forum Question Classification (MFQC) task.,We also contribute a multi-label dataset for the Medical Forum Question Classification (MFQC) task.,We also contribute a multi-label `Medical Forum Question Classification (MFQC)` dataset for the `MFQC` task.,We also contribute a multi-label `<DATASET>Medical Forum Question Classification (MFQC)</DATASET>` dataset for the `<DATASET>MFQC</DATASET>` task.,../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\bdb43582.txt,0.8019323671497585
13,"MedBERT achieves state-of-the-art performance on two benchmark datasets and performs very well in low resource settings.}, booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management}, pages = {3398–3402}, numpages = {5}, keywords = {online health communities, clinical text classification}, location = {Virtual Event, Queensland, Australia}, series = {CIKM '21} } ```","<SOFTWARE>MedBERT</SOFTWARE> achieves state-of-the-art performance on two benchmark datasets and performs very well in low resource settings.}, booktitle = {<PUBLICATION>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</PUBLICATION><CONFERENCE>30th ACM International Conference on Information &amp; Knowledge Management</CONFERENCE>}, pages = {3398–3402}, numpages = {5}, keywords = {online health communities, clinical text classification}, location = {Virtual Event, Queensland, Australia}, series = {<CONFERENCE>CIKM '21</CONFERENCE>} } ```","MedBERT achieves state-of-the-art performance on two benchmark datasets and performs very well in low resource settings.}, booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management}, pages = {3398–3402}, numpages = {5}, keywords = {online health communities, clinical text classification}, location = {Virtual Event, Queensland, Australia}, series = {CIKM '21} }","MedBERT achieves state-of-the-art performance on two benchmark <DATASET>datasets</DATASET> and performs very well in low resource settings.}, booktitle = {<PUBLICATION>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</PUBLICATION>}, pages = {3398–3402}, numpages = {5}, keywords = {online health communities, clinical text classification}, location = {Virtual Event, Queensland, Australia}, series = {<CONFERENCE>CIKM '21</CONFERENCE>} }",../results/deepseek-chat/prompt-0/zzz_roysoumya_knowledge-aware-med-classification_master_README.md.tsv\bafe2c24.txt,0.9951690821256038
