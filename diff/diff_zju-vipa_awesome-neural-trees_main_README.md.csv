sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
7,"* **New work of NTs and possible changes in this survey will be notified here.**  - Add ""ProGReST: Prototypical Graph Regression Soft Trees for Molecular Property Prediction"" [[Paper]](https://arxiv.org/pdf/2210.03745.pdf), an interesting work that combines prototype learning, soft decision trees and Graph Neural Networks for compound property prediction","* **New work of NTs and possible changes in this survey will be notified here.**  - Add ""<PUBLICATION>ProGReST: Prototypical Graph Regression Soft Trees for Molecular Property Prediction</PUBLICATION>"" [[Paper]](https://arxiv.org/pdf/2210.03745.pdf), an interesting work that combines prototype learning, soft decision trees and Graph Neural Networks for compound property prediction","* **New work of NTs and possible changes in this survey will be notified here.**  - Add `ProGReST: Prototypical Graph Regression Soft Trees for Molecular Property Prediction` [[Paper]](https://arxiv.org/pdf/2210.03745.pdf), an interesting work that combines prototype learning, soft decision trees and Graph Neural Networks for compound property prediction","* **New work of NTs and possible changes in this survey will be notified here.**  - Add `<PUBLICATION>ProGReST: Prototypical Graph Regression Soft Trees for Molecular Property Prediction</PUBLICATION>` [[Paper]](https://arxiv.org/pdf/2210.03745.pdf), an interesting work that combines prototype learning, soft decision trees and Graph Neural Networks for compound property prediction",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\4d976c20.txt,0.9943820224719101
9,"- Add ""Large-Scale Category Structure Aware Image Categorization"" [[Paper]](https://proceedings.neurips.cc/paper/2011/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf) & ""Leveraging Class Hierarchies with Metric-Guided Prototype Learning"" [[Paper]](https://arxiv.org/pdf/2007.03047.pdf), two methods incorporating the class hierarchy into the regulariser of the general objective function in section 3.","- Add ""<PUBLICATION>Large-Scale Category Structure Aware Image Categorization</PUBLICATION>"" [[Paper]](https://proceedings.neurips.cc/paper/2011/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf) & ""<PUBLICATION>Leveraging Class Hierarchies with Metric-Guided Prototype Learning</PUBLICATION>"" [[Paper]](https://arxiv.org/pdf/2007.03047.pdf), two methods incorporating the class hierarchy into the regulariser of the general objective function in section 3.","- Add `Large-Scale Category Structure Aware Image Categorization` [[Paper]](https://proceedings.neurips.cc/paper/2011/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf) & `Leveraging Class Hierarchies with Metric-Guided Prototype Learning` [[Paper]](https://arxiv.org/pdf/2007.03047.pdf), two methods incorporating the class hierarchy into the regulariser of the general objective function in section 3.","- Add `<PUBLICATION>Large-Scale Category Structure Aware Image Categorization</PUBLICATION>` [[Paper]](https://proceedings.neurips.cc/paper/2011/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf) & `<PUBLICATION>Leveraging Class Hierarchies with Metric-Guided Prototype Learning</PUBLICATION>` [[Paper]](https://arxiv.org/pdf/2007.03047.pdf), two methods incorporating the class hierarchy into the regulariser of the general objective function in section 3.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\90483941.txt,0.9900249376558603
13,Non-hybrid: NNs and DTs Cooperated Approaches.,Non-hybrid: NNs and DTs Cooperated Approaches.,`Non-hybrid: NNs and DTs Cooperated Approaches.`,`Non-hybrid: NNs and DTs Cooperated Approaches.`,../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\03df9309.txt,0.9787234042553191
15,They employ DTs as auxiliaries for NNs as well as using NNs as tools to improve the design of DTs.,They employ DTs as auxiliaries for NNs as well as using NNs as tools to improve the design of DTs.,They employ `DTs` as auxiliaries for `NNs` as well as using `NNs` as tools to improve the design of `DTs`.,They employ `<SOFTWARE>DTs</SOFTWARE>` as auxiliaries for `<SOFTWARE>NNs</SOFTWARE>` as well as using `<SOFTWARE>NNs</SOFTWARE>` as tools to improve the design of `<SOFTWARE>DTs</SOFTWARE>`.,../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\154a928e.txt,0.9607843137254902
18,"They are perceived implicit combinations of NNs and DTs, because NNs and DTs still operate on their  own paradigms and no hybrid model is produced.  #### 1.1 DTs as Structural Priors of NNs.","They are perceived implicit combinations of NNs and DTs, because NNs and DTs still operate on their  own paradigms and no hybrid model is produced.  #### 1.1 DTs as Structural Priors of NNs.","They are perceived implicit combinations of NNs and DTs, because NNs and DTs still operate on their own paradigms and no hybrid model is produced. #### 1.1 DTs as Structural Priors of NNs.","They are perceived implicit combinations of NNs and DTs, because NNs and DTs still operate on their own paradigms and no hybrid model is produced. #### 1.1 DTs as Structural Priors of NNs.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\27b248da.txt,0.9947089947089947
19,"Adopt DTs to approximate the target concept of NNs in terms of logical descriptions, *i.e.*, use DTs to design NNs  with structural priors","Adopt DTs to approximate the target concept of NNs in terms of logical descriptions, *i.e.*, use DTs to design NNs  with structural priors","Adopt DTs to approximate the target concept of NNs in terms of logical descriptions, *i.e.*, use DTs to design NNs with structural priors","Adopt <PROGLANG>DTs</PROGLANG> to approximate the target concept of <PROGLANG>NNs</PROGLANG> in terms of logical descriptions, *i.e.*, use <PROGLANG>DTs</PROGLANG> to design <PROGLANG>NNs</PROGLANG> with structural priors",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\65edc2bf.txt,0.9963636363636363
25,"Cios, N.","Cios, N.","`Cios, N.`","`Cios, N.`",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\145161a2.txt,0.8888888888888888
29,"doi=10.1.1.122.4561&rep=rep1&type=pdf)  - ***A knowledge acquisition system that concerns about the knowledge form DTs and NNs prefer:***   - **""Implementation and refinement of decision trees using neural networks for hybrid knowledge acquisition""**,  Artificial Intelligence in Engineering, 1995     - Katsuhiko Tsujino, Shogo Nishida     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0954181095000054)  - ***Create a disjunctive normal form formula for each class and reformulate the first layer of entropy net:***   - **""Initializing neural networks using decision trees""**, published by Rutgers University, 1990     - Arunava Banerjee     - [[Paper]](https://scholarship.libraries.rutgers.edu/esploro/outputs/technicalDocumentation/Initializing-neural-networks-using-decision-trees/991031549998404646)   - **""Initialization of neural networks by means of decision trees""**, Knowledge-Based Systems, 1995     - Irena Ivanova, Miroslav Kubat     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0950705196819174)   - **""On mapping decision trees and neural networks""**, Knowledge-Based Systems, 1999     - R.SetionoW, K.Leow     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S095070519900009X)  #### 1.2 DTs for Approximating NNs.","doi=10.1.1.122.4561&rep=rep1&type=pdf)  - ***A knowledge acquisition system that concerns about the knowledge form DTs and NNs prefer:***   - **""<PUBLICATION>Implementation and refinement of decision trees using neural networks for hybrid knowledge acquisition</PUBLICATION>""**,  Artificial Intelligence in Engineering, 1995     - Katsuhiko Tsujino, Shogo Nishida     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0954181095000054)  - ***Create a disjunctive normal form formula for each class and reformulate the first layer of entropy net:***   - **""<PUBLICATION>Initializing neural networks using decision trees</PUBLICATION>""**, published by Rutgers University, 1990     - Arunava Banerjee     - [[Paper]](https://scholarship.libraries.rutgers.edu/esploro/outputs/technicalDocumentation/Initializing-neural-networks-using-decision-trees/991031549998404646)   - **""<PUBLICATION>Initialization of neural networks by means of decision trees</PUBLICATION>""**, Knowledge-Based Systems, 1995     - Irena Ivanova, Miroslav Kubat     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0950705196819174)   - **""<PUBLICATION>On mapping decision trees and neural networks</PUBLICATION>""**, Knowledge-Based Systems, 1999     - R.SetionoW, K.Leow     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S095070519900009X)  #### 1.2 DTs for Approximating NNs.","doi=10.1.1.122.4561&rep=rep1&type=pdf)  - ***A knowledge acquisition system that concerns about the knowledge form DTs and NNs prefer:***   - **""Implementation and refinement of decision trees using neural networks for hybrid knowledge acquisition""**, Artificial Intelligence in Engineering, 1995     - Katsuhiko Tsujino, Shogo Nishida     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0954181095000054)  - ***Create a disjunctive normal form formula for each class and reformulate the first layer of entropy net:***   - **""Initializing neural networks using decision trees""**, published by Rutgers University, 1990     - Arunava Banerjee     - [[Paper]](https://scholarship.libraries.rutgers.edu/esploro/outputs/technicalDocumentation/Initializing-neural-networks-using-decision-trees/991031549998404646)   - **""Initialization of neural networks by means of decision trees""**, Knowledge-Based Systems, 1995     - Irena Ivanova, Miroslav Kubat     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0950705196819174)   - **""On mapping decision trees and neural networks""**, Knowledge-Based Systems, 1999     - R.SetionoW, K.Leow     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S095070519900009X)  #### 1.2 DTs for Approximating NNs.","doi=10.1.1.122.4561&rep=rep1&type=pdf)  - ***A knowledge acquisition system that concerns about the knowledge form DTs and NNs prefer:***   - **""<PUBLICATION>Implementation and refinement of decision trees using neural networks for hybrid knowledge acquisition</PUBLICATION>""**, <PUBLICATION>Artificial Intelligence in Engineering</PUBLICATION>, 1995     - Katsuhiko Tsujino, Shogo Nishida     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0954181095000054)  - ***Create a disjunctive normal form formula for each class and reformulate the first layer of entropy net:***   - **""<PUBLICATION>Initializing neural networks using decision trees</PUBLICATION>""**, published by <PUBLICATION>Rutgers University</PUBLICATION>, 1990     - Arunava Banerjee     - [[Paper]](https://scholarship.libraries.rutgers.edu/esploro/outputs/technicalDocumentation/Initializing-neural-networks-using-decision-trees/991031549998404646)   - **""<PUBLICATION>Initialization of neural networks by means of decision trees</PUBLICATION>""**, <PUBLICATION>Knowledge-Based Systems</PUBLICATION>, 1995     - Irena Ivanova, Miroslav Kubat     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/0950705196819174)   - **""<PUBLICATION>On mapping decision trees and neural networks</PUBLICATION>""**, <PUBLICATION>Knowledge-Based Systems</PUBLICATION>, 1999     - R.SetionoW, K.Leow     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S095070519900009X)  #### 1.2 DTs for Approximating NNs.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\b931bba7.txt,0.9996122528111672
32,"pq-origsite=gscholar&cbl=18750&diss=y)   - **""Extracting decision trees from trained neural networks""**, Pattern Recognition, 2020     - Olcay Boz      - [[Paper]](https://dl.acm.org/doi/abs/10.1145/775047.775113)   - **""NeC4.5: neural ensemble based C4.5""**, IEEE Transactions on Knowledge and Data Engineering, 2004     - Zhi-Hua Zhou, Yuan Jiang *(use NN ensembles)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/1294896)   - **""Extracting decision trees from trained neural networks""**, Pattern Recognition, 1999     - R.Krishnan, *et al.* *(adapt genetic algorithms to generate artificial examples)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320398001812)  - ***generalize the TREPAN algorithm***   - **""An investigation of TREPAN utilising a continuous oracle model""**, Data Analysis Techniques and Strategies, 2011      - William A Young *et al.* *(develop DTs derived from continuous-based models)*     - [[Paper]](https://www.researchgate.net/profile/William-Young-10/publication/227441144_An_investigation_of_TREPAN_utilising_a_continuous_oracle_model/links/00b495258560f7e8d3000000/An-investigation-of-TREPAN-utilising-a-continuous-oracle-model.pdf?","pq-origsite=gscholar&cbl=18750&diss=y)   - **""<PUBLICATION>Extracting decision trees from trained neural networks</PUBLICATION>""**, Pattern Recognition, 2020     - Olcay Boz      - [[Paper]](https://dl.acm.org/doi/abs/10.1145/775047.775113)   - **""<PUBLICATION>NeC4.5: neural ensemble based C4.5</PUBLICATION>""**, IEEE Transactions on Knowledge and Data Engineering, 2004     - Zhi-Hua Zhou, Yuan Jiang *(use NN ensembles)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/1294896)   - **""<PUBLICATION>Extracting decision trees from trained neural networks</PUBLICATION>""**, Pattern Recognition, 1999     - R.Krishnan, *et al.* *(adapt genetic algorithms to generate artificial examples)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320398001812)  - ***generalize the TREPAN algorithm***   - **""<PUBLICATION>An investigation of TREPAN utilising a continuous oracle model</PUBLICATION>""**, Data Analysis Techniques and Strategies, 2011      - William A Young *et al.* *(develop DTs derived from continuous-based models)*     - [[Paper]](https://www.researchgate.net/profile/William-Young-10/publication/227441144_An_investigation_of_TREPAN_utilising_a_continuous_oracle_model/links/00b495258560f7e8d3000000/An-investigation-of-TREPAN-utilising-a-continuous-oracle-model.pdf?","- **""Extracting decision trees from trained neural networks""**, Pattern Recognition, 2020
  - Olcay Boz
  - [[Paper]](https://dl.acm.org/doi/abs/10.1145/775047.775113)
- **""NeC4.5: neural ensemble based C4.5""**, IEEE Transactions on Knowledge and Data Engineering, 2004
  - Zhi-Hua Zhou, Yuan Jiang *(use NN ensembles)*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/1294896)
- **""Extracting decision trees from trained neural networks""**, Pattern Recognition, 1999
  - R.Krishnan, *et al.* *(adapt genetic algorithms to generate artificial examples)*
  - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320398001812)
- ***generalize the TREPAN algorithm***
- **""An investigation of TREPAN utilising a continuous oracle model""**, Data Analysis Techniques and Strategies, 2011
  - William A Young *et al.* *(develop DTs derived from continuous-based models)*
  - [[Paper]](https://www.researchgate.net/profile/William-Young-10/publication/227441144_An_investigation_of_TREPAN_utilising_a_continuous_oracle_model/links/00b495258560f7e8d3000000/An-investigation-of-TREPAN-utilising-a-continuous-oracle-model.pdf?","- **""<PUBLICATION>Extracting decision trees from trained neural networks</PUBLICATION>""**, <PUBLICATION>Pattern Recognition</PUBLICATION>, 2020
  - Olcay Boz
  - [[Paper]](https://dl.acm.org/doi/abs/10.1145/775047.775113)
- **""<PUBLICATION>NeC4.5: neural ensemble based C4.5</PUBLICATION>""**, <PUBLICATION>IEEE Transactions on Knowledge and Data Engineering</PUBLICATION>, 2004
  - Zhi-Hua Zhou, Yuan Jiang *(use NN ensembles)*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/1294896)
- **""<PUBLICATION>Extracting decision trees from trained neural networks</PUBLICATION>""**, <PUBLICATION>Pattern Recognition</PUBLICATION>, 1999
  - R.Krishnan, *et al.* *(adapt genetic algorithms to generate artificial examples)*
  - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320398001812)
- ***generalize the TREPAN algorithm***
- **""<PUBLICATION>An investigation of TREPAN utilising a continuous oracle model</PUBLICATION>""**, <PUBLICATION>Data Analysis Techniques and Strategies</PUBLICATION>, 2011
  - William A Young *et al.* *(develop DTs derived from continuous-based models)*
  - [[Paper]](https://www.researchgate.net/profile/William-Young-10/publication/227441144_An_investigation_of_TREPAN_utilising_a_continuous_oracle_model/links/00b495258560f7e8d3000000/An-investigation-of-TREPAN-utilising-a-continuous-oracle-model.pdf?",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\9902fb34.txt,0.9617346938775511
34,"Expires=1662897159&Signature=C2Z0VL3cIkc56vlIci5ERXC7VADyi9tEqIlvJ3CqHzaLB9bfY9Tma8UVsZpu1BXI1l24paZ0iJArqUUzEqrTvum7s93dAUL-pKmmBKausyKiAw3qj2Bx18I5jzDOat2TCKA6wd2GbiexuK7gtlfNgeu03fBg0Rx2UWt~2KW6RNMeamZinhzp1FCrSzH4fFRqhTuc2~UgajTzsaUlJHbJef-s9u2wOiwqNiEUAfwN8zG0tIEt-fE0GEUdSC9AzBVXLpodLTadDzUZODX7lzUX~o00-ZHxKl7VOnbi0wQ8OZw087zKQjqQNOw1ik16zfKMamZW~YS6e38aUgud0sOrBg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)   - **""Extracting fuzzy symbolic representation from artificial neural networks""**, NAFIPS, 1999     - Maciej Faifer *et al.* *(use fuzzy representation during the tree-induction process)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/781764)   - **""DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees""**, arXiv, 2022     - Peter Müller *et al.* *(incorporate DTs into graph neural networks)*     - [[Paper]](https://arxiv.org/abs/2205.13234)  - ***NNs perform significance analysis to select attributes***   - **""ANN-DT: an algorithm for extraction of decision trees from artificial neural networks""**, IEEE Transactions on Neural Networks, 1999     - Gregor PJ Schmitz *et al.*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/809084)   ##### *1.2.2 Decompositional Techniques.* Decompositional techniques concern units in the hidden layers.","Expires=1662897159&Signature=C2Z0VL3cIkc56vlIci5ERXC7VADyi9tEqIlvJ3CqHzaLB9bfY9Tma8UVsZpu1BXI1l24paZ0iJArqUUzEqrTvum7s93dAUL-pKmmBKausyKiAw3qj2Bx18I5jzDOat2TCKA6wd2GbiexuK7gtlfNgeu03fBg0Rx2UWt~2KW6RNMeamZinhzp1FCrSzH4fFRqhTuc2~UgajTzsaUlJHbJef-s9u2wOiwqNiEUAfwN8zG0tIEt-fE0GEUdSC9AzBVXLpodLTadDzUZODX7lzUX~o00-ZHxKl7VOnbi0wQ8OZw087zKQjqQNOw1ik16zfKMamZW~YS6e38aUgud0sOrBg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)   - **""<PUBLICATION>Extracting fuzzy symbolic representation from artificial neural networks</PUBLICATION>""**, <CONFERENCE>NAFIPS</CONFERENCE>, 1999     - Maciej Faifer *et al.* *(use fuzzy representation during the tree-induction process)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/781764)   - **""<PUBLICATION>DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees</PUBLICATION>""**, arXiv, 2022     - Peter Müller *et al.* *(incorporate DTs into graph neural networks)*     - [[Paper]](https://arxiv.org/abs/2205.13234)  - ***NNs perform significance analysis to select attributes***   - **""<PUBLICATION>ANN-DT: an algorithm for extraction of decision trees from artificial neural networks</PUBLICATION>""**, IEEE Transactions on Neural Networks, 1999     - Gregor PJ Schmitz *et al.*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/809084)   ##### *1.2.2 Decompositional Techniques.* Decompositional techniques concern units in the hidden layers.","- **""Extracting fuzzy symbolic representation from artificial neural networks""**, NAFIPS, 1999
  - Maciej Faifer *et al.* *(use fuzzy representation during the tree-induction process)*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/781764)
- **""DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees""**, arXiv, 2022
  - Peter Müller *et al.* *(incorporate DTs into graph neural networks)*
  - [[Paper]](https://arxiv.org/abs/2205.13234)
- ***NNs perform significance analysis to select attributes***
- **""ANN-DT: an algorithm for extraction of decision trees from artificial neural networks""**, IEEE Transactions on Neural Networks, 1999
  - Gregor PJ Schmitz *et al.*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/809084)
##### *1.2.2 Decompositional Techniques.* Decompositional techniques concern units in the hidden layers.","- **""<PUBLICATION>Extracting fuzzy symbolic representation from artificial neural networks</PUBLICATION>""**, <CONFERENCE>NAFIPS</CONFERENCE>, 1999
  - Maciej Faifer *et al.* *(use fuzzy representation during the tree-induction process)*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/781764)
- **""<PUBLICATION>DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2022
  - Peter Müller *et al.* *(incorporate DTs into graph neural networks)*
  - [[Paper]](https://arxiv.org/abs/2205.13234)
- ***NNs perform significance analysis to select attributes***
- **""<PUBLICATION>ANN-DT: an algorithm for extraction of decision trees from artificial neural networks</PUBLICATION>""**, <PUBLICATION>IEEE Transactions on Neural Networks</PUBLICATION>, 1999
  - Gregor PJ Schmitz *et al.*
  - [[Paper]](https://ieeexplore.ieee.org/abstract/document/809084)
##### *1.2.2 Decompositional Techniques.* Decompositional techniques concern units in the hidden layers.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\a9505c06.txt,0.7928011075219197
35,"They extract rules from the trained NN at the level of  individual neurons, thus gaining insight into their inner structures","They extract rules from the trained NN at the level of  individual neurons, thus gaining insight into their inner structures","They extract rules from the trained NN at the level of individual neurons, thus gaining insight into their inner structures","They extract rules from the trained NN at the level of individual neurons, thus gaining insight into their inner structures",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\35d2258b.txt,0.9959514170040485
37,"- ***Extract axis-aligned trees***   - **""Rule extraction from neural networks via decision tree induction""**, IJCNN, 2001     - Makoto Sato, Hiroshi Tsukimoto *(CRED algorithm that deals with NNs with one hidden layer)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/938448)   - **""DeepRED – Rule Extraction from Deep Neural Networks""**, International Conference on Discovery Science, 2016     - Jan Ruben Zilke, Eneldo Loza Mencía, Frederik Janssen *(Extend CRED algorithm by deriving intermediate rules for every additional hidden layer)*     - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-46307-0_29)   - **""Eclectic rule extraction from Neural Networks using aggregated Decision Trees""**, ICECE, 2012     - MD.","- ***Extract axis-aligned trees***   - **""<PUBLICATION>Rule extraction from neural networks via decision tree induction</PUBLICATION>""**, <CONFERENCE>IJCNN</CONFERENCE>, 2001     - Makoto Sato, Hiroshi Tsukimoto *(CRED algorithm that deals with NNs with one hidden layer)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/938448)   - **""<PUBLICATION>DeepRED – Rule Extraction from Deep Neural Networks</PUBLICATION>""**, <CONFERENCE>International Conference on Discovery Science</CONFERENCE>, 2016     - Jan Ruben Zilke, Eneldo Loza Mencía, Frederik Janssen *(Extend CRED algorithm by deriving intermediate rules for every additional hidden layer)*     - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-46307-0_29)   - **""<PUBLICATION>Eclectic rule extraction from Neural Networks using aggregated Decision Trees</PUBLICATION>""**, <CONFERENCE>ICECE</CONFERENCE>, 2012     - MD.","- ***Extract axis-aligned trees***  
  - **""Rule extraction from neural networks via decision tree induction""**, IJCNN, 2001  
    - Makoto Sato, Hiroshi Tsukimoto *(CRED algorithm that deals with NNs with one hidden layer)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/938448)  
  - **""DeepRED – Rule Extraction from Deep Neural Networks""**, International Conference on Discovery Science, 2016  
    - Jan Ruben Zilke, Eneldo Loza Mencía, Frederik Janssen *(Extend CRED algorithm by deriving intermediate rules for every additional hidden layer)*  
    - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-46307-0_29)  
  - **""Eclectic rule extraction from Neural Networks using aggregated Decision Trees""**, ICECE, 2012  
    - MD.","- ***Extract axis-aligned trees***  
  - **""<PUBLICATION>Rule extraction from neural networks via decision tree induction</PUBLICATION>""**, <CONFERENCE>IJCNN</CONFERENCE>, 2001  
    - Makoto Sato, Hiroshi Tsukimoto *(CRED algorithm that deals with NNs with one hidden layer)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/938448)  
  - **""<PUBLICATION>DeepRED – Rule Extraction from Deep Neural Networks</PUBLICATION>""**, <CONFERENCE>International Conference on Discovery Science</CONFERENCE>, 2016  
    - Jan Ruben Zilke, Eneldo Loza Mencía, Frederik Janssen *(Extend CRED algorithm by deriving intermediate rules for every additional hidden layer)*  
    - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-46307-0_29)  
  - **""<PUBLICATION>Eclectic rule extraction from Neural Networks using aggregated Decision Trees</PUBLICATION>""**, <CONFERENCE>ICECE</CONFERENCE>, 2012  
    - MD.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\0ca0e72d.txt,0.9894039735099338
42,"- ***Tree regularization***   - **""Beyond Sparsity: Tree Regularization of Deep Models for Interpretability""**, AAAI, 2018      - Mike Wu *et al.* *(a complexity penalty function that aims to optimize the deep model for interpretability and human-simulatability)*     - [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/11501) [[Code]](https://github.com/dtak/tree-regularization-public)   - **""Regional Tree Regularization for Interpretability in Deep Neural Networks""**, AAAI, 2020     - Mike Wu *et al.","- ***Tree regularization***   - **""<PUBLICATION>Beyond Sparsity: Tree Regularization of Deep Models for Interpretability</PUBLICATION>""**, <CONFERENCE>AAAI</CONFERENCE>, 2018      - Mike Wu *et al.* *(a complexity penalty function that aims to optimize the deep model for interpretability and human-simulatability)*     - [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/11501) [[Code]](https://github.com/dtak/tree-regularization-public)   - **""<PUBLICATION>Regional Tree Regularization for Interpretability in Deep Neural Networks</PUBLICATION>""**, <CONFERENCE>AAAI</CONFERENCE>, 2020     - Mike Wu *et al.","- ***Tree regularization***  
  - **""Beyond Sparsity: Tree Regularization of Deep Models for Interpretability""**, AAAI, 2018  
  - Mike Wu *et al.* *(a complexity penalty function that aims to optimize the deep model for interpretability and human-simulatability)*  
  - [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/11501) [[Code]](https://github.com/dtak/tree-regularization-public)  
  - **""Regional Tree Regularization for Interpretability in Deep Neural Networks""**, AAAI, 2020  
  - Mike Wu *et al.","- ***Tree regularization***  
  - **""<PUBLICATION>Beyond Sparsity: Tree Regularization of Deep Models for Interpretability</PUBLICATION>""**, <CONFERENCE>AAAI</CONFERENCE>, 2018  
  - Mike Wu *et al.* *(a complexity penalty function that aims to optimize the deep model for interpretability and human-simulatability)*  
  - [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/11501) [[Code]](https://github.com/dtak/tree-regularization-public)  
  - **""<PUBLICATION>Regional Tree Regularization for Interpretability in Deep Neural Networks</PUBLICATION>""**, <CONFERENCE>AAAI</CONFERENCE>, 2020  
  - Mike Wu *et al.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\f2e8adf1.txt,0.9893307468477207
47,Semi-hybrid: NNs Leveraging Class Hierarchies.,Semi-hybrid: NNs Leveraging Class Hierarchies.,`Semi-hybrid: NNs Leveraging Class Hierarchies.`,`<PUBLICATION>Semi-hybrid: NNs Leveraging Class Hierarchies</PUBLICATION>.`,../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\a7c65209.txt,0.9787234042553191
51,These  approaches are considered to be half and implicit integration of NNs and DTs.,These  approaches are considered to be half and implicit integration of NNs and DTs.,These approaches are considered to be half and implicit integration of NNs and DTs.,These approaches are considered to be half and implicit integration of NNs and DTs.,../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\632a6a88.txt,0.9940119760479041
59,"- ***Hierarchical multi-label classification using local neural networks***   - **""An integrated approach of neural network and decision tree to classification""**, ICMLC, 2014     - Ricardo Cerri, Rodrigo C Barros, André CPLF De Carvalho     - [[Paper]](https://www.sciencedirect.com/science/article/pii/S0022000013000718)   - **""Reduction strategies for hierarchical multi-label classification in protein function prediction""**, BMC Bioinformatics, 2016     - Ricardo Cerri *et al.*     - [[Paper]](https://link.springer.com/article/10.1186/s12859-016-1232-1)   - **""HD-CNN: Hierarchical Deep Convolutional Neural Networks for Large Scale Visual Recognition""**, ICCV, 2015     - Zhicheng Yan *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Yan_HD-CNN_Hierarchical_Deep_ICCV_2015_paper.html) [[Code]](https://github.com/Changgang-Zheng/HD-CNN)   - **""Your ""Flamingo"" is My ""Bird"": Fine-Grained, or Not""**, CVPR, 2021     - Dongliang Chang *et al.* *(disentangle coarse and fine features)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html) [[Code]](https://github.com/PRIS-CV/Fine-Grained-or-Not)  - ***Branch the network after a shared trunk***   - **""Learning to Make Better Mistakes: Semantics-aware Visual Food Recognition""**, ACM international conference on Multimedia, 2016      - Hui Wu *et al.* *(a single network backbone shared by multiple fully-connected layers)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/2964284.2967205)   - **""Do Convolutional Neural Networks Learn Class Hierarchy?""","- ***Hierarchical multi-label classification using local neural networks***   - **""<PUBLICATION>An integrated approach of neural network and decision tree to classification</PUBLICATION>""**, <CONFERENCE>ICMLC</CONFERENCE>, 2014     - Ricardo Cerri, Rodrigo C Barros, André CPLF De Carvalho     - [[Paper]](https://www.sciencedirect.com/science/article/pii/S0022000013000718)   - **""<PUBLICATION>Reduction strategies for hierarchical multi-label classification in protein function prediction</PUBLICATION>""**, BMC Bioinformatics, 2016     - Ricardo Cerri *et al.*     - [[Paper]](https://link.springer.com/article/10.1186/s12859-016-1232-1)   - **""<PUBLICATION>HD-CNN: Hierarchical Deep Convolutional Neural Networks for Large Scale Visual Recognition</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2015     - Zhicheng Yan *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Yan_HD-CNN_Hierarchical_Deep_ICCV_2015_paper.html) [[Code]](https://github.com/Changgang-Zheng/HD-CNN)   - **""<PUBLICATION>Your ""Flamingo"" is My ""Bird"": Fine-Grained, or Not</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2021     - Dongliang Chang *et al.* *(disentangle coarse and fine features)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html) [[Code]](https://github.com/PRIS-CV/Fine-Grained-or-Not)  - ***Branch the network after a shared trunk***   - **""<PUBLICATION>Learning to Make Better Mistakes: Semantics-aware Visual Food Recognition</PUBLICATION>""**, <CONFERENCE>ACM international conference on Multimedia</CONFERENCE>, 2016      - Hui Wu *et al.* *(a single network backbone shared by multiple fully-connected layers)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/2964284.2967205)   - **""<PUBLICATION>Do Convolutional Neural Networks Learn Class Hierarchy?</PUBLICATION>""","- ***Hierarchical multi-label classification using local neural networks***  
  - **""An integrated approach of neural network and decision tree to classification""**, ICMLC, 2014  
    - Ricardo Cerri, Rodrigo C Barros, André CPLF De Carvalho  
    - [[Paper]](https://www.sciencedirect.com/science/article/pii/S0022000013000718)  
  - **""Reduction strategies for hierarchical multi-label classification in protein function prediction""**, BMC Bioinformatics, 2016  
    - Ricardo Cerri *et al.*  
    - [[Paper]](https://link.springer.com/article/10.1186/s12859-016-1232-1)  
  - **""HD-CNN: Hierarchical Deep Convolutional Neural Networks for Large Scale Visual Recognition""**, ICCV, 2015  
    - Zhicheng Yan *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Yan_HD-CNN_Hierarchical_Deep_ICCV_2015_paper.html) [[Code]](https://github.com/Changgang-Zheng/HD-CNN)  
  - **""Your ""Flamingo"" is My ""Bird"": Fine-Grained, or Not""**, CVPR, 2021  
    - Dongliang Chang *et al.* *(disentangle coarse and fine features)*  
    - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html) [[Code]](https://github.com/PRIS-CV/Fine-Grained-or-Not)  
- ***Branch the network after a shared trunk***  
  - **""Learning to Make Better Mistakes: Semantics-aware Visual Food Recognition""**, ACM international conference on Multimedia, 2016  
    - Hui Wu *et al.* *(a single network backbone shared by multiple fully-connected layers)*  
    - [[Paper]](https://dl.acm.org/doi/abs/10.1145/2964284.2967205)  
  - **""Do Convolutional Neural Networks Learn Class Hierarchy?""","- ***Hierarchical multi-label classification using local neural networks***  
  - **""<PUBLICATION>An integrated approach of neural network and decision tree to classification</PUBLICATION>""**, <CONFERENCE>ICMLC</CONFERENCE>, 2014  
    - Ricardo Cerri, Rodrigo C Barros, André CPLF De Carvalho  
    - [[Paper]](https://www.sciencedirect.com/science/article/pii/S0022000013000718)  
  - **""<PUBLICATION>Reduction strategies for hierarchical multi-label classification in protein function prediction</PUBLICATION>""**, <PUBLICATION>BMC Bioinformatics</PUBLICATION>, 2016  
    - Ricardo Cerri *et al.*  
    - [[Paper]](https://link.springer.com/article/10.1186/s12859-016-1232-1)  
  - **""<PUBLICATION>HD-CNN: Hierarchical Deep Convolutional Neural Networks for Large Scale Visual Recognition</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2015  
    - Zhicheng Yan *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Yan_HD-CNN_Hierarchical_Deep_ICCV_2015_paper.html) [[Code]](https://github.com/Changgang-Zheng/HD-CNN)  
  - **""<PUBLICATION>Your ""Flamingo"" is My ""Bird"": Fine-Grained, or Not</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2021  
    - Dongliang Chang *et al.* *(disentangle coarse and fine features)*  
    - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html) [[Code]](https://github.com/PRIS-CV/Fine-Grained-or-Not)  
- ***Branch the network after a shared trunk***  
  - **""<PUBLICATION>Learning to Make Better Mistakes: Semantics-aware Visual Food Recognition</PUBLICATION>""**, <CONFERENCE>ACM international conference on Multimedia</CONFERENCE>, 2016  
    - Hui Wu *et al.* *(a single network backbone shared by multiple fully-connected layers)*  
    - [[Paper]](https://dl.acm.org/doi/abs/10.1145/2964284.2967205)  
  - **""<PUBLICATION>Do Convolutional Neural Networks Learn Class Hierarchy?</PUBLICATION>""",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\1e6300f8.txt,0.9902557856272838
60,"**, TVCG, 2017     - Alsallakh Bilal *et al.* *(deep CNN with branches at intermediate layers to fit the coarser-grained labels)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8017618)   - **""Fine-Grained Representation Learning and Recognition by Exploiting Hierarchical Semantic Embedding""**, ACM international conference on Multimedia, 2018     - Tianshui Chen *et al.* *(introduce an attention mechanism to incorporate the coarse-grained results for learning finer-grained features)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/3240508.3240523)  - ***Interactions between different branches***   - **""Label Hierarchy Transition: Modeling Class Hierarchies to Enhance Deep Classifiers""**, arXiv, 2021     - Renzhen Wang, *et al* *(propose label hierarchy transition matrices whose column vectors represent the conditional label distributions of classes between two adjacent hierarchies)*     - [[Paper]](https://arxiv.org/abs/2112.02353)   - **""Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification""**, CVPR, 2022     - Jingzhou Chen *et al.* *(propose the hierarchical residual network in which granularity-specific features from parent levels are added to features in children levels.)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html) [[Code]](https://github.com/MonsterZhZh/HRN)  #### 2.2 Hierarchical Loss Function.","**, <CONFERENCE>TVCG</CONFERENCE>, 2017     - Alsallakh Bilal *et al.* *(deep CNN with branches at intermediate layers to fit the coarser-grained labels)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8017618)   - **""<PUBLICATION>Fine-Grained Representation Learning and Recognition by Exploiting Hierarchical Semantic Embedding</PUBLICATION>""**, <CONFERENCE>ACM international conference on Multimedia</CONFERENCE>, 2018     - Tianshui Chen *et al.* *(introduce an attention mechanism to incorporate the coarse-grained results for learning finer-grained features)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/3240508.3240523)  - ***Interactions between different branches***   - **""<PUBLICATION>Label Hierarchy Transition: Modeling Class Hierarchies to Enhance Deep Classifiers</PUBLICATION>""**, arXiv, 2021     - Renzhen Wang, *et al* *(propose label hierarchy transition matrices whose column vectors represent the conditional label distributions of classes between two adjacent hierarchies)*     - [[Paper]](https://arxiv.org/abs/2112.02353)   - **""<PUBLICATION>Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2022     - Jingzhou Chen *et al.* *(propose the hierarchical residual network in which granularity-specific features from parent levels are added to features in children levels.)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html) [[Code]](https://github.com/MonsterZhZh/HRN)  #### 2.2 Hierarchical Loss Function.","- **""Fine-Grained Representation Learning and Recognition by Exploiting Hierarchical Semantic Embedding""**, ACM international conference on Multimedia, 2018     - Tianshui Chen *et al.* *(introduce an attention mechanism to incorporate the coarse-grained results for learning finer-grained features)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/3240508.3240523)  - ***Interactions between different branches***   - **""Label Hierarchy Transition: Modeling Class Hierarchies to Enhance Deep Classifiers""**, arXiv, 2021     - Renzhen Wang, *et al* *(propose label hierarchy transition matrices whose column vectors represent the conditional label distributions of classes between two adjacent hierarchies)*     - [[Paper]](https://arxiv.org/abs/2112.02353)   - **""Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification""**, CVPR, 2022     - Jingzhou Chen *et al.* *(propose the hierarchical residual network in which granularity-specific features from parent levels are added to features in children levels.)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html) [[Code]](https://github.com/MonsterZhZh/HRN)  #### 2.2 Hierarchical Loss Function.","- **""Fine-Grained Representation Learning and Recognition by Exploiting Hierarchical Semantic Embedding""**, <PUBLICATION>ACM international conference on Multimedia</PUBLICATION>, 2018     - Tianshui Chen *et al.* *(introduce an attention mechanism to incorporate the coarse-grained results for learning finer-grained features)*     - [[Paper]](https://dl.acm.org/doi/abs/10.1145/3240508.3240523)  - ***Interactions between different branches***   - **""Label Hierarchy Transition: Modeling Class Hierarchies to Enhance Deep Classifiers""**, <PUBLICATION>arXiv</PUBLICATION>, 2021     - Renzhen Wang, *et al* *(propose label hierarchy transition matrices whose column vectors represent the conditional label distributions of classes between two adjacent hierarchies)*     - [[Paper]](https://arxiv.org/abs/2112.02353)   - **""Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification""**, <CONFERENCE>CVPR</CONFERENCE>, 2022     - Jingzhou Chen *et al.* *(propose the hierarchical residual network in which granularity-specific features from parent levels are added to features in children levels.)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html) [[Code]](https://github.com/MonsterZhZh/HRN)  #### 2.2 Hierarchical Loss Function.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\522245f2.txt,0.9296847939037063
63,"- ***Predict at each grain separately, *i.e.*, first take a model pre-trained on one level, then tune it using labels from other levels***   - **""Coherent Hierarchical Multi-Label Classification Networks""**, NIPS, 2020     - Eleonora Giunchiglia, Thomas Lukasiewicz     - [[Paper]](https://proceedings.neurips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html) [[Code]](https://github.com/EGiunchiglia/C-HMCNN)   - **""Learning Hierarchical Visual Representations in Deep Neural Networks Using Hierarchical Linguistic Labels""**, arXiv, 2018     - Joshua C Peterson *et al.*     - [[Paper]](https://arxiv.org/abs/1805.07647)  - ***Utilize the hierarchical constraints directly***   - **""Learning hierarchical similarity metrics""**, CVPR, 2012     - Nakul Verma *et al.* *(probabilistic nearest-neighbor classification based framework)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6247938)   - **""Discriminative Transfer Learning with Tree-based Priors""**, NIPS, 2013     - Nitish Srivastava, Russ R Salakhutdinov *(DNN with hierarchical priors over the parameters of the classification layer)*     - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/9ac403da7947a183884c18a67d3aa8de-Abstract.html)   - **""Large-Scale Object Classification Using Label Relation Graphs""**, ECCV, 2018     - Jia Deng *et al.* *(encodes semantic relations into a directed acyclic graph and compute a loss defined on it)*     - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_4) [[Code]](https://github.com/kylemin/HEX-graph)   - **""Making Better Mistakes: Leveraging Class Hierarchies With Deep Networks""**, CVPR, 2020     - Luca Bertinetto *et al.* *(incorporate class hierarchy into the cross-entropy loss)*     - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Bertinetto_Making_Better_Mistakes_Leveraging_Class_Hierarchies_With_Deep_Networks_CVPR_2020_paper.html)  #### 2.3 Label Embedding.","- ***Predict at each grain separately, *i.e.*, first take a model pre-trained on one level, then tune it using labels from other levels***   - **""<PUBLICATION>Coherent Hierarchical Multi-Label Classification Networks</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2020     - Eleonora Giunchiglia, Thomas Lukasiewicz     - [[Paper]](https://proceedings.neurips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html) [[Code]](https://github.com/EGiunchiglia/C-HMCNN)   - **""<PUBLICATION>Learning Hierarchical Visual Representations in Deep Neural Networks Using Hierarchical Linguistic Labels</PUBLICATION>""**, arXiv, 2018     - Joshua C Peterson *et al.*     - [[Paper]](https://arxiv.org/abs/1805.07647)  - ***Utilize the hierarchical constraints directly***   - **""<PUBLICATION>Learning hierarchical similarity metrics</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2012     - Nakul Verma *et al.* *(probabilistic nearest-neighbor classification based framework)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6247938)   - **""<PUBLICATION>Discriminative Transfer Learning with Tree-based Priors</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2013     - Nitish Srivastava, Russ R Salakhutdinov *(DNN with hierarchical priors over the parameters of the classification layer)*     - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/9ac403da7947a183884c18a67d3aa8de-Abstract.html)   - **""<PUBLICATION>Large-Scale Object Classification Using Label Relation Graphs</PUBLICATION>""**, <CONFERENCE>ECCV</CONFERENCE>, 2018     - Jia Deng *et al.* *(encodes semantic relations into a directed acyclic graph and compute a loss defined on it)*     - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_4) [[Code]](https://github.com/kylemin/HEX-graph)   - **""<PUBLICATION>Making Better Mistakes: Leveraging Class Hierarchies With Deep Networks</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020     - Luca Bertinetto *et al.* *(incorporate class hierarchy into the cross-entropy loss)*     - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Bertinetto_Making_Better_Mistakes_Leveraging_Class_Hierarchies_With_Deep_Networks_CVPR_2020_paper.html)  #### 2.3 Label Embedding.","- ***Predict at each grain separately, *i.e.*, first take a model pre-trained on one level, then tune it using labels from other levels***  
  - **""Coherent Hierarchical Multi-Label Classification Networks""**, NIPS, 2020  
    - Eleonora Giunchiglia, Thomas Lukasiewicz  
    - [[Paper]](https://proceedings.neurips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html) [[Code]](https://github.com/EGiunchiglia/C-HMCNN)  
  - **""Learning Hierarchical Visual Representations in Deep Neural Networks Using Hierarchical Linguistic Labels""**, arXiv, 2018  
    - Joshua C Peterson *et al.*  
    - [[Paper]](https://arxiv.org/abs/1805.07647)  
- ***Utilize the hierarchical constraints directly***  
  - **""Learning hierarchical similarity metrics""**, CVPR, 2012  
    - Nakul Verma *et al.* *(probabilistic nearest-neighbor classification based framework)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6247938)  
  - **""Discriminative Transfer Learning with Tree-based Priors""**, NIPS, 2013  
    - Nitish Srivastava, Russ R Salakhutdinov *(DNN with hierarchical priors over the parameters of the classification layer)*  
    - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/9ac403da7947a183884c18a67d3aa8de-Abstract.html)  
  - **""Large-Scale Object Classification Using Label Relation Graphs""**, ECCV, 2018  
    - Jia Deng *et al.* *(encodes semantic relations into a directed acyclic graph and compute a loss defined on it)*  
    - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_4) [[Code]](https://github.com/kylemin/HEX-graph)  
  - **""Making Better Mistakes: Leveraging Class Hierarchies With Deep Networks""**, CVPR, 2020  
    - Luca Bertinetto *et al.* *(incorporate class hierarchy into the cross-entropy loss)*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Bertinetto_Making_Better_Mistakes_Leveraging_Class_Hierarchies_With_Deep_Networks_CVPR_2020_paper.html)  
#### 2.3 Label Embedding.","- ***Predict at each grain separately, *i.e.*, first take a model pre-trained on one level, then tune it using labels from other levels***  
  - **""<PUBLICATION>Coherent Hierarchical Multi-Label Classification Networks</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2020  
    - Eleonora Giunchiglia, Thomas Lukasiewicz  
    - [[Paper]](https://proceedings.neurips.cc/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html) [[Code]](https://github.com/EGiunchiglia/C-HMCNN)  
  - **""<PUBLICATION>Learning Hierarchical Visual Representations in Deep Neural Networks Using Hierarchical Linguistic Labels</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2018  
    - Joshua C Peterson *et al.*  
    - [[Paper]](https://arxiv.org/abs/1805.07647)  
- ***Utilize the hierarchical constraints directly***  
  - **""<PUBLICATION>Learning hierarchical similarity metrics</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2012  
    - Nakul Verma *et al.* *(probabilistic nearest-neighbor classification based framework)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6247938)  
  - **""<PUBLICATION>Discriminative Transfer Learning with Tree-based Priors</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2013  
    - Nitish Srivastava, Russ R Salakhutdinov *(DNN with hierarchical priors over the parameters of the classification layer)*  
    - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/9ac403da7947a183884c18a67d3aa8de-Abstract.html)  
  - **""<PUBLICATION>Large-Scale Object Classification Using Label Relation Graphs</PUBLICATION>""**, <CONFERENCE>ECCV</CONFERENCE>, 2018  
    - Jia Deng *et al.* *(encodes semantic relations into a directed acyclic graph and compute a loss defined on it)*  
    - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_4) [[Code]](https://github.com/kylemin/HEX-graph)  
  - **""<PUBLICATION>Making Better Mistakes: Leveraging Class Hierarchies With Deep Networks</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020  
    - Luca Bertinetto *et al.* *(incorporate class hierarchy into the cross-entropy loss)*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Bertinetto_Making_Better_Mistakes_Leveraging_Class_Hierarchies_With_Deep_Networks_CVPR_2020_paper.html)  
#### 2.3 Label Embedding.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\3dbf526e.txt,0.9903455284552846
66,"- ***DeViSE method that utilizes unannotated Wikipedia text***   - **""DeViSE: A Deep Visual-Semantic Embedding Model""**, NIPS, 2013     - Andrea Frome *et al.*     - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/7cce53cf90577442771720a370c3c723-Abstract.html) [[Code]](https://github.com/jean4599/DeViSE)  - ***Embeddings whose pair-wise dot products correspond to semantic similarity between classes***   - **""Hierarchy-Based Image Embeddings for Semantic Image Retrieval""**, WACV, 2019     - Björn Barz, Joachim Denzler     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8658633) [[Code]](https://github.com/cvjena/semantic-embeddings)  - **Employ the entailment cones to learn order-preserving embeddings**   - **""Hierarchical Image Classification Using Entailment Cone Embeddings""**, CVPR, 2020     - Ankit Dhall *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_CVPRW_2020/html/w50/Dhall_Hierarchical_Image_Classification_Using_Entailment_Cone_Embeddings_CVPRW_2020_paper.html) [[Code]](https://github.com/ankitdhall/learning_embeddings)  - ***Label embeddings in zero-shot classification***   - **""Latent Embeddings for Zero-Shot Classification""**, CVPR, 2016     - Yongqin Xian *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Xian_Latent_Embeddings_for_CVPR_2016_paper.html)   - **""Evaluation of Output Embeddings for Fine-Grained Image Classification""**, CVPR, 2015     - Zeynep Akata *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/html/Akata_Evaluation_of_Output_2015_CVPR_paper.html)   ### 3.","- ***DeViSE method that utilizes unannotated Wikipedia text***   - **""<PUBLICATION>DeViSE: A Deep Visual-Semantic Embedding Model</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2013     - Andrea Frome *et al.*     - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/7cce53cf90577442771720a370c3c723-Abstract.html) [[Code]](https://github.com/jean4599/DeViSE)  - ***Embeddings whose pair-wise dot products correspond to semantic similarity between classes***   - **""<PUBLICATION>Hierarchy-Based Image Embeddings for Semantic Image Retrieval</PUBLICATION>""**, <CONFERENCE>WACV</CONFERENCE>, 2019     - Björn Barz, Joachim Denzler     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8658633) [[Code]](https://github.com/cvjena/semantic-embeddings)  - **Employ the entailment cones to learn order-preserving embeddings**   - **""<PUBLICATION>Hierarchical Image Classification Using Entailment Cone Embeddings</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020     - Ankit Dhall *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_CVPRW_2020/html/w50/Dhall_Hierarchical_Image_Classification_Using_Entailment_Cone_Embeddings_CVPRW_2020_paper.html) [[Code]](https://github.com/ankitdhall/learning_embeddings)  - ***Label embeddings in zero-shot classification***   - **""<PUBLICATION>Latent Embeddings for Zero-Shot Classification</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2016     - Yongqin Xian *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Xian_Latent_Embeddings_for_CVPR_2016_paper.html)   - **""<PUBLICATION>Evaluation of Output Embeddings for Fine-Grained Image Classification</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2015     - Zeynep Akata *et al.*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/html/Akata_Evaluation_of_Output_2015_CVPR_paper.html)   ### 3.","- ***DeViSE method that utilizes unannotated Wikipedia text***  
  - **""DeViSE: A Deep Visual-Semantic Embedding Model""**, NIPS, 2013  
    - Andrea Frome *et al.*  
    - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/7cce53cf90577442771720a370c3c723-Abstract.html) [[Code]](https://github.com/jean4599/DeViSE)  
- ***Embeddings whose pair-wise dot products correspond to semantic similarity between classes***  
  - **""Hierarchy-Based Image Embeddings for Semantic Image Retrieval""**, WACV, 2019  
    - Björn Barz, Joachim Denzler  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8658633) [[Code]](https://github.com/cvjena/semantic-embeddings)  
- **Employ the entailment cones to learn order-preserving embeddings**  
  - **""Hierarchical Image Classification Using Entailment Cone Embeddings""**, CVPR, 2020  
    - Ankit Dhall *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPRW_2020/html/w50/Dhall_Hierarchical_Image_Classification_Using_Entailment_Cone_Embeddings_CVPRW_2020_paper.html) [[Code]](https://github.com/ankitdhall/learning_embeddings)  
- ***Label embeddings in zero-shot classification***  
  - **""Latent Embeddings for Zero-Shot Classification""**, CVPR, 2016  
    - Yongqin Xian *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Xian_Latent_Embeddings_for_CVPR_2016_paper.html)  
  - **""Evaluation of Output Embeddings for Fine-Grained Image Classification""**, CVPR, 2015  
    - Zeynep Akata *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/html/Akata_Evaluation_of_Output_2015_CVPR_paper.html)  
### 3.","- ***DeViSE method that utilizes unannotated Wikipedia text***  
  - **""<PUBLICATION>DeViSE: A Deep Visual-Semantic Embedding Model</PUBLICATION>""**, <CONFERENCE>NIPS</CONFERENCE>, 2013  
    - Andrea Frome *et al.*  
    - [[Paper]](https://proceedings.neurips.cc/paper/2013/hash/7cce53cf90577442771720a370c3c723-Abstract.html) [[Code]](https://github.com/jean4599/DeViSE)  
- ***Embeddings whose pair-wise dot products correspond to semantic similarity between classes***  
  - **""<PUBLICATION>Hierarchy-Based Image Embeddings for Semantic Image Retrieval</PUBLICATION>""**, <CONFERENCE>WACV</CONFERENCE>, 2019  
    - Björn Barz, Joachim Denzler  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8658633) [[Code]](https://github.com/cvjena/semantic-embeddings)  
- **Employ the entailment cones to learn order-preserving embeddings**  
  - **""<PUBLICATION>Hierarchical Image Classification Using Entailment Cone Embeddings</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020  
    - Ankit Dhall *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPRW_2020/html/w50/Dhall_Hierarchical_Image_Classification_Using_Entailment_Cone_Embeddings_CVPRW_2020_paper.html) [[Code]](https://github.com/ankitdhall/learning_embeddings)  
- ***Label embeddings in zero-shot classification***  
  - **""<PUBLICATION>Latent Embeddings for Zero-Shot Classification</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2016  
    - Yongqin Xian *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Xian_Latent_Embeddings_for_CVPR_2016_paper.html)  
  - **""<PUBLICATION>Evaluation of Output Embeddings for Fine-Grained Image Classification</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2015  
    - Zeynep Akata *et al.*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/html/Akata_Evaluation_of_Output_2015_CVPR_paper.html)  
### 3.",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\217c4270.txt,0.9891270580925753
67,Hybrid: Neural Decision Trees.,Hybrid: Neural Decision Trees.,`Hybrid: Neural Decision Trees.`,`Hybrid: <PUBLICATION>Neural Decision Trees</PUBLICATION>.`,../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\a6fd89c3.txt,0.967741935483871
75,"- ***Bigot NDTs with pure leaves***   - **""Structure-driven induction of decision tree classifiers through neural learning""**, Pattern Recognition, 1997     - Ishwar K Sethi *et al.* *(randomly initialized leaf classes)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320397000058)   - **""NBDT: Neural-Backed Decision Trees""**, ICCV, 2020     - Alvin Wan *et al.* *(assign a specific concept to each terminal and intermediate node by WordNet)*     - [[Paper]](https://arxiv.org/abs/2004.00221) [[Code]](https://github.com/alvinwan/nbdt-pytorch-image-models)  - ***Bigot NDTs with determined leaf distributions***   - **""Distilling a Neural Network Into a Soft Decision Tree""**, AI*IA, 2017     - Nicholas Frosst, Geoffrey Hinton *(jointly optimize leaves and other parameters via back-propagation)*     - [[Paper]](https://arxiv.org/abs/1711.09784) [[Code]](https://github.com/kimhc6028/soft-decision-tree)   - **""Policy-gradient Methods for Decision Trees""**, ESANN, 2016     - Aurélia Léon, Ludovic Denoyer *(use Monte Carlo approximation to expect the gradient of the objective function)*     - [[Paper]](http://www.smart-labex.fr/publications/pdf/56eab488c05ef.pdf)   - **""Deep Neural Decision Forests""**, ICCV, 2015     - Peter Kontschieder *et al.* *(propose a derivative-free strategy to solely optimize the leaf parameters, as a convex optimization problem)*     - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.html) [[Code]](https://github.com/jingxil/Neural-Decision-Forests)   - **""Deep Regression Forests for Age Estimation""**, CVPR, 2018     - Wei Shen *et al.* *(regression forests for age estimation)*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html) [[Code]](https://github.com/Sakura03/age_trans)   - **""Neural Decision Forests for Semantic Image Labelling""**, CVPR, 2014     - Samuel Rota Bulo, Peter Kontschieder *(decision forests for semantic image labelling)*     - [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Bulo_Neural_Decision_Forests_2014_CVPR_paper.html)   - **""Neural Prototype Trees for Interpretable Fine-Grained Image Recognition""**, CVPR, 2021     - WMeike Nauta, Ron van Bree, Christin Seifert *(prototype-based ante-hoc methods)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?","- ***Bigot NDTs with pure leaves***   - **""<PUBLICATION>Structure-driven induction of decision tree classifiers through neural learning</PUBLICATION>""**, Pattern Recognition, 1997     - Ishwar K Sethi *et al.* *(randomly initialized leaf classes)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320397000058)   - **""<PUBLICATION>NBDT: Neural-Backed Decision Trees</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2020     - Alvin Wan *et al.* *(assign a specific concept to each terminal and intermediate node by WordNet)*     - [[Paper]](https://arxiv.org/abs/2004.00221) [[Code]](https://github.com/alvinwan/nbdt-pytorch-image-models)  - ***Bigot NDTs with determined leaf distributions***   - **""<PUBLICATION>Distilling a Neural Network Into a Soft Decision Tree</PUBLICATION>""**, <CONFERENCE>AI*IA</CONFERENCE>, 2017     - Nicholas Frosst, Geoffrey Hinton *(jointly optimize leaves and other parameters via back-propagation)*     - [[Paper]](https://arxiv.org/abs/1711.09784) [[Code]](https://github.com/kimhc6028/soft-decision-tree)   - **""<PUBLICATION>Policy-gradient Methods for Decision Trees</PUBLICATION>""**, <CONFERENCE>ESANN</CONFERENCE>, 2016     - Aurélia Léon, Ludovic Denoyer *(use Monte Carlo approximation to expect the gradient of the objective function)*     - [[Paper]](http://www.smart-labex.fr/publications/pdf/56eab488c05ef.pdf)   - **""<PUBLICATION>Deep Neural Decision Forests</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2015     - Peter Kontschieder *et al.* *(propose a derivative-free strategy to solely optimize the leaf parameters, as a convex optimization problem)*     - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.html) [[Code]](https://github.com/jingxil/Neural-Decision-Forests)   - **""<PUBLICATION>Deep Regression Forests for Age Estimation</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2018     - Wei Shen *et al.* *(regression forests for age estimation)*     - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html) [[Code]](https://github.com/Sakura03/age_trans)   - **""<PUBLICATION>Neural Decision Forests for Semantic Image Labelling</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2014     - Samuel Rota Bulo, Peter Kontschieder *(decision forests for semantic image labelling)*     - [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Bulo_Neural_Decision_Forests_2014_CVPR_paper.html)   - **""<PUBLICATION>Neural Prototype Trees for Interpretable Fine-Grained Image Recognition</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2021     - WMeike Nauta, Ron van Bree, Christin Seifert *(prototype-based ante-hoc methods)*     - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?","- ***Bigot NDTs with pure leaves***  
  - **""Structure-driven induction of decision tree classifiers through neural learning""**, Pattern Recognition, 1997  
    - Ishwar K Sethi *et al.* *(randomly initialized leaf classes)*  
    - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320397000058)  
  - **""NBDT: Neural-Backed Decision Trees""**, ICCV, 2020  
    - Alvin Wan *et al.* *(assign a specific concept to each terminal and intermediate node by WordNet)*  
    - [[Paper]](https://arxiv.org/abs/2004.00221) [[Code]](https://github.com/alvinwan/nbdt-pytorch-image-models)  
- ***Bigot NDTs with determined leaf distributions***  
  - **""Distilling a Neural Network Into a Soft Decision Tree""**, AI*IA, 2017  
    - Nicholas Frosst, Geoffrey Hinton *(jointly optimize leaves and other parameters via back-propagation)*  
    - [[Paper]](https://arxiv.org/abs/1711.09784) [[Code]](https://github.com/kimhc6028/soft-decision-tree)  
  - **""Policy-gradient Methods for Decision Trees""**, ESANN, 2016  
    - Aurélia Léon, Ludovic Denoyer *(use Monte Carlo approximation to expect the gradient of the objective function)*  
    - [[Paper]](http://www.smart-labex.fr/publications/pdf/56eab488c05ef.pdf)  
  - **""Deep Neural Decision Forests""**, ICCV, 2015  
    - Peter Kontschieder *et al.* *(propose a derivative-free strategy to solely optimize the leaf parameters, as a convex optimization problem)*  
    - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.html) [[Code]](https://github.com/jingxil/Neural-Decision-Forests)  
  - **""Deep Regression Forests for Age Estimation""**, CVPR, 2018  
    - Wei Shen *et al.* *(regression forests for age estimation)*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html) [[Code]](https://github.com/Sakura03/age_trans)  
  - **""Neural Decision Forests for Semantic Image Labelling""**, CVPR, 2014  
    - Samuel Rota Bulo, Peter Kontschieder *(decision forests for semantic image labelling)*  
    - [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Bulo_Neural_Decision_Forests_2014_CVPR_paper.html)  
  - **""Neural Prototype Trees for Interpretable Fine-Grained Image Recognition""**, CVPR, 2021  
    - WMeike Nauta, Ron van Bree, Christin Seifert *(prototype-based ante-hoc methods)*  
    - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?","- ***Bigot NDTs with pure leaves***  
  - **""<PUBLICATION>Structure-driven induction of decision tree classifiers through neural learning</PUBLICATION>""**, <PUBLICATION>Pattern Recognition</PUBLICATION>, 1997  
    - Ishwar K Sethi *et al.* *(randomly initialized leaf classes)*  
    - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0031320397000058)  
  - **""<PUBLICATION>NBDT: Neural-Backed Decision Trees</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2020  
    - Alvin Wan *et al.* *(assign a specific concept to each terminal and intermediate node by WordNet)*  
    - [[Paper]](https://arxiv.org/abs/2004.00221) [[Code]](https://github.com/alvinwan/nbdt-pytorch-image-models)  
- ***Bigot NDTs with determined leaf distributions***  
  - **""<PUBLICATION>Distilling a Neural Network Into a Soft Decision Tree</PUBLICATION>""**, <CONFERENCE>AI*IA</CONFERENCE>, 2017  
    - Nicholas Frosst, Geoffrey Hinton *(jointly optimize leaves and other parameters via back-propagation)*  
    - [[Paper]](https://arxiv.org/abs/1711.09784) [[Code]](https://github.com/kimhc6028/soft-decision-tree)  
  - **""<PUBLICATION>Policy-gradient Methods for Decision Trees</PUBLICATION>""**, <CONFERENCE>ESANN</CONFERENCE>, 2016  
    - Aurélia Léon, Ludovic Denoyer *(use Monte Carlo approximation to expect the gradient of the objective function)*  
    - [[Paper]](http://www.smart-labex.fr/publications/pdf/56eab488c05ef.pdf)  
  - **""<PUBLICATION>Deep Neural Decision Forests</PUBLICATION>""**, <CONFERENCE>ICCV</CONFERENCE>, 2015  
    - Peter Kontschieder *et al.* *(propose a derivative-free strategy to solely optimize the leaf parameters, as a convex optimization problem)*  
    - [[Paper]](https://openaccess.thecvf.com/content_iccv_2015/html/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.html) [[Code]](https://github.com/jingxil/Neural-Decision-Forests)  
  - **""<PUBLICATION>Deep Regression Forests for Age Estimation</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2018  
    - Wei Shen *et al.* *(regression forests for age estimation)*  
    - [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html) [[Code]](https://github.com/Sakura03/age_trans)  
  - **""<PUBLICATION>Neural Decision Forests for Semantic Image Labelling</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2014  
    - Samuel Rota Bulo, Peter Kontschieder *(decision forests for semantic image labelling)*  
    - [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Bulo_Neural_Decision_Forests_2014_CVPR_paper.html)  
  - **""<PUBLICATION>Neural Prototype Trees for Interpretable Fine-Grained Image Recognition</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2021  
    - WMeike Nauta, Ron van Bree, Christin Seifert *(prototype-based ante-hoc methods)*  
    - [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\f3085c81.txt,0.9904015670910872
80,"- ***Hierarchical Mixtures of Experts (HME)***   - **""Hierarchical Mixtures of Experts and the EM Algorithm""**, Neural computation, 1994      - Michael I Jordan, Robert A Jacobs *(the original HME, a tree-structured model for regression and classification.)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6796382)   - **""Classification using hierarchical mixtures of experts""**, NNSP, 1994     - Steve R Waterhouse, Anthony J Robinson *(each leaf expert is non-linear and performs multi-way classification)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/366050)   - **""Bayesian Hierarchical Mixtures of Experts""**, arXiv, 2012     - Christopher M Bishop, Naonori Ueda, Steve Waterhouse *(bayesian treatments of the HME model to prevent the severe overfitting caused by maximum likelihood)*     - [[Paper]](https://arxiv.org/abs/1212.2447)     - ***Generalized HMEs in advanced frameworks***   - **""Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization""**, CVPR, 2020     - Ruyi Ji *et al.* *(incorporate convolutional operations along edges and use attention transformer modules to capture discriminative features)*     - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.html) [[Code]](https://isrc.iscas.ac.cn/gitlab/research/acnet)   - **""NDT: Neual Decision Tree Towards Fully Functioned Neural Graph""**, arXiv, 2017     - Han Xiao *(reformulate the non-differentiable information gain in the form of Dirac symbol and approximate it as a continuous function)*     - [[Paper]](https://arxiv.org/abs/1712.05934)   - **""Decision Forests, Convolutional Networks and the Models in-Between""**, arXiv, 2016     - Yani Ioannou *et al.* *(hybrid model between decision forests and convolutional networks)*     - [[Paper]](https://arxiv.org/abs/1603.01250)   - **""Deep Neural Decision Trees""**, arXiv, 2018     - Yongxin Yang, Irene Garcia Morillo, Timothy M Hospedales *(bin each feature of the input instance and determine the leaf node it will arrive)*     - [[Paper]](https://arxiv.org/abs/1806.06988) [[Code]](https://github.com/wOOL/DNDT)   - **""ViT-NeT: Interpretable Vision Transformers with Neural Tree Decoder""**, ICML, 2022     - Sangwon Kim, Jaeyeal Nam, Byoung Chul Ko *(transformer version of ProtoTree with expert leaves)*     - [[Paper]](https://proceedings.mlr.press/v162/kim22g.html) [[Code]](https://github.com/jumpsnack/ViT-NeT)  - ***Expert NDTs with architecture search phase***   - **""Adaptive Neural Trees""**, ICML, 2019     - Ryutaro Tanno *et al.* *(greedily choosing the best option between going deeper and splitting the input space)*     - [[Paper]](http://proceedings.mlr.press/v97/tanno19a.html?","- ***Hierarchical Mixtures of Experts (HME)***   - **""<PUBLICATION>Hierarchical Mixtures of Experts and the EM Algorithm</PUBLICATION>""**, Neural computation, 1994      - Michael I Jordan, Robert A Jacobs *(the original HME, a tree-structured model for regression and classification.)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6796382)   - **""<PUBLICATION>Classification using hierarchical mixtures of experts</PUBLICATION>""**, <CONFERENCE>NNSP</CONFERENCE>, 1994     - Steve R Waterhouse, Anthony J Robinson *(each leaf expert is non-linear and performs multi-way classification)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/366050)   - **""<PUBLICATION>Bayesian Hierarchical Mixtures of Experts</PUBLICATION>""**, arXiv, 2012     - Christopher M Bishop, Naonori Ueda, Steve Waterhouse *(bayesian treatments of the HME model to prevent the severe overfitting caused by maximum likelihood)*     - [[Paper]](https://arxiv.org/abs/1212.2447)     - ***Generalized HMEs in advanced frameworks***   - **""<PUBLICATION>Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020     - Ruyi Ji *et al.* *(incorporate convolutional operations along edges and use attention transformer modules to capture discriminative features)*     - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.html) [[Code]](https://isrc.iscas.ac.cn/gitlab/research/acnet)   - **""<PUBLICATION>NDT: Neual Decision Tree Towards Fully Functioned Neural Graph</PUBLICATION>""**, arXiv, 2017     - Han Xiao *(reformulate the non-differentiable information gain in the form of Dirac symbol and approximate it as a continuous function)*     - [[Paper]](https://arxiv.org/abs/1712.05934)   - **""<PUBLICATION>Decision Forests, Convolutional Networks and the Models in-Between</PUBLICATION>""**, arXiv, 2016     - Yani Ioannou *et al.* *(hybrid model between decision forests and convolutional networks)*     - [[Paper]](https://arxiv.org/abs/1603.01250)   - **""<PUBLICATION>Deep Neural Decision Trees</PUBLICATION>""**, arXiv, 2018     - Yongxin Yang, Irene Garcia Morillo, Timothy M Hospedales *(bin each feature of the input instance and determine the leaf node it will arrive)*     - [[Paper]](https://arxiv.org/abs/1806.06988) [[Code]](https://github.com/wOOL/DNDT)   - **""<PUBLICATION>ViT-NeT: Interpretable Vision Transformers with Neural Tree Decoder</PUBLICATION>""**, <CONFERENCE>ICML</CONFERENCE>, 2022     - Sangwon Kim, Jaeyeal Nam, Byoung Chul Ko *(transformer version of ProtoTree with expert leaves)*     - [[Paper]](https://proceedings.mlr.press/v162/kim22g.html) [[Code]](https://github.com/jumpsnack/ViT-NeT)  - ***Expert NDTs with architecture search phase***   - **""<PUBLICATION>Adaptive Neural Trees</PUBLICATION>""**, <CONFERENCE>ICML</CONFERENCE>, 2019     - Ryutaro Tanno *et al.* *(greedily choosing the best option between going deeper and splitting the input space)*     - [[Paper]](http://proceedings.mlr.press/v97/tanno19a.html?","- ***Hierarchical Mixtures of Experts (HME)***  
  - **""Hierarchical Mixtures of Experts and the EM Algorithm""**, Neural computation, 1994  
    - Michael I Jordan, Robert A Jacobs *(the original HME, a tree-structured model for regression and classification.)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6796382)  
  - **""Classification using hierarchical mixtures of experts""**, NNSP, 1994  
    - Steve R Waterhouse, Anthony J Robinson *(each leaf expert is non-linear and performs multi-way classification)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/366050)  
  - **""Bayesian Hierarchical Mixtures of Experts""**, arXiv, 2012  
    - Christopher M Bishop, Naonori Ueda, Steve Waterhouse *(bayesian treatments of the HME model to prevent the severe overfitting caused by maximum likelihood)*  
    - [[Paper]](https://arxiv.org/abs/1212.2447)  

- ***Generalized HMEs in advanced frameworks***  
  - **""Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization""**, CVPR, 2020  
    - Ruyi Ji *et al.* *(incorporate convolutional operations along edges and use attention transformer modules to capture discriminative features)*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.html) [[Code]](https://isrc.iscas.ac.cn/gitlab/research/acnet)  
  - **""NDT: Neual Decision Tree Towards Fully Functioned Neural Graph""**, arXiv, 2017  
    - Han Xiao *(reformulate the non-differentiable information gain in the form of Dirac symbol and approximate it as a continuous function)*  
    - [[Paper]](https://arxiv.org/abs/1712.05934)  
  - **""Decision Forests, Convolutional Networks and the Models in-Between""**, arXiv, 2016  
    - Yani Ioannou *et al.* *(hybrid model between decision forests and convolutional networks)*  
    - [[Paper]](https://arxiv.org/abs/1603.01250)  
  - **""Deep Neural Decision Trees""**, arXiv, 2018  
    - Yongxin Yang, Irene Garcia Morillo, Timothy M Hospedales *(bin each feature of the input instance and determine the leaf node it will arrive)*  
    - [[Paper]](https://arxiv.org/abs/1806.06988) [[Code]](https://github.com/wOOL/DNDT)  
  - **""ViT-NeT: Interpretable Vision Transformers with Neural Tree Decoder""**, ICML, 2022  
    - Sangwon Kim, Jaeyeal Nam, Byoung Chul Ko *(transformer version of ProtoTree with expert leaves)*  
    - [[Paper]](https://proceedings.mlr.press/v162/kim22g.html) [[Code]](https://github.com/jumpsnack/ViT-NeT)  

- ***Expert NDTs with architecture search phase***  
  - **""Adaptive Neural Trees""**, ICML, 2019  
    - Ryutaro Tanno *et al.* *(greedily choosing the best option between going deeper and splitting the input space)*  
    - [[Paper]](http://proceedings.mlr.press/v97/tanno19a.html?","- ***<PROJECT>Hierarchical Mixtures of Experts (HME)</PROJECT>***  
  - **""<PUBLICATION>Hierarchical Mixtures of Experts and the EM Algorithm</PUBLICATION>""**, <PUBLICATION>Neural computation</PUBLICATION>, 1994  
    - Michael I Jordan, Robert A Jacobs *(the original HME, a tree-structured model for regression and classification.)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6796382)  
  - **""<PUBLICATION>Classification using hierarchical mixtures of experts</PUBLICATION>""**, <CONFERENCE>NNSP</CONFERENCE>, 1994  
    - Steve R Waterhouse, Anthony J Robinson *(each leaf expert is non-linear and performs multi-way classification)*  
    - [[Paper]](https://ieeexplore.ieee.org/abstract/document/366050)  
  - **""<PUBLICATION>Bayesian Hierarchical Mixtures of Experts</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2012  
    - Christopher M Bishop, Naonori Ueda, Steve Waterhouse *(bayesian treatments of the HME model to prevent the severe overfitting caused by maximum likelihood)*  
    - [[Paper]](https://arxiv.org/abs/1212.2447)  

- ***Generalized HMEs in advanced frameworks***  
  - **""<PUBLICATION>Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization</PUBLICATION>""**, <CONFERENCE>CVPR</CONFERENCE>, 2020  
    - Ruyi Ji *et al.* *(incorporate convolutional operations along edges and use attention transformer modules to capture discriminative features)*  
    - [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.html) [[Code]](https://isrc.iscas.ac.cn/gitlab/research/acnet)  
  - **""<PUBLICATION>NDT: Neual Decision Tree Towards Fully Functioned Neural Graph</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2017  
    - Han Xiao *(reformulate the non-differentiable information gain in the form of Dirac symbol and approximate it as a continuous function)*  
    - [[Paper]](https://arxiv.org/abs/1712.05934)  
  - **""<PUBLICATION>Decision Forests, Convolutional Networks and the Models in-Between</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2016  
    - Yani Ioannou *et al.* *(hybrid model between decision forests and convolutional networks)*  
    - [[Paper]](https://arxiv.org/abs/1603.01250)  
  - **""<PUBLICATION>Deep Neural Decision Trees</PUBLICATION>""**, <PUBLICATION>arXiv</PUBLICATION>, 2018  
    - Yongxin Yang, Irene Garcia Morillo, Timothy M Hospedales *(bin each feature of the input instance and determine the leaf node it will arrive)*  
    - [[Paper]](https://arxiv.org/abs/1806.06988) [[Code]](https://github.com/wOOL/DNDT)  
  - **""<PUBLICATION>ViT-NeT: Interpretable Vision Transformers with Neural Tree Decoder</PUBLICATION>""**, <CONFERENCE>ICML</CONFERENCE>, 2022  
    - Sangwon Kim, Jaeyeal Nam, Byoung Chul Ko *(transformer version of ProtoTree with expert leaves)*  
    - [[Paper]](https://proceedings.mlr.press/v162/kim22g.html) [[Code]](https://github.com/jumpsnack/ViT-NeT)  

- ***Expert NDTs with architecture search phase***  
  - **""<PUBLICATION>Adaptive Neural Trees</PUBLICATION>""**, <CONFERENCE>ICML</CONFERENCE>, 2019  
    - Ryutaro Tanno *et al.* *(greedily choosing the best option between going deeper and splitting the input space)*  
    - [[Paper]](http://proceedings.mlr.press/v97/tanno19a.html?",../results/deepseek-chat/prompt-0/zzz_zju-vipa_awesome-neural-trees_main_README.md.tsv\6e3e47c8.txt,0.989365473236441
