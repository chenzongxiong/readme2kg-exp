sentence_idx,original_sentence,original_annotated,generated_annotated,source_file,similarity_score
1,# [Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries.],# [<PUBLICATION>Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries</PUBLICATION>.],# [Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries.],../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\e3bba87b.txt,1.0
2,"(https://arxiv.org/abs/1911.03826) Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez.","(https://arxiv.org/abs/1911.03826) Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez.","(https://arxiv.org/abs/1911.03826) <PUBLICATION>Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez</PUBLICATION>.
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\8e3b6b91.txt,0.99581589958159
3,"NeurIPS 2019   ## Overview This paper explores the task of interactive image retrieval using natural language queries, where a user progressively provides input queries to refine a set of retrieval results.","<CONFERENCE>NeurIPS 2019</CONFERENCE>   ## Overview This paper explores the task of interactive image retrieval using natural language queries, where a user progressively provides input queries to refine a set of retrieval results.","<CONFERENCE>NeurIPS 2019</CONFERENCE>   ## Overview This paper explores the task of interactive image retrieval using natural language queries, where a user progressively provides input queries to refine a set of retrieval results.
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\87c3b0bd.txt,0.9975786924939467
5,"We propose Drill-down, an effective framework for encoding multiple queries with an efficient compact state representation that significantly extends current methods for single-round image retrieval.","We propose Drill-down, an effective framework for encoding multiple queries with an efficient compact state representation that significantly extends current methods for single-round image retrieval.","We propose <PROJECT>Drill-down</PROJECT>, an effective framework for encoding multiple queries with an efficient compact state representation that significantly extends current methods for single-round image retrieval.",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\76aeaf68.txt,1.0
7,"Furthermore, we find that existing image datasets with textual captions can provide a surprisingly effective form of weak supervision for this task.","Furthermore, we find that existing image datasets with textual captions can provide a surprisingly effective form of weak supervision for this task.","Furthermore, we find that existing image <DATASET>datasets with textual captions</DATASET> can provide a surprisingly effective form of weak supervision for this task.",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\1a1c8cf6.txt,1.0
8,"We compare our method with existing sequential encoding and embedding networks, demonstrating superior performance on two proposed benchmarks: automatic image retrieval on a simulated scenario that uses region captions as queries, and interactive image retrieval using real queries from human evaluators.  ## Requirements - Setup a conda environment and install some prerequisite packages like this ```bash conda create -n retrieval python=3.6    # Create a virtual environment source activate retrieval              # Activate virtual environment conda install jupyter scikit-image cython opencv seaborn nltk pycairo h5py  # Install dependencies python -m nltk.downloader all        # Install NLTK data ``` - Please also install [pytorch](http://pytorch.org/) 1.0 (or higher), torchVision, and torchtext   ## Data  - Download the images of the Visual Genome dataset if you have not done so ```Shell .","We compare our method with existing sequential encoding and embedding networks, demonstrating superior performance on two proposed benchmarks: automatic image retrieval on a simulated scenario that uses region captions as queries, and interactive image retrieval using real queries from human evaluators.  ## Requirements - Setup a <SOFTWARE>conda</SOFTWARE> environment and install some prerequisite packages like this ```<PROGLANG>bash</PROGLANG> conda create -n retrieval <PROGLANG>python=3.6</PROGLANG>    # Create a virtual environment source activate retrieval              # Activate virtual environment <SOFTWARE>conda</SOFTWARE> install <SOFTWARE>jupyter</SOFTWARE> <SOFTWARE>scikit-image</SOFTWARE> <SOFTWARE>cython</SOFTWARE> <SOFTWARE>opencv</SOFTWARE> <SOFTWARE>seaborn</SOFTWARE> <SOFTWARE>nltk</SOFTWARE> <SOFTWARE>pycairo</SOFTWARE> <SOFTWARE>h5py</SOFTWARE>  # Install dependencies <SOFTWARE>python</SOFTWARE> -m <SOFTWARE>nltk</SOFTWARE>.downloader all        # Install <SOFTWARE>NLTK</SOFTWARE> data ``` - Please also install [<SOFTWARE>pytorch</SOFTWARE>](http://<SOFTWARE>pytorch</SOFTWARE>.org/) 1.0 (or higher), <SOFTWARE>torchVision</SOFTWARE>, and <SOFTWARE>torchtext</SOFTWARE>   ## Data  - Download the images of the <DATASET>Visual Genome</DATASET> dataset if you have not done so ```<PROGLANG>Shell</PROGLANG> .","Here is the annotated text in Markdown format:

We compare our method with existing sequential encoding and embedding networks, demonstrating superior performance on two proposed benchmarks: automatic image retrieval on a simulated scenario that uses region captions as queries, and interactive image retrieval using real queries from human evaluators.  ## Requirements - Setup a conda environment and install some prerequisite packages like this bash conda create -n retrieval <PROGLANG>python</PROGLANG>=3.6    # Create a virtual environment source activate retrieval              # Activate virtual environment conda install jupyter scikit-image cython opencv seaborn nltk pycairo h5py  # Install dependencies <PROGLANG>python</PROGLANG> -m nltk.downloader all        # Install NLTK data  - Please also install [<SOFTWARE>pytorch</SOFTWARE>](http://pytorch.org/) 1.0 (or higher), torchVision, and torchtext   ## Data  - Download the images of the <DATASET>Visual Genome</DATASET> dataset if you have not done so Shell .
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\4d9f0dd2.txt,0.9685124864277959
9,/experiments/scripts/fetch_images.sh ``` This will populate the `DrillDown/data` folder with `vg/VG_100K` and `vg/VG_100K_2`,/experiments/scripts/fetch_images.sh ``` This will populate the `DrillDown/data` folder with `vg/<DATASET>VG_100K</DATASET>` and `vg/<DATASET>VG_100K_2</DATASET>`,"/experiments/scripts/fetch_images.sh  This will populate the <DATASET>DrillDown/data</DATASET> folder with <DATASET>vg/VG_100K</DATASET> and <DATASET>vg/VG_100K_2</DATASET>
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\37d92613.txt,0.9583333333333334
10,.,.,".
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\cdb4ee2a.txt,0.6666666666666666
11,- Download the annotations of the images ```Shell .,- Download the annotations of the images ```<PROGLANG>Shell</PROGLANG> .,"- Download the annotations of the images <PROGLANG>Shell</PROGLANG> .
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\bb35c8a4.txt,0.96
12,"/experiments/scripts/fetch_annotations.sh ``` This will populate the `DrillDown/data` folder with `vg/sg_xmls` and `vg/rg_jsons`, which are per-image scene-graph and region-graph annotations","/experiments/scripts/fetch_annotations.sh ``` This will populate the `DrillDown/data` folder with `vg/sg_xmls` and `vg/rg_jsons`, which are per-image scene-graph and region-graph annotations","/experiments/scripts/fetch_annotations.sh  This will populate the <DATASET>DrillDown/data</DATASET> folder with <DATASET>vg/sg_xmls</DATASET> and <DATASET>vg/rg_jsons</DATASET>, which are per-image scene-graph and region-graph annotations
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\fc72729c.txt,0.9731182795698925
13,.,.,".
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\cdb4ee2a.txt,0.6666666666666666
14,- Download the global image features and region features ```Shell .,- Download the global image features and region features ```<PROGLANG>Shell</PROGLANG> .,"- Download the global image features and region features <PROGLANG>Shell</PROGLANG> .
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\bbf9c5a5.txt,0.9696969696969697
15,"/experiments/scripts/fetch_features.sh ``` This will populate the `DrillDown/data` folder with `vg/global_features` and `vg/region_36_final`, which are the global features and region features of the images.","/experiments/scripts/fetch_features.sh ``` This will populate the `DrillDown/data` folder with `vg/global_features` and `vg/region_36_final`, which are the global features and region features of the images.","/experiments/scripts/fetch_features.sh  This will populate the <DATASET>DrillDown/data</DATASET> folder with <DATASET>vg/global_features</DATASET> and <DATASET>vg/region_36_final</DATASET>, which are the global features and region features of the images.
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\c5ec6dd7.txt,0.9752475247524752
16,The global features were extracted from a pretrained ResNet101 model.,The global features were extracted from a pretrained ResNet101 model.,The global features were extracted from a pretrained <SOFTWARE>ResNet101</SOFTWARE> model.,../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\dfe59ed6.txt,1.0
17,The region features were extracted from a pretrained FasterRCNN model provided by https://github.com/peteanderson80/bottom-up-attention.,The region features were extracted from a pretrained FasterRCNN model provided by https://github.com/peteanderson80/bottom-up-attention.,The region features were extracted from a pretrained <SOFTWARE>FasterRCNN</SOFTWARE> model provided by https://github.com/<PROJECT>peteanderson80</PROJECT>/<PROJECT>bottom-up-attention</PROJECT>.,../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\fa9575cb.txt,1.0
18,"Please see `tools/save_image_features.py`, the FasterRCNN repo, and `tools/save_region_features.py` for more details","Please see `tools/save_image_features.py`, the FasterRCNN repo, and `tools/save_region_features.py` for more details","Please see <SOFTWARE>tools/save_image_features.py</SOFTWARE>, the <SOFTWARE>FasterRCNN</SOFTWARE> repo, and <SOFTWARE>tools/save_region_features.py</SOFTWARE> for more details",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\4439d296.txt,0.9824561403508771
19,.,.,".
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\cdb4ee2a.txt,0.6666666666666666
20,- Download the pretrained models ```Shell .,- Download the pretrained models ```<PROGLANG>Shell</PROGLANG> .,"- Download the annotations of the images <PROGLANG>Shell</PROGLANG> .
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\bb35c8a4.txt,0.6086956521739131
21,/experiments/scripts/fetch_pretrained_models.sh ``` This will populate the `DrillDown/data` folder with `caches/image_ckpts` and `caches/region_ckpts`   ## Training/evaluation scripts The training/evaluation scripts of different models are also included in `.,/experiments/scripts/fetch_pretrained_models.sh ``` This will populate the `DrillDown/data` folder with `caches/image_ckpts` and `caches/region_ckpts`   ## Training/evaluation scripts The training/evaluation scripts of different models are also included in `.,"/experiments/scripts/fetch_pretrained_models.sh  This will populate the <DATASET>DrillDown/data</DATASET> folder with <DATASET>caches/image_ckpts</DATASET> and <DATASET>caches/region_ckpts</DATASET>   ## Training/evaluation scripts The training/evaluation scripts of different models are also included in .
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\a495411c.txt,0.9587426326129665
22,/experiments/scripts`.,/experiments/scripts`.,/experiments/scripts.,../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\20729fca.txt,0.9767441860465116
23,"The results will appear in `DrillDown/logs` Please note that, when finetuning the supervisedly pretrained DrillDown model, e.g. runing the script ```Shell .","The results will appear in `DrillDown/logs` Please note that, when finetuning the supervisedly pretrained DrillDown model, e.g. runing the script ```<PROGLANG>Shell</PROGLANG> .","The results will appear in <PROJECT>DrillDown</PROJECT>/logs Please note that, when finetuning the supervisedly pretrained <PROJECT>DrillDown</PROJECT> model, e.g. runing the script <PROGLANG>Shell</PROGLANG> .",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\ee33d3b1.txt,0.9837133550488599
24,"/experiments/scripts/train_drill_down_3x128_reinforce.sh ``` the default pretrained model is `DrillDown/caches/region_ckpts/vg_f128_i3_sl_ckpt.pkl`.    ## Citing  If you find our paper/code useful, please consider citing:   @InProceedings{drilldown,     author={Fuwen Tan and Paola Cascante-Bonilla and Xiaoxiao Guo and Hui Wu and Song Feng and Vicente Ordonez},     title={Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries},     booktitle = {Neural Information Processing Systems (NeurIPS)},     month = {December},     year = {2019}     }        # License  This project is licensed under the [MIT license](https://opensource.org/licenses/MIT):  Copyright (c) 2019 University of Virginia, Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez.","/experiments/scripts/train_drill_down_3x128_reinforce.sh ``` the default pretrained model is `DrillDown/caches/region_ckpts/vg_f128_i3_sl_ckpt.pkl`.    ## Citing  If you find our paper/code useful, please consider citing:   @InProceedings{drilldown,     author={Fuwen Tan and Paola Cascante-Bonilla and Xiaoxiao Guo and Hui Wu and Song Feng and Vicente Ordonez},     title={<PUBLICATION>Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries</PUBLICATION>},     booktitle = {<CONFERENCE>Neural Information Processing Systems</CONFERENCE> (<CONFERENCE>NeurIPS</CONFERENCE>)},     month = {December},     year = {2019}     }        # License  This project is licensed under the [<LICENSE>MIT</LICENSE> license](https://opensource.org/licenses/MIT):  Copyright (c) 2019 University of Virginia, Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez.","/experiments/scripts/train_drill_down_3x128_reinforce.sh  the default pretrained model is <SOFTWARE>DrillDown/caches/region_ckpts/vg_f128_i3_sl_ckpt.pkl</SOFTWARE>.    ## Citing  If you find our paper/code useful, please consider citing:   @InProceedings{<PUBLICATION>drilldown</PUBLICATION>,     author={Fuwen Tan and Paola Cascante-Bonilla and Xiaoxiao Guo and Hui Wu and Song Feng and Vicente Ordonez},     title={<PUBLICATION>Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries</PUBLICATION>},     booktitle = {<CONFERENCE>Neural Information Processing Systems (NeurIPS)</CONFERENCE>},     month = {December},     year = {2019}     }        # License  This project is licensed under the <LICENSE>MIT license</LICENSE>(https://opensource.org/licenses/MIT):  Copyright (c) 2019 University of Virginia, Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, Hui Wu, Song Feng, Vicente Ordonez.
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\9f963973.txt,0.9950248756218906
25,"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.","Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.","Permission is hereby granted, free of charge, to any person obtaining a copy of this <SOFTWARE>software</SOFTWARE> and associated documentation files (the ""<SOFTWARE>Software</SOFTWARE>""), to deal in the <SOFTWARE>Software</SOFTWARE> without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the <SOFTWARE>Software</SOFTWARE>, and to permit persons to whom the <SOFTWARE>Software</SOFTWARE> is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the <SOFTWARE>Software</SOFTWARE>.
",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\af9039d2.txt,0.9991079393398751
26,"THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.","THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.","THE <SOFTWARE>SOFTWARE</SOFTWARE> IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\6958afd1.txt,1.0
27,"IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE <SOFTWARE>SOFTWARE</SOFTWARE> OR THE USE OR OTHER DEALINGS IN THE <SOFTWARE>SOFTWARE</SOFTWARE>.",../results/deepseek-chat/prompt-0/zzz_uvavision_DrillDown_master_README.md.tsv\6d594654.txt,1.0
