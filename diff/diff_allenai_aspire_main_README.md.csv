sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
6,Our approach improves performance on document similarity tasks in four datasets.,Our approach improves performance on document similarity tasks in four datasets.,Our approach improves performance on document similarity tasks in four `datasets`.,Our approach improves performance on document similarity tasks in four `<DATASET>datasets</DATASET>`.,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\eb18167e.txt,0.9876543209876543
8,"The pre-print can be accessed here: https://arxiv.org/abs/2111.08366  **NEWS:** This work has been accepted to NAACL 2022, stay tuned for the camera-ready paper and additional artifacts.  ### Contents 1.","The pre-print can be accessed here: https://arxiv.org/abs/2111.08366  **NEWS:** This work has been accepted to <CONFERENCE>NAACL 2022</CONFERENCE>, stay tuned for the camera-ready paper and additional artifacts.  ### Contents 1.","The pre-print can be accessed here: https://arxiv.org/abs/2111.08366  **NEWS:** This work has been accepted to `NAACL 2022`, stay tuned for the camera-ready paper and additional artifacts.  ### Contents 1.","The pre-print can be accessed here: https://arxiv.org/abs/2111.08366  **NEWS:** This work has been accepted to `<CONFERENCE>NAACL 2022</CONFERENCE>`, stay tuned for the camera-ready paper and additional artifacts.  ### Contents 1.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\b0681d49.txt,0.9950980392156863
19,"Obtain the model zip files:  - [`aspire-biencoder-biomed-scib-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-scib-full.zip) - [`aspire-biencoder-biomed-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-spec-full.zip) - [`aspire-biencoder-compsci-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip)  ```bash wget -O aspire-biencoder-compsci-spec-full.zip https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip unzip aspire-biencoder-compsci-spec-full.zip ```  Now it may be used as:  ```python  import os, json, codecs, torch from transformers import AutoTokenizer from examples.ex_aspire_bienc import AspireBiEnc  # Directory where zipped model was downloaded and unzipped. model_path = '.","Obtain the model zip files:  - [`aspire-biencoder-biomed-scib-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-scib-full.zip) - [`aspire-biencoder-biomed-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-spec-full.zip) - [`aspire-biencoder-compsci-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip)  ```<PROGLANG>bash</PROGLANG> wget -O aspire-biencoder-compsci-spec-full.zip https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip unzip aspire-biencoder-compsci-spec-full.zip ```  Now it may be used as:  ```<PROGLANG>python</PROGLANG>  import os, json, codecs, torch from transformers import AutoTokenizer from examples.ex_aspire_bienc import AspireBiEnc  # Directory where zipped model was downloaded and unzipped. model_path = '.","Obtain the model zip files:  
- [`aspire-biencoder-biomed-scib-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-scib-full.zip)  
- [`aspire-biencoder-biomed-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-spec-full.zip)  
- [`aspire-biencoder-compsci-spec-full`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip)  

```bash  
wget -O aspire-biencoder-compsci-spec-full.zip https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip  
unzip aspire-biencoder-compsci-spec-full.zip  
```  

Now it may be used as:  

```python  
import os, json, codecs, torch  
from transformers import AutoTokenizer  
from examples.ex_aspire_bienc import AspireBiEnc  

# Directory where zipped model was downloaded and unzipped.  
model_path = '.","Obtain the model zip files:  
- [`<SOFTWARE>aspire-biencoder-biomed-scib-full</SOFTWARE>`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-scib-full.zip)  
- [`<SOFTWARE>aspire-biencoder-biomed-spec-full</SOFTWARE>`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-biomed-spec-full.zip)  
- [`<SOFTWARE>aspire-biencoder-compsci-spec-full</SOFTWARE>`](https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip)  

```bash  
wget -O <SOFTWARE>aspire-biencoder-compsci-spec-full</SOFTWARE>.zip https://ai2-s2-research.s3.us-west-2.amazonaws.com/aspire/aspire-biencoder-compsci-spec-full.zip  
unzip <SOFTWARE>aspire-biencoder-compsci-spec-full</SOFTWARE>.zip  
```  

Now it may be used as:  

```python  
import os, json, codecs, torch  
from transformers import AutoTokenizer  
from examples.ex_aspire_bienc import <SOFTWARE>AspireBiEnc</SOFTWARE>  

# Directory where zipped model was downloaded and unzipped.  
model_path = '.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\e1c349ba.txt,0.920045045045045
20,"/aspire-biencoder-compsci-spec-full'  # Load hyperparameters from disk. with codecs.open(os.path.join(model_path, 'run_info.json'), 'r') as fp:     hparams = json.load(fp)     model_hparams = hparams['all_hparams']  # Initialize the tokenizer and model. aspire_tok = AutoTokenizer.from_pretrained(model_hparams['base-pt-layer']) aspire_bienc = AspireBiEnc(model_hparams)  # Load model parameters from disk. model_fname = os.path.join(model_path, 'model_cur_best.pt') aspire_bienc.load_state_dict(torch.load(model_fname))  # Encode example input. title = ""Multi-Vector Models with Textual Guidance for Fine-Grained Scientific ""         ""Document Similarity"" abstract = ""We present a new scientific document similarity model based on matching ""            ""fine-grained aspects of texts."" d = [title + aspire_tok.sep_token + abstract]  inputs = aspire_tok(d, padding=True, truncation=True, return_tensors=""pt"", max_length=512) clsrep = aspire_bienc.forward(inputs)  ```   #### Evaluation Datasets <a name=""evaldata""></a>  The paper uses the following evaluation datasets:  - RELISH was created in [Brown et al. 2019](https://academic.oup.com/database/article/doi/10.1093/database/baz085/5608006?","/aspire-biencoder-compsci-spec-full'  # Load hyperparameters from disk. with codecs.open(os.path.join(model_path, 'run_info.json'), 'r') as fp:     hparams = json.load(fp)     model_hparams = hparams['all_hparams']  # Initialize the tokenizer and model. aspire_tok = AutoTokenizer.from_pretrained(model_hparams['base-pt-layer']) aspire_bienc = AspireBiEnc(model_hparams)  # Load model parameters from disk. model_fname = os.path.join(model_path, 'model_cur_best.pt') aspire_bienc.load_state_dict(torch.load(model_fname))  # Encode example input. title = ""Multi-Vector Models with Textual Guidance for Fine-Grained Scientific ""         ""Document Similarity"" abstract = ""We present a new scientific document similarity model based on matching ""            ""fine-grained aspects of texts."" d = [title + aspire_tok.sep_token + abstract]  inputs = aspire_tok(d, padding=True, truncation=True, return_tensors=""pt"", max_length=512) clsrep = aspire_bienc.forward(inputs)  ```   #### Evaluation Datasets <a name=""evaldata""></a>  The paper uses the following evaluation datasets:  - <DATASET>RELISH</DATASET> was created in [Brown et al. 2019](https://academic.oup.com/database/article/doi/10.1093/database/baz085/5608006?","/aspire-biencoder-compsci-spec-full'  # Load hyperparameters from disk. with codecs.open(os.path.join(model_path, 'run_info.json'), 'r') as fp:     hparams = json.load(fp)     model_hparams = hparams['all_hparams']  # Initialize the tokenizer and model. aspire_tok = AutoTokenizer.from_pretrained(model_hparams['base-pt-layer']) aspire_bienc = AspireBiEnc(model_hparams)  # Load model parameters from disk. model_fname = os.path.join(model_path, 'model_cur_best.pt') aspire_bienc.load_state_dict(torch.load(model_fname))  # Encode example input. title = ""Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity"" abstract = ""We present a new scientific document similarity model based on matching fine-grained aspects of texts."" d = [title + aspire_tok.sep_token + abstract]  inputs = aspire_tok(d, padding=True, truncation=True, return_tensors=""pt"", max_length=512) clsrep = aspire_bienc.forward(inputs)  ```   #### Evaluation Datasets <a name=""evaldata""></a>  The paper uses the following evaluation datasets:  - RELISH was created in [Brown et al. 2019](https://academic.oup.com/database/article/doi/10.1093/database/baz085/5608006?","/aspire-biencoder-compsci-spec-full'  # Load hyperparameters from disk. with codecs.open(os.path.join(model_path, 'run_info.json'), 'r') as fp:     hparams = json.load(fp)     model_hparams = hparams['all_hparams']  # Initialize the tokenizer and model. aspire_tok = AutoTokenizer.from_pretrained(model_hparams['base-pt-layer']) aspire_bienc = AspireBiEnc(model_hparams)  # Load model parameters from disk. model_fname = os.path.join(model_path, 'model_cur_best.pt') aspire_bienc.load_state_dict(torch.load(model_fname))  # Encode example input. title = ""<PUBLICATION>Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity</PUBLICATION>"" abstract = ""We present a new scientific document similarity model based on matching fine-grained aspects of texts."" d = [title + aspire_tok.sep_token + abstract]  inputs = aspire_tok(d, padding=True, truncation=True, return_tensors=""pt"", max_length=512) clsrep = aspire_bienc.forward(inputs)  ```   #### Evaluation Datasets <a name=""evaldata""></a>  The paper uses the following evaluation datasets:  - <DATASET>RELISH</DATASET> was created in [<PUBLICATION>Brown et al. 2019</PUBLICATION>](https://academic.oup.com/database/article/doi/10.1093/database/baz085/5608006?",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\bb3dfd33.txt,0.9894112664125371
22,While I wasn't able to access the link in the publication.,While I wasn't able to access the link in the publication.,While I wasn't able to access the link in the `publication`.,While I wasn't able to access the link in the `<PUBLICATION>publication</PUBLICATION>`.,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\cc64b6b1.txt,0.9830508474576272
23,I was able to obtain a copy of the dataset from: [link](http://pubannotation.org/projects/RELISH-DB).,I was able to obtain a copy of the dataset from: [link](http://pubannotation.org/projects/RELISH-DB).,I was able to obtain a copy of the `RELISH-DB` dataset from: [link](http://pubannotation.org/projects/`RELISH-DB`).,I was able to obtain a copy of the `<DATASET>RELISH-DB</DATASET>` dataset from: [link](http://pubannotation.org/projects/`<DATASET>RELISH-DB</DATASET>`).,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\7dea159d.txt,0.9351851851851852
26,- TRECCOVID presents an ad-hoc search dataset.,- <DATASET>TRECCOVID</DATASET> presents an ad-hoc search dataset.,- `TRECCOVID` presents an ad-hoc search dataset.,- `<DATASET>TRECCOVID</DATASET>` presents an ad-hoc search dataset.,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\f7885d12.txt,0.9787234042553191
27,"The versions of the dataset used may be accessed here: [query topics](https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml), [relevance annotations](https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt), and the metadata for papers is obtained from the [CORD-19](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html) dataset in the [2021-06-21](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2021-06-21/metadata.csv) release.","The versions of the dataset used may be accessed here: [query topics](https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml), [relevance annotations](https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt), and the metadata for papers is obtained from the [<DATASET>CORD-19</DATASET>](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html) dataset in the [2021-06-21](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2021-06-21/metadata.csv) release.","The versions of the `dataset` used may be accessed here: [query topics](https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml), [relevance annotations](https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt), and the metadata for papers is obtained from the `CORD-19` `dataset` in the `2021-06-21` release.","The versions of the `<DATASET>dataset</DATASET>` used may be accessed here: [query topics](https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml), [relevance annotations](https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt), and the metadata for papers is obtained from the `<DATASET>CORD-19</DATASET>` `<DATASET>dataset</DATASET>` in the `<DATASET>2021-06-21</DATASET>` release.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\93350fec.txt,0.685857321652065
28,"The function `get_qbe_pools` in `pre_proc_treccovid.py`, converts the dataset in its original form to the reformulated form, TRECCOVID-RF, used in the paper.","The function `get_qbe_pools` in `pre_proc_<DATASET>treccovid</DATASET>.py`, converts the dataset in its original form to the reformulated form, <DATASET>TRECCOVID</DATASET>-RF, used in the paper.","The function `get_qbe_pools` in `pre_proc_treccovid.py`, converts the `dataset` in its original form to the reformulated form, `TRECCOVID-RF`, used in the `paper`.","The function `<PROGLANG>get_qbe_pools</PROGLANG>` in `<PROGLANG>pre_proc_treccovid.py</PROGLANG>`, converts the `<DATASET>dataset</DATASET>` in its original form to the reformulated form, `<DATASET>TRECCOVID-RF</DATASET>`, used in the `<PUBLICATION>paper</PUBLICATION>`.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\837cc195.txt,0.98125
31,- SciDocs is obtained from: [link](https://github.com/allenai/scidocs).,- <DATASET>SciDocs</DATASET> is obtained from: [link](https://github.com/allenai/<DATASET>scidocs</DATASET>).,- `SciDocs` is obtained from: [link](https://github.com/allenai/scidocs).,- `<PROJECT>SciDocs</PROJECT>` is obtained from: [link](https://github.com/allenai/<PROJECT>scidocs</PROJECT>).,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\4dd43e69.txt,0.9861111111111112
32,The dataset splits supplied alongside the original dataset are used as is,The dataset splits supplied alongside the original dataset are used as is,The `dataset splits` supplied alongside the original `dataset` are used as is,The `<DATASET>dataset splits</DATASET>` supplied alongside the original `<DATASET>dataset</DATASET>` are used as is,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\d48dc390.txt,0.9733333333333334
35,The dataset splits supplied alongside the original dataset are used as is.,The dataset splits supplied alongside the original dataset are used as is.,The `dataset splits` supplied alongside the original `dataset` are used as is.,The `<DATASET>dataset splits</DATASET>` supplied alongside the original `<DATASET>dataset</DATASET>` are used as is.,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\ff112d86.txt,0.9736842105263158
41,"Since we evaluate on datasets in the Biomedical (RELISH, TRECCOVID-RF), Computer Science (CSFCube), and mixed domains (SciDocs) we train separate models for these domains, the sub-directories named `s2orcbiomed`, `s2orccompsci`, and `s2orcscidocs` contain config files for the models trained for each domain.","Since we evaluate on datasets in the Biomedical (<DATASET>RELISH</DATASET>, <DATASET>TRECCOVID</DATASET>-RF), Computer Science (<DATASET>CSFCube</DATASET>), and mixed domains (<DATASET>SciDocs</DATASET>) we train separate models for these domains, the sub-directories named `s2orcbiomed`, `s2orccompsci`, and `s2orcscidocs` contain config files for the models trained for each domain.","Since we evaluate on datasets in the Biomedical (`RELISH`, `TRECCOVID-RF`), Computer Science (`CSFCube`), and mixed domains (`SciDocs`) we train separate models for these domains, the sub-directories named `s2orcbiomed`, `s2orccompsci`, and `s2orcscidocs` contain config files for the models trained for each domain.","Since we evaluate on datasets in the Biomedical (`<DATASET>RELISH</DATASET>`, `<DATASET>TRECCOVID-RF</DATASET>`), Computer Science (`<DATASET>CSFCube</DATASET>`), and mixed domains (`<DATASET>SciDocs</DATASET>`) we train separate models for these domains, the sub-directories named `s2orcbiomed`, `s2orccompsci`, and `s2orcscidocs` contain config files for the models trained for each domain.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\97fef831.txt,0.9807692307692307
50,This code assumes the 2019-09-28 release of S2ORC.,This code assumes the 2019-09-28 release of <DATASET>S2ORC</DATASET>.,This code assumes the 2019-09-28 release of `S2ORC`.,This code assumes the 2019-09-28 release of `<DATASET>S2ORC</DATASET>`.,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\4eefd09f.txt,0.9803921568627451
55,"`src/pre_process/pre_proc_{relish/scidocs/treccovid}.py`: Pre-process the evaluation datasets (RELISH, TRECCOVID, and SciDocs) into a format consumed by trained models and evaluation scripts.","`src/pre_process/pre_proc_{<DATASET>relish</DATASET>/<DATASET>scidocs</DATASET>/<DATASET>treccovid</DATASET>}.py`: Pre-process the evaluation datasets (<DATASET>RELISH</DATASET>, <DATASET>TRECCOVID</DATASET>, and <DATASET>SciDocs</DATASET>) into a format consumed by trained models and evaluation scripts.","`src/pre_process/pre_proc_{relish/scidocs/treccovid}.py`: Pre-process the evaluation RELISH, TRECCOVID, and SciDocs into a format consumed by trained models and evaluation scripts.","`src/pre_process/pre_proc_{relish/scidocs/treccovid}.py`: Pre-process the evaluation <DATASET>RELISH</DATASET>, <DATASET>TRECCOVID</DATASET>, and <DATASET>SciDocs</DATASET> into a format consumed by trained models and evaluation scripts.",../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\7d627d21.txt,0.9703504043126685
56,CSFCube data format matches the assumed format.,<DATASET>CSFCube</DATASET> data format matches the assumed format.,`CSFCube data format matches the assumed format.`,`<DATASET>CSFCube</DATASET> data format matches the assumed format.`,../results/deepseek-chat/prompt-0/zzz_allenai_aspire_main_README.md.tsv\682bce55.txt,0.9791666666666666
