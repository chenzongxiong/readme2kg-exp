sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
4,"**A robust model should be robust to changes in input that do not alter its semantics.** We test this property of 3 popular models: DrQA, BiDAF and QANet by manipulating questions in two ways- swapping important question word for:  1) its semantically correct synonym and 2) for word vector that is close in embedding space.","**A robust model should be robust to changes in input that do not alter its semantics.** We test this property of 3 popular models: DrQA, BiDAF and QANet by manipulating questions in two ways- swapping important question word for:  1) its semantically correct synonym and 2) for word vector that is close in embedding space.","**A robust model should be robust to changes in input that do not alter its semantics.** We test this property of 3 popular models: `DrQA`, `BiDAF` and `QANet` by manipulating questions in two ways- swapping important question word for:  1) its semantically correct synonym and 2) for word vector that is close in embedding space.","**A robust model should be robust to changes in input that do not alter its semantics.** We test this property of 3 popular models: `<SOFTWARE>DrQA</SOFTWARE>`, `<SOFTWARE>BiDAF</SOFTWARE>` and `<SOFTWARE>QANet</SOFTWARE>` by manipulating questions in two ways- swapping important question word for:  1) its semantically correct synonym and 2) for word vector that is close in embedding space.",../results/deepseek-chat/prompt-0/zzz_MI2DataLab_nlp_interpretability_framework_master_README.md.tsv\c8edc305.txt,0.9755351681957186
5,We estimate importance of words in asked questions with Locally Interpretable Model Agnostic Explanations method (LIME).   !,We estimate importance of words in asked questions with Locally Interpretable Model Agnostic Explanations method (LIME).   !,We estimate importance of words in asked questions with `Locally Interpretable Model Agnostic Explanations method (LIME).`   !,We estimate importance of words in asked questions with `<SOFTWARE>Locally Interpretable Model Agnostic Explanations method (LIME)</SOFTWARE>.`   !,../results/deepseek-chat/prompt-0/zzz_MI2DataLab_nlp_interpretability_framework_master_README.md.tsv\ad58ba94.txt,0.992
