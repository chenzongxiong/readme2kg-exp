sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
2,Do you have a wildlife camera trap image database and are finding it challenging to apply artificial intelligence systems due to the lack of labeled images?,Do you have a wildlife camera trap image database and are finding it challenging to apply artificial intelligence systems due to the lack of labeled images?,Do you have a wildlife `camera trap image database` and are finding it challenging to apply artificial intelligence systems due to the lack of labeled images?,Do you have a wildlife `<DATASET>camera trap image database</DATASET>` and are finding it challenging to apply artificial intelligence systems due to the lack of labeled images?,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\cebcae0e.txt,0.9936305732484076
10,"First, we leverage the predictive power of the amazing [Megadetector](https://github.com/microsoft/CameraTraps) (**MD**) to pre-select images that contain wildlife.","First, we leverage the predictive power of the amazing [<SOFTWARE>Megadetector</SOFTWARE>](https://github.com/microsoft/CameraTraps) (**<SOFTWARE>MD</SOFTWARE>**) to pre-select images that contain wildlife.","First, we leverage the predictive power of the amazing Megadetector (https://github.com/microsoft/CameraTraps) (**MD**) to pre-select images that contain wildlife.","First, we leverage the predictive power of the amazing <SOFTWARE>Megadetector</SOFTWARE> (https://github.com/microsoft/<SOFTWARE>CameraTraps</SOFTWARE>) (**MD**) to pre-select images that contain wildlife.",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\35ab7491.txt,0.9908256880733946
13,"Apart from our classification pipeline, we offer a simple interface for active learning.  ## Examples  We offer introductory minimal example scripts, which showcase our powerful package:  **EXAMPLE SCRIPTS COMING SOON**  *Please see our [experiments repository](https://github.com/slds-lmu/wildlife-experiments/) in the meantime :).*  ## Citation  By using this repo, please cite our paper [Automated wildlife image classification: An active learning tool for ecological applications](https://arxiv.org/abs/2303.15823), here is a bibtex entry for it:  ``` @article{bothmann_et_al_2023,  title = {Automated wildlife image classification: {An} active learning tool for ecological applications},  volume = {77},  issn = {1574-9541},  url = {https://www.sciencedirect.com/science/article/pii/S1574954123002601},  doi = {10.1016/j.ecoinf.2023.102231},  journal = {Ecological Informatics},  author = {Bothmann, Ludwig and Wimmer, Lisa and Charrakh, Omid and Weber, Tobias and Edelhoff, Hendrik and Peters, Wibke and Nguyen, Hien and Benjamin, Caryl and Menzel, Annette},  year = {2023},  pages = {102231} } ```  ## Workflow  ### 01: Folder structure  An optimal folder structure for working with our package is like:  ``` ├── labels.csv ├── images_megadetector.json └── images     ├── img_id1.xx     ├── ...     └── img_idn.xx ```  where `labels.csv` is a headless csv that contains entries as:  ``` img_id1.xx,<int_label> ... img_idn.xx,<int_label> ```  If your dataset follows the structure of separating classes by directories, we also offer a `DatasetConverter` for converting the file structure to the one above","Apart from our classification pipeline, we offer a simple interface for active learning.  ## Examples  We offer introductory minimal example scripts, which showcase our powerful package:  **EXAMPLE SCRIPTS COMING SOON**  *Please see our [experiments repository](https://github.com/slds-lmu/wildlife-experiments/) in the meantime :).*  ## Citation  By using this repo, please cite our paper [<PUBLICATION>Automated wildlife image classification: An active learning tool for ecological applications</PUBLICATION>](https://arxiv.org/abs/2303.15823), here is a bibtex entry for it:  ``` @article{bothmann_et_al_2023,  title = {<PUBLICATION>Automated wildlife image classification: {An} active learning tool for ecological applications</PUBLICATION>},  volume = {77},  issn = {1574-9541},  url = {https://www.sciencedirect.com/science/article/pii/S1574954123002601},  doi = {10.1016/j.ecoinf.2023.102231},  journal = {Ecological Informatics},  author = {Bothmann, Ludwig and Wimmer, Lisa and Charrakh, Omid and Weber, Tobias and Edelhoff, Hendrik and Peters, Wibke and Nguyen, Hien and Benjamin, Caryl and Menzel, Annette},  year = {2023},  pages = {102231} } ```  ## Workflow  ### 01: Folder structure  An optimal folder structure for working with our package is like:  ``` ├── labels.csv ├── images_megadetector.json └── images     ├── img_id1.xx     ├── ...     └── img_idn.xx ```  where `labels.csv` is a headless csv that contains entries as:  ``` img_id1.xx,<int_label> ... img_idn.xx,<int_label> ```  If your dataset follows the structure of separating classes by directories, we also offer a `DatasetConverter` for converting the file structure to the one above","Apart from our classification pipeline, we offer a simple interface for active learning.  ## Examples  We offer introductory minimal example scripts, which showcase our powerful package:  **EXAMPLE SCRIPTS COMING SOON**  *Please see our [experiments repository](https://github.com/slds-lmu/wildlife-experiments/) in the meantime :).*  ## Citation  By using this repo, please cite our paper Automated wildlife image classification: An active learning tool for ecological applications, here is a bibtex entry for it:  ``` @article{bothmann_et_al_2023,  title = {Automated wildlife image classification: {An} active learning tool for ecological applications},  volume = {77},  issn = {1574-9541},  url = {https://www.sciencedirect.com/science/article/pii/S1574954123002601},  doi = {10.1016/j.ecoinf.2023.102231},  journal = {Ecological Informatics},  author = {Bothmann, Ludwig and Wimmer, Lisa and Charrakh, Omid and Weber, Tobias and Edelhoff, Hendrik and Peters, Wibke and Nguyen, Hien and Benjamin, Caryl and Menzel, Annette},  year = {2023},  pages = {102231} } ```  ## Workflow  ### 01: Folder structure  An optimal folder structure for working with our package is like:  ``` ├── labels.csv ├── images_megadetector.json └── images     ├── img_id1.xx     ├── ...     └── img_idn.xx ```  where `labels.csv` is a headless csv that contains entries as:  ``` img_id1.xx,<int_label> ... img_idn.xx,<int_label> ```  If your dataset follows the structure of separating classes by directories, we also offer a DatasetConverter for converting the file structure to the one above","Apart from our classification pipeline, we offer a simple interface for active learning.  ## Examples  We offer introductory minimal example scripts, which showcase our powerful package:  **EXAMPLE SCRIPTS COMING SOON**  *Please see our [experiments repository](https://github.com/<PROJECT>slds-lmu</PROJECT>/<PROJECT>wildlife-experiments</PROJECT>/) in the meantime :).*  ## Citation  By using this repo, please cite our paper <PUBLICATION>Automated wildlife image classification: An active learning tool for ecological applications</PUBLICATION>, here is a bibtex entry for it:  ``` @article{bothmann_et_al_2023,  title = {Automated wildlife image classification: {An} active learning tool for ecological applications},  volume = {77},  issn = {1574-9541},  url = {https://www.sciencedirect.com/science/article/pii/S1574954123002601},  doi = {10.1016/j.ecoinf.2023.102231},  journal = {<PUBLICATION>Ecological Informatics</PUBLICATION>},  author = {Bothmann, Ludwig and Wimmer, Lisa and Charrakh, Omid and Weber, Tobias and Edelhoff, Hendrik and Peters, Wibke and Nguyen, Hien and Benjamin, Caryl and Menzel, Annette},  year = {2023},  pages = {102231} } ```  ## Workflow  ### 01: Folder structure  An optimal folder structure for working with our package is like:  ``` ├── labels.csv ├── images_megadetector.json └── images     ├── img_id1.xx     ├── ...     └── img_idn.xx ```  where `labels.csv` is a headless csv that contains entries as:  ``` img_id1.xx,<int_label> ... img_idn.xx,<int_label> ```  If your <DATASET>dataset</DATASET> follows the structure of separating classes by directories, we also offer a <SOFTWARE>DatasetConverter</SOFTWARE> for converting the file structure to the one above",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\bf4fecdb.txt,0.9880578252671276
14,.,.,The results are saved in a `.json` file.,The results are saved in a `<PROGLANG>.json</PROGLANG>` file.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\2749c44d.txt,0.04878048780487805
15,`.xx` symbolizes that it doesn't matter what format the image files have as long as the format is compatible with `PIL`.  ###  02: Prediction of Bounding Boxes  #### Running the Megadetector  This package includes an implementation of the [Megadetector](https://github.com/microsoft/CameraTraps) for detecting objects in camera traps.,`.xx` symbolizes that it doesn't matter what format the image files have as long as the format is compatible with `<SOFTWARE>PIL</SOFTWARE>`.  ###  02: Prediction of Bounding Boxes  #### Running the Megadetector  This package includes an implementation of the [<SOFTWARE>Megadetector</SOFTWARE>](https://github.com/microsoft/CameraTraps) for detecting objects in camera traps.,`.xx` symbolizes that it doesn't matter what format the image files have as long as the format is compatible with `PIL`.  ###  02: Prediction of Bounding Boxes  #### Running the Megadetector  This package includes an implementation of the Megadetector for detecting objects in camera traps.,`.xx` symbolizes that it doesn't matter what format the image files have as long as the format is compatible with `<PROGLANG>PIL</PROGLANG>`.  ###  02: Prediction of Bounding Boxes  #### Running the Megadetector  This package includes an implementation of the <SOFTWARE>Megadetector</SOFTWARE> for detecting objects in camera traps.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\aeda4104.txt,0.9294871794871795
26,```python from wildlifeml.data import BBoxMapper mapper = BBoxMapper(detector_file_path='<path_to_images_megadetector.json>') key_map = mapper.get_keymap() ```  ### 03: Creating a Wildlife Dataset  #### Initializing a Dataset  Our dataset builds on the Keras `Sequence` utility and thus supports multi-threaded loading during training.,```<PROGLANG>python</PROGLANG> from <SOFTWARE>wildlifeml</SOFTWARE>.data import BBoxMapper mapper = BBoxMapper(detector_file_path='<path_to_images_megadetector.json>') key_map = mapper.get_keymap() ```  ### 03: Creating a Wildlife Dataset  #### Initializing a Dataset  Our dataset builds on the <SOFTWARE>Keras</SOFTWARE> `Sequence` utility and thus supports multi-threaded loading during training.,"```python from wildlifeml.data import BBoxMapper mapper = BBoxMapper(detector_file_path='<path_to_images_megadetector.json>') key_map = mapper.get_keymap() ```  ### 03: Creating a Wildlife Dataset  #### Initializing a Dataset  Our dataset builds on the Keras `Sequence` utility and thus supports multi-threaded loading during training.
```","```python from <PROGLANG>wildlifeml</PROGLANG>.data import <SOFTWARE>BBoxMapper</SOFTWARE> mapper = <SOFTWARE>BBoxMapper</SOFTWARE>(detector_file_path='<path_to_images_megadetector.json>') key_map = mapper.get_keymap() ```  ### 03: Creating a <DATASET>Wildlife</DATASET> Dataset  #### Initializing a <DATASET>Dataset</DATASET>  Our <DATASET>dataset</DATASET> builds on the <SOFTWARE>Keras</SOFTWARE> `<PROGLANG>Sequence</PROGLANG>` utility and thus supports multi-threaded loading during training.
```",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\33b28a68.txt,0.9940652818991098
27,"For defining the content of the dataset, a list of keys pointing to the respective images shall be provided.","For defining the content of the dataset, a list of keys pointing to the respective images shall be provided.","For defining the content of the `dataset`, a list of keys pointing to the respective images shall be provided.","For defining the content of the `<DATASET>dataset</DATASET>`, a list of keys pointing to the respective images shall be provided.",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\5fc77a6a.txt,0.9908256880733946
29,"This corresponds to a list that contains the identifiers provided by the MD file, e.g:  ```python train_keys = ['img_id1.xx_001', 'img_id1.xx_002', 'img_id2.xx_001'] ```  Using a key based initialization, one can easily derive cross validation splits, test sets or other variants based on one MD file.","This corresponds to a list that contains the identifiers provided by the <SOFTWARE>MD</SOFTWARE> file, e.g:  ```<PROGLANG>python</PROGLANG> train_keys = ['img_id1.xx_001', 'img_id1.xx_002', 'img_id2.xx_001'] ```  Using a key based initialization, one can easily derive cross validation splits, test sets or other variants based on one <SOFTWARE>MD</SOFTWARE> file.","This can be mitigated by the `BBoxMapper`, which computes a dictionary that is structured as follows:  ``` {     ""img_id1.xx"": [         ""img_id1.xx_001"",         ""img_id1.xx_002"",         ........","This can be mitigated by the `<SOFTWARE>BBoxMapper</SOFTWARE>`, which computes a dictionary that is structured as follows:  ``` {     ""img_id1.xx"": [         ""img_id1.xx_001"",         ""img_id1.xx_002"",         ........",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\099f81a1.txt,0.3132530120481928
32,The trainer first loads a pretrained `model_backbone` from the Keras hub and then conducts training in two stages.,The trainer first loads a pretrained `model_backbone` from the <SOFTWARE>Keras</SOFTWARE> hub and then conducts training in two stages.,The trainer first loads a pretrained `model_backbone` from the `Keras hub` and then conducts training in two stages.,The trainer first loads a pretrained `<SOFTWARE>model_backbone</SOFTWARE>` from the `<SOFTWARE>Keras hub</SOFTWARE>` and then conducts training in two stages.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\add70281.txt,0.991304347826087
37,"```python trainer.fit(train_dataset, val_dataset) ```  ### 05: Evaluating a model  Due to our cascaded MD approach.","```<PROGLANG>python</PROGLANG> trainer.fit(train_dataset, val_dataset) ```  ### 05: Evaluating a model  Due to our cascaded <SOFTWARE>MD</SOFTWARE> approach.","```python trainer.fit(train_dataset, val_dataset) ```  ### 05: Evaluating a model  Due to our cascaded MD approach.
```","```python trainer.fit(<DATASET>train_dataset</DATASET>, <DATASET>val_dataset</DATASET>) ```  ### 05: Evaluating a model  Due to our cascaded MD approach.
```",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\8b71354f.txt,0.9829059829059829
38,The evaluation of the model requires a bit more care than a usual Keras model.,The evaluation of the model requires a bit more care than a usual <SOFTWARE>Keras</SOFTWARE> model.,The evaluation of the model requires a bit more care than a usual `Keras` model.,The evaluation of the model requires a bit more care than a usual `<SOFTWARE>Keras</SOFTWARE>` model.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\b92fb0ab.txt,0.9873417721518988
42,Required parameters for the evaluator are:  - `label_file_path`: Path pointing to the labels - `detector_file_path`: Path to the MD file - `dataset`: `WildlifeDataset` to evaluate - `num_classes`: Number of classes in the dataset.,Required parameters for the evaluator are:  - `label_file_path`: Path pointing to the labels - `detector_file_path`: Path to the <SOFTWARE>MD</SOFTWARE> file - `dataset`: `WildlifeDataset` to evaluate - `num_classes`: Number of classes in the dataset.,Required parameters for the evaluator are:  - `label_file_path`: Path pointing to the labels - `detector_file_path`: Path to the MD file - `WildlifeDataset` to evaluate - `num_classes`: Number of classes in the dataset.,Required parameters for the evaluator are:  - `label_file_path`: Path pointing to the labels - `detector_file_path`: Path to the MD file - `<DATASET>WildlifeDataset</DATASET>` to evaluate - `num_classes`: Number of classes in the dataset.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\9eaa001d.txt,0.9755011135857461
45,Specify otherwise if this is not the case in your dataset.,Specify otherwise if this is not the case in your dataset.,Specify otherwise if this is not the case in your `dataset`.,Specify otherwise if this is not the case in your `<DATASET>dataset</DATASET>`.,../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\c11d2b92.txt,0.9830508474576272
46,"An example is:  ```python from wildlifeml.training.evaluator import Evaluator  evaluator = Evaluator(     detector_file_path='<path_to_images_megadetector.json>',     label_file_path='<path_to_labels.csv>',     dataset=training_dataset,     num_classes=10,     conf_threshold=0.1,     empty_class_id=99 ) ```  For a trained model, which is contained in a `WildlifeTrainer`, the accuracy, precision, recall and f1 score is computed as:  ```python evaluator.evaluate(trainer) metrics = evaluator.compute_metrics() ```  If you wish to extract the predictions and ground-truth labels for all individual observations, use `evaluator.get_details()`.  ### 06: Active Learning  Apart from fitting a model in a fully supervised way, we offer an active learning pipeline.","An example is:  ```<PROGLANG>python</PROGLANG> from <SOFTWARE>wildlifeml</SOFTWARE>.training.evaluator import Evaluator  evaluator = Evaluator(     detector_file_path='<path_to_images_megadetector.json>',     label_file_path='<path_to_labels.csv>',     dataset=training_dataset,     num_classes=10,     conf_threshold=0.1,     empty_class_id=99 ) ```  For a trained model, which is contained in a `WildlifeTrainer`, the <EVALMETRIC>accuracy</EVALMETRIC>, <EVALMETRIC>precision</EVALMETRIC>, <EVALMETRIC>recall</EVALMETRIC> and <EVALMETRIC>f1 score</EVALMETRIC> is computed as:  ```<PROGLANG>python</PROGLANG> evaluator.evaluate(trainer) metrics = evaluator.compute_metrics() ```  If you wish to extract the predictions and ground-truth labels for all individual observations, use `evaluator.get_details()`.  ### 06: Active Learning  Apart from fitting a model in a fully supervised way, we offer an active learning pipeline.","An example is:  ```python from wildlifeml.training.evaluator import Evaluator  evaluator = Evaluator(     detector_file_path='<path_to_images_megadetector.json>',     label_file_path='<path_to_labels.csv>',     dataset=training_dataset,     num_classes=10,     conf_threshold=0.1,     empty_class_id=99 ) ```  For a trained model, which is contained in a `WildlifeTrainer`, the `accuracy`, `precision`, `recall` and `f1 score` is computed as:  ```python evaluator.evaluate(trainer) metrics = evaluator.compute_metrics() ```  If you wish to extract the predictions and ground-truth labels for all individual observations, use `evaluator.get_details()`.  ### 06: Active Learning  Apart from fitting a model in a fully supervised way, we offer an active learning pipeline.","An example is:  ```<PROGLANG>python</PROGLANG> from <SOFTWARE>wildlifeml.training.evaluator</SOFTWARE> import <SOFTWARE>Evaluator</SOFTWARE>  evaluator = <SOFTWARE>Evaluator</SOFTWARE>(     detector_file_path='<path_to_images_megadetector.json>',     label_file_path='<path_to_labels.csv>',     dataset=training_dataset,     num_classes=10,     conf_threshold=0.1,     empty_class_id=99 ) ```  For a trained model, which is contained in a `<SOFTWARE>WildlifeTrainer</SOFTWARE>`, the `<EVALMETRIC>accuracy</EVALMETRIC>`, `<EVALMETRIC>precision</EVALMETRIC>`, `<EVALMETRIC>recall</EVALMETRIC>` and `<EVALMETRIC>f1 score</EVALMETRIC>` is computed as:  ```<PROGLANG>python</PROGLANG> evaluator.evaluate(trainer) metrics = evaluator.compute_metrics() ```  If you wish to extract the predictions and ground-truth labels for all individual observations, use `<SOFTWARE>evaluator.get_details()</SOFTWARE>`.  ### 06: Active Learning  Apart from fitting a model in a fully supervised way, we offer an active learning pipeline.",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\7529ab64.txt,0.9633986928104575
50,"For an elaborated introduction to the areas of active learning, we recommend to read our paper.","For an elaborated introduction to the areas of active learning, we recommend to read our paper.","`For an elaborated introduction to the areas of active learning, we recommend to read our paper.`","`For an elaborated introduction to the areas of active learning, we recommend to read our <PUBLICATION>paper</PUBLICATION>.`",../results/deepseek-chat/prompt-0/zzz_slds-lmu_wildlife-ml_main_README.md.tsv\7143b43c.txt,0.9895833333333334
