sentence_idx,original_sentence,original_annotated,generated_annotated,source_file,similarity_score
1,# Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets <br> This repository contains code to simulated 2D/3D cellular structures and synthesize corresponding microscopy image data based on Denoising Diffusion Probabilistic Models (DDPM).,# <PUBLICATION>Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets</PUBLICATION> <br> This repository contains code to simulated 2D/3D cellular structures and synthesize corresponding microscopy image data based on Denoising Diffusion Probabilistic Models (DDPM).,"# <PUBLICATION>Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets</PUBLICATION> <br> This repository contains code to simulated 2D/3D cellular structures and synthesize corresponding microscopy image data based on <SOFTWARE>Denoising Diffusion Probabilistic Models (DDPM)</SOFTWARE>.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\1e13380e.txt,0.9983136593591906
2,"Sketches are generated to indicate cell shapes and structural characteristics, and they serve as a basis for the diffusion process to ultimately allow for the generation of fully-annotated microscopy image data sets without the need for human annotation effort.","Sketches are generated to indicate cell shapes and structural characteristics, and they serve as a basis for the diffusion process to ultimately allow for the generation of fully-annotated microscopy image data sets without the need for human annotation effort.","Sketches are generated to indicate cell shapes and structural characteristics, and they serve as a basis for the diffusion process to ultimately allow for the generation of fully-annotated microscopy image <DATASET>data sets</DATASET> without the need for human annotation effort.",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\fa492903.txt,1.0
3,Generated data sets are available at <a href=https://osf.io/dnp65/>OSF</a> and the article is available at <a href=https://journals.plos.org/ploscompbiol/article?,Generated data sets are available at <a href=https://osf.io/dnp65/>OSF</a> and the article is available at <a href=https://journals.plos.org/ploscompbiol/article?,Generated data sets are available at <a href=https://<DATASET>osf.io/dnp65</DATASET>/>OSF</a> and the article is available at <a href=https://<PUBLICATION>journals.plos.org/ploscompbiol/article</PUBLICATION>?,../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\6d8fd8e5.txt,1.0
4,id=10.1371/journal.pcbi.1011890>PLOS CB</a>.,id=10.1371/journal.pcbi.1011890>PLOS CB</a>.,id=10.1371/journal.pcbi.1011890><PUBLICATION>PLOS CB</PUBLICATION></a>.,../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\673034a9.txt,1.0
5,"To access the trained models and get a showcase of the fully-simulated data sets, please visit to our <a href=https://transfer.lfb.rwth-aachen.de/CellDiffusion>website</a> (work in progress).","To access the trained models and get a showcase of the fully-simulated data sets, please visit to our <a href=https://transfer.lfb.rwth-aachen.de/CellDiffusion>website</a> (work in progress).","To access the trained models and get a showcase of the fully-simulated <DATASET>data sets</DATASET>, please visit to our <a href=https://transfer.lfb.rwth-aachen.de/<SOFTWARE>CellDiffusion</SOFTWARE>>website</a> (work in progress).",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\15c78921.txt,1.0
6,"<br><br> <span style=""white-space:nowrap""><img src=""figures/example_data.png"" alt=""Diverse examplary synthetic data samples."" align=""middle"" width=""100%"" /><br> <span style=""white-space:nowrap""><img src=""figures/multi-channel.png"" alt=""Synthetic multi-channel data sample."" align=""middle"" width=""32.7%"" /><img src=""figures/overlapping_cells.png"" alt=""Synthetic data sample of overlapping cells."" align=""middle"" width=""32.7%"" /><img src=""figures/timeseries.gif"" alt=""Synthetic timeseries data sample."" align=""middle"" width=""32.7%"" /></span></span><br> <em>Exemplary synthetic samples from our experiments</em><br><br><br>   If you are using code or data, please cite the following work: ``` @article{eschweiler2024celldiffusion,   title={Denoising diffusion probabilistic models for generation of realistic fully-annotated microscopy image datasets},   author={Eschweiler, Dennis and Yilmaz, R{\""u}veyda and Baumann, Matisse and Laube, Ina and Roy, Rijo and Jose, Abin and Br{\""u}ckner, Daniel and Stegmaier, Johannes},   journal={PLOS Computational Biology},   volume={20},   number={2},   pages={e1011890},   year={2024} } ``` <br><br><br> We provide Jupyter Notebooks that give an overview of how to preprocess your data, train and apply the image generation process.","<br><br> <span style=""white-space:nowrap""><img src=""figures/example_data.png"" alt=""Diverse examplary synthetic data samples."" align=""middle"" width=""100%"" /><br> <span style=""white-space:nowrap""><img src=""figures/multi-channel.png"" alt=""Synthetic multi-channel data sample."" align=""middle"" width=""32.7%"" /><img src=""figures/overlapping_cells.png"" alt=""Synthetic data sample of overlapping cells."" align=""middle"" width=""32.7%"" /><img src=""figures/timeseries.gif"" alt=""Synthetic timeseries data sample."" align=""middle"" width=""32.7%"" /></span></span><br> <em>Exemplary synthetic samples from our experiments</em><br><br><br>   If you are using code or data, please cite the following work: ``` @article{eschweiler2024celldiffusion,   title={<PUBLICATION>Denoising diffusion probabilistic models for generation of realistic fully-annotated microscopy image datasets</PUBLICATION>},   author={Eschweiler, Dennis and Yilmaz, R{\""u}veyda and Baumann, Matisse and Laube, Ina and Roy, Rijo and Jose, Abin and Br{\""u}ckner, Daniel and Stegmaier, Johannes},   journal={<PUBLICATION>PLOS Computational Biology</PUBLICATION>},   volume={20},   number={2},   pages={e1011890},   year={2024} } ``` <br><br><br> We provide <SOFTWARE>Jupyter Notebooks</SOFTWARE> that give an overview of how to preprocess your data, train and apply the image generation process.","<br><br> <span style=""white-space:nowrap""><img src=""figures/example_data.png"" alt=""Diverse examplary synthetic data samples."" align=""middle"" width=""100%"" /><br> <span style=""white-space:nowrap""><img src=""figures/multi-channel.png"" alt=""Synthetic multi-channel data sample."" align=""middle"" width=""32.7%"" /><img src=""figures/overlapping_cells.png"" alt=""Synthetic data sample of overlapping cells."" align=""middle"" width=""32.7%"" /><img src=""figures/timeseries.gif"" alt=""Synthetic timeseries data sample."" align=""middle"" width=""32.7%"" /></span></span><br> <em>Exemplary synthetic samples from our experiments</em><br><br><br>   If you are using code or data, please cite the following work:  @article{eschweiler2024celldiffusion,   title={<PUBLICATION>Denoising diffusion probabilistic models for generation of realistic fully-annotated microscopy image datasets</PUBLICATION>},   author={Eschweiler, Dennis and Yilmaz, R{\""u}veyda and Baumann, Matisse and Laube, Ina and Roy, Rijo and Jose, Abin and Br{\""u}ckner, Daniel and Stegmaier, Johannes},   journal={<PUBLICATION>PLOS Computational Biology</PUBLICATION>},   volume={20},   number={2},   pages={e1011890},   year={2024} }  <br><br><br> We provide <SOFTWARE>Jupyter Notebooks</SOFTWARE> that give an overview of how to preprocess your data, train and apply the image generation process.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\d3f9ceb9.txt,0.9972364784840111
8,"Therefore, each image file has to be converted to hdf5, which can be done by using `utils.h5_converter.prepare_images`.","Therefore, each image file has to be converted to hdf5, which can be done by using `utils.h5_converter.prepare_images`.","Therefore, each image file has to be converted to hdf5, which can be done by using <SOFTWARE>utils.h5_converter.prepare_images</SOFTWARE>.",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\ad7b2f6d.txt,0.9915254237288136
10,This can be done by using `utils.csv_generator.create_csv`.,This can be done by using `utils.csv_generator.create_csv`.,This can be done by using <SOFTWARE>utils.csv_generator.create_csv</SOFTWARE>.,../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\899eae10.txt,0.9827586206896551
11,"A more detailed explanation is given in `jupyter_preparation_script.ipynb`.   ## Diffusion Model Training and Application To use the proposed pipeline to either train or apply your models, make sure to adapt all parameters in the pipeline files `models/DiffusionModel3D` or `models/DiffusionModel2D`, and in the training script `train_script.py` or application script `apply_script_diffusion.py`.","A more detailed explanation is given in `jupyter_preparation_script.ipynb`.   ## Diffusion Model Training and Application To use the proposed pipeline to either train or apply your models, make sure to adapt all parameters in the pipeline files `models/DiffusionModel3D` or `models/DiffusionModel2D`, and in the training script `train_script.py` or application script `apply_script_diffusion.py`.","A more detailed explanation is given in <SOFTWARE>jupyter_preparation_script.ipynb</SOFTWARE>.   ## Diffusion Model Training and Application To use the proposed pipeline to either train or apply your models, make sure to adapt all parameters in the pipeline files <SOFTWARE>models/DiffusionModel3D</SOFTWARE> or <SOFTWARE>models/DiffusionModel2D</SOFTWARE>, and in the training script <SOFTWARE>train_script.py</SOFTWARE> or application script <SOFTWARE>apply_script_diffusion.py</SOFTWARE>.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\8343e34b.txt,0.8122605363984674
13,"A more detailed explanation is given in `jupyter_train_script.ipynb` and `jupyter_apply_script.ipynb`.   ## Simulation of Cellular Structures and Sketch Generation Since the proposed approach is working in a very intuitive manner, sketches can generally be created in any arbitrary way.","A more detailed explanation is given in `jupyter_train_script.ipynb` and `jupyter_apply_script.ipynb`.   ## Simulation of Cellular Structures and Sketch Generation Since the proposed approach is working in a very intuitive manner, sketches can generally be created in any arbitrary way.","A more detailed explanation is given in <SOFTWARE>jupyter_train_script.ipynb</SOFTWARE> and <SOFTWARE>jupyter_apply_script.ipynb</SOFTWARE>.   ## Simulation of Cellular Structures and Sketch Generation Since the proposed approach is working in a very intuitive manner, sketches can generally be created in any arbitrary way.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\414ea9a9.txt,0.9736379613356766
15,id=10.1371/journal.pone.0260509'>3D fluorescence microscopy data synthesis for segmentation and benchmarking</a>.,id=10.1371/journal.pone.0260509'><PUBLICATION>3D fluorescence microscopy data synthesis for segmentation and benchmarking</PUBLICATION></a>.,"id=10.1371/journal.pone.0260509'>3D fluorescence microscopy <DATASET>data synthesis</DATASET> for segmentation and benchmarking</a>.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\24307c12.txt,0.9955947136563876
16,"Nevertheless, the functionality used in this work can be found in `utils.synthetic_cell_membrane_masks` and `utils.synthetic_cell_nuclei_masks` for cellular membranes and nuclei, respectively.  ## Processing Times and Hardware Requirements Due to the layout and working principle of the computation cluster we used, determining precise hardware requirements was difficult.","Nevertheless, the functionality used in this work can be found in `utils.synthetic_cell_membrane_masks` and `utils.synthetic_cell_nuclei_masks` for cellular membranes and nuclei, respectively.  ## Processing Times and Hardware Requirements Due to the layout and working principle of the computation cluster we used, determining precise hardware requirements was difficult.","Nevertheless, the functionality used in this work can be found in <SOFTWARE>utils.synthetic_cell_membrane_masks</SOFTWARE> and <SOFTWARE>utils.synthetic_cell_nuclei_masks</SOFTWARE> for cellular membranes and nuclei, respectively.  ## Processing Times and Hardware Requirements Due to the layout and working principle of the computation cluster we used, determining precise hardware requirements was difficult.
",../results/deepseek-chat/prompt-0/zzz_stegmaierj_diffusionmodelsforimagesynthesis_main_README.md.tsv\1ce7239f.txt,0.979757085020243
