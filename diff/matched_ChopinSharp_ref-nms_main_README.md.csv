sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,"# Ref-NMS Official codebase for AAAI 2021 paper [""Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding""](https://arxiv.org/abs/2009.01449).  ## Prerequisites The following dependencies should be enough.","# Ref-NMS Official codebase for <CONFERENCE>AAAI 2021</CONFERENCE> paper [""<PUBLICATION>Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding</PUBLICATION>""](https://arxiv.org/abs/2009.01449).  ## Prerequisites The following dependencies should be enough.","# Ref-NMS Official codebase for AAAI 2021 paper [""Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding""](https://arxiv.org/abs/2009.01449).  ## Prerequisites The following dependencies should be enough.
","# <SOFTWARE>Ref-NMS</SOFTWARE> Official codebase for <PUBLICATION>AAAI 2021 paper [""Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding""](https://arxiv.org/abs/2009.01449)</PUBLICATION>.  ## Prerequisites The following dependencies should be enough.
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\92e3bb32.txt,0.9978494623655914
2,See [environment.yml](environment.yml) for complete environment settings. - python 3.7.6 - pytorch 1.1.0 - torchvision 0.3.0 - tensorboard 2.1.0 - spacy 2.2.3  ## Data Preparation Follow instructions in `data/README.md` to setup `data` directory.,See [environment.yml](environment.yml) for complete environment settings. - <SOFTWARE>python 3.7.6</SOFTWARE> - <SOFTWARE>pytorch 1.1.0</SOFTWARE> - <SOFTWARE>torchvision 0.3.0</SOFTWARE> - <SOFTWARE>tensorboard 2.1.0</SOFTWARE> - <SOFTWARE>spacy 2.2.3</SOFTWARE>  ## Data Preparation Follow instructions in `data/README.md` to setup `data` directory.,"See [environment.yml](environment.yml) for complete environment settings. - python 3.7.6 - pytorch 1.1.0 - torchvision 0.3.0 - tensorboard 2.1.0 - spacy 2.2.3  ## Data Preparation Follow instructions in data/README.md to setup data directory.
","See [environment.yml](environment.yml) for complete environment settings. - <PROGLANG>python</PROGLANG> 3.7.6 - <PROGLANG>pytorch</PROGLANG> 1.1.0 - <PROGLANG>torchvision</PROGLANG> 0.3.0 - <PROGLANG>tensorboard</PROGLANG> 2.1.0 - <PROGLANG>spacy</PROGLANG> 2.2.3  ## Data Preparation Follow instructions in data/README.md to setup data directory.
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\761a2ea1.txt,0.9284253578732107
3,Run following script to setup `cache` directory: ``` sh scripts/prepare_data.sh ``` This should generate following files under `cache` directory: - vocabulary file: `std_vocab_<dataset>_<split_by>.txt` - selected GloVe feature: `std_glove_<dataset>_<split_by>.npy` - referring expression database: `std_refdb_<dataset>_<split_by>.json` - critical objects database: `std_ctxdb_<dataset>_<split_by>.json`   ## Train **Train with binary XE loss:** ``` PYTHONPATH=$PWD python tools/train_att_vanilla.py --dataset refcoco --split-by unc ```  **Train with ranking loss:** ``` PYTHONPATH=$PWD python tools/train_att_rank.py --dataset refcoco --split-by unc ```  We use tensorboard to monitor the training process.,Run following script to setup `cache` directory: ``` sh scripts/prepare_data.sh ``` This should generate following files under `cache` directory: - vocabulary file: `std_vocab_<dataset>_<split_by>.txt` - selected GloVe feature: `std_glove_<dataset>_<split_by>.npy` - referring expression database: `std_refdb_<dataset>_<split_by>.json` - critical objects database: `std_ctxdb_<dataset>_<split_by>.json`   ## Train **Train with binary XE loss:** ``` PYTHONPATH=$PWD python tools/train_att_vanilla.py --dataset <DATASET>refcoco</DATASET> --split-by unc ```  **Train with ranking loss:** ``` PYTHONPATH=$PWD python tools/train_att_rank.py --dataset <DATASET>refcoco</DATASET> --split-by unc ```  We use tensorboard to monitor the training process.,"Run following script to setup cache directory:  sh scripts/prepare_data.sh  This should generate following files under cache directory: - vocabulary file: std_vocab_refcoco_split_by.txt - selected GloVe feature: std_glove_refcoco_split_by.npy - referring expression database: std_refdb_refcoco_split_by.json - critical objects database: std_ctxdb_refcoco_split_by.json   ## Train **Train with binary XE loss:**  PYTHONPATH=$PWD python tools/train_att_vanilla.py --dataset refcoco --split-by unc   **Train with ranking loss:**  PYTHONPATH=$PWD python tools/train_att_rank.py --dataset refcoco --split-by unc   We use tensorboard to monitor the training process.
","Run following script to setup cache directory:  sh scripts/prepare_data.sh  This should generate following files under cache directory: - vocabulary file: std_vocab_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.txt - selected GloVe feature: std_glove_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.npy - referring expression database: std_refdb_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.json - critical objects database: std_ctxdb_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.json   ## Train **Train with binary XE loss:**  <PROGLANG>PYTHONPATH</PROGLANG>=$PWD <PROGLANG>python</PROGLANG> tools/train_att_vanilla.py --dataset <DATASET>refcoco</DATASET> --split-by <DATASET>unc</DATASET>   **Train with ranking loss:**  <PROGLANG>PYTHONPATH</PROGLANG>=$PWD <PROGLANG>python</PROGLANG> tools/train_att_rank.py --dataset <DATASET>refcoco</DATASET> --split-by <DATASET>unc</DATASET>   We use <SOFTWARE>tensorboard</SOFTWARE> to monitor the training process.
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\332d33ae.txt,0.8193123628383321
4,The log file can be found in `tb` folder.  ## Evaluate Recall **Save Ref-NMS proposals:** ``` PYTHONPATH=$PWD python tools/save_ref_nms_proposals.py --dataset refcoco --split-by unc --tid <tid> --m <loss_type> ``` `<loss_type>` can be either `att_vanilla` for binary XE loss or `att_rank` for rank loss.,The log file can be found in `tb` folder.  ## Evaluate <EVALMETRIC>Recall</EVALMETRIC> **Save Ref-NMS proposals:** ``` PYTHONPATH=$PWD python tools/save_ref_nms_proposals.py --dataset <DATASET>refcoco</DATASET> --split-by unc --tid <tid> --m <loss_type> ``` `<loss_type>` can be either `att_vanilla` for binary XE loss or `att_rank` for rank loss.,The log file can be found in tb folder.  ## Evaluate Recall **Save Ref-NMS proposals:**  PYTHONPATH=$PWD python tools/save_ref_nms_proposals.py --dataset refcoco --split-by unc --tid <tid> --m <loss_type>  <loss_type> can be either att_vanilla for binary XE loss or att_rank for rank loss.,The log file can be found in tb folder.  ## Evaluate <EVALMETRIC>Recall</EVALMETRIC> **Save Ref-NMS proposals:**  PYTHONPATH=$PWD python tools/save_ref_nms_proposals.py --dataset <DATASET>refcoco</DATASET> --split-by unc --tid <tid> --m <loss_type>  <loss_type> can be either att_vanilla for binary XE loss or att_rank for rank loss.,../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\48976f3c.txt,0.9290540540540541
5,**Evaluate recall on referent object:** ``` PYTHONPATH=$PWD python tools/eval_proposal_hit_rate.py --m <loss_type> --dataset refcoco --split-by unc --tid <tid> --conf <conf> ``` `conf` parameter is the score threshold used to filter Ref-NMS proposals.,**Evaluate <EVALMETRIC>recall</EVALMETRIC> on referent object:** ``` PYTHONPATH=$PWD python tools/eval_proposal_hit_rate.py --m <loss_type> --dataset <DATASET>refcoco</DATASET> --split-by unc --tid <tid> --conf <conf> ``` `conf` parameter is the score threshold used to filter Ref-NMS proposals.,"**Evaluate recall on referent object:**  PYTHONPATH=$PWD python tools/eval_proposal_hit_rate.py --m <loss_type> --dataset refcoco --split-by unc --tid <tid> --conf <conf>  conf parameter is the score threshold used to filter Ref-NMS proposals.
","**Evaluate <EVALMETRIC>recall</EVALMETRIC> on referent object:**  PYTHONPATH=$PWD <PROGLANG>python</PROGLANG> tools/eval_proposal_hit_rate.py --m <loss_type> --<DATASET>dataset refcoco</DATASET> --split-by unc --tid <tid> --conf <conf>  conf parameter is the score threshold used to filter Ref-NMS proposals.
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\e81355cb.txt,0.9616161616161616
6,It should be picked properly so that the recall of the referent is high while the number of proposals per expression is around 8-10.,It should be picked properly so that the recall of the referent is high while the number of proposals per expression is around 8-10.,It should be picked properly so that the recall of the referent is high while the number of proposals per expression is around 8-10.,It should be picked properly so that the <EVALMETRIC>recall</EVALMETRIC> of the referent is high while the number of proposals per expression is around 8-10.,../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\7284d2ae.txt,1.0
7,**Evaluate recall on critical objects:** ``` PYTHONPATH=$PWD python tools/eval_proposal_ctx_recall.py --m <loss_type> --dataset refcoco --split-by unc --tid <tid> --conf <conf> ```  ## Evaluate REG Performance Save MAttNet-style detection file: ``` PYTHONPATH=$PWD python tools/save_matt_dets.py --dataset refcoco --split-by unc --m <loss_type> --tid <tid> --conf <conf> ``` This script will save all the detection information needed for downstream REG evaluation to `output/matt_dets_<loss_type>_<tid>_<dataset>_<split_by>_<top_N>.json`.,**Evaluate <EVALMETRIC>recall</EVALMETRIC> on critical objects:** ``` PYTHONPATH=$PWD python tools/eval_proposal_ctx_<EVALMETRIC>recall</EVALMETRIC>.py --m <loss_type> --dataset <DATASET>refcoco</DATASET> --split-by unc --tid <tid> --conf <conf> ```  ## Evaluate REG Performance Save MAttNet-style detection file: ``` PYTHONPATH=$PWD python tools/save_matt_dets.py --dataset <DATASET>refcoco</DATASET> --split-by unc --m <loss_type> --tid <tid> --conf <conf> ``` This script will save all the detection information needed for downstream REG evaluation to `output/matt_dets_<loss_type>_<tid>_<dataset>_<split_by>_<top_N>.json`.,"**Evaluate recall on critical objects:**  PYTHONPATH=$PWD python tools/eval_proposal_ctx_recall.py --m <loss_type> --dataset refcoco --split-by unc --tid <tid> --conf <conf>   ## Evaluate REG Performance Save MAttNet-style detection file:  PYTHONPATH=$PWD python tools/save_matt_dets.py --dataset refcoco --split-by unc --m <loss_type> --tid <tid> --conf <conf>  This script will save all the detection information needed for downstream REG evaluation to output/matt_dets_<loss_type>_<tid>__<split_by>_<top_N>.json.
","**Evaluate <EVALMETRIC>recall</EVALMETRIC> on critical objects:**  PYTHONPATH=$PWD python tools/eval_proposal_ctx_recall.py --m <loss_type> --dataset <DATASET>refcoco</DATASET> --split-by unc --tid <tid> --conf <conf>   ## Evaluate REG Performance Save MAttNet-style detection file:  PYTHONPATH=$PWD python tools/save_matt_dets.py --dataset <DATASET>refcoco</DATASET> --split-by unc --m <loss_type> --tid <tid> --conf <conf>  This script will save all the detection information needed for downstream REG evaluation to output/matt_dets_<loss_type>_<tid>_<dataset>_<split_by>_<top_N>.json.
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\2d7f0c9e.txt,0.9772296015180265
8,We provide altered version of [MAttNet](https://github.com/ChopinSharp/MAttNet) and [CM-A-E](https://github.com/ChopinSharp/CM-Erase-REG) for downstream REG task evaluation.,We provide altered version of [<SOFTWARE>MAttNet</SOFTWARE>](https://github.com/ChopinSharp/<SOFTWARE>MAttNet</SOFTWARE>) and [<SOFTWARE>CM-A-E</SOFTWARE>](https://github.com/ChopinSharp/<SOFTWARE>CM-Erase-REG</SOFTWARE>) for downstream REG task evaluation.,We provide altered version of [MAttNet](https://github.com/ChopinSharp/MAttNet) and [CM-A-E](https://github.com/ChopinSharp/CM-Erase-REG) for downstream REG task evaluation.,We provide altered version of <SOFTWARE>[MAttNet](https://github.com/ChopinSharp/MAttNet)</SOFTWARE> and <SOFTWARE>[CM-A-E](https://github.com/ChopinSharp/CM-Erase-REG)</SOFTWARE> for downstream REG task evaluation.,../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\145d5699.txt,1.0
9,"First, follow the README in each repository to reproduce the original reported results as baseline (c.f.","First, follow the README in each repository to reproduce the original reported results as baseline (c.f.","First, follow the README in each repository to reproduce the original reported results as baseline (c.f.","First, follow the README in each repository to reproduce the original reported results as baseline (c.f.",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\00b16e92.txt,1.0
10,Table 2 in our paper).,Table 2 in our paper).,"Table 2 in our paper).
","Table 2 in our <PUBLICATION>paper</PUBLICATION>).
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\4e21e8bd.txt,0.9777777777777777
11,"Then, run the following commands to evaluate on REC and RES task: ``` # Evaluate REC performance python tools/extract_mrcn_ref_feats.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> # Evaluate RES performance python tools/run_propose_to_mask.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref_masks.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save ```  ## Pretrained Models We provide pre-trained model weights as long as the corresponding **MAttNet-style detection file** (note the MattNet-style detection files can be directly used to evaluate downstream REG task performance).","Then, run the following commands to evaluate on REC and RES task: ``` # Evaluate REC performance python tools/extract_mrcn_ref_feats.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> # Evaluate RES performance python tools/run_propose_to_mask.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref_masks.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save ```  ## Pretrained Models We provide pre-trained model weights as long as the corresponding **MAttNet-style detection file** (note the MattNet-style detection files can be directly used to evaluate downstream REG task performance).","Then, run the following commands to evaluate on REC and RES task:  # Evaluate REC performance python tools/extract_mrcn_ref_feats.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> # Evaluate RES performance python tools/run_propose_to_mask.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> python tools/eval_ref_masks.py --dataset refcoco --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save   ## Pretrained Models We provide pre-trained model weights as long as the corresponding **MAttNet-style detection file** (note the MattNet-style detection files can be directly used to evaluate downstream REG task performance).
","Then, run the following commands to evaluate on REC and RES task:  # Evaluate REC performance <PROGLANG>python</PROGLANG> tools/extract_mrcn_ref_feats.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> <PROGLANG>python</PROGLANG> tools/eval_ref.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> # Evaluate RES performance <PROGLANG>python</PROGLANG> tools/run_propose_to_mask.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> <PROGLANG>python</PROGLANG> tools/eval_ref_masks.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save   ## Pretrained Models We provide pre-trained model weights as long as the corresponding **<SOFTWARE>MAttNet</SOFTWARE>-style detection file** (note the <SOFTWARE>MattNet</SOFTWARE>-style detection files can be directly used to evaluate downstream REG task performance).
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\f072bbd2.txt,0.9954574951330305
12,"With these files, one can easily reproduce our reported results.","With these files, one can easily reproduce our reported results.","With these files, one can easily reproduce our reported results.","With these files, one can easily reproduce our reported results.",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\d905fd2a.txt,1.0
13,[[Google Drive]](https://drive.google.com/drive/folders/1BPqWW0LrAEBFna7b-ORF2TcrY7K_DDvM?,[[<SOFTWARE>Google Drive</SOFTWARE>]](https://drive.google.com/drive/folders/1BPqWW0LrAEBFna7b-ORF2TcrY7K_DDvM?,"[[Google Drive]](https://drive.google.com/drive/folders/1BPqWW0LrAEBFna7b-ORF2TcrY7K_DDvM?
","[[<SOFTWARE>Google Drive</SOFTWARE>]](https://drive.google.com/drive/folders/1BPqWW0LrAEBFna7b-ORF2TcrY7K_DDvM?
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\aad9ea08.txt,0.994475138121547
14,"usp=sharing) [[Baidu Disk]](https://pan.baidu.com/s/1G4k7APKSUs-_5StXoYaNrA) (extraction code: 5a9r)  ## Citation ``` @inproceedings{chen2021ref,   title={Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding},   author={Chen, Long and Ma, Wenbo and Xiao, Jun and Zhang, Hanwang and Chang, Shih-Fu},   booktitle={AAAI},   year={2021} } ```","usp=sharing) [[<SOFTWARE>Baidu Disk</SOFTWARE>]](https://pan.baidu.com/s/1G4k7APKSUs-_5StXoYaNrA) (extraction code: 5a9r)  ## Citation ``` @inproceedings{chen2021ref,   title={<PUBLICATION>Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding</PUBLICATION>},   author={Chen, Long and Ma, Wenbo and Xiao, Jun and Zhang, Hanwang and Chang, Shih-Fu},   booktitle={<CONFERENCE>AAAI</CONFERENCE>},   year={2021} } ```","usp=sharing) [[Baidu Disk]](https://pan.baidu.com/s/1G4k7APKSUs-_5StXoYaNrA) (extraction code: 5a9r)  ## Citation  @inproceedings{chen2021ref,   title={Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding},   author={Chen, Long and Ma, Wenbo and Xiao, Jun and Zhang, Hanwang and Chang, Shih-Fu},   booktitle={AAAI},   year={2021} } 
","usp=sharing) [[Baidu Disk]](https://pan.baidu.com/s/1G4k7APKSUs-_5StXoYaNrA) (extraction code: 5a9r)  ## Citation  @inproceedings{chen2021ref,   title={<PUBLICATION>Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding</PUBLICATION>},   author={Chen, Long and Ma, Wenbo and Xiao, Jun and Zhang, Hanwang and Chang, Shih-Fu},   booktitle={<CONFERENCE>AAAI</CONFERENCE>},   year={2021} } 
",../results/deepseek-chat/prompt-0/zzz_ChopinSharp_ref-nms_main_README.md.tsv\19aba8c5.txt,0.9904240766073872
