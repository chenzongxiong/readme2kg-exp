sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,"# BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization Authors: [Wojciech Kryściński](https://twitter.com/iam_wkr), [Nazneen Rajani](https://twitter.com/nazneenrajani), [Divyansh Agarwal](https://twitter.com/jigsaw2212), [Caiming Xiong](https://twitter.com/caimingxiong), [Dragomir Radev](http://www.cs.yale.edu/homes/radev/)  ## Introduction The majority of available text summarization datasets include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases.","# <PUBLICATION>BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization</PUBLICATION><DATASET>BOOKSUM</DATASET>: A Collection of Datasets for Long-form Narrative Summarization Authors: [Wojciech Kryściński](https://twitter.com/iam_wkr), [Nazneen Rajani](https://twitter.com/nazneenrajani), [Divyansh Agarwal](https://twitter.com/jigsaw2212), [Caiming Xiong](https://twitter.com/caimingxiong), [Dragomir Radev](http://www.cs.yale.edu/homes/radev/)  ## Introduction The majority of available text summarization datasets include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases.","# BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization Authors: [Wojciech Kryściński](https://twitter.com/iam_wkr), [Nazneen Rajani](https://twitter.com/nazneenrajani), [Divyansh Agarwal](https://twitter.com/jigsaw2212), [Caiming Xiong](https://twitter.com/caimingxiong), [Dragomir Radev](http://www.cs.yale.edu/homes/radev/)  ## Introduction The majority of available text summarization datasets include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases.
","# <PUBLICATION>BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization</PUBLICATION> Authors: [Wojciech Kryściński](https://twitter.com/iam_wkr), [Nazneen Rajani](https://twitter.com/nazneenrajani), [Divyansh Agarwal](https://twitter.com/jigsaw2212), [Caiming Xiong](https://twitter.com/caimingxiong), [Dragomir Radev](http://www.cs.yale.edu/homes/radev/)  ## Introduction The majority of available text summarization <DATASET>datasets</DATASET> include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\1ccfb679.txt,0.9991079393398751
2,"While relevant, such datasets will offer limited challenges for future generations of text summarization systems.","While relevant, such datasets will offer limited challenges for future generations of text summarization systems.","While relevant, such datasets will offer limited challenges for future generations of text summarization systems.","While relevant, such <DATASET>datasets</DATASET> will offer limited challenges for future generations of text summarization systems.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\45ec676a.txt,1.0
3,"We address these issues by introducing BookSum, a collection of datasets for long-form narrative summarization.","We address these issues by introducing <DATASET>BookSum</DATASET>, a collection of datasets for long-form narrative summarization.","We address these issues by introducing BookSum, a collection of datasets for long-form narrative summarization.","We address these issues by introducing <PROJECT>BookSum</PROJECT>, a collection of <DATASET>datasets</DATASET> for long-form narrative summarization.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\028cf51f.txt,1.0
4,"Our dataset covers source documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level.","Our dataset covers source documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level.","Our dataset covers source documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level.","Our <DATASET>dataset</DATASET> covers source documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\3ca6ef6c.txt,1.0
5,"The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures.","The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures.","The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures.","The domain and structure of our <DATASET>dataset</DATASET> poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\6c4a9ead.txt,1.0
6,"To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset.","To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset.","To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset.","To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our <DATASET>dataset</DATASET>.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\0147e772.txt,1.0
7,"Paper link: https://arxiv.org/abs/2105.08209  <p align=""center""><img src=""misc/book_sumv4.png""></p>   ## Table of Contents  1.","Paper link: https://arxiv.org/abs/2105.08209  <p align=""center""><img src=""misc/book_sumv4.png""></p>   ## Table of Contents  1.","Paper link: https://arxiv.org/abs/2105.08209  <p align=""center""><img src=""misc/book_sumv4.png""></p>   ## Table of Contents  1.
","Paper link: https://arxiv.org/abs/2105.08209  <p align=""center""><img src=""misc/book_sumv4.png""></p>   ## Table of Contents  1.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\61b69e1a.txt,0.9960474308300395
11,[License](#license) 5.,[License](#license) 5.,[License](#license) 5.,[<LICENSE>License</LICENSE>](#license) 5.,../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\2eb59737.txt,1.0
13,"[Get Involved](#get-involved)  ## Updates #### 4/15/2021 Initial commit   ## Citation ``` @article{kryscinski2021booksum,       title={BookSum: A Collection of Datasets for Long-form Narrative Summarization},        author={Wojciech Kry{\'s}ci{\'n}ski and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},       year={2021},       eprint={2105.08209},       archivePrefix={arXiv},       primaryClass={cs.CL} } ```  ## Legal Note By downloading or using the resources, including any code or scripts, shared in this code repository, you hereby agree to the following terms, and your use of the resources is conditioned on and subject to these terms. 1.","[Get Involved](#get-involved)  ## Updates #### 4/15/2021 Initial commit   ## Citation ``` @article{kryscinski2021booksum,       title={<PUBLICATION>BookSum: A Collection of Datasets for Long-form Narrative Summarization</PUBLICATION><DATASET>BookSum</DATASET>: A Collection of Datasets for Long-form Narrative Summarization},        author={Wojciech Kry{\'s}ci{\'n}ski and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},       year={2021},       eprint={2105.08209},       archivePrefix={arXiv},       primaryClass={cs.CL} } ```  ## Legal Note By downloading or using the resources, including any code or scripts, shared in this code repository, you hereby agree to the following terms, and your use of the resources is conditioned on and subject to these terms. 1.","[Get Involved](#get-involved)  ## Updates #### 4/15/2021 Initial commit   ## Citation  @article{kryscinski2021booksum,       title={BookSum: A Collection of Datasets for Long-form Narrative Summarization},        author={Wojciech Kry{\'s}ci{\'n}ski and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},       year={2021},       eprint={2105.08209},       archivePrefix={arXiv},       primaryClass={cs.CL} }   ## Legal Note By downloading or using the resources, including any code or scripts, shared in this code repository, you hereby agree to the following terms, and your use of the resources is conditioned on and subject to these terms. 1.
","[Get Involved](#get-involved)  ## Updates #### 4/15/2021 Initial commit   ## Citation  @article{kryscinski2021booksum,       title={<PUBLICATION>BookSum: A Collection of Datasets for Long-form Narrative Summarization</PUBLICATION>},        author={Wojciech Kry{\'s}ci{\'n}ski and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},       year={2021},       eprint={2105.08209},       archivePrefix={arXiv},       primaryClass={cs.CL} }   ## Legal Note By downloading or using the resources, including any code or scripts, shared in this code repository, you hereby agree to the following terms, and your use of the resources is conditioned on and subject to these terms. 1.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\d9dfc7e1.txt,0.9947955390334573
18,"Furthermore, we are not liable for any damage, loss or expense of any kind arising from or relating to your use of the resources shared in this code repository or the data collected, regardless of whether such liability is based in tort, contract or otherwise.  ## License The code is released under the **BSD-3 License** (see `LICENSE.txt` for details).   ## Usage  #### 1.","Furthermore, we are not liable for any damage, loss or expense of any kind arising from or relating to your use of the resources shared in this code repository or the data collected, regardless of whether such liability is based in tort, contract or otherwise.  ## License The code is released under the **<LICENSE>BSD-3 License</LICENSE>** (see `LICENSE.txt` for details).   ## Usage  #### 1.","Furthermore, we are not liable for any damage, loss or expense of any kind arising from or relating to your use of the resources shared in this code repository or the data collected, regardless of whether such liability is based in tort, contract or otherwise.  ## License The code is released under the BSD-3 License (see LICENSE.txt for details).   ## Usage  #### 1.","Furthermore, we are not liable for any damage, loss or expense of any kind arising from or relating to your use of the resources shared in this code repository or the data collected, regardless of whether such liability is based in tort, contract or otherwise.  ## License The code is released under the <LICENSE>BSD-3 License</LICENSE> (see LICENSE.txt for details).   ## Usage  #### 1.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\01c659d1.txt,0.9919137466307277
19,"Chapterized Project Guteberg Data The chapterized book text from Gutenberg, for the books we use in our work, has been made available through a public GCP bucket.","Chapterized Project Guteberg Data The chapterized book text from Gutenberg, for the books we use in our work, has been made available through a public GCP bucket.","Here is the annotated text in Markdown format:

Chapterized Project Guteberg Data The chapterized book text from Gutenberg, for the books we use in our work, has been made available through a public GCP bucket.","Here is the annotated text in Markdown format:

Chapterized <PROJECT>Project Guteberg</PROJECT> <DATASET>Data</DATASET> The chapterized book text from <PROJECT>Gutenberg</PROJECT>, for the books we use in our work, has been made available through a public <SOFTWARE>GCP bucket</SOFTWARE>.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\fe7316c1.txt,0.8709677419354839
20,It can be fetched using: ``` gsutil cp gs://sfr-books-dataset-chapters-research/all_chapterized_books.zip . ```  or downloaded directly [here](https://storage.cloud.google.com/sfr-books-dataset-chapters-research/all_chapterized_books.zip).  #### 2.,It can be fetched using: ``` <SOFTWARE>gsutil</SOFTWARE> cp gs://sfr-books-dataset-chapters-research/all_chapterized_books.zip . ```  or downloaded directly [here](https://storage.cloud.google.com/sfr-books-dataset-chapters-research/all_chapterized_books.zip).  #### 2.,"It can be fetched using:  gsutil cp gs://sfr-books-dataset-chapters-research/all_chapterized_books.zip .   or downloaded directly [here](https://storage.cloud.google.com/sfr-books-dataset-chapters-research/all_chapterized_books.zip).  #### 2.
","It can be fetched using:  gsutil cp gs://<DATASET>sfr-books-dataset-chapters-research</DATASET>/all_chapterized_books.zip .   or downloaded directly [here](https://storage.cloud.google.com/<DATASET>sfr-books-dataset-chapters-research</DATASET>/all_chapterized_books.zip).  #### 2.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\4374cbe1.txt,0.9857433808553971
21,Data Collection Data collection scripts for the summary text are organized by the different sources that we use summaries from.,Data Collection Data collection scripts for the summary text are organized by the different sources that we use summaries from.,"Data Collection Data collection scripts for the summary text are organized by the different sources that we use summaries from.
","Data Collection Data collection scripts for the summary text are organized by the different sources that we use summaries from.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\01aeca40.txt,0.996078431372549
22,"Note: At the time of collecting the data, all links in literature_links.tsv were working for the respective sources.","Note: At the time of collecting the data, all links in literature_links.tsv were working for the respective sources.","Note: At the time of collecting the data, all links in literature_links.tsv were working for the respective sources.","Note: At the time of collecting the data, all links in <DATASET>literature_links.tsv</DATASET> were working for the respective sources.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\98648cf2.txt,1.0
23,"For each data source, the file `literature_links.tsv.pruned` contains the links for the books in our dataset.","For each data source, the file `literature_links.tsv.pruned` contains the links for the books in our dataset.","For each data source, the file literature_links.tsv.pruned contains the links for the books in our dataset.","For each data source, the file <SOFTWARE>literature_links.tsv.pruned</SOFTWARE> contains the links for the books in our <DATASET>dataset</DATASET>.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\3e63d191.txt,0.9907407407407407
24,Run `get_summaries.py` to collect the summaries from the links for each source.,Run `get_summaries.py` to collect the summaries from the links for each source.,"Run get_summaries.py to collect the summaries from the links for each source.
","Run get_summaries.py to collect the summaries from the links for each source.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\3c0c9dbf.txt,0.9808917197452229
25,"Additionally, `get_works.py` can be used to collect an exhaustive set of summaries from that source.  ``` cd scripts/data_collection/cliffnotes/ python get_summaries.py ```  #### 3.","Additionally, `get_works.py` can be used to collect an exhaustive set of summaries from that source.  ``` cd scripts/data_collection/cliffnotes/ <SOFTWARE>python</SOFTWARE> get_summaries.py ```  #### 3.","Additionally, get_works.py can be used to collect an exhaustive set of summaries from that source.   cd scripts/data_collection/cliffnotes/ python get_summaries.py   #### 3.
","Additionally, <SOFTWARE>get_works.py</SOFTWARE> can be used to collect an exhaustive set of summaries from that source.   cd scripts/data_collection/cliffnotes/ python <SOFTWARE>get_summaries.py</SOFTWARE>   #### 3.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\9c975f26.txt,0.9746478873239437
26,Data Cleaning   1.,Data Cleaning   1.,"Data Cleaning   1.
","Data Cleaning   1.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\f1ee6722.txt,0.972972972972973
27,Perform basic cleanup operations and setup the summary text for splitting and further cleaning operations     ```     cd scripts/data_cleaning_scripts/     python basic_clean.py     ```  2.,Perform basic cleanup operations and setup the summary text for splitting and further cleaning operations     ```     cd scripts/data_cleaning_scripts/     <SOFTWARE>python</SOFTWARE> basic_clean.py     ```  2.,     cd scripts/data_cleaning_scripts/     python basic_clean.py       2.,     cd scripts/data_cleaning_scripts/     <PROGLANG>python</PROGLANG> basic_clean.py       2.,../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\8ec25dab.txt,0.5572519083969466
28,"Using a mapping of which chapter summaries are separable (`alignments/chapter_summary_aligned.jsonl.aggregate_splits`), the summary text is split into different sections (eg.","Using a mapping of which chapter summaries are separable (`alignments/chapter_summary_aligned.jsonl.aggregate_splits`), the summary text is split into different sections (eg.","Using a mapping of which chapter summaries are separable (alignments/chapter_summary_aligned.jsonl.aggregate_splits), the summary text is split into different sections (eg.","Using a mapping of which chapter summaries are separable (<DATASET>alignments/chapter_summary_aligned.jsonl.aggregate_splits</DATASET>), the summary text is split into different sections (eg.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\14bdb393.txt,0.9942196531791907
29,"Chapters 1-3 summary separated into 3 different sections - Chapter 1 summary, Chapter 2 summary, Chapter 3 summary)     ```     python split_aggregate_chaps_all_sources.py     ```  3.","Chapters 1-3 summary separated into 3 different sections - Chapter 1 summary, Chapter 2 summary, Chapter 3 summary)     ```     <SOFTWARE>python</SOFTWARE> split_aggregate_chaps_all_sources.py     ```  3.","Chapters 1-3 summary separated into 3 different sections - Chapter 1 summary, Chapter 2 summary, Chapter 3 summary)          python split_aggregate_chaps_all_sources.py       3.
","Chapters 1-3 summary separated into 3 different sections - Chapter 1 summary, Chapter 2 summary, Chapter 3 summary)          <PROGLANG>python</PROGLANG> <SOFTWARE>split_aggregate_chaps_all_sources.py</SOFTWARE>       3.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\544d8da3.txt,0.9806094182825484
30,"The main cleanup script separates out analysis/commentary/notes from the summary text, removes prefixes etc.     ```     python clean_summaries.py     ```  #### Data Alignments Generating paragraph alignments from the chapter-level-summary-alignments, is performed individually for the train/test/val splits:  Gather the data from the summaries and book chapters into a single jsonl.","The main cleanup script separates out analysis/commentary/notes from the summary text, removes prefixes etc.     ```     <SOFTWARE>python</SOFTWARE> clean_summaries.py     ```  #### Data Alignments Generating paragraph alignments from the chapter-level-summary-alignments, is performed individually for the train/test/val splits:  Gather the data from the summaries and book chapters into a single jsonl.","The main cleanup script separates out analysis/commentary/notes from the summary text, removes prefixes etc.          python clean_summaries.py       #### Data Alignments Generating paragraph alignments from the chapter-level-summary-alignments, is performed individually for the train/test/val splits:  Gather the data from the summaries and book chapters into a single jsonl.
","The main cleanup script separates out analysis/commentary/notes from the summary text, removes prefixes etc.          <PROGLANG>python</PROGLANG> clean_summaries.py       #### Data Alignments Generating paragraph alignments from the chapter-level-summary-alignments, is performed individually for the train/test/val splits:  Gather the data from the summaries and book chapters into a single jsonl.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\9864327d.txt,0.9908015768725361
31,The script needs to be run separately for each split as the matched file ``` cd paragraph-level-summary-alignments python gather_data.py --matched_file /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl --split_paragraphs ```  Generate alignments of the paragraphs with sentences from the summary using the bi-encoder **paraphrase-distilroberta-base-v1** ``` python align_data_bi_encoder_paraphrase.py --data_path /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl.gathered --stable_alignment ```  ## Troubleshooting 1.,The script needs to be run separately for each split as the matched file ``` cd paragraph-level-summary-alignments <SOFTWARE>python</SOFTWARE> gather_data.py --matched_file /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl --split_paragraphs ```  Generate alignments of the paragraphs with sentences from the summary using the bi-encoder **<SOFTWARE>paraphrase-distilroberta-base-v1</SOFTWARE>** ``` <SOFTWARE>python</SOFTWARE> align_data_bi_encoder_paraphrase.py --data_path /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl.gathered --stable_alignment ```  ## Troubleshooting 1.,"The script needs to be run separately for each split as the matched file  cd paragraph-level-summary-alignments python gather_data.py --matched_file /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl --split_paragraphs   Generate alignments of the paragraphs with sentences from the summary using the bi-encoder **paraphrase-distilroberta-base-v1**  python align_data_bi_encoder_paraphrase.py --data_path /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl.gathered --stable_alignment   ## Troubleshooting 1.
","The script needs to be run separately for each split as the matched file  cd paragraph-level-summary-alignments python gather_data.py --matched_file /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl --split_paragraphs   Generate alignments of the paragraphs with sentences from the summary using the bi-encoder **<SOFTWARE>paraphrase-distilroberta-base-v1</SOFTWARE>**  python align_data_bi_encoder_paraphrase.py --data_path /path/to/chapter_summary_aligned_{train/test/val}_split.jsonl.gathered --stable_alignment   ## Troubleshooting 1.
",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\908eedf4.txt,0.9878618113912232
34,Some links that constantly throw errors are aggregated in a file called - 'section_errors.txt'.,Some links that constantly throw errors are aggregated in a file called - 'section_errors.txt'.,Some links that constantly throw errors are aggregated in a file called - section_errors.txt.,Some links that constantly throw errors are aggregated in a file called - <DATASET>section_errors.txt</DATASET>.,../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\8607a2d0.txt,0.9893617021276596
37,"It is recommended to download them in booksum root directory for the scripts to work without requiring any modifications to the paths.   ## Get Involved Please create a GitHub issue if you have any questions, suggestions, requests or bug-reports.","It is recommended to download them in booksum root directory for the scripts to work without requiring any modifications to the paths.   ## Get Involved Please create a GitHub issue if you have any questions, suggestions, requests or bug-reports.","Here is the annotated text in Markdown format:

It is recommended to download them in booksum root directory for the scripts to work without requiring any modifications to the paths.   ## Get Involved Please create a GitHub issue if you have any questions, suggestions, requests or bug-reports.","Here is the annotated text in Markdown format:

It is recommended to download them in <DATASET>booksum</DATASET> root directory for the scripts to work without requiring any modifications to the paths.   ## Get Involved Please create a <SOFTWARE>GitHub</SOFTWARE> issue if you have any questions, suggestions, requests or bug-reports.",../results/deepseek-chat/prompt-0/zzz_salesforce_booksum_main_README.md.tsv\2146a3a6.txt,0.9111111111111111
