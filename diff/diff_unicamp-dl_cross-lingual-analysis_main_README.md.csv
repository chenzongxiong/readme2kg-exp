sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,# Cross-lingual analysis  This repository contains the translation codes used in the paper [A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813).,# Cross-lingual analysis  This repository contains the translation codes used in the paper [<PUBLICATION>A cost-benefit analysis of cross-lingual transfer methods</PUBLICATION>](https://arxiv.org/abs/2105.06813).,# Cross-lingual analysis  This repository contains the translation codes used in the paper `[A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813)`.,# Cross-lingual analysis  This repository contains the translation codes used in the paper `<PUBLICATION>[A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813)</PUBLICATION>`.,../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\9a23a79f.txt,0.9946236559139785
2,"In this work, we analyze cross-lingual methods on three tasks in terms of their effectiveness (e.g., accuracy), development and deployment costs, as well as their latencies at inference time.","In this work, we analyze cross-lingual methods on three tasks in terms of their effectiveness (e.g., <EVALMETRIC>accuracy</EVALMETRIC>), development and deployment costs, as well as their latencies at inference time.","In this work, we analyze cross-lingual methods on three tasks in terms of their effectiveness (e.g., `accuracy`), development and deployment costs, as well as their latencies at inference time.","In this work, we analyze cross-lingual methods on three tasks in terms of their effectiveness (e.g., `<EVALMETRIC>accuracy</EVALMETRIC>`), development and deployment costs, as well as their latencies at inference time.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\1331a980.txt,0.9947916666666666
3,"We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training dataset to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in English.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training dataset to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in English.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training `dataset` to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in `English`.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training `<DATASET>dataset</DATASET>` to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in `<PROGLANG>English</PROGLANG>`.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\f9925a23.txt,0.9782082324455206
4,"Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three `datasets` used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three `<DATASET>datasets</DATASET>` used in this work.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\6b5edc53.txt,0.9927007299270073
5,"The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous published results.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous published results.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous `published results`.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous `<PUBLICATION>published results</PUBLICATION>`.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\84d8b2fd.txt,0.995850622406639
6,"Metrics are: Exact Match and F1-score for Q&A, Accuracy and F1-score for NLI and MRR@10 for Text Ranking","Metrics are: <EVALMETRIC>Exact Match</EVALMETRIC> and <EVALMETRIC>F1-score</EVALMETRIC> for Q&A, <EVALMETRIC>Accuracy</EVALMETRIC> and <EVALMETRIC>F1-score</EVALMETRIC> for NLI and <EVALMETRIC>MRR@10</EVALMETRIC> for Text Ranking","Metrics are: `Exact Match` and `F1-score` for Q&A, `Accuracy` and `F1-score` for NLI and `MRR@10` for Text Ranking","Metrics are: `<EVALMETRIC>Exact Match</EVALMETRIC>` and `<EVALMETRIC>F1-score</EVALMETRIC>` for Q&A, `<EVALMETRIC>Accuracy</EVALMETRIC>` and `<EVALMETRIC>F1-score</EVALMETRIC>` for NLI and `<EVALMETRIC>MRR@10</EVALMETRIC>` for Text Ranking",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\fc4eff9a.txt,0.9541284403669725
18,usp=sharing) (NLI)  The datasets SQuAD and MNLI are directly downloaded from the notebooks of this repository.,usp=sharing) (NLI)  The datasets <DATASET>SQuAD</DATASET> and <DATASET>MNLI</DATASET> are directly downloaded from the notebooks of this repository.,`usp=sharing) (NLI)  The datasets SQuAD and MNLI are directly downloaded from the notebooks of this repository.`,`usp=sharing) (NLI)  The datasets <DATASET>SQuAD</DATASET> and <DATASET>MNLI</DATASET> are directly downloaded from the notebooks of this repository.`,../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\e7c313e5.txt,0.990990990990991
