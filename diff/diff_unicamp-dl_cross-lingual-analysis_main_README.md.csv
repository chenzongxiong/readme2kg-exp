sentence_idx,original_sentence,original_annotated,de_annotated_content,generated_annotated,source_file,similarity_score
1,# Cross-lingual analysis  This repository contains the translation codes used in the paper [A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813).,# Cross-lingual analysis  This repository contains the translation codes used in the paper [<PUBLICATION>A cost-benefit analysis of cross-lingual transfer methods</PUBLICATION>](https://arxiv.org/abs/2105.06813).,# Cross-lingual analysis  This repository contains the translation codes used in the paper [A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813).,# Cross-lingual analysis  This repository contains the translation codes used in the paper <PUBLICATION>[A cost-benefit analysis of cross-lingual transfer methods](https://arxiv.org/abs/2105.06813)</PUBLICATION>.,../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\9a23a79f.txt,1.0
3,"We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training dataset to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in English.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training dataset to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in English.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training dataset to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in English.","We experiment with the following transfer learning techniques: 1) fine-tuning a bilingual model on a source language and evaluating it on the target language without translation, i.e., in a zero-shot manner; 2) automatic translation of the training <DATASET>dataset</DATASET> to the target language; 3) automatic translation of the test set to the source language at inference time and evaluation of a model fine-tuned in <PROGLANG>English</PROGLANG>.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\f9925a23.txt,1.0
4,"Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work.","Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three <DATASET>datasets</DATASET> used in this work.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\6b5edc53.txt,1.0
5,"The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous published results.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous published results.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous published results.","The study is a result of an ongoing Master's Program.  ## Evaluation benchmarks The models were benchmarked on three tasks (Question Answering, Natural Language Inference and Passage Text Ranking) and compared to previous <PUBLICATION>published results</PUBLICATION>.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\84d8b2fd.txt,1.0
7,.,.,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.020202020202020204
8,| Model                           | Pre-train     | Fine-tune       | F1           | Accuracy    |  | ------------------------------- | ------------- | --------------- | ------------ | ----------- |  | mBERT (Souza et al,| Model                           | Pre-train     | Fine-tune       | <EVALMETRIC>F1</EVALMETRIC>           | <EVALMETRIC>Accuracy</EVALMETRIC>    |  | ------------------------------- | ------------- | --------------- | ------------ | ----------- |  | mBERT (Souza et al,"| Model                           | Pre-train     | Fine-tune       | F1           | Accuracy    |  | ------------------------------- | ------------- | --------------- | ------------ | ----------- |  | mBERT (Souza et al
","| Model                           | Pre-train     | Fine-tune       | F1           | Accuracy    |  | ------------------------------- | ------------- | --------------- | ------------ | ----------- |  | <SOFTWARE>mBERT</SOFTWARE> (<PUBLICATION>Souza et al</PUBLICATION>
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\db47d491.txt,0.9977324263038548
9,.,.,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.020202020202020204
10,)            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al,)            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   0.8680     |   0.8680    | | <SOFTWARE>PTT5</SOFTWARE> (Carmo et al,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.9948717948717949
11,.,.,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.020202020202020204
12,)             | EN & PT       |   ASSIN2        |   0.8850     |   0.8860    | | BERTimbau Large (Souza et al,)             | EN & PT       |   <DATASET>ASSIN2</DATASET>        |   0.8850     |   0.8860    | | <SOFTWARE>BERTimbau Large</SOFTWARE> (Souza et al,)             | EN & PT       |   ASSIN2        |   0.8850     |   0.8860    | | BERTimbau Large (Souza et al,)             | EN & PT       |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8850</EVALMETRIC>     |   <EVALMETRIC>0.8860</EVALMETRIC>    | | <SOFTWARE>BERTimbau Large</SOFTWARE> (<PUBLICATION>Souza et al</PUBLICATION>,../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\b97432da.txt,1.0
13,.,.,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.020202020202020204
14,)  | EN & PT       |   ASSIN2        |   0.9000     |   0.9000    | | BERT-pt (ours)                  | EN & PT       |  MNLI + ASSIN2  |   0.9207     |   0.9207    |                       ## How to Translate   We made available the following data and the respectives notebooks with translation code: - [SQuAD](https://colab.research.google.com/drive/1CSNwfWJCwhFgYTtjxsDvUdN1DMuU_P4-?,)  | EN & PT       |   <DATASET>ASSIN2</DATASET>        |   0.9000     |   0.9000    | | BERT-pt (ours)                  | EN & PT       |  <DATASET>MNLI</DATASET> + <DATASET>ASSIN2</DATASET>  |   0.9207     |   0.9207    |                       ## How to Translate   We made available the following data and the respectives notebooks with translation code: - [<DATASET>SQuAD</DATASET>](https://<SOFTWARE>colab</SOFTWARE>.research.google.com/drive/1CSNwfWJCwhFgYTtjxsDvUdN1DMuU_P4-?,")  | EN & PT       |   ASSIN2        |   0.9000     |   0.9000    | | BERT-pt (ours)                  | EN & PT       |  MNLI + ASSIN2  |   0.9207     |   0.9207    |                       ## How to Translate   We made available the following data and the respectives notebooks with translation code: - [SQuAD](https://colab.research.google.com/drive/1CSNwfWJCwhFgYTtjxsDvUdN1DMuU_P4-?
",")  | EN & PT       |   <DATASET>ASSIN2</DATASET>        |   0.9000     |   0.9000    | | BERT-pt (ours)                  | EN & PT       |  <DATASET>MNLI</DATASET> + <DATASET>ASSIN2</DATASET>  |   0.9207     |   0.9207    |                       ## How to Translate   We made available the following data and the respectives notebooks with translation code: - [<DATASET>SQuAD</DATASET>](https://colab.research.google.com/drive/1CSNwfWJCwhFgYTtjxsDvUdN1DMuU_P4-?
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\4acca24f.txt,0.9987029831387808
15,usp=sharing) (Q&A) - [FaQuAD](https://colab.research.google.com/drive/1HdPjzn61genPyZfiDG5fqAwPNI4vhegw?,usp=sharing) (Q&A) - [<DATASET>FaQuAD</DATASET>](https://colab.research.google.com/drive/1HdPjzn61genPyZfiDG5fqAwPNI4vhegw?,"usp=sharing) (Q&A) - [FaQuAD](https://colab.research.google.com/drive/1HdPjzn61genPyZfiDG5fqAwPNI4vhegw?
","usp=sharing) (Q&A) - [<DATASET>FaQuAD</DATASET>](https://colab.research.google.com/drive/1HdPjzn61genPyZfiDG5fqAwPNI4vhegw?
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\c4edaed7.txt,0.9952153110047847
16,usp=sharing) (Q&A) - [MNLI](https://colab.research.google.com/drive/1Y9ZaJuN-SVo0fmwypPzcJCOetFw-A2tx?,usp=sharing) (Q&A) - [<DATASET>MNLI</DATASET>](https://colab.research.google.com/drive/1Y9ZaJuN-SVo0fmwypPzcJCOetFw-A2tx?,"usp=sharing) (Q&A) - [MNLI](https://colab.research.google.com/drive/1Y9ZaJuN-SVo0fmwypPzcJCOetFw-A2tx?
","usp=sharing) (Q&A) - [<DATASET>MNLI</DATASET>](https://colab.research.google.com/drive/1Y9ZaJuN-SVo0fmwypPzcJCOetFw-A2tx?
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\eae596e1.txt,0.9951219512195122
17,usp=sharing) (NLI) - [ASSIN2](https://colab.research.google.com/drive/1S5zwaw8KWee8y6Vyq-XHC8Am3GmGFpv9?,usp=sharing) (NLI) - [<DATASET>ASSIN2</DATASET>](https://colab.research.google.com/drive/1S5zwaw8KWee8y6Vyq-XHC8Am3GmGFpv9?,"usp=sharing) (NLI) - [ASSIN2](https://colab.research.google.com/drive/1S5zwaw8KWee8y6Vyq-XHC8Am3GmGFpv9?
","usp=sharing) (NLI) - [<DATASET>ASSIN2</DATASET>](https://colab.research.google.com/drive/1S5zwaw8KWee8y6Vyq-XHC8Am3GmGFpv9?
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\33d38a05.txt,0.9952153110047847
18,usp=sharing) (NLI)  The datasets SQuAD and MNLI are directly downloaded from the notebooks of this repository.,usp=sharing) (NLI)  The datasets <DATASET>SQuAD</DATASET> and <DATASET>MNLI</DATASET> are directly downloaded from the notebooks of this repository.,"Here is the annotated text in Markdown format:

usp=sharing) (NLI)  The datasets SQuAD and MNLI are directly downloaded from the notebooks of this repository.","Here is the annotated text in Markdown format:

usp=sharing) (NLI)  The datasets <DATASET>SQuAD</DATASET> and <DATASET>MNLI</DATASET> are directly downloaded from the notebooks of this repository.",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\e7c313e5.txt,0.8208955223880597
19,We also provide the FaQuAD and ASSIN2 datasets,We also provide the <DATASET>FaQuAD</DATASET> and <DATASET>ASSIN2</DATASET> datasets,"Here is the annotated text in Markdown format:

We also provide the FaQuAD and ASSIN2 datasets
","Here is the annotated text in Markdown format:

We also provide the <DATASET>FaQuAD</DATASET> and <DATASET>ASSIN2</DATASET> datasets
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\90b5c1e8.txt,0.6524822695035462
20,.,.,")            | 100 languages |   ASSIN2        |   0.8680     |   0.8680    | | PTT5 (Carmo et al
",")            | 100 languages |   <DATASET>ASSIN2</DATASET>        |   <EVALMETRIC>0.8680</EVALMETRIC>     |   <EVALMETRIC>0.8680</EVALMETRIC>    | | PTT5 (Carmo et al
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\44fccf78.txt,0.020202020202020204
21,"|                                 |   SQuAD    | FaQuAD   | MNLI       | ASSIN2   |  | ------------------------------- | ---------- | -------- | ---------- |--------- |  | Training examples               |  86,288    |   837    |   392,702  |  6,500   |    | Test examples                   |  21,557    |   63     |   20,000   |  2,448   |     | Translate Train (Batch size = 1)|    34h     |   -      |    36h     |    -     |   | Translate Test (Batch size = 1) |    -       |  1m 30s  |    -       |   31m    | ## References  [1] [BERTimbau: Pretrained BERT Models for Brazilian Portuguese](https://www.researchgate.net/publication/345395208_BERTimbau_Pretrained_BERT_Models_for_Brazilian_Portuguese)  [2] [PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data](https://arxiv.org/abs/2008.09144)  ## How do I cite this work?","|                                 |   <DATASET>SQuAD</DATASET>    | <DATASET>FaQuAD</DATASET>   | <DATASET>MNLI</DATASET>       | <DATASET>ASSIN2</DATASET>   |  | ------------------------------- | ---------- | -------- | ---------- |--------- |  | Training examples               |  86,288    |   837    |   392,702  |  6,500   |    | Test examples                   |  21,557    |   63     |   20,000   |  2,448   |     | Translate Train (Batch size = 1)|    34h     |   -      |    36h     |    -     |   | Translate Test (Batch size = 1) |    -       |  1m 30s  |    -       |   31m    | ## References  [1] [<PUBLICATION>BERTimbau: Pretrained BERT Models for Brazilian Portuguese</PUBLICATION>](https://www.researchgate.net/publication/345395208_BERTimbau_Pretrained_BERT_Models_for_Brazilian_Portuguese)  [2] [<PUBLICATION>PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data</PUBLICATION>](https://arxiv.org/abs/2008.09144)  ## How do I cite this work?","|                                 |   SQuAD    | FaQuAD   | MNLI       | ASSIN2   |  | ------------------------------- | ---------- | -------- | ---------- |--------- |  | Training examples               |  86,288    |   837    |   392,702  |  6,500   |    | Test examples                   |  21,557    |   63     |   20,000   |  2,448   |     | Translate Train (Batch size = 1)|    34h     |   -      |    36h     |    -     |   | Translate Test (Batch size = 1) |    -       |  1m 30s  |    -       |   31m    | ## References  [1] [BERTimbau: Pretrained BERT Models for Brazilian Portuguese](https://www.researchgate.net/publication/345395208_BERTimbau_Pretrained_BERT_Models_for_Brazilian_Portuguese)  [2] [PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data](https://arxiv.org/abs/2008.09144)  ## How do I cite this work?
","|                                 |   <DATASET>SQuAD</DATASET>    | <DATASET>FaQuAD</DATASET>   | <DATASET>MNLI</DATASET>       | <DATASET>ASSIN2</DATASET>   |  | ------------------------------- | ---------- | -------- | ---------- |--------- |  | Training examples               |  86,288    |   837    |   392,702  |  6,500   |    | Test examples                   |  21,557    |   63     |   20,000   |  2,448   |     | Translate Train (Batch size = 1)|    34h     |   -      |    36h     |    -     |   | Translate Test (Batch size = 1) |    -       |  1m 30s  |    -       |   31m    | ## References  [1] <PUBLICATION>[BERTimbau: Pretrained BERT Models for Brazilian Portuguese](https://www.researchgate.net/publication/345395208_BERTimbau_Pretrained_BERT_Models_for_Brazilian_Portuguese)</PUBLICATION>  [2] <PUBLICATION>[PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data](https://arxiv.org/abs/2008.09144)</PUBLICATION>  ## How do I cite this work?
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\7e04cbda.txt,0.9994114184814596
22,"~~~ {.xml  @article{cross-lingual2021,     title={A cost-benefit analysis of cross-lingual transfer methods},     author={Moraes, Guilherme and Bonif치cio, Luiz Henrique and Rodrigues de Souza, Leandro and Nogueira, Rodrigo and Lotufo, Roberto},     journal={arXiv preprint arXiv:2105.06813},     url={https://arxiv.org/abs/2105.06813},     year={2021} } ~~~","~~~ {.xml  @article{cross-lingual2021,     title={<PUBLICATION>A cost-benefit analysis of cross-lingual transfer methods</PUBLICATION>},     author={Moraes, Guilherme and Bonif치cio, Luiz Henrique and Rodrigues de Souza, Leandro and Nogueira, Rodrigo and Lotufo, Roberto},     journal={arXiv preprint arXiv:2105.06813},     url={https://arxiv.org/abs/2105.06813},     year={2021} } ~~~","~~~ {.xml  @article{cross-lingual2021,     title={A cost-benefit analysis of cross-lingual transfer methods},     author={Moraes, Guilherme and Bonif치cio, Luiz Henrique and Rodrigues de Souza, Leandro and Nogueira, Rodrigo and Lotufo, Roberto},     journal={arXiv preprint arXiv:2105.06813},     url={https://arxiv.org/abs/2105.06813},     year={2021} } ~~~
","~~~ {.xml  @article{cross-lingual2021,     title={A cost-benefit analysis of cross-lingual transfer methods},     author={Moraes, Guilherme and Bonif치cio, Luiz Henrique and Rodrigues de Souza, Leandro and Nogueira, Rodrigo and Lotufo, Roberto},     journal={<PUBLICATION>arXiv preprint arXiv:2105.06813</PUBLICATION>},     url={https://arxiv.org/abs/2105.06813},     year={2021} } ~~~
",../results/deepseek-chat/prompt-0/zzz_unicamp-dl_cross-lingual-analysis_main_README.md.tsv\bc969a20.txt,0.9986013986013986
