#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=<div align="center">
#Text=<img align="center" width="30%" alt="image" src="https://github.com/AI4Finance-Foundation/FinGPT/assets/31713746/e0371951-1ce1-488e-aa25-0992dafcc139">
#Text=</div>
#Text=
#Text=# FinGPT: Open-Source Financial Large Language Models
#Text=[!
1-1	0-1	<	_	_	
1-2	1-4	div	_	_	
1-3	5-10	align	_	_	
1-4	10-11	=	_	_	
1-5	11-12	"	_	_	
1-6	12-18	center	_	_	
1-7	18-19	"	_	_	
1-8	19-20	>	_	_	
1-9	21-22	<	_	_	
1-10	22-25	img	_	_	
1-11	26-31	align	_	_	
1-12	31-32	=	_	_	
1-13	32-33	"	_	_	
1-14	33-39	center	_	_	
1-15	39-40	"	_	_	
1-16	41-46	width	_	_	
1-17	46-47	=	_	_	
1-18	47-48	"	_	_	
1-19	48-51	30%	_	_	
1-20	51-52	"	_	_	
1-21	53-56	alt	_	_	
1-22	56-57	=	_	_	
1-23	57-58	"	_	_	
1-24	58-63	image	_	_	
1-25	63-64	"	_	_	
1-26	65-68	src	_	_	
1-27	68-69	=	_	_	
1-28	69-70	"	_	_	
1-29	70-75	https	_	_	
1-30	75-76	:	_	_	
1-31	76-77	/	_	_	
1-32	77-78	/	_	_	
1-33	78-88	github.com	_	_	
1-34	88-89	/	_	_	
1-35	89-110	AI4Finance-Foundation	_	_	
1-36	110-111	/	_	_	
1-37	111-117	FinGPT	*	PROJECT	
1-38	117-118	/	_	_	
1-39	118-124	assets	_	_	
1-40	124-125	/	_	_	
1-41	125-133	31713746	_	_	
1-42	133-134	/	_	_	
1-43	134-142	e0371951	_	_	
1-44	142-143	-	_	_	
1-45	143-147	1ce1	_	_	
1-46	147-148	-	_	_	
1-47	148-157	488e-aa25	_	_	
1-48	157-158	-	_	_	
1-49	158-170	0992dafcc139	_	_	
1-50	170-171	"	_	_	
1-51	171-172	>	_	_	
1-52	173-174	<	_	_	
1-53	174-175	/	_	_	
1-54	175-178	div	_	_	
1-55	178-179	>	_	_	
1-56	181-182	#	_	_	
1-57	183-189	FinGPT	*[1]|*[2]	PUBLICATION[1]|PROJECT[2]	
1-58	189-190	:	*[1]	PUBLICATION[1]	
1-59	191-202	Open-Source	*[1]	PUBLICATION[1]	
1-60	203-212	Financial	*[1]	PUBLICATION[1]	
1-61	213-218	Large	*[1]	PUBLICATION[1]	
1-62	219-227	Language	*[1]	PUBLICATION[1]	
1-63	228-234	Models	*[1]	PUBLICATION[1]	
1-64	235-236	[	_	_	
1-65	236-237	!	_	_	

#Text=[Downloads](https://static.pepy.tech/badge/fingpt)](https://pepy.tech/project/fingpt)
#Text=[!
2-1	237-238	[	_	_	
2-2	238-247	Downloads	_	_	
2-3	247-248	]	_	_	
2-4	248-249	(	_	_	
2-5	249-254	https	_	_	
2-6	254-255	:	_	_	
2-7	255-256	/	_	_	
2-8	256-257	/	_	_	
2-9	257-273	static.pepy.tech	_	_	
2-10	273-274	/	_	_	
2-11	274-279	badge	_	_	
2-12	279-280	/	_	_	
2-13	280-286	fingpt	*	PROJECT	
2-14	286-287	)	_	_	
2-15	287-288	]	_	_	
2-16	288-289	(	_	_	
2-17	289-294	https	_	_	
2-18	294-295	:	_	_	
2-19	295-296	/	_	_	
2-20	296-297	/	_	_	
2-21	297-306	pepy.tech	_	_	
2-22	306-307	/	_	_	
2-23	307-314	project	_	_	
2-24	314-315	/	_	_	
2-25	315-321	fingpt	*	PROJECT	
2-26	321-322	)	_	_	
2-27	323-324	[	_	_	
2-28	324-325	!	_	_	

#Text=[Downloads](https://static.pepy.tech/badge/fingpt/week)](https://pepy.tech/project/fingpt)
#Text=[!
3-1	325-326	[	_	_	
3-2	326-335	Downloads	_	_	
3-3	335-336	]	_	_	
3-4	336-337	(	_	_	
3-5	337-342	https	_	_	
3-6	342-343	:	_	_	
3-7	343-344	/	_	_	
3-8	344-345	/	_	_	
3-9	345-361	static.pepy.tech	_	_	
3-10	361-362	/	_	_	
3-11	362-367	badge	_	_	
3-12	367-368	/	_	_	
3-13	368-374	fingpt	*	PROJECT	
3-14	374-375	/	_	_	
3-15	375-379	week	_	_	
3-16	379-380	)	_	_	
3-17	380-381	]	_	_	
3-18	381-382	(	_	_	
3-19	382-387	https	_	_	
3-20	387-388	:	_	_	
3-21	388-389	/	_	_	
3-22	389-390	/	_	_	
3-23	390-399	pepy.tech	_	_	
3-24	399-400	/	_	_	
3-25	400-407	project	_	_	
3-26	407-408	/	_	_	
3-27	408-414	fingpt	*	PROJECT	
3-28	414-415	)	_	_	
3-29	416-417	[	_	_	
3-30	417-418	!	_	_	

#Text=[Python 3.8](https://img.shields.io/badge/python-3.6-blue.svg)](https://www.python.org/downloads/release/python-360/)
#Text=[!
4-1	418-419	[	_	_	
4-2	419-425	Python	*[3]	SOFTWARE[3]	
4-3	426-429	3.8	*[3]	SOFTWARE[3]	
4-4	429-430	]	_	_	
4-5	430-431	(	_	_	
4-6	431-436	https	_	_	
4-7	436-437	:	_	_	
4-8	437-438	/	_	_	
4-9	438-439	/	_	_	
4-10	439-453	img.shields.io	_	_	
4-11	453-454	/	_	_	
4-12	454-459	badge	_	_	
4-13	459-460	/	_	_	
4-14	460-466	python	*[4]	SOFTWARE[4]	
4-15	466-467	-	*[4]	SOFTWARE[4]	
4-16	467-470	3.6	*[4]	SOFTWARE[4]	
4-17	470-471	-	_	_	
4-18	471-479	blue.svg	_	_	
4-19	479-480	)	_	_	
4-20	480-481	]	_	_	
4-21	481-482	(	_	_	
4-22	482-487	https	_	_	
4-23	487-488	:	_	_	
4-24	488-489	/	_	_	
4-25	489-490	/	_	_	
4-26	490-504	www.python.org	_	_	
4-26.1	494-500	python	*	PROGLANG	
4-27	504-505	/	_	_	
4-28	505-514	downloads	_	_	
4-29	514-515	/	_	_	
4-30	515-522	release	_	_	
4-31	522-523	/	_	_	
4-32	523-529	python	_	_	
4-33	529-530	-	_	_	
4-34	530-533	360	_	_	
4-35	533-534	/	_	_	
4-36	534-535	)	_	_	
4-37	536-537	[	_	_	
4-38	537-538	!	_	_	

#Text=[PyPI](https://img.shields.io/pypi/v/fingpt.svg)](https://pypi.org/project/fingpt/)
#Text=!
5-1	538-539	[	_	_	
5-2	539-543	PyPI	_	_	
5-3	543-544	]	_	_	
5-4	544-545	(	_	_	
5-5	545-550	https	_	_	
5-6	550-551	:	_	_	
5-7	551-552	/	_	_	
5-8	552-553	/	_	_	
5-9	553-567	img.shields.io	_	_	
5-10	567-568	/	_	_	
5-11	568-572	pypi	_	_	
5-12	572-573	/	_	_	
5-13	573-574	v	_	_	
5-14	574-575	/	_	_	
5-15	575-585	fingpt.svg	_	_	
5-16	585-586	)	_	_	
5-17	586-587	]	_	_	
5-18	587-588	(	_	_	
5-19	588-593	https	_	_	
5-20	593-594	:	_	_	
5-21	594-595	/	_	_	
5-22	595-596	/	_	_	
5-23	596-604	pypi.org	_	_	
5-24	604-605	/	_	_	
5-25	605-612	project	_	_	
5-26	612-613	/	_	_	
5-27	613-619	fingpt	*	PROJECT	
5-28	619-620	/	_	_	
5-29	620-621	)	_	_	
5-30	622-623	!	_	_	

#Text=[License](https://img.shields.io/github/license/AI4Finance-Foundation/fingpt.svg?
6-1	623-624	[	_	_	
6-2	624-631	License	_	_	
6-3	631-632	]	_	_	
6-4	632-633	(	_	_	
6-5	633-638	https	_	_	
6-6	638-639	:	_	_	
6-7	639-640	/	_	_	
6-8	640-641	/	_	_	
6-9	641-655	img.shields.io	_	_	
6-10	655-656	/	_	_	
6-11	656-662	github	_	_	
6-12	662-663	/	_	_	
6-13	663-670	license	_	_	
6-14	670-671	/	_	_	
6-15	671-692	AI4Finance-Foundation	_	_	
6-16	692-693	/	_	_	
6-17	693-703	fingpt.svg	_	_	
6-18	703-704	?	_	_	

#Text=color=brightgreen)
#Text=!
7-1	704-709	color	_	_	
7-2	709-710	=	_	_	
7-3	710-721	brightgreen	_	_	
7-4	721-722	)	_	_	
7-5	723-724	!	_	_	

#Text=[](https://img.shields.io/github/issues-raw/AI4Finance-Foundation/fingpt?
8-1	724-725	[	_	_	
8-2	725-726	]	_	_	
8-3	726-727	(	_	_	
8-4	727-732	https	_	_	
8-5	732-733	:	_	_	
8-6	733-734	/	_	_	
8-7	734-735	/	_	_	
8-8	735-749	img.shields.io	_	_	
8-9	749-750	/	_	_	
8-10	750-756	github	_	_	
8-11	756-757	/	_	_	
8-12	757-767	issues-raw	_	_	
8-13	767-768	/	_	_	
8-14	768-789	AI4Finance-Foundation	_	_	
8-15	789-790	/	_	_	
8-16	790-796	fingpt	*	PROJECT	
8-17	796-797	?	_	_	

#Text=label=Issues)
#Text=!
9-1	797-802	label	_	_	
9-2	802-803	=	_	_	
9-3	803-809	Issues	_	_	
9-4	809-810	)	_	_	
9-5	811-812	!	_	_	

#Text=[](https://img.shields.io/github/issues-closed-raw/AI4Finance-Foundation/fingpt?
10-1	812-813	[	_	_	
10-2	813-814	]	_	_	
10-3	814-815	(	_	_	
10-4	815-820	https	_	_	
10-5	820-821	:	_	_	
10-6	821-822	/	_	_	
10-7	822-823	/	_	_	
10-8	823-837	img.shields.io	_	_	
10-9	837-838	/	_	_	
10-10	838-844	github	_	_	
10-11	844-845	/	_	_	
10-12	845-862	issues-closed-raw	_	_	
10-13	862-863	/	_	_	
10-14	863-884	AI4Finance-Foundation	_	_	
10-15	884-885	/	_	_	
10-16	885-891	fingpt	_	_	
10-17	891-892	?	_	_	

#Text=label=Closed+Issues)
#Text=!
11-1	892-897	label	_	_	
11-2	897-898	=	_	_	
11-3	898-904	Closed	_	_	
11-4	904-905	+	_	_	
11-5	905-911	Issues	_	_	
11-6	911-912	)	_	_	
11-7	913-914	!	_	_	

#Text=[](https://img.shields.io/github/issues-pr-raw/AI4Finance-Foundation/fingpt?
12-1	914-915	[	_	_	
12-2	915-916	]	_	_	
12-3	916-917	(	_	_	
12-4	917-922	https	_	_	
12-5	922-923	:	_	_	
12-6	923-924	/	_	_	
12-7	924-925	/	_	_	
12-8	925-939	img.shields.io	_	_	
12-9	939-940	/	_	_	
12-10	940-946	github	_	_	
12-11	946-947	/	_	_	
12-12	947-960	issues-pr-raw	_	_	
12-13	960-961	/	_	_	
12-14	961-982	AI4Finance-Foundation	_	_	
12-15	982-983	/	_	_	
12-16	983-989	fingpt	_	_	
12-17	989-990	?	_	_	

#Text=label=Open+PRs)
#Text=!
13-1	990-995	label	_	_	
13-2	995-996	=	_	_	
13-3	996-1000	Open	_	_	
13-4	1000-1001	+	_	_	
13-5	1001-1004	PRs	_	_	
13-6	1004-1005	)	_	_	
13-7	1006-1007	!	_	_	

#Text=[](https://img.shields.io/github/issues-pr-closed-raw/AI4Finance-Foundation/fingpt?
14-1	1007-1008	[	_	_	
14-2	1008-1009	]	_	_	
14-3	1009-1010	(	_	_	
14-4	1010-1015	https	_	_	
14-5	1015-1016	:	_	_	
14-6	1016-1017	/	_	_	
14-7	1017-1018	/	_	_	
14-8	1018-1032	img.shields.io	_	_	
14-9	1032-1033	/	_	_	
14-10	1033-1039	github	_	_	
14-11	1039-1040	/	_	_	
14-12	1040-1060	issues-pr-closed-raw	_	_	
14-13	1060-1061	/	_	_	
14-14	1061-1082	AI4Finance-Foundation	_	_	
14-15	1082-1083	/	_	_	
14-16	1083-1089	fingpt	_	_	
14-17	1089-1090	?	_	_	

#Text=label=Closed+PRs)
#Text=
#Text=<div align="center">
#Text=<img align="center" src=figs/logo_transparent_background.png width="40%"/>
#Text=</div>
#Text=
#Text=Let us not expect Wall Street to open-source LLMs or open APIs, due to FinTech institutes' internal regulations and policies.
15-1	1090-1095	label	_	_	
15-2	1095-1096	=	_	_	
15-3	1096-1102	Closed	_	_	
15-4	1102-1103	+	_	_	
15-5	1103-1106	PRs	_	_	
15-6	1106-1107	)	_	_	
15-7	1109-1110	<	_	_	
15-8	1110-1113	div	_	_	
15-9	1114-1119	align	_	_	
15-10	1119-1120	=	_	_	
15-11	1120-1121	"	_	_	
15-12	1121-1127	center	_	_	
15-13	1127-1128	"	_	_	
15-14	1128-1129	>	_	_	
15-15	1130-1131	<	_	_	
15-16	1131-1134	img	_	_	
15-17	1135-1140	align	_	_	
15-18	1140-1141	=	_	_	
15-19	1141-1142	"	_	_	
15-20	1142-1148	center	_	_	
15-21	1148-1149	"	_	_	
15-22	1150-1153	src	_	_	
15-23	1153-1154	=	_	_	
15-24	1154-1158	figs	_	_	
15-25	1158-1159	/	_	_	
15-26	1159-1190	logo_transparent_background.png	_	_	
15-27	1191-1196	width	_	_	
15-28	1196-1197	=	_	_	
15-29	1197-1198	"	_	_	
15-30	1198-1201	40%	_	_	
15-31	1201-1202	"	_	_	
15-32	1202-1203	/	_	_	
15-33	1203-1204	>	_	_	
15-34	1205-1206	<	_	_	
15-35	1206-1207	/	_	_	
15-36	1207-1210	div	_	_	
15-37	1210-1211	>	_	_	
15-38	1213-1216	Let	_	_	
15-39	1217-1219	us	_	_	
15-40	1220-1223	not	_	_	
15-41	1224-1230	expect	_	_	
15-42	1231-1235	Wall	_	_	
15-43	1236-1242	Street	_	_	
15-44	1243-1245	to	_	_	
15-45	1246-1257	open-source	_	_	
15-46	1258-1262	LLMs	_	_	
15-47	1263-1265	or	_	_	
15-48	1266-1270	open	_	_	
15-49	1271-1275	APIs	_	_	
15-50	1275-1276	,	_	_	
15-51	1277-1280	due	_	_	
15-52	1281-1283	to	_	_	
15-53	1284-1291	FinTech	_	_	
15-54	1292-1302	institutes	_	_	
15-55	1302-1303	'	_	_	
15-56	1304-1312	internal	_	_	
15-57	1313-1324	regulations	_	_	
15-58	1325-1328	and	_	_	
15-59	1329-1337	policies	_	_	
15-60	1337-1338	.	_	_	

#Text=[Blueprint of FinGPT](https://arxiv.org/abs/2306.06031)
#Text=
#Text=<https://huggingface.co/FinGPT>
#Text=
#Text=[!
16-1	1340-1341	[	_	_	
16-2	1341-1350	Blueprint	_	_	
16-3	1351-1353	of	_	_	
16-4	1354-1360	FinGPT	_	_	
16-5	1360-1361	]	_	_	
16-6	1361-1362	(	_	_	
16-7	1362-1367	https	_	_	
16-8	1367-1368	:	_	_	
16-9	1368-1369	/	_	_	
16-10	1369-1370	/	_	_	
16-11	1370-1379	arxiv.org	_	_	
16-12	1379-1380	/	_	_	
16-13	1380-1383	abs	_	_	
16-14	1383-1384	/	_	_	
16-15	1384-1394	2306.06031	_	_	
16-16	1394-1395	)	_	_	
16-17	1397-1398	<	_	_	
16-18	1398-1403	https	_	_	
16-19	1403-1404	:	_	_	
16-20	1404-1405	/	_	_	
16-21	1405-1406	/	_	_	
16-22	1406-1420	huggingface.co	_	_	
16-23	1420-1421	/	_	_	
16-24	1421-1427	FinGPT	*	SOFTWARE	
16-25	1427-1428	>	_	_	
16-26	1430-1431	[	_	_	
16-27	1431-1432	!	_	_	

#Text=[](https://dcbadge.vercel.app/api/server/trsr8SXpW5)](https://discord.gg/trsr8SXpW5)
#Text=
#Text=!
17-1	1432-1433	[	_	_	
17-2	1433-1434	]	_	_	
17-3	1434-1435	(	_	_	
17-4	1435-1440	https	_	_	
17-5	1440-1441	:	_	_	
17-6	1441-1442	/	_	_	
17-7	1442-1443	/	_	_	
17-8	1443-1461	dcbadge.vercel.app	_	_	
17-9	1461-1462	/	_	_	
17-10	1462-1465	api	_	_	
17-11	1465-1466	/	_	_	
17-12	1466-1472	server	_	_	
17-13	1472-1473	/	_	_	
17-14	1473-1483	trsr8SXpW5	_	_	
17-15	1483-1484	)	_	_	
17-16	1484-1485	]	_	_	
17-17	1485-1486	(	_	_	
17-18	1486-1491	https	_	_	
17-19	1491-1492	:	_	_	
17-20	1492-1493	/	_	_	
17-21	1493-1494	/	_	_	
17-22	1494-1504	discord.gg	_	_	
17-23	1504-1505	/	_	_	
17-24	1505-1515	trsr8SXpW5	_	_	
17-25	1515-1516	)	_	_	
17-26	1518-1519	!	_	_	

#Text=[Visitors](https://api.visitorbadge.io/api/VisitorHit?
18-1	1519-1520	[	_	_	
18-2	1520-1528	Visitors	_	_	
18-3	1528-1529	]	_	_	
18-4	1529-1530	(	_	_	
18-5	1530-1535	https	_	_	
18-6	1535-1536	:	_	_	
18-7	1536-1537	/	_	_	
18-8	1537-1538	/	_	_	
18-9	1538-1557	api.visitorbadge.io	_	_	
18-10	1557-1558	/	_	_	
18-11	1558-1561	api	_	_	
18-12	1561-1562	/	_	_	
18-13	1562-1572	VisitorHit	_	_	
18-14	1572-1573	?	_	_	

#Text=user=AI4Finance-Foundation&repo=FinGPT&countColor=%23B17A)
#Text=
#Text=
#Text=## What's New:
#Text= - [Model Release] Nov, 2023: We release [FinGPT-Forecaster](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster)!
19-1	1573-1577	user	_	_	
19-2	1577-1578	=	_	_	
19-3	1578-1599	AI4Finance-Foundation	_	_	
19-4	1599-1600	&	_	_	
19-5	1600-1604	repo	_	_	
19-6	1604-1605	=	_	_	
19-7	1605-1611	FinGPT	*	PROJECT	
19-8	1611-1612	&	_	_	
19-9	1612-1622	countColor	_	_	
19-10	1622-1623	=	_	_	
19-11	1623-1624	%	_	_	
19-12	1624-1630	23B17A	_	_	
19-13	1630-1631	)	_	_	
19-14	1634-1635	#	_	_	
19-15	1635-1636	#	_	_	
19-16	1637-1643	What's	_	_	
19-17	1644-1647	New	_	_	
19-18	1647-1648	:	_	_	
19-19	1650-1651	-	_	_	
19-20	1652-1653	[	_	_	
19-21	1653-1658	Model	_	_	
19-22	1659-1666	Release	_	_	
19-23	1666-1667	]	_	_	
19-24	1668-1671	Nov	_	_	
19-25	1671-1672	,	_	_	
19-26	1673-1677	2023	_	_	
19-27	1677-1678	:	_	_	
19-28	1679-1681	We	_	_	
19-29	1682-1689	release	_	_	
19-30	1690-1691	[	_	_	
19-31	1691-1708	FinGPT-Forecaster	*	SOFTWARE	
19-32	1708-1709	]	_	_	
19-33	1709-1710	(	_	_	
19-34	1710-1715	https	_	_	
19-35	1715-1716	:	_	_	
19-36	1716-1717	/	_	_	
19-37	1717-1718	/	_	_	
19-38	1718-1728	github.com	_	_	
19-39	1728-1729	/	_	_	
19-40	1729-1750	AI4Finance-Foundation	_	_	
19-41	1750-1751	/	_	_	
19-42	1751-1757	FinGPT	*	PROJECT	
19-43	1757-1758	/	_	_	
19-44	1758-1762	tree	_	_	
19-45	1762-1763	/	_	_	
19-46	1763-1769	master	_	_	
19-47	1769-1770	/	_	_	
19-48	1770-1776	fingpt	*	SOFTWARE	
19-49	1776-1777	/	_	_	
19-50	1777-1794	FinGPT_Forecaster	*	SOFTWARE	
19-51	1794-1795	)	_	_	
19-52	1795-1796	!	_	_	

#Text=🔥[Demo](https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster), [Medium Blog](https://medium.datadriveninvestor.com/introducing-fingpt-forecaster-the-future-of-robo-advisory-services-50add34e3d3c) & [Model](https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora) are available on Huggingface🤗!
20-1	1798-1800	🔥	_	_	
20-2	1800-1801	[	_	_	
20-3	1801-1805	Demo	_	_	
20-4	1805-1806	]	_	_	
20-5	1806-1807	(	_	_	
20-6	1807-1812	https	_	_	
20-7	1812-1813	:	_	_	
20-8	1813-1814	/	_	_	
20-9	1814-1815	/	_	_	
20-10	1815-1829	huggingface.co	_	_	
20-11	1829-1830	/	_	_	
20-12	1830-1836	spaces	_	_	
20-13	1836-1837	/	_	_	
20-14	1837-1843	FinGPT	*[5]|*[6]	SOFTWARE[5]|PROJECT[6]	
20-15	1843-1844	/	*[5]	SOFTWARE[5]	
20-16	1844-1861	FinGPT-Forecaster	*[5]	SOFTWARE[5]	
20-17	1861-1862	)	_	_	
20-18	1862-1863	,	_	_	
20-19	1864-1865	[	_	_	
20-20	1865-1871	Medium	_	_	
20-21	1872-1876	Blog	_	_	
20-22	1876-1877	]	_	_	
20-23	1877-1878	(	_	_	
20-24	1878-1883	https	_	_	
20-25	1883-1884	:	_	_	
20-26	1884-1885	/	_	_	
20-27	1885-1886	/	_	_	
20-28	1886-1915	medium.datadriveninvestor.com	_	_	
20-29	1915-1916	/	_	_	
20-30	1916-1982	introducing-fingpt-forecaster-the-future-of-robo-advisory-services	_	_	
20-30.1	1928-1934	fingpt	*	PROJECT	
20-31	1982-1983	-	_	_	
20-32	1983-1995	50add34e3d3c	_	_	
20-33	1995-1996	)	_	_	
20-34	1997-1998	&	_	_	
20-35	1999-2000	[	_	_	
20-36	2000-2005	Model	_	_	
20-37	2005-2006	]	_	_	
20-38	2006-2007	(	_	_	
20-39	2007-2012	https	_	_	
20-40	2012-2013	:	_	_	
20-41	2013-2014	/	_	_	
20-42	2014-2015	/	_	_	
20-43	2015-2029	huggingface.co	_	_	
20-44	2029-2030	/	_	_	
20-45	2030-2036	FinGPT	*[7]|*[8]	SOFTWARE[7]|PROJECT[8]	
20-46	2036-2037	/	*[7]	SOFTWARE[7]	
20-47	2037-2060	fingpt-forecaster_dow30	*[7]	SOFTWARE[7]	
20-48	2060-2061	_	*[7]	SOFTWARE[7]	
20-49	2061-2067	llama2	*[7]	SOFTWARE[7]	
20-50	2067-2068	-	*[7]	SOFTWARE[7]	
20-51	2068-2075	7b_lora	*[7]	SOFTWARE[7]	
20-52	2075-2076	)	_	_	
20-53	2077-2080	are	_	_	
20-54	2081-2090	available	_	_	
20-55	2091-2093	on	_	_	
20-56	2094-2105	Huggingface	_	_	
20-57	2105-2107	🤗	_	_	
20-58	2107-2108	!	_	_	

#Text=- [Paper Acceptance] Oct, 2023: ["FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets"](https://arxiv.org/abs/2310.04793) is accepted🎉 by [Instruction Workshop](https://an-instructive-workshop.github.io/) @ NeurIPS 2023 
#Text= - [Paper Acceptance] Oct, 2023: ["FinGPT: Democratizing Internet-scale Data for Financial Large Language Models"](https://arxiv.org/abs/2307.10485) is accepted🎉 by [Instruction Workshop](https://an-instructive-workshop.github.io/) @ NeurIPS 2023
#Text= - [Model Release] Oct, 2023: We release the [financial multi-task LLMs](https://huggingface.co/FinGPT) 🔥 produced when evaluating base-LLMs on [FinGPT-Benchmark](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark)
#Text= - [Paper Acceptance] Sep, 2023: ["Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models"](https://arxiv.org/abs/2310.04027) is accepted🎉 by [ACM International Conference on AI in Finance (ICAIF-23)](https://ai-finance.org/icaif-23-accepted-papers/)
#Text= - [Model Release] Aug, 2023: We release the [financial sentiment analysis model](https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora) 🔥
#Text= - [Paper Acceptance] Jul, 2023: ["Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models"](https://arxiv.org/abs/2306.12659) is accepted🎉 by [FinLLM 2023](https://finllm.github.io/workshop/#/fcb)@IJCAI 2023
#Text= - [Paper Acceptance] Jul, 2023: ["FinGPT: Open-Source Financial Large Language Models"](https://arxiv.org/abs/2306.06031) is accepted🎉 by [FinLLM 2023](https://finllm.github.io/workshop/#/fcb)@IJCAI 2023
#Text= - [Medium Blog] Jun 2023: [FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications](https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8)
#Text=
#Text=## Why FinGPT?
21-1	2110-2111	-	_	_	
21-2	2112-2113	[	_	_	
21-3	2113-2118	Paper	_	_	
21-4	2119-2129	Acceptance	_	_	
21-5	2129-2130	]	_	_	
21-6	2131-2134	Oct	_	_	
21-7	2134-2135	,	_	_	
21-8	2136-2140	2023	_	_	
21-9	2140-2141	:	_	_	
21-10	2142-2143	[	_	_	
21-11	2143-2144	"	_	_	
21-12	2144-2150	FinGPT	*[9]|*[10]	PUBLICATION[9]|PROJECT[10]	
21-13	2150-2151	:	*[9]	PUBLICATION[9]	
21-14	2152-2163	Instruction	*[9]	PUBLICATION[9]	
21-15	2164-2170	Tuning	*[9]	PUBLICATION[9]	
21-16	2171-2180	Benchmark	*[9]	PUBLICATION[9]	
21-17	2181-2184	for	*[9]	PUBLICATION[9]	
21-18	2185-2196	Open-Source	*[9]	PUBLICATION[9]	
21-19	2197-2202	Large	*[9]	PUBLICATION[9]	
21-20	2203-2211	Language	*[9]	PUBLICATION[9]	
21-21	2212-2218	Models	*[9]	PUBLICATION[9]	
21-22	2219-2221	in	*[9]	PUBLICATION[9]	
21-23	2222-2231	Financial	*[9]	PUBLICATION[9]	
21-24	2232-2240	Datasets	*[9]	PUBLICATION[9]	
21-25	2240-2241	"	_	_	
21-26	2241-2242	]	_	_	
21-27	2242-2243	(	_	_	
21-28	2243-2248	https	_	_	
21-29	2248-2249	:	_	_	
21-30	2249-2250	/	_	_	
21-31	2250-2251	/	_	_	
21-32	2251-2260	arxiv.org	_	_	
21-33	2260-2261	/	_	_	
21-34	2261-2264	abs	_	_	
21-35	2264-2265	/	_	_	
21-36	2265-2275	2310.04793	_	_	
21-37	2275-2276	)	_	_	
21-38	2277-2279	is	_	_	
21-39	2280-2288	accepted	_	_	
21-40	2288-2290	🎉	_	_	
21-41	2291-2293	by	_	_	
21-42	2294-2295	[	_	_	
21-43	2295-2306	Instruction	*[11]	WORKSHOP[11]	
21-44	2307-2315	Workshop	*[11]	WORKSHOP[11]	
21-45	2315-2316	]	_	_	
21-46	2316-2317	(	_	_	
21-47	2317-2322	https	_	_	
21-48	2322-2323	:	_	_	
21-49	2323-2324	/	_	_	
21-50	2324-2325	/	_	_	
21-51	2325-2358	an-instructive-workshop.github.io	_	_	
21-52	2358-2359	/	_	_	
21-53	2359-2360	)	_	_	
21-54	2361-2362	@	_	_	
21-55	2363-2370	NeurIPS	*[12]	CONFERENCE[12]	
21-56	2371-2375	2023	*[12]	CONFERENCE[12]	
21-57	2378-2379	-	_	_	
21-58	2380-2381	[	_	_	
21-59	2381-2386	Paper	_	_	
21-60	2387-2397	Acceptance	_	_	
21-61	2397-2398	]	_	_	
21-62	2399-2402	Oct	_	_	
21-63	2402-2403	,	_	_	
21-64	2404-2408	2023	_	_	
21-65	2408-2409	:	_	_	
21-66	2410-2411	[	_	_	
21-67	2411-2412	"	_	_	
21-68	2412-2418	FinGPT	*[13]	PUBLICATION[13]	
21-69	2418-2419	:	*[13]	PUBLICATION[13]	
21-70	2420-2433	Democratizing	*[13]	PUBLICATION[13]	
21-71	2434-2448	Internet-scale	*[13]	PUBLICATION[13]	
21-72	2449-2453	Data	*[13]	PUBLICATION[13]	
21-73	2454-2457	for	*[13]	PUBLICATION[13]	
21-74	2458-2467	Financial	*[13]	PUBLICATION[13]	
21-75	2468-2473	Large	*[13]	PUBLICATION[13]	
21-76	2474-2482	Language	*[13]	PUBLICATION[13]	
21-77	2483-2489	Models	*[13]	PUBLICATION[13]	
21-78	2489-2490	"	_	_	
21-79	2490-2491	]	_	_	
21-80	2491-2492	(	_	_	
21-81	2492-2497	https	_	_	
21-82	2497-2498	:	_	_	
21-83	2498-2499	/	_	_	
21-84	2499-2500	/	_	_	
21-85	2500-2509	arxiv.org	_	_	
21-86	2509-2510	/	_	_	
21-87	2510-2513	abs	_	_	
21-88	2513-2514	/	_	_	
21-89	2514-2524	2307.10485	_	_	
21-90	2524-2525	)	_	_	
21-91	2526-2528	is	_	_	
21-92	2529-2537	accepted	_	_	
21-93	2537-2539	🎉	_	_	
21-94	2540-2542	by	_	_	
21-95	2543-2544	[	_	_	
21-96	2544-2555	Instruction	*[14]	WORKSHOP[14]	
21-97	2556-2564	Workshop	*[14]	WORKSHOP[14]	
21-98	2564-2565	]	_	_	
21-99	2565-2566	(	_	_	
21-100	2566-2571	https	_	_	
21-101	2571-2572	:	_	_	
21-102	2572-2573	/	_	_	
21-103	2573-2574	/	_	_	
21-104	2574-2607	an-instructive-workshop.github.io	_	_	
21-105	2607-2608	/	_	_	
21-106	2608-2609	)	_	_	
21-107	2610-2611	@	_	_	
21-108	2612-2619	NeurIPS	*[15]	CONFERENCE[15]	
21-109	2620-2624	2023	*[15]	CONFERENCE[15]	
21-110	2626-2627	-	_	_	
21-111	2628-2629	[	_	_	
21-112	2629-2634	Model	_	_	
21-113	2635-2642	Release	_	_	
21-114	2642-2643	]	_	_	
21-115	2644-2647	Oct	_	_	
21-116	2647-2648	,	_	_	
21-117	2649-2653	2023	_	_	
21-118	2653-2654	:	_	_	
21-119	2655-2657	We	_	_	
21-120	2658-2665	release	_	_	
21-121	2666-2669	the	_	_	
21-122	2670-2671	[	_	_	
21-123	2671-2680	financial	_	_	
21-124	2681-2691	multi-task	_	_	
21-125	2692-2696	LLMs	_	_	
21-126	2696-2697	]	_	_	
21-127	2697-2698	(	_	_	
21-128	2698-2703	https	_	_	
21-129	2703-2704	:	_	_	
21-130	2704-2705	/	_	_	
21-131	2705-2706	/	_	_	
21-132	2706-2720	huggingface.co	_	_	
21-133	2720-2721	/	_	_	
21-134	2721-2727	FinGPT	*	PROJECT	
21-135	2727-2728	)	_	_	
21-136	2729-2731	🔥	_	_	
21-137	2732-2740	produced	_	_	
21-138	2741-2745	when	_	_	
21-139	2746-2756	evaluating	_	_	
21-140	2757-2766	base-LLMs	_	_	
21-141	2767-2769	on	_	_	
21-142	2770-2771	[	_	_	
21-143	2771-2787	FinGPT-Benchmark	_	_	
21-144	2787-2788	]	_	_	
21-145	2788-2789	(	_	_	
21-146	2789-2794	https	_	_	
21-147	2794-2795	:	_	_	
21-148	2795-2796	/	_	_	
21-149	2796-2797	/	_	_	
21-150	2797-2807	github.com	_	_	
21-151	2807-2808	/	_	_	
21-152	2808-2829	AI4Finance-Foundation	_	_	
21-153	2829-2830	/	_	_	
21-154	2830-2836	FinGPT	*	PROJECT	
21-155	2836-2837	/	_	_	
21-156	2837-2841	tree	_	_	
21-157	2841-2842	/	_	_	
21-158	2842-2848	master	_	_	
21-159	2848-2849	/	_	_	
21-160	2849-2855	fingpt	_	_	
21-161	2855-2856	/	_	_	
21-162	2856-2872	FinGPT_Benchmark	_	_	
21-163	2872-2873	)	_	_	
21-164	2875-2876	-	_	_	
21-165	2877-2878	[	_	_	
21-166	2878-2883	Paper	_	_	
21-167	2884-2894	Acceptance	_	_	
21-168	2894-2895	]	_	_	
21-169	2896-2899	Sep	_	_	
21-170	2899-2900	,	_	_	
21-171	2901-2905	2023	_	_	
21-172	2905-2906	:	_	_	
21-173	2907-2908	[	_	_	
21-174	2908-2909	"	_	_	
21-175	2909-2918	Enhancing	*[16]	PUBLICATION[16]	
21-176	2919-2928	Financial	*[16]	PUBLICATION[16]	
21-177	2929-2938	Sentiment	*[16]	PUBLICATION[16]	
21-178	2939-2947	Analysis	*[16]	PUBLICATION[16]	
21-179	2948-2951	via	*[16]	PUBLICATION[16]	
21-180	2952-2961	Retrieval	*[16]	PUBLICATION[16]	
21-181	2962-2971	Augmented	*[16]	PUBLICATION[16]	
21-182	2972-2977	Large	*[16]	PUBLICATION[16]	
21-183	2978-2986	Language	*[16]	PUBLICATION[16]	
21-184	2987-2993	Models	*[16]	PUBLICATION[16]	
21-185	2993-2994	"	_	_	
21-186	2994-2995	]	_	_	
21-187	2995-2996	(	_	_	
21-188	2996-3001	https	_	_	
21-189	3001-3002	:	_	_	
21-190	3002-3003	/	_	_	
21-191	3003-3004	/	_	_	
21-192	3004-3013	arxiv.org	_	_	
21-193	3013-3014	/	_	_	
21-194	3014-3017	abs	_	_	
21-195	3017-3018	/	_	_	
21-196	3018-3028	2310.04027	_	_	
21-197	3028-3029	)	_	_	
21-198	3030-3032	is	_	_	
21-199	3033-3041	accepted	_	_	
21-200	3041-3043	🎉	_	_	
21-201	3044-3046	by	_	_	
21-202	3047-3048	[	_	_	
21-203	3048-3051	ACM	*[17]	CONFERENCE[17]	
21-204	3052-3065	International	*[17]	CONFERENCE[17]	
21-205	3066-3076	Conference	*[17]	CONFERENCE[17]	
21-206	3077-3079	on	*[17]	CONFERENCE[17]	
21-207	3080-3082	AI	*[17]	CONFERENCE[17]	
21-208	3083-3085	in	*[17]	CONFERENCE[17]	
21-209	3086-3093	Finance	*[17]	CONFERENCE[17]	
21-210	3094-3095	(	_	_	
21-211	3095-3100	ICAIF	*[18]	CONFERENCE[18]	
21-212	3100-3101	-	*[18]	CONFERENCE[18]	
21-213	3101-3103	23	*[18]	CONFERENCE[18]	
21-214	3103-3104	)	_	_	
21-215	3104-3105	]	_	_	
21-216	3105-3106	(	_	_	
21-217	3106-3111	https	_	_	
21-218	3111-3112	:	_	_	
21-219	3112-3113	/	_	_	
21-220	3113-3114	/	_	_	
21-221	3114-3128	ai-finance.org	_	_	
21-222	3128-3129	/	_	_	
21-223	3129-3134	icaif	_	_	
21-224	3134-3135	-	_	_	
21-225	3135-3137	23	_	_	
21-226	3137-3138	-	_	_	
21-227	3138-3153	accepted-papers	_	_	
21-228	3153-3154	/	_	_	
21-229	3154-3155	)	_	_	
21-230	3157-3158	-	_	_	
21-231	3159-3160	[	_	_	
21-232	3160-3165	Model	_	_	
21-233	3166-3173	Release	_	_	
21-234	3173-3174	]	_	_	
21-235	3175-3178	Aug	_	_	
21-236	3178-3179	,	_	_	
21-237	3180-3184	2023	_	_	
21-238	3184-3185	:	_	_	
21-239	3186-3188	We	_	_	
21-240	3189-3196	release	_	_	
21-241	3197-3200	the	_	_	
21-242	3201-3202	[	_	_	
21-243	3202-3211	financial	_	_	
21-244	3212-3221	sentiment	_	_	
21-245	3222-3230	analysis	_	_	
21-246	3231-3236	model	_	_	
21-247	3236-3237	]	_	_	
21-248	3237-3238	(	_	_	
21-249	3238-3243	https	_	_	
21-250	3243-3244	:	_	_	
21-251	3244-3245	/	_	_	
21-252	3245-3246	/	_	_	
21-253	3246-3260	huggingface.co	_	_	
21-254	3260-3261	/	_	_	
21-255	3261-3267	FinGPT	_	_	
21-256	3267-3268	/	_	_	
21-257	3268-3291	fingpt-sentiment_llama2	_	_	
21-258	3291-3292	-	_	_	
21-259	3292-3300	13b_lora	_	_	
21-260	3300-3301	)	_	_	
21-261	3302-3304	🔥	_	_	
21-262	3306-3307	-	_	_	
21-263	3308-3309	[	_	_	
21-264	3309-3314	Paper	_	_	
21-265	3315-3325	Acceptance	_	_	
21-266	3325-3326	]	_	_	
21-267	3327-3330	Jul	_	_	
21-268	3330-3331	,	_	_	
21-269	3332-3336	2023	_	_	
21-270	3336-3337	:	_	_	
21-271	3338-3339	[	_	_	
21-272	3339-3340	"	_	_	
21-273	3340-3355	Instruct-FinGPT	*[19]	PUBLICATION[19]	
21-274	3355-3356	:	*[19]	PUBLICATION[19]	
21-275	3357-3366	Financial	*[19]	PUBLICATION[19]	
21-276	3367-3376	Sentiment	*[19]	PUBLICATION[19]	
21-277	3377-3385	Analysis	*[19]	PUBLICATION[19]	
21-278	3386-3388	by	*[19]	PUBLICATION[19]	
21-279	3389-3400	Instruction	*[19]	PUBLICATION[19]	
21-280	3401-3407	Tuning	*[19]	PUBLICATION[19]	
21-281	3408-3410	of	*[19]	PUBLICATION[19]	
21-282	3411-3426	General-Purpose	*[19]	PUBLICATION[19]	
21-283	3427-3432	Large	*[19]	PUBLICATION[19]	
21-284	3433-3441	Language	*[19]	PUBLICATION[19]	
21-285	3442-3448	Models	*[19]	PUBLICATION[19]	
21-286	3448-3449	"	_	_	
21-287	3449-3450	]	_	_	
21-288	3450-3451	(	_	_	
21-289	3451-3456	https	_	_	
21-290	3456-3457	:	_	_	
21-291	3457-3458	/	_	_	
21-292	3458-3459	/	_	_	
21-293	3459-3468	arxiv.org	_	_	
21-294	3468-3469	/	_	_	
21-295	3469-3472	abs	_	_	
21-296	3472-3473	/	_	_	
21-297	3473-3483	2306.12659	_	_	
21-298	3483-3484	)	_	_	
21-299	3485-3487	is	_	_	
21-300	3488-3496	accepted	_	_	
21-301	3496-3498	🎉	_	_	
21-302	3499-3501	by	_	_	
21-303	3502-3503	[	_	_	
21-304	3503-3509	FinLLM	*[20]	WORKSHOP[20]	
21-305	3510-3514	2023	*[20]	WORKSHOP[20]	
21-306	3514-3515	]	_	_	
21-307	3515-3516	(	_	_	
21-308	3516-3521	https	_	_	
21-309	3521-3522	:	_	_	
21-310	3522-3523	/	_	_	
21-311	3523-3524	/	_	_	
21-312	3524-3540	finllm.github.io	_	_	
21-313	3540-3541	/	_	_	
21-314	3541-3549	workshop	_	_	
21-315	3549-3550	/	_	_	
21-316	3550-3551	#	_	_	
21-317	3551-3552	/	_	_	
21-318	3552-3555	fcb	_	_	
21-319	3555-3556	)	_	_	
21-320	3556-3557	@	_	_	
21-321	3557-3562	IJCAI	*[21]	CONFERENCE[21]	
21-322	3563-3567	2023	*[21]	CONFERENCE[21]	
21-323	3569-3570	-	_	_	
21-324	3571-3572	[	_	_	
21-325	3572-3577	Paper	_	_	
21-326	3578-3588	Acceptance	_	_	
21-327	3588-3589	]	_	_	
21-328	3590-3593	Jul	_	_	
21-329	3593-3594	,	_	_	
21-330	3595-3599	2023	_	_	
21-331	3599-3600	:	_	_	
21-332	3601-3602	[	_	_	
21-333	3602-3603	"	_	_	
21-334	3603-3609	FinGPT	*[22]|*[23]	PUBLICATION[22]|PROJECT[23]	
21-335	3609-3610	:	*[22]	PUBLICATION[22]	
21-336	3611-3622	Open-Source	*[22]	PUBLICATION[22]	
21-337	3623-3632	Financial	*[22]	PUBLICATION[22]	
21-338	3633-3638	Large	*[22]	PUBLICATION[22]	
21-339	3639-3647	Language	*[22]	PUBLICATION[22]	
21-340	3648-3654	Models	*[22]	PUBLICATION[22]	
21-341	3654-3655	"	_	_	
21-342	3655-3656	]	_	_	
21-343	3656-3657	(	_	_	
21-344	3657-3662	https	_	_	
21-345	3662-3663	:	_	_	
21-346	3663-3664	/	_	_	
21-347	3664-3665	/	_	_	
21-348	3665-3674	arxiv.org	_	_	
21-349	3674-3675	/	_	_	
21-350	3675-3678	abs	_	_	
21-351	3678-3679	/	_	_	
21-352	3679-3689	2306.06031	_	_	
21-353	3689-3690	)	_	_	
21-354	3691-3693	is	_	_	
21-355	3694-3702	accepted	_	_	
21-356	3702-3704	🎉	_	_	
21-357	3705-3707	by	_	_	
21-358	3708-3709	[	_	_	
21-359	3709-3715	FinLLM	*[24]	WORKSHOP[24]	
21-360	3716-3720	2023	*[24]	WORKSHOP[24]	
21-361	3720-3721	]	_	_	
21-362	3721-3722	(	_	_	
21-363	3722-3727	https	_	_	
21-364	3727-3728	:	_	_	
21-365	3728-3729	/	_	_	
21-366	3729-3730	/	_	_	
21-367	3730-3746	finllm.github.io	_	_	
21-368	3746-3747	/	_	_	
21-369	3747-3755	workshop	_	_	
21-370	3755-3756	/	_	_	
21-371	3756-3757	#	_	_	
21-372	3757-3758	/	_	_	
21-373	3758-3761	fcb	_	_	
21-374	3761-3762	)	_	_	
21-375	3762-3763	@	_	_	
21-376	3763-3768	IJCAI	*[25]	CONFERENCE[25]	
21-377	3769-3773	2023	*[25]	CONFERENCE[25]	
21-378	3775-3776	-	_	_	
21-379	3777-3778	[	_	_	
21-380	3778-3784	Medium	_	_	
21-381	3785-3789	Blog	_	_	
21-382	3789-3790	]	_	_	
21-383	3791-3794	Jun	_	_	
21-384	3795-3799	2023	_	_	
21-385	3799-3800	:	_	_	
21-386	3801-3802	[	_	_	
21-387	3802-3808	FinGPT	*	PROJECT	
21-388	3808-3809	:	_	_	
21-389	3810-3818	Powering	_	_	
21-390	3819-3822	the	_	_	
21-391	3823-3829	Future	_	_	
21-392	3830-3832	of	_	_	
21-393	3833-3840	Finance	_	_	
21-394	3841-3845	with	_	_	
21-395	3846-3848	20	_	_	
21-396	3849-3861	Cutting-Edge	_	_	
21-397	3862-3874	Applications	_	_	
21-398	3874-3875	]	_	_	
21-399	3875-3876	(	_	_	
21-400	3876-3881	https	_	_	
21-401	3881-3882	:	_	_	
21-402	3882-3883	/	_	_	
21-403	3883-3884	/	_	_	
21-404	3884-3913	medium.datadriveninvestor.com	_	_	
21-405	3913-3914	/	_	_	
21-406	3914-3956	fingpt-powering-the-future-of-finance-with	_	_	
21-406.1	3914-3920	fingpt	*	PROJECT	
21-407	3956-3957	-	_	_	
21-408	3957-3959	20	_	_	
21-409	3959-3960	-	_	_	
21-410	3960-3985	cutting-edge-applications	_	_	
21-411	3985-3986	-	_	_	
21-412	3986-3998	7c4d082ad3d8	_	_	
21-413	3998-3999	)	_	_	
21-414	4001-4002	#	_	_	
21-415	4002-4003	#	_	_	
21-416	4004-4007	Why	_	_	
21-417	4008-4014	FinGPT	*	PROJECT	
21-418	4014-4015	?	_	_	

#Text=1).
22-1	4017-4018	1	_	_	
22-2	4018-4019	)	_	_	
22-3	4019-4020	.	_	_	

#Text=Finance is highly dynamic.
23-1	4021-4028	Finance	_	_	
23-2	4029-4031	is	_	_	
23-3	4032-4038	highly	_	_	
23-4	4039-4046	dynamic	_	_	
23-5	4046-4047	.	_	_	

#Text=[BloombergGPT](https://arxiv.org/abs/2303.17564) trained an LLM using a mixture of finance data and general-purpose data, which took about 53 days, at a cost of around **$3M**).
24-1	4048-4049	[	_	_	
24-2	4049-4061	BloombergGPT	*	SOFTWARE	
24-3	4061-4062	]	_	_	
24-4	4062-4063	(	_	_	
24-5	4063-4068	https	_	_	
24-6	4068-4069	:	_	_	
24-7	4069-4070	/	_	_	
24-8	4070-4071	/	_	_	
24-9	4071-4080	arxiv.org	_	_	
24-10	4080-4081	/	_	_	
24-11	4081-4084	abs	_	_	
24-12	4084-4085	/	_	_	
24-13	4085-4095	2303.17564	_	_	
24-14	4095-4096	)	_	_	
24-15	4097-4104	trained	_	_	
24-16	4105-4107	an	_	_	
24-17	4108-4111	LLM	_	_	
24-18	4112-4117	using	_	_	
24-19	4118-4119	a	_	_	
24-20	4120-4127	mixture	_	_	
24-21	4128-4130	of	_	_	
24-22	4131-4138	finance	_	_	
24-23	4139-4143	data	_	_	
24-24	4144-4147	and	_	_	
24-25	4148-4163	general-purpose	_	_	
24-26	4164-4168	data	_	_	
24-27	4168-4169	,	_	_	
24-28	4170-4175	which	_	_	
24-29	4176-4180	took	_	_	
24-30	4181-4186	about	_	_	
24-31	4187-4189	53	_	_	
24-32	4190-4194	days	_	_	
24-33	4194-4195	,	_	_	
24-34	4196-4198	at	_	_	
24-35	4199-4200	a	_	_	
24-36	4201-4205	cost	_	_	
24-37	4206-4208	of	_	_	
24-38	4209-4215	around	_	_	
24-39	4216-4217	*	_	_	
24-40	4217-4218	*	_	_	
24-41	4218-4221	$3M	_	_	
24-42	4221-4222	*	_	_	
24-43	4222-4223	*	_	_	
24-44	4223-4224	)	_	_	
24-45	4224-4225	.	_	_	

#Text=It is costly to retrain an LLM model like BloombergGPT every month or every week, thus lightweight adaptation is highly favorable.
25-1	4226-4228	It	_	_	
25-2	4229-4231	is	_	_	
25-3	4232-4238	costly	_	_	
25-4	4239-4241	to	_	_	
25-5	4242-4249	retrain	_	_	
25-6	4250-4252	an	_	_	
25-7	4253-4256	LLM	_	_	
25-8	4257-4262	model	_	_	
25-9	4263-4267	like	_	_	
25-10	4268-4280	BloombergGPT	*	SOFTWARE	
25-11	4281-4286	every	_	_	
25-12	4287-4292	month	_	_	
25-13	4293-4295	or	_	_	
25-14	4296-4301	every	_	_	
25-15	4302-4306	week	_	_	
25-16	4306-4307	,	_	_	
25-17	4308-4312	thus	_	_	
25-18	4313-4324	lightweight	_	_	
25-19	4325-4335	adaptation	_	_	
25-20	4336-4338	is	_	_	
25-21	4339-4345	highly	_	_	
25-22	4346-4355	favorable	_	_	
25-23	4355-4356	.	_	_	

#Text=FinGPT can be fine-tuned swiftly to incorporate new data (the cost falls significantly, less than **$300 per fine-tuning**).
#Text=
#Text=2).
26-1	4357-4363	FinGPT	_	_	
26-2	4364-4367	can	_	_	
26-3	4368-4370	be	_	_	
26-4	4371-4381	fine-tuned	_	_	
26-5	4382-4389	swiftly	_	_	
26-6	4390-4392	to	_	_	
26-7	4393-4404	incorporate	_	_	
26-8	4405-4408	new	_	_	
26-9	4409-4413	data	_	_	
26-10	4414-4415	(	_	_	
26-11	4415-4418	the	_	_	
26-12	4419-4423	cost	_	_	
26-13	4424-4429	falls	_	_	
26-14	4430-4443	significantly	_	_	
26-15	4443-4444	,	_	_	
26-16	4445-4449	less	_	_	
26-17	4450-4454	than	_	_	
26-18	4455-4456	*	_	_	
26-19	4456-4457	*	_	_	
26-20	4457-4461	$300	_	_	
26-21	4462-4465	per	_	_	
26-22	4466-4477	fine-tuning	_	_	
26-23	4477-4478	*	_	_	
26-24	4478-4479	*	_	_	
26-25	4479-4480	)	_	_	
26-26	4480-4481	.	_	_	
26-27	4483-4484	2	_	_	
26-28	4484-4485	)	_	_	
26-29	4485-4486	.	_	_	

#Text=Democratizing Internet-scale financial data is critical, say allowing timely updates of the model (monthly or weekly updates) using an automatic data curation pipeline.
27-1	4487-4500	Democratizing	_	_	
27-2	4501-4515	Internet-scale	_	_	
27-3	4516-4525	financial	_	_	
27-4	4526-4530	data	_	_	
27-5	4531-4533	is	_	_	
27-6	4534-4542	critical	_	_	
27-7	4542-4543	,	_	_	
27-8	4544-4547	say	_	_	
27-9	4548-4556	allowing	_	_	
27-10	4557-4563	timely	_	_	
27-11	4564-4571	updates	_	_	
27-12	4572-4574	of	_	_	
27-13	4575-4578	the	_	_	
27-14	4579-4584	model	_	_	
27-15	4585-4586	(	_	_	
27-16	4586-4593	monthly	_	_	
27-17	4594-4596	or	_	_	
27-18	4597-4603	weekly	_	_	
27-19	4604-4611	updates	_	_	
27-20	4611-4612	)	_	_	
27-21	4613-4618	using	_	_	
27-22	4619-4621	an	_	_	
27-23	4622-4631	automatic	_	_	
27-24	4632-4636	data	_	_	
27-25	4637-4645	curation	_	_	
27-26	4646-4654	pipeline	_	_	
27-27	4654-4655	.	_	_	

#Text=BloombergGPT has privileged data access and APIs, while FinGPT presents a more accessible alternative.
28-1	4657-4669	BloombergGPT	_	_	
28-2	4670-4673	has	_	_	
28-3	4674-4684	privileged	_	_	
28-4	4685-4689	data	_	_	
28-5	4690-4696	access	_	_	
28-6	4697-4700	and	_	_	
28-7	4701-4705	APIs	_	_	
28-8	4705-4706	,	_	_	
28-9	4707-4712	while	_	_	
28-10	4713-4719	FinGPT	*	PROJECT	
28-11	4720-4728	presents	_	_	
28-12	4729-4730	a	_	_	
28-13	4731-4735	more	_	_	
28-14	4736-4746	accessible	_	_	
28-15	4747-4758	alternative	_	_	
28-16	4758-4759	.	_	_	

#Text=It prioritizes lightweight adaptation, leveraging the best available open-source LLMs.
#Text=
#Text=3).
29-1	4760-4762	It	_	_	
29-2	4763-4774	prioritizes	_	_	
29-3	4775-4786	lightweight	_	_	
29-4	4787-4797	adaptation	_	_	
29-5	4797-4798	,	_	_	
29-6	4799-4809	leveraging	_	_	
29-7	4810-4813	the	_	_	
29-8	4814-4818	best	_	_	
29-9	4819-4828	available	_	_	
29-10	4829-4840	open-source	_	_	
29-11	4841-4845	LLMs	_	_	
29-12	4845-4846	.	_	_	
29-13	4848-4849	3	_	_	
29-14	4849-4850	)	_	_	
29-15	4850-4851	.	_	_	

#Text=The key technology is "RLHF (Reinforcement learning from human feedback)", which is missing in BloombergGPT.
30-1	4852-4855	The	_	_	
30-2	4856-4859	key	_	_	
30-3	4860-4870	technology	_	_	
30-4	4871-4873	is	_	_	
30-5	4874-4875	"	_	_	
30-6	4875-4879	RLHF	_	_	
30-7	4880-4881	(	_	_	
30-8	4881-4894	Reinforcement	_	_	
30-9	4895-4903	learning	_	_	
30-10	4904-4908	from	_	_	
30-11	4909-4914	human	_	_	
30-12	4915-4923	feedback	_	_	
30-13	4923-4924	)	_	_	
30-14	4924-4925	"	_	_	
30-15	4925-4926	,	_	_	
30-16	4927-4932	which	_	_	
30-17	4933-4935	is	_	_	
30-18	4936-4943	missing	_	_	
30-19	4944-4946	in	_	_	
30-20	4947-4959	BloombergGPT	*	SOFTWARE	
30-21	4959-4960	.	_	_	

#Text=RLHF enables an LLM model to learn individual preferences (risk-aversion level, investing habits, personalized robo-advisor, etc.), which is the "secret" ingredient of ChatGPT and GPT4.
#Text=
#Text=
#Text=### Milestone of AI Robo-Advisor: FinGPT-Forecaster
#Text=
#Text=Try the latest released FinGPT-Forecaster demo at our [HuggingFace Space](https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster)
#Text=
#Text=The dataset for FinGPT-Forecaster: https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405
#Text=
#Text=!
31-1	4961-4965	RLHF	_	_	
31-2	4966-4973	enables	_	_	
31-3	4974-4976	an	_	_	
31-4	4977-4980	LLM	_	_	
31-5	4981-4986	model	_	_	
31-6	4987-4989	to	_	_	
31-7	4990-4995	learn	_	_	
31-8	4996-5006	individual	_	_	
31-9	5007-5018	preferences	_	_	
31-10	5019-5020	(	_	_	
31-11	5020-5033	risk-aversion	_	_	
31-12	5034-5039	level	_	_	
31-13	5039-5040	,	_	_	
31-14	5041-5050	investing	_	_	
31-15	5051-5057	habits	_	_	
31-16	5057-5058	,	_	_	
31-17	5059-5071	personalized	_	_	
31-18	5072-5084	robo-advisor	_	_	
31-19	5084-5085	,	_	_	
31-20	5086-5089	etc	_	_	
31-21	5089-5090	.	_	_	
31-22	5090-5091	)	_	_	
31-23	5091-5092	,	_	_	
31-24	5093-5098	which	_	_	
31-25	5099-5101	is	_	_	
31-26	5102-5105	the	_	_	
31-27	5106-5107	"	_	_	
31-28	5107-5113	secret	_	_	
31-29	5113-5114	"	_	_	
31-30	5115-5125	ingredient	_	_	
31-31	5126-5128	of	_	_	
31-32	5129-5136	ChatGPT	*	SOFTWARE	
31-33	5137-5140	and	_	_	
31-34	5141-5145	GPT4	*	SOFTWARE	
31-35	5145-5146	.	_	_	
31-36	5149-5150	#	_	_	
31-37	5150-5151	#	_	_	
31-38	5151-5152	#	_	_	
31-39	5153-5162	Milestone	_	_	
31-40	5163-5165	of	_	_	
31-41	5166-5168	AI	_	_	
31-42	5169-5181	Robo-Advisor	_	_	
31-43	5181-5182	:	_	_	
31-44	5183-5200	FinGPT-Forecaster	*	SOFTWARE	
31-45	5202-5205	Try	_	_	
31-46	5206-5209	the	_	_	
31-47	5210-5216	latest	_	_	
31-48	5217-5225	released	_	_	
31-49	5226-5243	FinGPT-Forecaster	*	SOFTWARE	
31-50	5244-5248	demo	_	_	
31-51	5249-5251	at	_	_	
31-52	5252-5255	our	_	_	
31-53	5256-5257	[	_	_	
31-54	5257-5268	HuggingFace	_	_	
31-55	5269-5274	Space	_	_	
31-56	5274-5275	]	_	_	
31-57	5275-5276	(	_	_	
31-58	5276-5281	https	_	_	
31-59	5281-5282	:	_	_	
31-60	5282-5283	/	_	_	
31-61	5283-5284	/	_	_	
31-62	5284-5298	huggingface.co	_	_	
31-63	5298-5299	/	_	_	
31-64	5299-5305	spaces	_	_	
31-65	5305-5306	/	_	_	
31-66	5306-5312	FinGPT	*[26]	SOFTWARE[26]	
31-67	5312-5313	/	*[26]	SOFTWARE[26]	
31-68	5313-5330	FinGPT-Forecaster	*[26]	SOFTWARE[26]	
31-69	5330-5331	)	_	_	
31-70	5333-5336	The	_	_	
31-71	5337-5344	dataset	_	_	
31-72	5345-5348	for	_	_	
31-73	5349-5366	FinGPT-Forecaster	*	SOFTWARE	
31-74	5366-5367	:	_	_	
31-75	5368-5373	https	_	_	
31-76	5373-5374	:	_	_	
31-77	5374-5375	/	_	_	
31-78	5375-5376	/	_	_	
31-79	5376-5390	huggingface.co	_	_	
31-80	5390-5391	/	_	_	
31-81	5391-5399	datasets	_	_	
31-82	5399-5400	/	_	_	
31-83	5400-5406	FinGPT	*[27]	DATASET[27]	
31-84	5406-5407	/	*[27]	DATASET[27]	
31-85	5407-5430	fingpt-forecaster-dow30	*[27]	DATASET[27]	
31-86	5430-5431	-	*[27]	DATASET[27]	
31-87	5431-5437	202305	*[27]	DATASET[27]	
31-88	5437-5438	-	*[27]	DATASET[27]	
31-89	5438-5444	202405	*[27]	DATASET[27]	
31-90	5446-5447	!	_	_	

#Text=[demo_interface](fingpt/FinGPT_Forecaster/figs/interface.png)
#Text=
#Text=Enter the following inputs:
#Text=
#Text=1) ticker symbol (e.g.
32-1	5447-5448	[	_	_	
32-2	5448-5462	demo_interface	_	_	
32-3	5462-5463	]	_	_	
32-4	5463-5464	(	_	_	
32-5	5464-5470	fingpt	_	_	
32-6	5470-5471	/	_	_	
32-7	5471-5488	FinGPT_Forecaster	_	_	
32-8	5488-5489	/	_	_	
32-9	5489-5493	figs	_	_	
32-10	5493-5494	/	_	_	
32-11	5494-5507	interface.png	_	_	
32-12	5507-5508	)	_	_	
32-13	5510-5515	Enter	_	_	
32-14	5516-5519	the	_	_	
32-15	5520-5529	following	_	_	
32-16	5530-5536	inputs	_	_	
32-17	5536-5537	:	_	_	
32-18	5539-5540	1	_	_	
32-19	5540-5541	)	_	_	
32-20	5542-5548	ticker	_	_	
32-21	5549-5555	symbol	_	_	
32-22	5556-5557	(	_	_	
32-23	5557-5560	e.g	_	_	
32-24	5560-5561	.	_	_	

#Text=AAPL, MSFT, NVDA)
#Text=2) the day from which you want the prediction to happen (yyyy-mm-dd)
#Text=3) the number of past weeks where market news are retrieved
#Text=4) whether to add the latest basic financials as additional information
#Text=
#Text=Click Submit！
33-1	5562-5566	AAPL	_	_	
33-2	5566-5567	,	_	_	
33-3	5568-5572	MSFT	_	_	
33-4	5572-5573	,	_	_	
33-5	5574-5578	NVDA	_	_	
33-6	5578-5579	)	_	_	
33-7	5580-5581	2	_	_	
33-8	5581-5582	)	_	_	
33-9	5583-5586	the	_	_	
33-10	5587-5590	day	_	_	
33-11	5591-5595	from	_	_	
33-12	5596-5601	which	_	_	
33-13	5602-5605	you	_	_	
33-14	5606-5610	want	_	_	
33-15	5611-5614	the	_	_	
33-16	5615-5625	prediction	_	_	
33-17	5626-5628	to	_	_	
33-18	5629-5635	happen	_	_	
33-19	5636-5637	(	_	_	
33-20	5637-5647	yyyy-mm-dd	_	_	
33-21	5647-5648	)	_	_	
33-22	5649-5650	3	_	_	
33-23	5650-5651	)	_	_	
33-24	5652-5655	the	_	_	
33-25	5656-5662	number	_	_	
33-26	5663-5665	of	_	_	
33-27	5666-5670	past	_	_	
33-28	5671-5676	weeks	_	_	
33-29	5677-5682	where	_	_	
33-30	5683-5689	market	_	_	
33-31	5690-5694	news	_	_	
33-32	5695-5698	are	_	_	
33-33	5699-5708	retrieved	_	_	
33-34	5709-5710	4	_	_	
33-35	5710-5711	)	_	_	
33-36	5712-5719	whether	_	_	
33-37	5720-5722	to	_	_	
33-38	5723-5726	add	_	_	
33-39	5727-5730	the	_	_	
33-40	5731-5737	latest	_	_	
33-41	5738-5743	basic	_	_	
33-42	5744-5754	financials	_	_	
33-43	5755-5757	as	_	_	
33-44	5758-5768	additional	_	_	
33-45	5769-5780	information	_	_	
33-46	5782-5787	Click	_	_	
33-47	5788-5794	Submit	_	_	
33-48	5794-5795	！	_	_	

#Text=And you'll be responded with a well-rounded analysis of the company and a prediction for next week's stock price movement!
34-1	5796-5799	And	_	_	
34-2	5800-5806	you'll	_	_	
34-3	5807-5809	be	_	_	
34-4	5810-5819	responded	_	_	
34-5	5820-5824	with	_	_	
34-6	5825-5826	a	_	_	
34-7	5827-5839	well-rounded	_	_	
34-8	5840-5848	analysis	_	_	
34-9	5849-5851	of	_	_	
34-10	5852-5855	the	_	_	
34-11	5856-5863	company	_	_	
34-12	5864-5867	and	_	_	
34-13	5868-5869	a	_	_	
34-14	5870-5880	prediction	_	_	
34-15	5881-5884	for	_	_	
34-16	5885-5889	next	_	_	
34-17	5890-5896	week's	_	_	
34-18	5897-5902	stock	_	_	
34-19	5903-5908	price	_	_	
34-20	5909-5917	movement	_	_	
34-21	5917-5918	!	_	_	

#Text=For detailed and more customized implementation, please refer to [FinGPT-Forecaster](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster)
#Text=
#Text=
#Text=## FinGPT Demos: 
#Text=
#Text=### Current State-of-the-arts for Financial Sentiment Analysis
#Text=
#Text=* [FinGPT V3 (Updated on 10/12/2023)](.
35-1	5920-5923	For	_	_	
35-2	5924-5932	detailed	_	_	
35-3	5933-5936	and	_	_	
35-4	5937-5941	more	_	_	
35-5	5942-5952	customized	_	_	
35-6	5953-5967	implementation	_	_	
35-7	5967-5968	,	_	_	
35-8	5969-5975	please	_	_	
35-9	5976-5981	refer	_	_	
35-10	5982-5984	to	_	_	
35-11	5985-5986	[	_	_	
35-12	5986-6003	FinGPT-Forecaster	_	_	
35-13	6003-6004	]	_	_	
35-14	6004-6005	(	_	_	
35-15	6005-6010	https	_	_	
35-16	6010-6011	:	_	_	
35-17	6011-6012	/	_	_	
35-18	6012-6013	/	_	_	
35-19	6013-6023	github.com	_	_	
35-20	6023-6024	/	_	_	
35-21	6024-6045	AI4Finance-Foundation	_	_	
35-22	6045-6046	/	_	_	
35-23	6046-6052	FinGPT	*	PROJECT	
35-24	6052-6053	/	_	_	
35-25	6053-6057	tree	_	_	
35-26	6057-6058	/	_	_	
35-27	6058-6064	master	_	_	
35-28	6064-6065	/	_	_	
35-29	6065-6071	fingpt	_	_	
35-30	6071-6072	/	_	_	
35-31	6072-6089	FinGPT_Forecaster	_	_	
35-32	6089-6090	)	_	_	
35-33	6093-6094	#	_	_	
35-34	6094-6095	#	_	_	
35-35	6096-6102	FinGPT	_	_	
35-36	6103-6108	Demos	_	_	
35-37	6108-6109	:	_	_	
35-38	6112-6113	#	_	_	
35-39	6113-6114	#	_	_	
35-40	6114-6115	#	_	_	
35-41	6116-6123	Current	_	_	
35-42	6124-6141	State-of-the-arts	_	_	
35-43	6142-6145	for	_	_	
35-44	6146-6155	Financial	_	_	
35-45	6156-6165	Sentiment	_	_	
35-46	6166-6174	Analysis	_	_	
35-47	6176-6177	*	_	_	
35-48	6178-6179	[	_	_	
35-49	6179-6185	FinGPT	_	_	
35-50	6186-6188	V3	_	_	
35-51	6189-6190	(	_	_	
35-52	6190-6197	Updated	_	_	
35-53	6198-6200	on	_	_	
35-54	6201-6203	10	_	_	
35-55	6203-6204	/	_	_	
35-56	6204-6206	12	_	_	
35-57	6206-6207	/	_	_	
35-58	6207-6211	2023	_	_	
35-59	6211-6212	)	_	_	
35-60	6212-6213	]	_	_	
35-61	6213-6214	(	_	_	
35-62	6214-6215	.	_	_	

#Text=/fingpt)
#Text=  
#Text=  * What's new: **Best trainable and inferable FinGPT for sentiment analysis on a single RTX 3090, which is even better than GPT-4 and ChatGPT Finetuning.**
#Text=  
#Text=  * [FinGPT v3](https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora) series are LLMs finetuned with the LoRA method on the News and Tweets sentiment analysis dataset which achieve the best scores on most of the financial sentiment analysis datasets with low cost
36-1	6215-6216	/	_	_	
36-2	6216-6222	fingpt	_	_	
36-3	6222-6223	)	_	_	
36-4	6229-6230	*	_	_	
36-5	6231-6237	What's	_	_	
36-6	6238-6241	new	_	_	
36-7	6241-6242	:	_	_	
36-8	6243-6244	*	_	_	
36-9	6244-6245	*	_	_	
36-10	6245-6249	Best	_	_	
36-11	6250-6259	trainable	_	_	
36-12	6260-6263	and	_	_	
36-13	6264-6273	inferable	_	_	
36-14	6274-6280	FinGPT	*	SOFTWARE	
36-15	6281-6284	for	_	_	
36-16	6285-6294	sentiment	_	_	
36-17	6295-6303	analysis	_	_	
36-18	6304-6306	on	_	_	
36-19	6307-6308	a	_	_	
36-20	6309-6315	single	_	_	
36-21	6316-6319	RTX	_	_	
36-22	6320-6324	3090	_	_	
36-23	6324-6325	,	_	_	
36-24	6326-6331	which	_	_	
36-25	6332-6334	is	_	_	
36-26	6335-6339	even	_	_	
36-27	6340-6346	better	_	_	
36-28	6347-6351	than	_	_	
36-29	6352-6355	GPT	*[28]	SOFTWARE[28]	
36-30	6355-6356	-	*[28]	SOFTWARE[28]	
36-31	6356-6357	4	*[28]	SOFTWARE[28]	
36-32	6358-6361	and	_	_	
36-33	6362-6369	ChatGPT	*	SOFTWARE	
36-34	6370-6380	Finetuning	_	_	
36-35	6380-6381	.	_	_	
36-36	6381-6382	*	_	_	
36-37	6382-6383	*	_	_	
36-38	6389-6390	*	_	_	
36-39	6391-6392	[	_	_	
36-40	6392-6398	FinGPT	*[29]	SOFTWARE[29]	
36-41	6399-6401	v3	*[29]	SOFTWARE[29]	
36-42	6401-6402	]	_	_	
36-43	6402-6403	(	_	_	
36-44	6403-6408	https	_	_	
36-45	6408-6409	:	_	_	
36-46	6409-6410	/	_	_	
36-47	6410-6411	/	_	_	
36-48	6411-6425	huggingface.co	_	_	
36-49	6425-6426	/	_	_	
36-50	6426-6432	FinGPT	*[30]	SOFTWARE[30]	
36-51	6432-6433	/	*[30]	SOFTWARE[30]	
36-52	6433-6456	fingpt-sentiment_llama2	*[30]	SOFTWARE[30]	
36-53	6456-6457	-	*[30]	SOFTWARE[30]	
36-54	6457-6465	13b_lora	*[30]	SOFTWARE[30]	
36-55	6465-6466	)	_	_	
36-56	6467-6473	series	_	_	
36-57	6474-6477	are	_	_	
36-58	6478-6482	LLMs	_	_	
36-59	6483-6492	finetuned	_	_	
36-60	6493-6497	with	_	_	
36-61	6498-6501	the	_	_	
36-62	6502-6506	LoRA	_	_	
36-63	6507-6513	method	_	_	
36-64	6514-6516	on	_	_	
36-65	6517-6520	the	_	_	
36-66	6521-6525	News	_	_	
36-67	6526-6529	and	_	_	
36-68	6530-6536	Tweets	_	_	
36-69	6537-6546	sentiment	_	_	
36-70	6547-6555	analysis	_	_	
36-71	6556-6563	dataset	_	_	
36-72	6564-6569	which	_	_	
36-73	6570-6577	achieve	_	_	
36-74	6578-6581	the	_	_	
36-75	6582-6586	best	_	_	
36-76	6587-6593	scores	_	_	
36-77	6594-6596	on	_	_	
36-78	6597-6601	most	_	_	
36-79	6602-6604	of	_	_	
36-80	6605-6608	the	_	_	
36-81	6609-6618	financial	_	_	
36-82	6619-6628	sentiment	_	_	
36-83	6629-6637	analysis	_	_	
36-84	6638-6646	datasets	_	_	
36-85	6647-6651	with	_	_	
36-86	6652-6655	low	_	_	
36-87	6656-6660	cost	_	_	

#Text=.
37-1	6660-6661	.	_	_	

#Text=* FinGPT v3.3 use llama2-13b as base model; FinGPT v3.2 uses llama2-7b as base model; FinGPT v3.1 uses chatglm2-6B as base model
38-1	6667-6668	*	_	_	
38-2	6669-6675	FinGPT	*[31]	SOFTWARE[31]	
38-3	6676-6680	v3.3	*[31]	SOFTWARE[31]	
38-4	6681-6684	use	_	_	
38-5	6685-6691	llama2	*[32]	SOFTWARE[32]	
38-6	6691-6692	-	*[32]	SOFTWARE[32]	
38-7	6692-6695	13b	*[32]	SOFTWARE[32]	
38-8	6696-6698	as	_	_	
38-9	6699-6703	base	_	_	
38-10	6704-6709	model	_	_	
38-11	6709-6710	;	_	_	
38-12	6711-6717	FinGPT	*[33]	SOFTWARE[33]	
38-13	6718-6722	v3.2	*[33]	SOFTWARE[33]	
38-14	6723-6727	uses	_	_	
38-15	6728-6734	llama2	*[34]	SOFTWARE[34]	
38-16	6734-6735	-	*[34]	SOFTWARE[34]	
38-17	6735-6737	7b	*[34]	SOFTWARE[34]	
38-18	6738-6740	as	_	_	
38-19	6741-6745	base	_	_	
38-20	6746-6751	model	_	_	
38-21	6751-6752	;	_	_	
38-22	6753-6759	FinGPT	*[35]	SOFTWARE[35]	
38-23	6760-6764	v3.1	*[35]	SOFTWARE[35]	
38-24	6765-6769	uses	_	_	
38-25	6770-6778	chatglm2	*[36]	SOFTWARE[36]	
38-26	6778-6779	-	*[36]	SOFTWARE[36]	
38-27	6779-6781	6B	*[36]	SOFTWARE[36]	
38-28	6782-6784	as	_	_	
38-29	6785-6789	base	_	_	
38-30	6790-6795	model	_	_	

#Text=.
39-1	6795-6796	.	_	_	

#Text=* Benchmark Results:
#Text=  
#Text=  * | Weighted F1                                                  |    FPB    |  FiQA-SA  |   TFNS    |   NWGI    |      Devices       |    Time     |      Cost      |
#Text=    | ------------------------------------------------------------ | :-------: | :-------: | :-------: | :-------: | :----------------: | :---------: | :------------: |
#Text=    | [FinGPT v3.3](https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora)| **0.882** |   0.874   | **0.903** | **0.643** |    1 × RTX 3090    | 17.25 hours |     $17.25     |
#Text=    | FinGPT v3.2|   0.850   |   0.860   |   0.894   |   0.636   |      1 × A100      |  5.5 hours  |    $ 22.55     |
#Text=    | FinGPT v3.1|   0.855   |   0.850   |   0.875   |   0.642   |      1 × A100      |  5.5 hours  |    $ 22.55     |
#Text=    | FinGPT (8bit)                                                |   0.855   |   0.847   |   0.879   |   0.632   |    1 × RTX 3090    | 6.47 hours  |     $ 6.47     |
#Text=    | FinGPT (QLoRA)                                               |   0.777   |   0.752   |   0.828   |   0.583   |    1 × RTX 3090    | 4.15 hours  |     $ 4.15     |
#Text=    | OpenAI Fine-tune                                             |   0.878   | **0.887** |   0.883   |     -     |         -          |      -      |       -        |
#Text=    | GPT-4                                                        |   0.833   |   0.630   |   0.808   |     -     |         -          |      -      |       -        |
#Text=    | FinBERT                                                      |   0.880   |   0.596   |   0.733   |   0.538   | 4 × NVIDIA K80 GPU |      -      |       -        |
#Text=    | Llama2-7B                                                    |   0.390   |   0.800   |   0.296   |   0.503   |    2048 × A100     |   21 days   | $ 4.23 million |
#Text=    | BloombergGPT                                                 |   0.511   |   0.751   |     -     |     -     |     512 × A100     |   53 days   | $ 2.67 million |
#Text=  
#Text=    **Cost per GPU hour.** For **A100 GPUs**, the AWS p4d.24xlarge instance, equipped with 8 A100 GPUs is used as a benchmark to estimate the costs.
40-1	6802-6803	*	_	_	
40-2	6804-6813	Benchmark	_	_	
40-3	6814-6821	Results	_	_	
40-4	6821-6822	:	_	_	
40-5	6828-6829	*	_	_	
40-6	6830-6831	|	_	_	
40-7	6832-6840	Weighted	*[37]	EVALMETRIC[37]	
40-8	6841-6843	F1	*[37]	EVALMETRIC[37]	
40-9	6893-6894	|	_	_	
40-10	6898-6901	FPB	_	_	
40-11	6905-6906	|	_	_	
40-12	6908-6915	FiQA-SA	_	_	
40-13	6917-6918	|	_	_	
40-14	6921-6925	TFNS	*	DATASET	
40-15	6929-6930	|	_	_	
40-16	6933-6937	NWGI	*	DATASET	
40-17	6941-6942	|	_	_	
40-18	6948-6955	Devices	_	_	
40-19	6962-6963	|	_	_	
40-20	6967-6971	Time	_	_	
40-21	6976-6977	|	_	_	
40-22	6983-6987	Cost	_	_	
40-23	6993-6994	|	_	_	
40-24	6999-7000	|	_	_	
40-25	7001-7002	-	_	_	
40-26	7002-7003	-	_	_	
40-27	7003-7004	-	_	_	
40-28	7004-7005	-	_	_	
40-29	7005-7006	-	_	_	
40-30	7006-7007	-	_	_	
40-31	7007-7008	-	_	_	
40-32	7008-7009	-	_	_	
40-33	7009-7010	-	_	_	
40-34	7010-7011	-	_	_	
40-35	7011-7012	-	_	_	
40-36	7012-7013	-	_	_	
40-37	7013-7014	-	_	_	
40-38	7014-7015	-	_	_	
40-39	7015-7016	-	_	_	
40-40	7016-7017	-	_	_	
40-41	7017-7018	-	_	_	
40-42	7018-7019	-	_	_	
40-43	7019-7020	-	_	_	
40-44	7020-7021	-	_	_	
40-45	7021-7022	-	_	_	
40-46	7022-7023	-	_	_	
40-47	7023-7024	-	_	_	
40-48	7024-7025	-	_	_	
40-49	7025-7026	-	_	_	
40-50	7026-7027	-	_	_	
40-51	7027-7028	-	_	_	
40-52	7028-7029	-	_	_	
40-53	7029-7030	-	_	_	
40-54	7030-7031	-	_	_	
40-55	7031-7032	-	_	_	
40-56	7032-7033	-	_	_	
40-57	7033-7034	-	_	_	
40-58	7034-7035	-	_	_	
40-59	7035-7036	-	_	_	
40-60	7036-7037	-	_	_	
40-61	7037-7038	-	_	_	
40-62	7038-7039	-	_	_	
40-63	7039-7040	-	_	_	
40-64	7040-7041	-	_	_	
40-65	7041-7042	-	_	_	
40-66	7042-7043	-	_	_	
40-67	7043-7044	-	_	_	
40-68	7044-7045	-	_	_	
40-69	7045-7046	-	_	_	
40-70	7046-7047	-	_	_	
40-71	7047-7048	-	_	_	
40-72	7048-7049	-	_	_	
40-73	7049-7050	-	_	_	
40-74	7050-7051	-	_	_	
40-75	7051-7052	-	_	_	
40-76	7052-7053	-	_	_	
40-77	7053-7054	-	_	_	
40-78	7054-7055	-	_	_	
40-79	7055-7056	-	_	_	
40-80	7056-7057	-	_	_	
40-81	7057-7058	-	_	_	
40-82	7058-7059	-	_	_	
40-83	7059-7060	-	_	_	
40-84	7060-7061	-	_	_	
40-85	7062-7063	|	_	_	
40-86	7064-7065	:	_	_	
40-87	7065-7066	-	_	_	
40-88	7066-7067	-	_	_	
40-89	7067-7068	-	_	_	
40-90	7068-7069	-	_	_	
40-91	7069-7070	-	_	_	
40-92	7070-7071	-	_	_	
40-93	7071-7072	-	_	_	
40-94	7072-7073	:	_	_	
40-95	7074-7075	|	_	_	
40-96	7076-7077	:	_	_	
40-97	7077-7078	-	_	_	
40-98	7078-7079	-	_	_	
40-99	7079-7080	-	_	_	
40-100	7080-7081	-	_	_	
40-101	7081-7082	-	_	_	
40-102	7082-7083	-	_	_	
40-103	7083-7084	-	_	_	
40-104	7084-7085	:	_	_	
40-105	7086-7087	|	_	_	
40-106	7088-7089	:	_	_	
40-107	7089-7090	-	_	_	
40-108	7090-7091	-	_	_	
40-109	7091-7092	-	_	_	
40-110	7092-7093	-	_	_	
40-111	7093-7094	-	_	_	
40-112	7094-7095	-	_	_	
40-113	7095-7096	-	_	_	
40-114	7096-7097	:	_	_	
40-115	7098-7099	|	_	_	
40-116	7100-7101	:	_	_	
40-117	7101-7102	-	_	_	
40-118	7102-7103	-	_	_	
40-119	7103-7104	-	_	_	
40-120	7104-7105	-	_	_	
40-121	7105-7106	-	_	_	
40-122	7106-7107	-	_	_	
40-123	7107-7108	-	_	_	
40-124	7108-7109	:	_	_	
40-125	7110-7111	|	_	_	
40-126	7112-7113	:	_	_	
40-127	7113-7114	-	_	_	
40-128	7114-7115	-	_	_	
40-129	7115-7116	-	_	_	
40-130	7116-7117	-	_	_	
40-131	7117-7118	-	_	_	
40-132	7118-7119	-	_	_	
40-133	7119-7120	-	_	_	
40-134	7120-7121	-	_	_	
40-135	7121-7122	-	_	_	
40-136	7122-7123	-	_	_	
40-137	7123-7124	-	_	_	
40-138	7124-7125	-	_	_	
40-139	7125-7126	-	_	_	
40-140	7126-7127	-	_	_	
40-141	7127-7128	-	_	_	
40-142	7128-7129	-	_	_	
40-143	7129-7130	:	_	_	
40-144	7131-7132	|	_	_	
40-145	7133-7134	:	_	_	
40-146	7134-7135	-	_	_	
40-147	7135-7136	-	_	_	
40-148	7136-7137	-	_	_	
40-149	7137-7138	-	_	_	
40-150	7138-7139	-	_	_	
40-151	7139-7140	-	_	_	
40-152	7140-7141	-	_	_	
40-153	7141-7142	-	_	_	
40-154	7142-7143	-	_	_	
40-155	7143-7144	:	_	_	
40-156	7145-7146	|	_	_	
40-157	7147-7148	:	_	_	
40-158	7148-7149	-	_	_	
40-159	7149-7150	-	_	_	
40-160	7150-7151	-	_	_	
40-161	7151-7152	-	_	_	
40-162	7152-7153	-	_	_	
40-163	7153-7154	-	_	_	
40-164	7154-7155	-	_	_	
40-165	7155-7156	-	_	_	
40-166	7156-7157	-	_	_	
40-167	7157-7158	-	_	_	
40-168	7158-7159	-	_	_	
40-169	7159-7160	-	_	_	
40-170	7160-7161	:	_	_	
40-171	7162-7163	|	_	_	
40-172	7168-7169	|	_	_	
40-173	7170-7171	[	_	_	
40-174	7171-7177	FinGPT	*[38]	SOFTWARE[38]	
40-175	7178-7182	v3.3	*[38]	SOFTWARE[38]	
40-176	7182-7183	]	_	_	
40-177	7183-7184	(	_	_	
40-178	7184-7189	https	_	_	
40-179	7189-7190	:	_	_	
40-180	7190-7191	/	_	_	
40-181	7191-7192	/	_	_	
40-182	7192-7206	huggingface.co	_	_	
40-183	7206-7207	/	_	_	
40-184	7207-7213	FinGPT	*[39]	SOFTWARE[39]	
40-185	7213-7214	/	*[39]	SOFTWARE[39]	
40-186	7214-7237	fingpt-sentiment_llama2	*[39]	SOFTWARE[39]	
40-187	7237-7238	-	*[39]	SOFTWARE[39]	
40-188	7238-7246	13b_lora	*[39]	SOFTWARE[39]	
40-189	7246-7247	)	_	_	
40-190	7247-7248	|	_	_	
40-191	7249-7250	*	_	_	
40-192	7250-7251	*	_	_	
40-193	7251-7256	0.882	_	_	
40-194	7256-7257	*	_	_	
40-195	7257-7258	*	_	_	
40-196	7259-7260	|	_	_	
40-197	7263-7268	0.874	_	_	
40-198	7271-7272	|	_	_	
40-199	7273-7274	*	_	_	
40-200	7274-7275	*	_	_	
40-201	7275-7280	0.903	_	_	
40-202	7280-7281	*	_	_	
40-203	7281-7282	*	_	_	
40-204	7283-7284	|	_	_	
40-205	7285-7286	*	_	_	
40-206	7286-7287	*	_	_	
40-207	7287-7292	0.643	_	_	
40-208	7292-7293	*	_	_	
40-209	7293-7294	*	_	_	
40-210	7295-7296	|	_	_	
40-211	7300-7301	1	_	_	
40-212	7302-7303	×	_	_	
40-213	7304-7307	RTX	_	_	
40-214	7308-7312	3090	_	_	
40-215	7316-7317	|	_	_	
40-216	7318-7323	17.25	_	_	
40-217	7324-7329	hours	_	_	
40-218	7330-7331	|	_	_	
40-219	7336-7342	$17.25	_	_	
40-220	7347-7348	|	_	_	
40-221	7353-7354	|	_	_	
40-222	7355-7361	FinGPT	*[40]	SOFTWARE[40]	
40-223	7362-7366	v3.2	*[40]	SOFTWARE[40]	
40-224	7366-7367	|	_	_	
40-225	7370-7375	0.850	_	_	
40-226	7378-7379	|	_	_	
40-227	7382-7387	0.860	_	_	
40-228	7390-7391	|	_	_	
40-229	7394-7399	0.894	_	_	
40-230	7402-7403	|	_	_	
40-231	7406-7411	0.636	_	_	
40-232	7414-7415	|	_	_	
40-233	7421-7422	1	_	_	
40-234	7423-7424	×	_	_	
40-235	7425-7429	A100	_	_	
40-236	7435-7436	|	_	_	
40-237	7438-7441	5.5	_	_	
40-238	7442-7447	hours	_	_	
40-239	7449-7450	|	_	_	
40-240	7454-7455	$	_	_	
40-241	7456-7461	22.55	_	_	
40-242	7466-7467	|	_	_	
40-243	7472-7473	|	_	_	
40-244	7474-7480	FinGPT	*[41]	SOFTWARE[41]	
40-245	7481-7485	v3.1	*[41]	SOFTWARE[41]	
40-246	7485-7486	|	_	_	
40-247	7489-7494	0.855	_	_	
40-248	7497-7498	|	_	_	
40-249	7501-7506	0.850	_	_	
40-250	7509-7510	|	_	_	
40-251	7513-7518	0.875	_	_	
40-252	7521-7522	|	_	_	
40-253	7525-7530	0.642	_	_	
40-254	7533-7534	|	_	_	
40-255	7540-7541	1	_	_	
40-256	7542-7543	×	_	_	
40-257	7544-7548	A100	_	_	
40-258	7554-7555	|	_	_	
40-259	7557-7560	5.5	_	_	
40-260	7561-7566	hours	_	_	
40-261	7568-7569	|	_	_	
40-262	7573-7574	$	_	_	
40-263	7575-7580	22.55	_	_	
40-264	7585-7586	|	_	_	
40-265	7591-7592	|	_	_	
40-266	7593-7599	FinGPT	*[42]	SOFTWARE[42]	
40-267	7600-7601	(	*[42]	SOFTWARE[42]	
40-268	7601-7605	8bit	*[42]	SOFTWARE[42]	
40-269	7605-7606	)	*[42]	SOFTWARE[42]	
40-270	7654-7655	|	_	_	
40-271	7658-7663	0.855	_	_	
40-272	7666-7667	|	_	_	
40-273	7670-7675	0.847	_	_	
40-274	7678-7679	|	_	_	
40-275	7682-7687	0.879	_	_	
40-276	7690-7691	|	_	_	
40-277	7694-7699	0.632	_	_	
40-278	7702-7703	|	_	_	
40-279	7707-7708	1	_	_	
40-280	7709-7710	×	_	_	
40-281	7711-7714	RTX	_	_	
40-282	7715-7719	3090	_	_	
40-283	7723-7724	|	_	_	
40-284	7725-7729	6.47	_	_	
40-285	7730-7735	hours	_	_	
40-286	7737-7738	|	_	_	
40-287	7743-7744	$	_	_	
40-288	7745-7749	6.47	_	_	
40-289	7754-7755	|	_	_	
40-290	7760-7761	|	_	_	
40-291	7762-7768	FinGPT	*[43]	SOFTWARE[43]	
40-292	7769-7770	(	*[43]	SOFTWARE[43]	
40-293	7770-7775	QLoRA	*[43]	SOFTWARE[43]	
40-294	7775-7776	)	*[43]	SOFTWARE[43]	
40-295	7823-7824	|	_	_	
40-296	7827-7832	0.777	_	_	
40-297	7835-7836	|	_	_	
40-298	7839-7844	0.752	_	_	
40-299	7847-7848	|	_	_	
40-300	7851-7856	0.828	_	_	
40-301	7859-7860	|	_	_	
40-302	7863-7868	0.583	_	_	
40-303	7871-7872	|	_	_	
40-304	7876-7877	1	_	_	
40-305	7878-7879	×	_	_	
40-306	7880-7883	RTX	_	_	
40-307	7884-7888	3090	_	_	
40-308	7892-7893	|	_	_	
40-309	7894-7898	4.15	_	_	
40-310	7899-7904	hours	_	_	
40-311	7906-7907	|	_	_	
40-312	7912-7913	$	_	_	
40-313	7914-7918	4.15	_	_	
40-314	7923-7924	|	_	_	
40-315	7929-7930	|	_	_	
40-316	7931-7937	OpenAI	_	_	
40-317	7938-7947	Fine-tune	_	_	
40-318	7992-7993	|	_	_	
40-319	7996-8001	0.878	_	_	
40-320	8004-8005	|	_	_	
40-321	8006-8007	*	_	_	
40-322	8007-8008	*	_	_	
40-323	8008-8013	0.887	_	_	
40-324	8013-8014	*	_	_	
40-325	8014-8015	*	_	_	
40-326	8016-8017	|	_	_	
40-327	8020-8025	0.883	_	_	
40-328	8028-8029	|	_	_	
40-329	8034-8035	-	_	_	
40-330	8040-8041	|	_	_	
40-331	8050-8051	-	_	_	
40-332	8061-8062	|	_	_	
40-333	8068-8069	-	_	_	
40-334	8075-8076	|	_	_	
40-335	8083-8084	-	_	_	
40-336	8092-8093	|	_	_	
40-337	8098-8099	|	_	_	
40-338	8100-8103	GPT	*[44]	SOFTWARE[44]	
40-339	8103-8104	-	*[44]	SOFTWARE[44]	
40-340	8104-8105	4	*[44]	SOFTWARE[44]	
40-341	8161-8162	|	_	_	
40-342	8165-8170	0.833	_	_	
40-343	8173-8174	|	_	_	
40-344	8177-8182	0.630	_	_	
40-345	8185-8186	|	_	_	
40-346	8189-8194	0.808	_	_	
40-347	8197-8198	|	_	_	
40-348	8203-8204	-	_	_	
40-349	8209-8210	|	_	_	
40-350	8219-8220	-	_	_	
40-351	8230-8231	|	_	_	
40-352	8237-8238	-	_	_	
40-353	8244-8245	|	_	_	
40-354	8252-8253	-	_	_	
40-355	8261-8262	|	_	_	
40-356	8267-8268	|	_	_	
40-357	8269-8276	FinBERT	_	_	
40-358	8330-8331	|	_	_	
40-359	8334-8339	0.880	_	_	
40-360	8342-8343	|	_	_	
40-361	8346-8351	0.596	_	_	
40-362	8354-8355	|	_	_	
40-363	8358-8363	0.733	_	_	
40-364	8366-8367	|	_	_	
40-365	8370-8375	0.538	_	_	
40-366	8378-8379	|	_	_	
40-367	8380-8381	4	_	_	
40-368	8382-8383	×	_	_	
40-369	8384-8390	NVIDIA	_	_	
40-370	8391-8394	K80	_	_	
40-371	8395-8398	GPU	_	_	
40-372	8399-8400	|	_	_	
40-373	8406-8407	-	_	_	
40-374	8413-8414	|	_	_	
40-375	8421-8422	-	_	_	
40-376	8430-8431	|	_	_	
40-377	8436-8437	|	_	_	
40-378	8438-8444	Llama2	_	_	
40-379	8444-8445	-	_	_	
40-380	8445-8447	7B	_	_	
40-381	8499-8500	|	_	_	
40-382	8503-8508	0.390	_	_	
40-383	8511-8512	|	_	_	
40-384	8515-8520	0.800	_	_	
40-385	8523-8524	|	_	_	
40-386	8527-8532	0.296	_	_	
40-387	8535-8536	|	_	_	
40-388	8539-8544	0.503	_	_	
40-389	8547-8548	|	_	_	
40-390	8552-8556	2048	_	_	
40-391	8557-8558	×	_	_	
40-392	8559-8563	A100	_	_	
40-393	8568-8569	|	_	_	
40-394	8572-8574	21	_	_	
40-395	8575-8579	days	_	_	
40-396	8582-8583	|	_	_	
40-397	8584-8585	$	_	_	
40-398	8586-8590	4.23	_	_	
40-399	8591-8598	million	_	_	
40-400	8599-8600	|	_	_	
40-401	8605-8606	|	_	_	
40-402	8607-8619	BloombergGPT	*	SOFTWARE	
40-403	8668-8669	|	_	_	
40-404	8672-8677	0.511	_	_	
40-405	8680-8681	|	_	_	
40-406	8684-8689	0.751	_	_	
40-407	8692-8693	|	_	_	
40-408	8698-8699	-	_	_	
40-409	8704-8705	|	_	_	
40-410	8710-8711	-	_	_	
40-411	8716-8717	|	_	_	
40-412	8722-8725	512	_	_	
40-413	8726-8727	×	_	_	
40-414	8728-8732	A100	_	_	
40-415	8737-8738	|	_	_	
40-416	8741-8743	53	_	_	
40-417	8744-8748	days	_	_	
40-418	8751-8752	|	_	_	
40-419	8753-8754	$	_	_	
40-420	8755-8759	2.67	_	_	
40-421	8760-8767	million	_	_	
40-422	8768-8769	|	_	_	
40-423	8777-8778	*	_	_	
40-424	8778-8779	*	_	_	
40-425	8779-8783	Cost	_	_	
40-426	8784-8787	per	_	_	
40-427	8788-8791	GPU	_	_	
40-428	8792-8796	hour	_	_	
40-429	8796-8797	.	_	_	
40-430	8797-8798	*	_	_	
40-431	8798-8799	*	_	_	
40-432	8800-8803	For	_	_	
40-433	8804-8805	*	_	_	
40-434	8805-8806	*	_	_	
40-435	8806-8810	A100	_	_	
40-436	8811-8815	GPUs	_	_	
40-437	8815-8816	*	_	_	
40-438	8816-8817	*	_	_	
40-439	8817-8818	,	_	_	
40-440	8819-8822	the	_	_	
40-441	8823-8826	AWS	_	_	
40-442	8827-8830	p4d	_	_	
40-443	8830-8839	.24xlarge	_	_	
40-444	8840-8848	instance	_	_	
40-445	8848-8849	,	_	_	
40-446	8850-8858	equipped	_	_	
40-447	8859-8863	with	_	_	
40-448	8864-8865	8	_	_	
40-449	8866-8870	A100	_	_	
40-450	8871-8875	GPUs	_	_	
40-451	8876-8878	is	_	_	
40-452	8879-8883	used	_	_	
40-453	8884-8886	as	_	_	
40-454	8887-8888	a	_	_	
40-455	8889-8898	benchmark	_	_	
40-456	8899-8901	to	_	_	
40-457	8902-8910	estimate	_	_	
40-458	8911-8914	the	_	_	
40-459	8915-8920	costs	_	_	
40-460	8920-8921	.	_	_	

#Text=Note that BloombergGPT also used p4d.24xlarge As of July 11, 2023, the hourly rate for this instance stands at $32.773.
41-1	8922-8926	Note	_	_	
41-2	8927-8931	that	_	_	
41-3	8932-8944	BloombergGPT	*	SOFTWARE	
41-4	8945-8949	also	_	_	
41-5	8950-8954	used	_	_	
41-6	8955-8958	p4d	_	_	
41-7	8958-8967	.24xlarge	_	_	
41-8	8968-8970	As	_	_	
41-9	8971-8973	of	_	_	
41-10	8974-8978	July	_	_	
41-11	8979-8981	11	_	_	
41-12	8981-8982	,	_	_	
41-13	8983-8987	2023	_	_	
41-14	8987-8988	,	_	_	
41-15	8989-8992	the	_	_	
41-16	8993-8999	hourly	_	_	
41-17	9000-9004	rate	_	_	
41-18	9005-9008	for	_	_	
41-19	9009-9013	this	_	_	
41-20	9014-9022	instance	_	_	
41-21	9023-9029	stands	_	_	
41-22	9030-9032	at	_	_	
41-23	9033-9040	$32.773	_	_	
41-24	9040-9041	.	_	_	

#Text=Consequently, the estimated cost per GPU hour comes to $32.77 divided by 8, resulting in approximately **$4.10**.
42-1	9042-9054	Consequently	_	_	
42-2	9054-9055	,	_	_	
42-3	9056-9059	the	_	_	
42-4	9060-9069	estimated	_	_	
42-5	9070-9074	cost	_	_	
42-6	9075-9078	per	_	_	
42-7	9079-9082	GPU	_	_	
42-8	9083-9087	hour	_	_	
42-9	9088-9093	comes	_	_	
42-10	9094-9096	to	_	_	
42-11	9097-9103	$32.77	_	_	
42-12	9104-9111	divided	_	_	
42-13	9112-9114	by	_	_	
42-14	9115-9116	8	_	_	
42-15	9116-9117	,	_	_	
42-16	9118-9127	resulting	_	_	
42-17	9128-9130	in	_	_	
42-18	9131-9144	approximately	_	_	
42-19	9145-9146	*	_	_	
42-20	9146-9147	*	_	_	
42-21	9147-9152	$4.10	_	_	
42-22	9152-9153	*	_	_	
42-23	9153-9154	*	_	_	
42-24	9154-9155	.	_	_	

#Text=With this value as the reference unit price (1 GPU hour).
43-1	9156-9160	With	_	_	
43-2	9161-9165	this	_	_	
43-3	9166-9171	value	_	_	
43-4	9172-9174	as	_	_	
43-5	9175-9178	the	_	_	
43-6	9179-9188	reference	_	_	
43-7	9189-9193	unit	_	_	
43-8	9194-9199	price	_	_	
43-9	9200-9201	(	_	_	
43-10	9201-9202	1	_	_	
43-11	9203-9206	GPU	_	_	
43-12	9207-9211	hour	_	_	
43-13	9211-9212	)	_	_	
43-14	9212-9213	.	_	_	

#Text=**BloombergGPT estimated cost= 512 x 53 x 24 = 651,264 GPU hours x $4.10 = $2,670,182.40**.
44-1	9214-9215	*	_	_	
44-2	9215-9216	*	_	_	
44-3	9216-9228	BloombergGPT	*	SOFTWARE	
44-4	9229-9238	estimated	_	_	
44-5	9239-9243	cost	_	_	
44-6	9243-9244	=	_	_	
44-7	9245-9248	512	_	_	
44-8	9249-9250	x	_	_	
44-9	9251-9253	53	_	_	
44-10	9254-9255	x	_	_	
44-11	9256-9258	24	_	_	
44-12	9259-9260	=	_	_	
44-13	9261-9268	651,264	_	_	
44-14	9269-9272	GPU	_	_	
44-15	9273-9278	hours	_	_	
44-16	9279-9280	x	_	_	
44-17	9281-9286	$4.10	_	_	
44-18	9287-9288	=	_	_	
44-19	9289-9302	$2,670,182.40	_	_	
44-20	9302-9303	*	_	_	
44-21	9303-9304	*	_	_	
44-22	9304-9305	.	_	_	

#Text=For **RTX 3090**, we assume its cost per hour is approximately **$1.0**, which is actually much higher than available GPUs from platforms like vast.ai
45-1	9306-9309	For	_	_	
45-2	9310-9311	*	_	_	
45-3	9311-9312	*	_	_	
45-4	9312-9315	RTX	_	_	
45-5	9316-9320	3090	_	_	
45-6	9320-9321	*	_	_	
45-7	9321-9322	*	_	_	
45-8	9322-9323	,	_	_	
45-9	9324-9326	we	_	_	
45-10	9327-9333	assume	_	_	
45-11	9334-9337	its	_	_	
45-12	9338-9342	cost	_	_	
45-13	9343-9346	per	_	_	
45-14	9347-9351	hour	_	_	
45-15	9352-9354	is	_	_	
45-16	9355-9368	approximately	_	_	
45-17	9369-9370	*	_	_	
45-18	9370-9371	*	_	_	
45-19	9371-9375	$1.0	_	_	
45-20	9375-9376	*	_	_	
45-21	9376-9377	*	_	_	
45-22	9377-9378	,	_	_	
45-23	9379-9384	which	_	_	
45-24	9385-9387	is	_	_	
45-25	9388-9396	actually	_	_	
45-26	9397-9401	much	_	_	
45-27	9402-9408	higher	_	_	
45-28	9409-9413	than	_	_	
45-29	9414-9423	available	_	_	
45-30	9424-9428	GPUs	_	_	
45-31	9429-9433	from	_	_	
45-32	9434-9443	platforms	_	_	
45-33	9444-9448	like	_	_	
45-34	9449-9456	vast.ai	_	_	

#Text=.
46-1	9456-9457	.	_	_	

#Text=* Reproduce the results by running [benchmarks](.
47-1	9463-9464	*	_	_	
47-2	9465-9474	Reproduce	_	_	
47-3	9475-9478	the	_	_	
47-4	9479-9486	results	_	_	
47-5	9487-9489	by	_	_	
47-6	9490-9497	running	_	_	
47-7	9498-9499	[	_	_	
47-8	9499-9509	benchmarks	_	_	
47-9	9509-9510	]	_	_	
47-10	9510-9511	(	_	_	
47-11	9511-9512	.	_	_	

#Text=/fingpt/FinGPT_Sentiment_Analysis_v3/benchmark/benchmarks.ipynb), and the detailed tutorial is on the way
48-1	9512-9513	/	_	_	
48-2	9513-9519	fingpt	_	_	
48-3	9519-9520	/	_	_	
48-4	9520-9548	FinGPT_Sentiment_Analysis_v3	_	_	
48-5	9548-9549	/	_	_	
48-6	9549-9558	benchmark	_	_	
48-7	9558-9559	/	_	_	
48-8	9559-9575	benchmarks.ipynb	_	_	
48-9	9575-9576	)	_	_	
48-10	9576-9577	,	_	_	
48-11	9578-9581	and	_	_	
48-12	9582-9585	the	_	_	
48-13	9586-9594	detailed	_	_	
48-14	9595-9603	tutorial	_	_	
48-15	9604-9606	is	_	_	
48-16	9607-9609	on	_	_	
48-17	9610-9613	the	_	_	
48-18	9614-9617	way	_	_	

#Text=.
49-1	9617-9618	.	_	_	

#Text=* Finetune your own FinGPT v3 model with the LoRA method on only an RTX 3090 with this [notebook](.
50-1	9621-9622	*	_	_	
50-2	9623-9631	Finetune	_	_	
50-3	9632-9636	your	_	_	
50-4	9637-9640	own	_	_	
50-5	9641-9647	FinGPT	*[45]	SOFTWARE[45]	
50-6	9648-9650	v3	*[45]	SOFTWARE[45]	
50-7	9651-9656	model	_	_	
50-8	9657-9661	with	_	_	
50-9	9662-9665	the	_	_	
50-10	9666-9670	LoRA	_	_	
50-11	9671-9677	method	_	_	
50-12	9678-9680	on	_	_	
50-13	9681-9685	only	_	_	
50-14	9686-9688	an	_	_	
50-15	9689-9692	RTX	_	_	
50-16	9693-9697	3090	_	_	
50-17	9698-9702	with	_	_	
50-18	9703-9707	this	_	_	
50-19	9708-9709	[	_	_	
50-20	9709-9717	notebook	_	_	
50-21	9717-9718	]	_	_	
50-22	9718-9719	(	_	_	
50-23	9719-9720	.	_	_	

#Text=/fingpt/FinGPT_Sentiment_Analysis_v3/training_8bit/train_Llama2_13B.ipynb) in 8bit or this [notebook](.
51-1	9720-9721	/	_	_	
51-2	9721-9727	fingpt	_	_	
51-3	9727-9728	/	_	_	
51-4	9728-9756	FinGPT_Sentiment_Analysis_v3	_	_	
51-5	9756-9757	/	_	_	
51-6	9757-9765	training	_	_	
51-7	9765-9766	_	_	_	
51-8	9766-9770	8bit	_	_	
51-9	9770-9771	/	_	_	
51-10	9771-9783	train_Llama2	_	_	
51-11	9783-9784	_	_	_	
51-12	9784-9793	13B.ipynb	_	_	
51-13	9793-9794	)	_	_	
51-14	9795-9797	in	_	_	
51-15	9798-9802	8bit	_	_	
51-16	9803-9805	or	_	_	
51-17	9806-9810	this	_	_	
51-18	9811-9812	[	_	_	
51-19	9812-9820	notebook	_	_	
51-20	9820-9821	]	_	_	
51-21	9821-9822	(	_	_	
51-22	9822-9823	.	_	_	

#Text=/fingpt/FinGPT_Sentiment_Analysis_v3/training_int4/train.ipynb) in int4 (QLoRA)
#Text=  
#Text=* [FinGPT V1](.
52-1	9823-9824	/	_	_	
52-2	9824-9830	fingpt	_	_	
52-3	9830-9831	/	_	_	
52-4	9831-9859	FinGPT_Sentiment_Analysis_v3	_	_	
52-5	9859-9860	/	_	_	
52-6	9860-9873	training_int4	_	_	
52-7	9873-9874	/	_	_	
52-8	9874-9885	train.ipynb	_	_	
52-9	9885-9886	)	_	_	
52-10	9887-9889	in	_	_	
52-11	9890-9894	int4	_	_	
52-12	9895-9896	(	_	_	
52-13	9896-9901	QLoRA	_	_	
52-14	9901-9902	)	_	_	
52-15	9906-9907	*	_	_	
52-16	9908-9909	[	_	_	
52-17	9909-9915	FinGPT	*[46]	SOFTWARE[46]	
52-18	9916-9918	V1	*[46]	SOFTWARE[46]	
52-19	9918-9919	]	_	_	
52-20	9919-9920	(	_	_	
52-21	9920-9921	.	_	_	

#Text=/fingpt)
#Text=  + **FinGPT by finetuning ChatGLM2 / Llama2 with LoRA with the market-labeled data for the Chinese Market**
#Text= 
#Text=## Instruction Tuning Datasets and Models
#Text=The datasets we used, and the **multi-task financial LLM** models are available at <https://huggingface.co/FinGPT>
#Text=
#Text=[Our Code](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark)
#Text=  
#Text=  | Datasets | Train Rows |  Test Rows |Description  |
#Text=  | --------- | ----------------- | ------------ | --------------------- |
#Text=  | [fingpt-sentiment-train](https://huggingface.co/datasets/FinGPT/fingpt-sentiment-train) | 76.8K | N/A|Sentiment Analysis Training Instructions |
#Text=  | [fingpt-finred](https://huggingface.co/datasets/FinGPT/fingpt-finred)| 27.6k | 5.11k | Financial Relation Extraction Instructions |
#Text=  | [fingpt-headline](https://huggingface.co/datasets/FinGPT/fingpt-headline) | 82.2k | 20.5k | Financial Headline Analysis Instructions|
#Text=  | [fingpt-ner](https://huggingface.co/datasets/FinGPT/fingpt-ner) | 511   | 98  | Financial Named-Entity Recognition Instructions|
#Text=  | [fingpt-fiqa_qa](https://huggingface.co/datasets/FinGPT/fingpt-fiqa_qa) | 17.1k   | N/A  | Financial Q&A Instructions|
#Text=  | [fingpt-fineval](https://huggingface.co/datasets/FinGPT/fingpt-fineval) | 1.06k   | 265  | Chinese Multiple-Choice Questions Instructions|
#Text=
#Text=  Multi-task financial LLMs Models:
#Text=```python
#Text=  demo_tasks = [
#Text=      'Financial Sentiment Analysis',
#Text=      'Financial Relation Extraction',
#Text=      'Financial Headline Classification',
#Text=      'Financial Named Entity Recognition',]
#Text=  demo_inputs = [
#Text=      "Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano",
#Text=      "Apple Inc.
53-1	9921-9922	/	_	_	
53-2	9922-9928	fingpt	_	_	
53-3	9928-9929	)	_	_	
53-4	9932-9933	+	_	_	
53-5	9934-9935	*	_	_	
53-6	9935-9936	*	_	_	
53-7	9936-9942	FinGPT	_	_	
53-8	9943-9945	by	_	_	
53-9	9946-9956	finetuning	_	_	
53-10	9957-9965	ChatGLM2	_	_	
53-11	9966-9967	/	_	_	
53-12	9968-9974	Llama2	_	_	
53-13	9975-9979	with	_	_	
53-14	9980-9984	LoRA	_	_	
53-15	9985-9989	with	_	_	
53-16	9990-9993	the	_	_	
53-17	9994-10008	market-labeled	_	_	
53-18	10009-10013	data	_	_	
53-19	10014-10017	for	_	_	
53-20	10018-10021	the	_	_	
53-21	10022-10029	Chinese	_	_	
53-22	10030-10036	Market	_	_	
53-23	10036-10037	*	_	_	
53-24	10037-10038	*	_	_	
53-25	10041-10042	#	_	_	
53-26	10042-10043	#	_	_	
53-27	10044-10055	Instruction	_	_	
53-28	10056-10062	Tuning	_	_	
53-29	10063-10071	Datasets	_	_	
53-30	10072-10075	and	_	_	
53-31	10076-10082	Models	_	_	
53-32	10083-10086	The	_	_	
53-33	10087-10095	datasets	_	_	
53-34	10096-10098	we	_	_	
53-35	10099-10103	used	_	_	
53-36	10103-10104	,	_	_	
53-37	10105-10108	and	_	_	
53-38	10109-10112	the	_	_	
53-39	10113-10114	*	_	_	
53-40	10114-10115	*	_	_	
53-41	10115-10125	multi-task	_	_	
53-42	10126-10135	financial	_	_	
53-43	10136-10139	LLM	_	_	
53-44	10139-10140	*	_	_	
53-45	10140-10141	*	_	_	
53-46	10142-10148	models	_	_	
53-47	10149-10152	are	_	_	
53-48	10153-10162	available	_	_	
53-49	10163-10165	at	_	_	
53-50	10166-10167	<	_	_	
53-51	10167-10172	https	_	_	
53-52	10172-10173	:	_	_	
53-53	10173-10174	/	_	_	
53-54	10174-10175	/	_	_	
53-55	10175-10189	huggingface.co	_	_	
53-56	10189-10190	/	_	_	
53-57	10190-10196	FinGPT	_	_	
53-58	10196-10197	>	_	_	
53-59	10199-10200	[	_	_	
53-60	10200-10203	Our	_	_	
53-61	10204-10208	Code	_	_	
53-62	10208-10209	]	_	_	
53-63	10209-10210	(	_	_	
53-64	10210-10215	https	_	_	
53-65	10215-10216	:	_	_	
53-66	10216-10217	/	_	_	
53-67	10217-10218	/	_	_	
53-68	10218-10228	github.com	_	_	
53-69	10228-10229	/	_	_	
53-70	10229-10250	AI4Finance-Foundation	_	_	
53-71	10250-10251	/	_	_	
53-72	10251-10257	FinGPT	*	PROJECT	
53-73	10257-10258	/	_	_	
53-74	10258-10262	tree	_	_	
53-75	10262-10263	/	_	_	
53-76	10263-10269	master	_	_	
53-77	10269-10270	/	_	_	
53-78	10270-10276	fingpt	_	_	
53-79	10276-10277	/	_	_	
53-80	10277-10293	FinGPT_Benchmark	_	_	
53-81	10293-10294	)	_	_	
53-82	10300-10301	|	_	_	
53-83	10302-10310	Datasets	_	_	
53-84	10311-10312	|	_	_	
53-85	10313-10318	Train	_	_	
53-86	10319-10323	Rows	_	_	
53-87	10324-10325	|	_	_	
53-88	10327-10331	Test	_	_	
53-89	10332-10336	Rows	_	_	
53-90	10337-10338	|	_	_	
53-91	10338-10349	Description	_	_	
53-92	10351-10352	|	_	_	
53-93	10355-10356	|	_	_	
53-94	10357-10358	-	_	_	
53-95	10358-10359	-	_	_	
53-96	10359-10360	-	_	_	
53-97	10360-10361	-	_	_	
53-98	10361-10362	-	_	_	
53-99	10362-10363	-	_	_	
53-100	10363-10364	-	_	_	
53-101	10364-10365	-	_	_	
53-102	10365-10366	-	_	_	
53-103	10367-10368	|	_	_	
53-104	10369-10370	-	_	_	
53-105	10370-10371	-	_	_	
53-106	10371-10372	-	_	_	
53-107	10372-10373	-	_	_	
53-108	10373-10374	-	_	_	
53-109	10374-10375	-	_	_	
53-110	10375-10376	-	_	_	
53-111	10376-10377	-	_	_	
53-112	10377-10378	-	_	_	
53-113	10378-10379	-	_	_	
53-114	10379-10380	-	_	_	
53-115	10380-10381	-	_	_	
53-116	10381-10382	-	_	_	
53-117	10382-10383	-	_	_	
53-118	10383-10384	-	_	_	
53-119	10384-10385	-	_	_	
53-120	10385-10386	-	_	_	
53-121	10387-10388	|	_	_	
53-122	10389-10390	-	_	_	
53-123	10390-10391	-	_	_	
53-124	10391-10392	-	_	_	
53-125	10392-10393	-	_	_	
53-126	10393-10394	-	_	_	
53-127	10394-10395	-	_	_	
53-128	10395-10396	-	_	_	
53-129	10396-10397	-	_	_	
53-130	10397-10398	-	_	_	
53-131	10398-10399	-	_	_	
53-132	10399-10400	-	_	_	
53-133	10400-10401	-	_	_	
53-134	10402-10403	|	_	_	
53-135	10404-10405	-	_	_	
53-136	10405-10406	-	_	_	
53-137	10406-10407	-	_	_	
53-138	10407-10408	-	_	_	
53-139	10408-10409	-	_	_	
53-140	10409-10410	-	_	_	
53-141	10410-10411	-	_	_	
53-142	10411-10412	-	_	_	
53-143	10412-10413	-	_	_	
53-144	10413-10414	-	_	_	
53-145	10414-10415	-	_	_	
53-146	10415-10416	-	_	_	
53-147	10416-10417	-	_	_	
53-148	10417-10418	-	_	_	
53-149	10418-10419	-	_	_	
53-150	10419-10420	-	_	_	
53-151	10420-10421	-	_	_	
53-152	10421-10422	-	_	_	
53-153	10422-10423	-	_	_	
53-154	10423-10424	-	_	_	
53-155	10424-10425	-	_	_	
53-156	10426-10427	|	_	_	
53-157	10430-10431	|	_	_	
53-158	10432-10433	[	_	_	
53-159	10433-10455	fingpt-sentiment-train	*	DATASET	
53-160	10455-10456	]	_	_	
53-161	10456-10457	(	_	_	
53-162	10457-10462	https	_	_	
53-163	10462-10463	:	_	_	
53-164	10463-10464	/	_	_	
53-165	10464-10465	/	_	_	
53-166	10465-10479	huggingface.co	_	_	
53-167	10479-10480	/	_	_	
53-168	10480-10488	datasets	_	_	
53-169	10488-10489	/	_	_	
53-170	10489-10495	FinGPT	*[47]	DATASET[47]	
53-171	10495-10496	/	*[47]	DATASET[47]	
53-172	10496-10518	fingpt-sentiment-train	*[47]	DATASET[47]	
53-173	10518-10519	)	_	_	
53-174	10520-10521	|	_	_	
53-175	10522-10527	76.8K	_	_	
53-176	10528-10529	|	_	_	
53-177	10530-10531	N	_	_	
53-178	10531-10532	/	_	_	
53-179	10532-10533	A	_	_	
53-180	10533-10534	|	_	_	
53-181	10534-10543	Sentiment	_	_	
53-182	10544-10552	Analysis	_	_	
53-183	10553-10561	Training	_	_	
53-184	10562-10574	Instructions	_	_	
53-185	10575-10576	|	_	_	
53-186	10579-10580	|	_	_	
53-187	10581-10582	[	_	_	
53-188	10582-10595	fingpt-finred	*	DATASET	
53-189	10595-10596	]	_	_	
53-190	10596-10597	(	_	_	
53-191	10597-10602	https	_	_	
53-192	10602-10603	:	_	_	
53-193	10603-10604	/	_	_	
53-194	10604-10605	/	_	_	
53-195	10605-10619	huggingface.co	_	_	
53-196	10619-10620	/	_	_	
53-197	10620-10628	datasets	_	_	
53-198	10628-10629	/	_	_	
53-199	10629-10635	FinGPT	*[48]	DATASET[48]	
53-200	10635-10636	/	*[48]	DATASET[48]	
53-201	10636-10649	fingpt-finred	*[48]	DATASET[48]	
53-202	10649-10650	)	_	_	
53-203	10650-10651	|	_	_	
53-204	10652-10657	27.6k	_	_	
53-205	10658-10659	|	_	_	
53-206	10660-10665	5.11k	_	_	
53-207	10666-10667	|	_	_	
53-208	10668-10677	Financial	_	_	
53-209	10678-10686	Relation	_	_	
53-210	10687-10697	Extraction	_	_	
53-211	10698-10710	Instructions	_	_	
53-212	10711-10712	|	_	_	
53-213	10715-10716	|	_	_	
53-214	10717-10718	[	_	_	
53-215	10718-10733	fingpt-headline	_	_	
53-216	10733-10734	]	_	_	
53-217	10734-10735	(	_	_	
53-218	10735-10740	https	_	_	
53-219	10740-10741	:	_	_	
53-220	10741-10742	/	_	_	
53-221	10742-10743	/	_	_	
53-222	10743-10757	huggingface.co	_	_	
53-223	10757-10758	/	_	_	
53-224	10758-10766	datasets	_	_	
53-225	10766-10767	/	_	_	
53-226	10767-10773	FinGPT	*[49]	DATASET[49]	
53-227	10773-10774	/	*[49]	DATASET[49]	
53-228	10774-10789	fingpt-headline	*[49]	DATASET[49]	
53-229	10789-10790	)	_	_	
53-230	10791-10792	|	_	_	
53-231	10793-10798	82.2k	_	_	
53-232	10799-10800	|	_	_	
53-233	10801-10806	20.5k	_	_	
53-234	10807-10808	|	_	_	
53-235	10809-10818	Financial	_	_	
53-236	10819-10827	Headline	_	_	
53-237	10828-10836	Analysis	_	_	
53-238	10837-10849	Instructions	_	_	
53-239	10849-10850	|	_	_	
53-240	10853-10854	|	_	_	
53-241	10855-10856	[	_	_	
53-242	10856-10866	fingpt-ner	*	DATASET	
53-243	10866-10867	]	_	_	
53-244	10867-10868	(	_	_	
53-245	10868-10873	https	_	_	
53-246	10873-10874	:	_	_	
53-247	10874-10875	/	_	_	
53-248	10875-10876	/	_	_	
53-249	10876-10890	huggingface.co	_	_	
53-250	10890-10891	/	_	_	
53-251	10891-10899	datasets	_	_	
53-252	10899-10900	/	_	_	
53-253	10900-10906	FinGPT	*[50]	DATASET[50]	
53-254	10906-10907	/	*[50]	DATASET[50]	
53-255	10907-10917	fingpt-ner	*[50]	DATASET[50]	
53-256	10917-10918	)	_	_	
53-257	10919-10920	|	_	_	
53-258	10921-10924	511	_	_	
53-259	10927-10928	|	_	_	
53-260	10929-10931	98	_	_	
53-261	10933-10934	|	_	_	
53-262	10935-10944	Financial	_	_	
53-263	10945-10957	Named-Entity	_	_	
53-264	10958-10969	Recognition	_	_	
53-265	10970-10982	Instructions	_	_	
53-266	10982-10983	|	_	_	
53-267	10986-10987	|	_	_	
53-268	10988-10989	[	_	_	
53-269	10989-11003	fingpt-fiqa_qa	*	DATASET	
53-270	11003-11004	]	_	_	
53-271	11004-11005	(	_	_	
53-272	11005-11010	https	_	_	
53-273	11010-11011	:	_	_	
53-274	11011-11012	/	_	_	
53-275	11012-11013	/	_	_	
53-276	11013-11027	huggingface.co	_	_	
53-277	11027-11028	/	_	_	
53-278	11028-11036	datasets	_	_	
53-279	11036-11037	/	_	_	
53-280	11037-11043	FinGPT	*[51]	DATASET[51]	
53-281	11043-11044	/	*[51]	DATASET[51]	
53-282	11044-11058	fingpt-fiqa_qa	*[51]	DATASET[51]	
53-283	11058-11059	)	_	_	
53-284	11060-11061	|	_	_	
53-285	11062-11067	17.1k	_	_	
53-286	11070-11071	|	_	_	
53-287	11072-11073	N	_	_	
53-288	11073-11074	/	_	_	
53-289	11074-11075	A	_	_	
53-290	11077-11078	|	_	_	
53-291	11079-11088	Financial	_	_	
53-292	11089-11090	Q	_	_	
53-293	11090-11091	&	_	_	
53-294	11091-11092	A	_	_	
53-295	11093-11105	Instructions	_	_	
53-296	11105-11106	|	_	_	
53-297	11109-11110	|	_	_	
53-298	11111-11112	[	_	_	
53-299	11112-11126	fingpt-fineval	*	DATASET	
53-300	11126-11127	]	_	_	
53-301	11127-11128	(	_	_	
53-302	11128-11133	https	_	_	
53-303	11133-11134	:	_	_	
53-304	11134-11135	/	_	_	
53-305	11135-11136	/	_	_	
53-306	11136-11150	huggingface.co	_	_	
53-307	11150-11151	/	_	_	
53-308	11151-11159	datasets	_	_	
53-309	11159-11160	/	_	_	
53-310	11160-11166	FinGPT	*[52]	DATASET[52]	
53-311	11166-11167	/	*[52]	DATASET[52]	
53-312	11167-11181	fingpt-fineval	*[52]	DATASET[52]	
53-313	11181-11182	)	_	_	
53-314	11183-11184	|	_	_	
53-315	11185-11190	1.06k	_	_	
53-316	11193-11194	|	_	_	
53-317	11195-11198	265	_	_	
53-318	11200-11201	|	_	_	
53-319	11202-11209	Chinese	_	_	
53-320	11210-11225	Multiple-Choice	_	_	
53-321	11226-11235	Questions	_	_	
53-322	11236-11248	Instructions	_	_	
53-323	11248-11249	|	_	_	
53-324	11253-11263	Multi-task	_	_	
53-325	11264-11273	financial	_	_	
53-326	11274-11278	LLMs	_	_	
53-327	11279-11285	Models	_	_	
53-328	11285-11286	:	_	_	
53-329	11287-11288	`	_	_	
53-330	11288-11289	`	_	_	
53-331	11289-11290	`	_	_	
53-332	11290-11296	python	*	PROGLANG	
53-333	11299-11309	demo_tasks	_	_	
53-334	11310-11311	=	_	_	
53-335	11312-11313	[	_	_	
53-336	11320-11321	'	_	_	
53-337	11321-11330	Financial	_	_	
53-338	11331-11340	Sentiment	_	_	
53-339	11341-11349	Analysis	_	_	
53-340	11349-11350	'	_	_	
53-341	11350-11351	,	_	_	
53-342	11358-11359	'	_	_	
53-343	11359-11368	Financial	_	_	
53-344	11369-11377	Relation	_	_	
53-345	11378-11388	Extraction	_	_	
53-346	11388-11389	'	_	_	
53-347	11389-11390	,	_	_	
53-348	11397-11398	'	_	_	
53-349	11398-11407	Financial	_	_	
53-350	11408-11416	Headline	_	_	
53-351	11417-11431	Classification	_	_	
53-352	11431-11432	'	_	_	
53-353	11432-11433	,	_	_	
53-354	11440-11441	'	_	_	
53-355	11441-11450	Financial	_	_	
53-356	11451-11456	Named	_	_	
53-357	11457-11463	Entity	_	_	
53-358	11464-11475	Recognition	_	_	
53-359	11475-11476	'	_	_	
53-360	11476-11477	,	_	_	
53-361	11477-11478	]	_	_	
53-362	11481-11492	demo_inputs	_	_	
53-363	11493-11494	=	_	_	
53-364	11495-11496	[	_	_	
53-365	11503-11504	"	_	_	
53-366	11504-11511	Glaxo's	_	_	
53-367	11512-11516	ViiV	_	_	
53-368	11517-11527	Healthcare	_	_	
53-369	11528-11533	Signs	_	_	
53-370	11534-11539	China	_	_	
53-371	11540-11553	Manufacturing	_	_	
53-372	11554-11558	Deal	_	_	
53-373	11559-11563	With	_	_	
53-374	11564-11570	Desano	_	_	
53-375	11570-11571	"	_	_	
53-376	11571-11572	,	_	_	
53-377	11579-11580	"	_	_	
53-378	11580-11585	Apple	_	_	
53-379	11586-11589	Inc	_	_	
53-380	11589-11590	.	_	_	

#Text=Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.",
#Text=      'gold trades in red in early trade; eyes near-term range at rs 28,300-28,600',
#Text=      'This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (" Bank "), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .',]
#Text=  demo_instructions = [
#Text=      'What is the sentiment of this news?
54-1	11591-11596	Chief	_	_	
54-2	11597-11606	Executive	_	_	
54-3	11607-11612	Steve	_	_	
54-4	11613-11617	Jobs	_	_	
54-5	11618-11624	sought	_	_	
54-6	11625-11627	to	_	_	
54-7	11628-11634	soothe	_	_	
54-8	11635-11643	investor	_	_	
54-9	11644-11652	concerns	_	_	
54-10	11653-11658	about	_	_	
54-11	11659-11662	his	_	_	
54-12	11663-11669	health	_	_	
54-13	11670-11672	on	_	_	
54-14	11673-11679	Monday	_	_	
54-15	11679-11680	,	_	_	
54-16	11681-11687	saying	_	_	
54-17	11688-11691	his	_	_	
54-18	11692-11698	weight	_	_	
54-19	11699-11703	loss	_	_	
54-20	11704-11707	was	_	_	
54-21	11708-11714	caused	_	_	
54-22	11715-11717	by	_	_	
54-23	11718-11719	a	_	_	
54-24	11720-11727	hormone	_	_	
54-25	11728-11737	imbalance	_	_	
54-26	11738-11742	that	_	_	
54-27	11743-11745	is	_	_	
54-28	11746-11756	relatively	_	_	
54-29	11757-11763	simple	_	_	
54-30	11764-11766	to	_	_	
54-31	11767-11772	treat	_	_	
54-32	11772-11773	.	_	_	
54-33	11773-11774	"	_	_	
54-34	11774-11775	,	_	_	
54-35	11782-11783	'	_	_	
54-36	11783-11787	gold	_	_	
54-37	11788-11794	trades	_	_	
54-38	11795-11797	in	_	_	
54-39	11798-11801	red	_	_	
54-40	11802-11804	in	_	_	
54-41	11805-11810	early	_	_	
54-42	11811-11816	trade	_	_	
54-43	11816-11817	;	_	_	
54-44	11818-11822	eyes	_	_	
54-45	11823-11832	near-term	_	_	
54-46	11833-11838	range	_	_	
54-47	11839-11841	at	_	_	
54-48	11842-11844	rs	_	_	
54-49	11845-11851	28,300	_	_	
54-50	11851-11852	-	_	_	
54-51	11852-11858	28,600	_	_	
54-52	11858-11859	'	_	_	
54-53	11859-11860	,	_	_	
54-54	11867-11868	'	_	_	
54-55	11868-11872	This	_	_	
54-56	11873-11877	LOAN	_	_	
54-57	11878-11881	AND	_	_	
54-58	11882-11890	SECURITY	_	_	
54-59	11891-11900	AGREEMENT	_	_	
54-60	11901-11906	dated	_	_	
54-61	11907-11914	January	_	_	
54-62	11915-11917	27	_	_	
54-63	11918-11919	,	_	_	
54-64	11920-11924	1999	_	_	
54-65	11925-11926	,	_	_	
54-66	11927-11934	between	_	_	
54-67	11935-11942	SILICON	_	_	
54-68	11943-11949	VALLEY	_	_	
54-69	11950-11954	BANK	_	_	
54-70	11955-11956	(	_	_	
54-71	11956-11957	"	_	_	
54-72	11958-11962	Bank	_	_	
54-73	11963-11964	"	_	_	
54-74	11964-11965	)	_	_	
54-75	11965-11966	,	_	_	
54-76	11967-11968	a	_	_	
54-77	11969-11979	California	_	_	
54-78	11980-11981	-	_	_	
54-79	11982-11991	chartered	_	_	
54-80	11992-11996	bank	_	_	
54-81	11997-12001	with	_	_	
54-82	12002-12005	its	_	_	
54-83	12006-12015	principal	_	_	
54-84	12016-12021	place	_	_	
54-85	12022-12024	of	_	_	
54-86	12025-12033	business	_	_	
54-87	12034-12036	at	_	_	
54-88	12037-12041	3003	_	_	
54-89	12042-12048	Tasman	_	_	
54-90	12049-12054	Drive	_	_	
54-91	12055-12056	,	_	_	
54-92	12057-12062	Santa	_	_	
54-93	12063-12068	Clara	_	_	
54-94	12069-12070	,	_	_	
54-95	12071-12081	California	_	_	
54-96	12082-12087	95054	_	_	
54-97	12088-12092	with	_	_	
54-98	12093-12094	a	_	_	
54-99	12095-12099	loan	_	_	
54-100	12100-12110	production	_	_	
54-101	12111-12117	office	_	_	
54-102	12118-12125	located	_	_	
54-103	12126-12128	at	_	_	
54-104	12129-12131	40	_	_	
54-105	12132-12139	William	_	_	
54-106	12140-12142	St	_	_	
54-107	12143-12144	.	_	_	
54-108	12144-12145	,	_	_	
54-109	12146-12149	Ste	_	_	
54-110	12150-12151	.	_	_	
54-111	12151-12152	'	_	_	
54-112	12152-12153	,	_	_	
54-113	12153-12154	]	_	_	
54-114	12157-12174	demo_instructions	_	_	
54-115	12175-12176	=	_	_	
54-116	12177-12178	[	_	_	
54-117	12185-12186	'	_	_	
54-118	12186-12190	What	_	_	
54-119	12191-12193	is	_	_	
54-120	12194-12197	the	_	_	
54-121	12198-12207	sentiment	_	_	
54-122	12208-12210	of	_	_	
54-123	12211-12215	this	_	_	
54-124	12216-12220	news	_	_	
54-125	12220-12221	?	_	_	

#Text=Please choose an answer from {negative/neutral/positive}.',
#Text=      'Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text.
55-1	12222-12228	Please	_	_	
55-2	12229-12235	choose	_	_	
55-3	12236-12238	an	_	_	
55-4	12239-12245	answer	_	_	
55-5	12246-12250	from	_	_	
55-6	12251-12252	{	_	_	
55-7	12252-12260	negative	_	_	
55-8	12260-12261	/	_	_	
55-9	12261-12268	neutral	_	_	
55-10	12268-12269	/	_	_	
55-11	12269-12277	positive	_	_	
55-12	12277-12278	}	_	_	
55-13	12278-12279	.	_	_	
55-14	12279-12280	'	_	_	
55-15	12280-12281	,	_	_	
55-16	12288-12289	'	_	_	
55-17	12289-12294	Given	_	_	
55-18	12295-12302	phrases	_	_	
55-19	12303-12307	that	_	_	
55-20	12308-12316	describe	_	_	
55-21	12317-12320	the	_	_	
55-22	12321-12333	relationship	_	_	
55-23	12334-12341	between	_	_	
55-24	12342-12345	two	_	_	
55-25	12346-12351	words	_	_	
55-26	12351-12352	/	_	_	
55-27	12352-12359	phrases	_	_	
55-28	12360-12362	as	_	_	
55-29	12363-12370	options	_	_	
55-30	12370-12371	,	_	_	
55-31	12372-12379	extract	_	_	
55-32	12380-12383	the	_	_	
55-33	12384-12388	word	_	_	
55-34	12388-12389	/	_	_	
55-35	12389-12395	phrase	_	_	
55-36	12396-12400	pair	_	_	
55-37	12401-12404	and	_	_	
55-38	12405-12408	the	_	_	
55-39	12409-12422	corresponding	_	_	
55-40	12423-12430	lexical	_	_	
55-41	12431-12443	relationship	_	_	
55-42	12444-12451	between	_	_	
55-43	12452-12456	them	_	_	
55-44	12457-12461	from	_	_	
55-45	12462-12465	the	_	_	
55-46	12466-12471	input	_	_	
55-47	12472-12476	text	_	_	
55-48	12476-12477	.	_	_	

#Text=The output format should be "relation1: word1, word2; relation2: word3, word4".
56-1	12478-12481	The	_	_	
56-2	12482-12488	output	_	_	
56-3	12489-12495	format	_	_	
56-4	12496-12502	should	_	_	
56-5	12503-12505	be	_	_	
56-6	12506-12507	"	_	_	
56-7	12507-12516	relation1	_	_	
56-8	12516-12517	:	_	_	
56-9	12518-12523	word1	_	_	
56-10	12523-12524	,	_	_	
56-11	12525-12530	word2	_	_	
56-12	12530-12531	;	_	_	
56-13	12532-12541	relation2	_	_	
56-14	12541-12542	:	_	_	
56-15	12543-12548	word3	_	_	
56-16	12548-12549	,	_	_	
56-17	12550-12555	word4	_	_	
56-18	12555-12556	"	_	_	
56-19	12556-12557	.	_	_	

#Text=Options: product/material produced, manufacturer, distributed by, industry, position held, original broadcaster, owned by, founded by, distribution format, headquarters location, stock exchange, currency, parent organization, chief executive officer, director/manager, owner of, operator, member of, employer, chairperson, platform, subsidiary, legal form, publisher, developer, brand, business division, location of formation, creator.',
#Text=      'Does the news headline talk about price going up?
57-1	12558-12565	Options	_	_	
57-2	12565-12566	:	_	_	
57-3	12567-12574	product	_	_	
57-4	12574-12575	/	_	_	
57-5	12575-12583	material	_	_	
57-6	12584-12592	produced	_	_	
57-7	12592-12593	,	_	_	
57-8	12594-12606	manufacturer	_	_	
57-9	12606-12607	,	_	_	
57-10	12608-12619	distributed	_	_	
57-11	12620-12622	by	_	_	
57-12	12622-12623	,	_	_	
57-13	12624-12632	industry	_	_	
57-14	12632-12633	,	_	_	
57-15	12634-12642	position	_	_	
57-16	12643-12647	held	_	_	
57-17	12647-12648	,	_	_	
57-18	12649-12657	original	_	_	
57-19	12658-12669	broadcaster	_	_	
57-20	12669-12670	,	_	_	
57-21	12671-12676	owned	_	_	
57-22	12677-12679	by	_	_	
57-23	12679-12680	,	_	_	
57-24	12681-12688	founded	_	_	
57-25	12689-12691	by	_	_	
57-26	12691-12692	,	_	_	
57-27	12693-12705	distribution	_	_	
57-28	12706-12712	format	_	_	
57-29	12712-12713	,	_	_	
57-30	12714-12726	headquarters	_	_	
57-31	12727-12735	location	_	_	
57-32	12735-12736	,	_	_	
57-33	12737-12742	stock	_	_	
57-34	12743-12751	exchange	_	_	
57-35	12751-12752	,	_	_	
57-36	12753-12761	currency	_	_	
57-37	12761-12762	,	_	_	
57-38	12763-12769	parent	_	_	
57-39	12770-12782	organization	_	_	
57-40	12782-12783	,	_	_	
57-41	12784-12789	chief	_	_	
57-42	12790-12799	executive	_	_	
57-43	12800-12807	officer	_	_	
57-44	12807-12808	,	_	_	
57-45	12809-12817	director	_	_	
57-46	12817-12818	/	_	_	
57-47	12818-12825	manager	_	_	
57-48	12825-12826	,	_	_	
57-49	12827-12832	owner	_	_	
57-50	12833-12835	of	_	_	
57-51	12835-12836	,	_	_	
57-52	12837-12845	operator	_	_	
57-53	12845-12846	,	_	_	
57-54	12847-12853	member	_	_	
57-55	12854-12856	of	_	_	
57-56	12856-12857	,	_	_	
57-57	12858-12866	employer	_	_	
57-58	12866-12867	,	_	_	
57-59	12868-12879	chairperson	_	_	
57-60	12879-12880	,	_	_	
57-61	12881-12889	platform	_	_	
57-62	12889-12890	,	_	_	
57-63	12891-12901	subsidiary	_	_	
57-64	12901-12902	,	_	_	
57-65	12903-12908	legal	_	_	
57-66	12909-12913	form	_	_	
57-67	12913-12914	,	_	_	
57-68	12915-12924	publisher	_	_	
57-69	12924-12925	,	_	_	
57-70	12926-12935	developer	_	_	
57-71	12935-12936	,	_	_	
57-72	12937-12942	brand	_	_	
57-73	12942-12943	,	_	_	
57-74	12944-12952	business	_	_	
57-75	12953-12961	division	_	_	
57-76	12961-12962	,	_	_	
57-77	12963-12971	location	_	_	
57-78	12972-12974	of	_	_	
57-79	12975-12984	formation	_	_	
57-80	12984-12985	,	_	_	
57-81	12986-12993	creator	_	_	
57-82	12993-12994	.	_	_	
57-83	12994-12995	'	_	_	
57-84	12995-12996	,	_	_	
57-85	13003-13004	'	_	_	
57-86	13004-13008	Does	_	_	
57-87	13009-13012	the	_	_	
57-88	13013-13017	news	_	_	
57-89	13018-13026	headline	_	_	
57-90	13027-13031	talk	_	_	
57-91	13032-13037	about	_	_	
57-92	13038-13043	price	_	_	
57-93	13044-13049	going	_	_	
57-94	13050-13052	up	_	_	
57-95	13052-13053	?	_	_	

#Text=Please choose an answer from {Yes/No}.',
#Text=      'Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.',]
#Text=```
#Text=
#Text=  | Models | Description  | Function |
#Text=  | --------- | --------------------- |---------------- |
#Text=  | [fingpt-mt_llama2-7b_lora](https://huggingface.co/FinGPT/fingpt-mt_llama2-7b_lora)| Fine-tuned Llama2-7b model with LoRA | Multi-Task |
#Text=  | [fingpt-mt_falcon-7b_lora](https://huggingface.co/FinGPT/fingpt-mt_falcon-7b_lora)| Fine-tuned falcon-7b model with LoRA  | Multi-Task |
#Text=  | [fingpt-mt_bloom-7b1_lora](https://huggingface.co/FinGPT/fingpt-mt_bloom-7b1_lora) | Fine-tuned bloom-7b1 model with LoRA | Multi-Task |
#Text=  | [fingpt-mt_mpt-7b_lora](https://huggingface.co/FinGPT/fingpt-mt_mpt-7b_lora) | Fine-tuned mpt-7b model with LoRA | Multi-Task |
#Text=  | [fingpt-mt_chatglm2-6b_lora](https://huggingface.co/FinGPT/fingpt-mt_chatglm2-6b_lora) | Fine-tuned chatglm-6b model with LoRA | Multi-Task |
#Text=  | [fingpt-mt_qwen-7b_lora](https://huggingface.co/FinGPT/fingpt-mt_qwen-7b_lora) | Fine-tuned qwen-7b model with LoRA | Multi-Task |
#Text=  | [fingpt-sentiment_llama2-13b_lora](https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora) | Fine-tuned llama2-13b model with LoRA | Single-Task |
#Text=  | [fingpt-forecaster_dow30_llama2-7b_lora](https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora) | Fine-tuned llama2-7b model with LoRA | Single-Task |
#Text=
#Text=  
#Text=## Tutorials
#Text=[[Training] Beginner’s Guide to FinGPT: Training with LoRA and ChatGLM2–6B One Notebook, $10 GPU](https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99)
#Text=
#Text=## Understanding FinGPT: An Educational Blog Series
#Text=+ [FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications
#Text=](https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8)
#Text=+ [FinGPT I: Why We Built the First Open-Source Large Language Model for Finance
#Text=](https://medium.datadriveninvestor.com/fingpt-i-why-we-built-the-first-open-source-large-language-model-for-finance-c01b5517ca)
#Text=+ [FinGPT II: Cracking the Financial Sentiment Analysis Task Using Instruction Tuning of General-Purpose Large Language Models
#Text=](https://medium.datadriveninvestor.com/fingpt-ii-cracking-the-financial-sentiment-analysis-task-using-instruction-tuning-of-3333bce428c4)
#Text=
#Text=
#Text=## FinGPT Ecosystem
#Text=### FinGPT embraces a full-stack framework for FinLLMs with five layers:
#Text=1.
58-1	13054-13060	Please	_	_	
58-2	13061-13067	choose	_	_	
58-3	13068-13070	an	_	_	
58-4	13071-13077	answer	_	_	
58-5	13078-13082	from	_	_	
58-6	13083-13084	{	_	_	
58-7	13084-13087	Yes	_	_	
58-8	13087-13088	/	_	_	
58-9	13088-13090	No	_	_	
58-10	13090-13091	}	_	_	
58-11	13091-13092	.	_	_	
58-12	13092-13093	'	_	_	
58-13	13093-13094	,	_	_	
58-14	13101-13102	'	_	_	
58-15	13102-13108	Please	_	_	
58-16	13109-13116	extract	_	_	
58-17	13117-13125	entities	_	_	
58-18	13126-13129	and	_	_	
58-19	13130-13135	their	_	_	
58-20	13136-13141	types	_	_	
58-21	13142-13146	from	_	_	
58-22	13147-13150	the	_	_	
58-23	13151-13156	input	_	_	
58-24	13157-13165	sentence	_	_	
58-25	13165-13166	,	_	_	
58-26	13167-13173	entity	_	_	
58-27	13174-13179	types	_	_	
58-28	13180-13186	should	_	_	
58-29	13187-13189	be	_	_	
58-30	13190-13196	chosen	_	_	
58-31	13197-13201	from	_	_	
58-32	13202-13203	{	_	_	
58-33	13203-13209	person	_	_	
58-34	13209-13210	/	_	_	
58-35	13210-13222	organization	_	_	
58-36	13222-13223	/	_	_	
58-37	13223-13231	location	_	_	
58-38	13231-13232	}	_	_	
58-39	13232-13233	.	_	_	
58-40	13233-13234	'	_	_	
58-41	13234-13235	,	_	_	
58-42	13235-13236	]	_	_	
58-43	13237-13238	`	_	_	
58-44	13238-13239	`	_	_	
58-45	13239-13240	`	_	_	
58-46	13244-13245	|	_	_	
58-47	13246-13252	Models	_	_	
58-48	13253-13254	|	_	_	
58-49	13255-13266	Description	_	_	
58-50	13268-13269	|	_	_	
58-51	13270-13278	Function	_	_	
58-52	13279-13280	|	_	_	
58-53	13283-13284	|	_	_	
58-54	13285-13286	-	_	_	
58-55	13286-13287	-	_	_	
58-56	13287-13288	-	_	_	
58-57	13288-13289	-	_	_	
58-58	13289-13290	-	_	_	
58-59	13290-13291	-	_	_	
58-60	13291-13292	-	_	_	
58-61	13292-13293	-	_	_	
58-62	13293-13294	-	_	_	
58-63	13295-13296	|	_	_	
58-64	13297-13298	-	_	_	
58-65	13298-13299	-	_	_	
58-66	13299-13300	-	_	_	
58-67	13300-13301	-	_	_	
58-68	13301-13302	-	_	_	
58-69	13302-13303	-	_	_	
58-70	13303-13304	-	_	_	
58-71	13304-13305	-	_	_	
58-72	13305-13306	-	_	_	
58-73	13306-13307	-	_	_	
58-74	13307-13308	-	_	_	
58-75	13308-13309	-	_	_	
58-76	13309-13310	-	_	_	
58-77	13310-13311	-	_	_	
58-78	13311-13312	-	_	_	
58-79	13312-13313	-	_	_	
58-80	13313-13314	-	_	_	
58-81	13314-13315	-	_	_	
58-82	13315-13316	-	_	_	
58-83	13316-13317	-	_	_	
58-84	13317-13318	-	_	_	
58-85	13319-13320	|	_	_	
58-86	13320-13321	-	_	_	
58-87	13321-13322	-	_	_	
58-88	13322-13323	-	_	_	
58-89	13323-13324	-	_	_	
58-90	13324-13325	-	_	_	
58-91	13325-13326	-	_	_	
58-92	13326-13327	-	_	_	
58-93	13327-13328	-	_	_	
58-94	13328-13329	-	_	_	
58-95	13329-13330	-	_	_	
58-96	13330-13331	-	_	_	
58-97	13331-13332	-	_	_	
58-98	13332-13333	-	_	_	
58-99	13333-13334	-	_	_	
58-100	13334-13335	-	_	_	
58-101	13335-13336	-	_	_	
58-102	13337-13338	|	_	_	
58-103	13341-13342	|	_	_	
58-104	13343-13344	[	_	_	
58-105	13344-13360	fingpt-mt_llama2	*[53]	SOFTWARE[53]	
58-106	13360-13361	-	*[53]	SOFTWARE[53]	
58-107	13361-13368	7b_lora	*[53]	SOFTWARE[53]	
58-108	13368-13369	]	_	_	
58-109	13369-13370	(	_	_	
58-110	13370-13375	https	_	_	
58-111	13375-13376	:	_	_	
58-112	13376-13377	/	_	_	
58-113	13377-13378	/	_	_	
58-114	13378-13392	huggingface.co	_	_	
58-115	13392-13393	/	_	_	
58-116	13393-13399	FinGPT	*[54]	SOFTWARE[54]	
58-117	13399-13400	/	*[54]	SOFTWARE[54]	
58-118	13400-13416	fingpt-mt_llama2	*[54]	SOFTWARE[54]	
58-119	13416-13417	-	*[54]	SOFTWARE[54]	
58-120	13417-13424	7b_lora	*[54]	SOFTWARE[54]	
58-121	13424-13425	)	_	_	
58-122	13425-13426	|	_	_	
58-123	13427-13437	Fine-tuned	_	_	
58-124	13438-13444	Llama2	*[55]	SOFTWARE[55]	
58-125	13444-13445	-	*[55]	SOFTWARE[55]	
58-126	13445-13447	7b	*[55]	SOFTWARE[55]	
58-127	13448-13453	model	_	_	
58-128	13454-13458	with	_	_	
58-129	13459-13463	LoRA	_	_	
58-130	13464-13465	|	_	_	
58-131	13466-13476	Multi-Task	_	_	
58-132	13477-13478	|	_	_	
58-133	13481-13482	|	_	_	
58-134	13483-13484	[	_	_	
58-135	13484-13500	fingpt-mt_falcon	*[56]	SOFTWARE[56]	
58-136	13500-13501	-	*[56]	SOFTWARE[56]	
58-137	13501-13508	7b_lora	*[56]	SOFTWARE[56]	
58-138	13508-13509	]	_	_	
58-139	13509-13510	(	_	_	
58-140	13510-13515	https	_	_	
58-141	13515-13516	:	_	_	
58-142	13516-13517	/	_	_	
58-143	13517-13518	/	_	_	
58-144	13518-13532	huggingface.co	_	_	
58-145	13532-13533	/	_	_	
58-146	13533-13539	FinGPT	*[57]	SOFTWARE[57]	
58-147	13539-13540	/	*[57]	SOFTWARE[57]	
58-148	13540-13556	fingpt-mt_falcon	*[57]	SOFTWARE[57]	
58-149	13556-13557	-	*[57]	SOFTWARE[57]	
58-150	13557-13564	7b_lora	*[57]	SOFTWARE[57]	
58-151	13564-13565	)	_	_	
58-152	13565-13566	|	_	_	
58-153	13567-13577	Fine-tuned	_	_	
58-154	13578-13584	falcon	*[58]	SOFTWARE[58]	
58-155	13584-13585	-	*[58]	SOFTWARE[58]	
58-156	13585-13587	7b	*[58]	SOFTWARE[58]	
58-157	13588-13593	model	_	_	
58-158	13594-13598	with	_	_	
58-159	13599-13603	LoRA	_	_	
58-160	13605-13606	|	_	_	
58-161	13607-13617	Multi-Task	_	_	
58-162	13618-13619	|	_	_	
58-163	13622-13623	|	_	_	
58-164	13624-13625	[	_	_	
58-165	13625-13640	fingpt-mt_bloom	*[59]	SOFTWARE[59]	
58-166	13640-13641	-	*[59]	SOFTWARE[59]	
58-167	13641-13644	7b1	*[59]	SOFTWARE[59]	
58-168	13644-13645	_	*[59]	SOFTWARE[59]	
58-169	13645-13649	lora	*[59]	SOFTWARE[59]	
58-170	13649-13650	]	_	_	
58-171	13650-13651	(	_	_	
58-172	13651-13656	https	_	_	
58-173	13656-13657	:	_	_	
58-174	13657-13658	/	_	_	
58-175	13658-13659	/	_	_	
58-176	13659-13673	huggingface.co	_	_	
58-177	13673-13674	/	_	_	
58-178	13674-13680	FinGPT	*[60]	SOFTWARE[60]	
58-179	13680-13681	/	*[60]	SOFTWARE[60]	
58-180	13681-13696	fingpt-mt_bloom	*[60]	SOFTWARE[60]	
58-181	13696-13697	-	*[60]	SOFTWARE[60]	
58-182	13697-13700	7b1	*[60]	SOFTWARE[60]	
58-183	13700-13701	_	*[60]	SOFTWARE[60]	
58-184	13701-13705	lora	*[60]	SOFTWARE[60]	
58-185	13705-13706	)	_	_	
58-186	13707-13708	|	_	_	
58-187	13709-13719	Fine-tuned	_	_	
58-188	13720-13725	bloom	*[61]	SOFTWARE[61]	
58-189	13725-13726	-	*[61]	SOFTWARE[61]	
58-190	13726-13729	7b1	*[61]	SOFTWARE[61]	
58-191	13730-13735	model	_	_	
58-192	13736-13740	with	_	_	
58-193	13741-13745	LoRA	_	_	
58-194	13746-13747	|	_	_	
58-195	13748-13758	Multi-Task	_	_	
58-196	13759-13760	|	_	_	
58-197	13763-13764	|	_	_	
58-198	13765-13766	[	_	_	
58-199	13766-13779	fingpt-mt_mpt	*[62]	SOFTWARE[62]	
58-200	13779-13780	-	*[62]	SOFTWARE[62]	
58-201	13780-13787	7b_lora	*[62]	SOFTWARE[62]	
58-202	13787-13788	]	_	_	
58-203	13788-13789	(	_	_	
58-204	13789-13794	https	_	_	
58-205	13794-13795	:	_	_	
58-206	13795-13796	/	_	_	
58-207	13796-13797	/	_	_	
58-208	13797-13811	huggingface.co	_	_	
58-209	13811-13812	/	_	_	
58-210	13812-13818	FinGPT	*[63]	SOFTWARE[63]	
58-211	13818-13819	/	*[63]	SOFTWARE[63]	
58-212	13819-13832	fingpt-mt_mpt	*[63]	SOFTWARE[63]	
58-213	13832-13833	-	*[63]	SOFTWARE[63]	
58-214	13833-13840	7b_lora	*[63]	SOFTWARE[63]	
58-215	13840-13841	)	_	_	
58-216	13842-13843	|	_	_	
58-217	13844-13854	Fine-tuned	_	_	
58-218	13855-13858	mpt	*[64]	SOFTWARE[64]	
58-219	13858-13859	-	*[64]	SOFTWARE[64]	
58-220	13859-13861	7b	*[64]	SOFTWARE[64]	
58-221	13862-13867	model	_	_	
58-222	13868-13872	with	_	_	
58-223	13873-13877	LoRA	_	_	
58-224	13878-13879	|	_	_	
58-225	13880-13890	Multi-Task	_	_	
58-226	13891-13892	|	_	_	
58-227	13895-13896	|	_	_	
58-228	13897-13898	[	_	_	
58-229	13898-13916	fingpt-mt_chatglm2	*[65]	SOFTWARE[65]	
58-230	13916-13917	-	*[65]	SOFTWARE[65]	
58-231	13917-13924	6b_lora	*[65]	SOFTWARE[65]	
58-232	13924-13925	]	_	_	
58-233	13925-13926	(	_	_	
58-234	13926-13931	https	_	_	
58-235	13931-13932	:	_	_	
58-236	13932-13933	/	_	_	
58-237	13933-13934	/	_	_	
58-238	13934-13948	huggingface.co	_	_	
58-239	13948-13949	/	_	_	
58-240	13949-13955	FinGPT	*[66]	SOFTWARE[66]	
58-241	13955-13956	/	*[66]	SOFTWARE[66]	
58-242	13956-13974	fingpt-mt_chatglm2	*[66]	SOFTWARE[66]	
58-243	13974-13975	-	*[66]	SOFTWARE[66]	
58-244	13975-13982	6b_lora	*[66]	SOFTWARE[66]	
58-245	13982-13983	)	_	_	
58-246	13984-13985	|	_	_	
58-247	13986-13996	Fine-tuned	_	_	
58-248	13997-14004	chatglm	*[67]	SOFTWARE[67]	
58-249	14004-14005	-	*[67]	SOFTWARE[67]	
58-250	14005-14007	6b	*[67]	SOFTWARE[67]	
58-251	14008-14013	model	_	_	
58-252	14014-14018	with	_	_	
58-253	14019-14023	LoRA	_	_	
58-254	14024-14025	|	_	_	
58-255	14026-14036	Multi-Task	_	_	
58-256	14037-14038	|	_	_	
58-257	14041-14042	|	_	_	
58-258	14043-14044	[	_	_	
58-259	14044-14058	fingpt-mt_qwen	_	_	
58-260	14058-14059	-	_	_	
58-261	14059-14066	7b_lora	_	_	
58-262	14066-14067	]	_	_	
58-263	14067-14068	(	_	_	
58-264	14068-14073	https	_	_	
58-265	14073-14074	:	_	_	
58-266	14074-14075	/	_	_	
58-267	14075-14076	/	_	_	
58-268	14076-14090	huggingface.co	_	_	
58-269	14090-14091	/	_	_	
58-270	14091-14097	FinGPT	*[68]	SOFTWARE[68]	
58-271	14097-14098	/	*[68]	SOFTWARE[68]	
58-272	14098-14112	fingpt-mt_qwen	*[68]	SOFTWARE[68]	
58-273	14112-14113	-	*[68]	SOFTWARE[68]	
58-274	14113-14120	7b_lora	*[68]	SOFTWARE[68]	
58-275	14120-14121	)	_	_	
58-276	14122-14123	|	_	_	
58-277	14124-14134	Fine-tuned	_	_	
58-278	14135-14139	qwen	*[69]	SOFTWARE[69]	
58-279	14139-14140	-	*[69]	SOFTWARE[69]	
58-280	14140-14142	7b	*[69]	SOFTWARE[69]	
58-281	14143-14148	model	_	_	
58-282	14149-14153	with	_	_	
58-283	14154-14158	LoRA	_	_	
58-284	14159-14160	|	_	_	
58-285	14161-14171	Multi-Task	_	_	
58-286	14172-14173	|	_	_	
58-287	14176-14177	|	_	_	
58-288	14178-14179	[	_	_	
58-289	14179-14202	fingpt-sentiment_llama2	*[70]	SOFTWARE[70]	
58-290	14202-14203	-	*[70]	SOFTWARE[70]	
58-291	14203-14211	13b_lora	*[70]	SOFTWARE[70]	
58-292	14211-14212	]	_	_	
58-293	14212-14213	(	_	_	
58-294	14213-14218	https	_	_	
58-295	14218-14219	:	_	_	
58-296	14219-14220	/	_	_	
58-297	14220-14221	/	_	_	
58-298	14221-14235	huggingface.co	_	_	
58-299	14235-14236	/	_	_	
58-300	14236-14242	FinGPT	*[71]	SOFTWARE[71]	
58-301	14242-14243	/	*[71]	SOFTWARE[71]	
58-302	14243-14266	fingpt-sentiment_llama2	*[71]	SOFTWARE[71]	
58-303	14266-14267	-	*[71]	SOFTWARE[71]	
58-304	14267-14275	13b_lora	*[71]	SOFTWARE[71]	
58-305	14275-14276	)	_	_	
58-306	14277-14278	|	_	_	
58-307	14279-14289	Fine-tuned	_	_	
58-308	14290-14296	llama2	*[72]	SOFTWARE[72]	
58-309	14296-14297	-	*[72]	SOFTWARE[72]	
58-310	14297-14300	13b	*[72]	SOFTWARE[72]	
58-311	14301-14306	model	_	_	
58-312	14307-14311	with	_	_	
58-313	14312-14316	LoRA	_	_	
58-314	14317-14318	|	_	_	
58-315	14319-14330	Single-Task	_	_	
58-316	14331-14332	|	_	_	
58-317	14335-14336	|	_	_	
58-318	14337-14338	[	_	_	
58-319	14338-14361	fingpt-forecaster_dow30	*[73]	SOFTWARE[73]	
58-320	14361-14362	_	*[73]	SOFTWARE[73]	
58-321	14362-14368	llama2	*[73]	SOFTWARE[73]	
58-322	14368-14369	-	*[73]	SOFTWARE[73]	
58-323	14369-14376	7b_lora	*[73]	SOFTWARE[73]	
58-324	14376-14377	]	_	_	
58-325	14377-14378	(	_	_	
58-326	14378-14383	https	_	_	
58-327	14383-14384	:	_	_	
58-328	14384-14385	/	_	_	
58-329	14385-14386	/	_	_	
58-330	14386-14400	huggingface.co	_	_	
58-331	14400-14401	/	_	_	
58-332	14401-14407	FinGPT	*[74]	SOFTWARE[74]	
58-333	14407-14408	/	*[74]	SOFTWARE[74]	
58-334	14408-14431	fingpt-forecaster_dow30	*[74]	SOFTWARE[74]	
58-335	14431-14432	_	*[74]	SOFTWARE[74]	
58-336	14432-14438	llama2	*[74]	SOFTWARE[74]	
58-337	14438-14439	-	*[74]	SOFTWARE[74]	
58-338	14439-14446	7b_lora	*[74]	SOFTWARE[74]	
58-339	14446-14447	)	_	_	
58-340	14448-14449	|	_	_	
58-341	14450-14460	Fine-tuned	_	_	
58-342	14461-14467	llama2	*[75]	SOFTWARE[75]	
58-343	14467-14468	-	*[75]	SOFTWARE[75]	
58-344	14468-14470	7b	*[75]	SOFTWARE[75]	
58-345	14471-14476	model	_	_	
58-346	14477-14481	with	_	_	
58-347	14482-14486	LoRA	_	_	
58-348	14487-14488	|	_	_	
58-349	14489-14500	Single-Task	_	_	
58-350	14501-14502	|	_	_	
58-351	14507-14508	#	_	_	
58-352	14508-14509	#	_	_	
58-353	14510-14519	Tutorials	_	_	
58-354	14520-14521	[	_	_	
58-355	14521-14522	[	_	_	
58-356	14522-14530	Training	_	_	
58-357	14530-14531	]	_	_	
58-358	14532-14540	Beginner	_	_	
58-359	14540-14541	’	_	_	
58-360	14541-14542	s	_	_	
58-361	14543-14548	Guide	_	_	
58-362	14549-14551	to	_	_	
58-363	14552-14558	FinGPT	*	PROJECT	
58-364	14558-14559	:	_	_	
58-365	14560-14568	Training	_	_	
58-366	14569-14573	with	_	_	
58-367	14574-14578	LoRA	_	_	
58-368	14579-14582	and	_	_	
58-369	14583-14591	ChatGLM2	*[76]	SOFTWARE[76]	
58-370	14591-14592	–	*[76]	SOFTWARE[76]	
58-371	14592-14594	6B	*[76]	SOFTWARE[76]	
58-372	14595-14598	One	_	_	
58-373	14599-14607	Notebook	_	_	
58-374	14607-14608	,	_	_	
58-375	14609-14612	$10	_	_	
58-376	14613-14616	GPU	_	_	
58-377	14616-14617	]	_	_	
58-378	14617-14618	(	_	_	
58-379	14618-14623	https	_	_	
58-380	14623-14624	:	_	_	
58-381	14624-14625	/	_	_	
58-382	14625-14626	/	_	_	
58-383	14626-14646	byfintech.medium.com	_	_	
58-384	14646-14647	/	_	_	
58-385	14647-14700	beginners-guide-to-fingpt-training-with-lora-chatglm2	_	_	
58-385.1	14666-14672	fingpt	*	PROJECT	
58-385.2	14692-14700	chatglm2	*[77]	SOFTWARE[77]	
58-386	14700-14701	-	*[77]	SOFTWARE[77]	
58-387	14701-14703	6b	*[77]	SOFTWARE[77]	
58-388	14703-14704	-	_	_	
58-389	14704-14716	9eb5ace7fe99	_	_	
58-390	14716-14717	)	_	_	
58-391	14719-14720	#	_	_	
58-392	14720-14721	#	_	_	
58-393	14722-14735	Understanding	_	_	
58-394	14736-14742	FinGPT	*	PROJECT	
58-395	14742-14743	:	_	_	
58-396	14744-14746	An	_	_	
58-397	14747-14758	Educational	_	_	
58-398	14759-14763	Blog	_	_	
58-399	14764-14770	Series	_	_	
58-400	14771-14772	+	_	_	
58-401	14773-14774	[	_	_	
58-402	14774-14780	FinGPT	*[78]|*[79]	PUBLICATION[78]|PROJECT[79]	
58-403	14780-14781	:	*[78]	PUBLICATION[78]	
58-404	14782-14790	Powering	*[78]	PUBLICATION[78]	
58-405	14791-14794	the	*[78]	PUBLICATION[78]	
58-406	14795-14801	Future	*[78]	PUBLICATION[78]	
58-407	14802-14804	of	*[78]	PUBLICATION[78]	
58-408	14805-14812	Finance	*[78]	PUBLICATION[78]	
58-409	14813-14817	with	*[78]	PUBLICATION[78]	
58-410	14818-14820	20	*[78]	PUBLICATION[78]	
58-411	14821-14833	Cutting-Edge	*[78]	PUBLICATION[78]	
58-412	14834-14846	Applications	*[78]	PUBLICATION[78]	
58-413	14847-14848	]	_	_	
58-414	14848-14849	(	_	_	
58-415	14849-14854	https	_	_	
58-416	14854-14855	:	_	_	
58-417	14855-14856	/	_	_	
58-418	14856-14857	/	_	_	
58-419	14857-14886	medium.datadriveninvestor.com	_	_	
58-420	14886-14887	/	_	_	
58-421	14887-14929	fingpt-powering-the-future-of-finance-with	_	_	
58-421.1	14887-14893	fingpt	*	PROJECT	
58-422	14929-14930	-	_	_	
58-423	14930-14932	20	_	_	
58-424	14932-14933	-	_	_	
58-425	14933-14958	cutting-edge-applications	_	_	
58-426	14958-14959	-	_	_	
58-427	14959-14971	7c4d082ad3d8	_	_	
58-428	14971-14972	)	_	_	
58-429	14973-14974	+	_	_	
58-430	14975-14976	[	_	_	
58-431	14976-14982	FinGPT	*	PROJECT	
58-432	14983-14984	I	_	_	
58-433	14984-14985	:	_	_	
58-434	14986-14989	Why	_	_	
58-435	14990-14992	We	_	_	
58-436	14993-14998	Built	_	_	
58-437	14999-15002	the	_	_	
58-438	15003-15008	First	_	_	
58-439	15009-15020	Open-Source	_	_	
58-440	15021-15026	Large	_	_	
58-441	15027-15035	Language	_	_	
58-442	15036-15041	Model	_	_	
58-443	15042-15045	for	_	_	
58-444	15046-15053	Finance	_	_	
58-445	15054-15055	]	_	_	
58-446	15055-15056	(	_	_	
58-447	15056-15061	https	_	_	
58-448	15061-15062	:	_	_	
58-449	15062-15063	/	_	_	
58-450	15063-15064	/	_	_	
58-451	15064-15093	medium.datadriveninvestor.com	_	_	
58-452	15093-15094	/	_	_	
58-453	15094-15181	fingpt-i-why-we-built-the-first-open-source-large-language-model-for-finance-c01b5517ca	_	_	
58-454	15181-15182	)	_	_	
58-455	15183-15184	+	_	_	
58-456	15185-15186	[	_	_	
58-457	15186-15192	FinGPT	*	PROJECT	
58-458	15193-15195	II	_	_	
58-459	15195-15196	:	_	_	
58-460	15197-15205	Cracking	_	_	
58-461	15206-15209	the	_	_	
58-462	15210-15219	Financial	_	_	
58-463	15220-15229	Sentiment	_	_	
58-464	15230-15238	Analysis	_	_	
58-465	15239-15243	Task	_	_	
58-466	15244-15249	Using	_	_	
58-467	15250-15261	Instruction	_	_	
58-468	15262-15268	Tuning	_	_	
58-469	15269-15271	of	_	_	
58-470	15272-15287	General-Purpose	_	_	
58-471	15288-15293	Large	_	_	
58-472	15294-15302	Language	_	_	
58-473	15303-15309	Models	_	_	
58-474	15310-15311	]	_	_	
58-475	15311-15312	(	_	_	
58-476	15312-15317	https	_	_	
58-477	15317-15318	:	_	_	
58-478	15318-15319	/	_	_	
58-479	15319-15320	/	_	_	
58-480	15320-15349	medium.datadriveninvestor.com	_	_	
58-481	15349-15350	/	_	_	
58-482	15350-15434	fingpt-ii-cracking-the-financial-sentiment-analysis-task-using-instruction-tuning-of	_	_	
58-483	15434-15435	-	_	_	
58-484	15435-15447	3333bce428c4	_	_	
58-485	15447-15448	)	_	_	
58-486	15451-15452	#	_	_	
58-487	15452-15453	#	_	_	
58-488	15454-15460	FinGPT	*	PROJECT	
58-489	15461-15470	Ecosystem	_	_	
58-490	15471-15472	#	_	_	
58-491	15472-15473	#	_	_	
58-492	15473-15474	#	_	_	
58-493	15475-15481	FinGPT	*	PROJECT	
58-494	15482-15490	embraces	_	_	
58-495	15491-15492	a	_	_	
58-496	15493-15503	full-stack	_	_	
58-497	15504-15513	framework	_	_	
58-498	15514-15517	for	_	_	
58-499	15518-15525	FinLLMs	_	_	
58-500	15526-15530	with	_	_	
58-501	15531-15535	five	_	_	
58-502	15536-15542	layers	_	_	
58-503	15542-15543	:	_	_	
58-504	15544-15545	1	_	_	
58-505	15545-15546	.	_	_	

#Text=**Data source layer**: This layer assures comprehensive market coverage, addressing the temporal sensitivity of financial data through real-time information capture.
#Text=2.
59-1	15547-15548	*	_	_	
59-2	15548-15549	*	_	_	
59-3	15549-15553	Data	_	_	
59-4	15554-15560	source	_	_	
59-5	15561-15566	layer	_	_	
59-6	15566-15567	*	_	_	
59-7	15567-15568	*	_	_	
59-8	15568-15569	:	_	_	
59-9	15570-15574	This	_	_	
59-10	15575-15580	layer	_	_	
59-11	15581-15588	assures	_	_	
59-12	15589-15602	comprehensive	_	_	
59-13	15603-15609	market	_	_	
59-14	15610-15618	coverage	_	_	
59-15	15618-15619	,	_	_	
59-16	15620-15630	addressing	_	_	
59-17	15631-15634	the	_	_	
59-18	15635-15643	temporal	_	_	
59-19	15644-15655	sensitivity	_	_	
59-20	15656-15658	of	_	_	
59-21	15659-15668	financial	_	_	
59-22	15669-15673	data	_	_	
59-23	15674-15681	through	_	_	
59-24	15682-15691	real-time	_	_	
59-25	15692-15703	information	_	_	
59-26	15704-15711	capture	_	_	
59-27	15711-15712	.	_	_	
59-28	15713-15714	2	_	_	
59-29	15714-15715	.	_	_	

#Text=**Data engineering layer**: Primed for real-time NLP data processing, this layer tackles the inherent challenges of high temporal sensitivity and low signal-to-noise ratio in financial data.
#Text=3.
60-1	15716-15717	*	_	_	
60-2	15717-15718	*	_	_	
60-3	15718-15722	Data	_	_	
60-4	15723-15734	engineering	_	_	
60-5	15735-15740	layer	_	_	
60-6	15740-15741	*	_	_	
60-7	15741-15742	*	_	_	
60-8	15742-15743	:	_	_	
60-9	15744-15750	Primed	_	_	
60-10	15751-15754	for	_	_	
60-11	15755-15764	real-time	_	_	
60-12	15765-15768	NLP	_	_	
60-13	15769-15773	data	_	_	
60-14	15774-15784	processing	_	_	
60-15	15784-15785	,	_	_	
60-16	15786-15790	this	_	_	
60-17	15791-15796	layer	_	_	
60-18	15797-15804	tackles	_	_	
60-19	15805-15808	the	_	_	
60-20	15809-15817	inherent	_	_	
60-21	15818-15828	challenges	_	_	
60-22	15829-15831	of	_	_	
60-23	15832-15836	high	_	_	
60-24	15837-15845	temporal	_	_	
60-25	15846-15857	sensitivity	_	_	
60-26	15858-15861	and	_	_	
60-27	15862-15865	low	_	_	
60-28	15866-15881	signal-to-noise	_	_	
60-29	15882-15887	ratio	_	_	
60-30	15888-15890	in	_	_	
60-31	15891-15900	financial	_	_	
60-32	15901-15905	data	_	_	
60-33	15905-15906	.	_	_	
60-34	15907-15908	3	_	_	
60-35	15908-15909	.	_	_	

#Text=**LLMs layer**: Focusing on a range of fine-tuning methodologies such as LoRA, this layer mitigates the highly dynamic nature of financial data, ensuring the model’s relevance and accuracy.
#Text=4.
61-1	15910-15911	*	_	_	
61-2	15911-15912	*	_	_	
61-3	15912-15916	LLMs	_	_	
61-4	15917-15922	layer	_	_	
61-5	15922-15923	*	_	_	
61-6	15923-15924	*	_	_	
61-7	15924-15925	:	_	_	
61-8	15926-15934	Focusing	_	_	
61-9	15935-15937	on	_	_	
61-10	15938-15939	a	_	_	
61-11	15940-15945	range	_	_	
61-12	15946-15948	of	_	_	
61-13	15949-15960	fine-tuning	_	_	
61-14	15961-15974	methodologies	_	_	
61-15	15975-15979	such	_	_	
61-16	15980-15982	as	_	_	
61-17	15983-15987	LoRA	_	_	
61-18	15987-15988	,	_	_	
61-19	15989-15993	this	_	_	
61-20	15994-15999	layer	_	_	
61-21	16000-16009	mitigates	_	_	
61-22	16010-16013	the	_	_	
61-23	16014-16020	highly	_	_	
61-24	16021-16028	dynamic	_	_	
61-25	16029-16035	nature	_	_	
61-26	16036-16038	of	_	_	
61-27	16039-16048	financial	_	_	
61-28	16049-16053	data	_	_	
61-29	16053-16054	,	_	_	
61-30	16055-16063	ensuring	_	_	
61-31	16064-16067	the	_	_	
61-32	16068-16073	model	_	_	
61-33	16073-16074	’	_	_	
61-34	16074-16075	s	_	_	
61-35	16076-16085	relevance	_	_	
61-36	16086-16089	and	_	_	
61-37	16090-16098	accuracy	_	_	
61-38	16098-16099	.	_	_	
61-39	16100-16101	4	_	_	
61-40	16101-16102	.	_	_	

#Text=**Task layer**: This layer is responsible for executing fundamental tasks.
62-1	16103-16104	*	_	_	
62-2	16104-16105	*	_	_	
62-3	16105-16109	Task	_	_	
62-4	16110-16115	layer	_	_	
62-5	16115-16116	*	_	_	
62-6	16116-16117	*	_	_	
62-7	16117-16118	:	_	_	
62-8	16119-16123	This	_	_	
62-9	16124-16129	layer	_	_	
62-10	16130-16132	is	_	_	
62-11	16133-16144	responsible	_	_	
62-12	16145-16148	for	_	_	
62-13	16149-16158	executing	_	_	
62-14	16159-16170	fundamental	_	_	
62-15	16171-16176	tasks	_	_	
62-16	16176-16177	.	_	_	

#Text=These tasks serve as the benchmarks for performance evaluations and cross-comparisons in the realm of FinLLMs
#Text=5.
63-1	16178-16183	These	_	_	
63-2	16184-16189	tasks	_	_	
63-3	16190-16195	serve	_	_	
63-4	16196-16198	as	_	_	
63-5	16199-16202	the	_	_	
63-6	16203-16213	benchmarks	_	_	
63-7	16214-16217	for	_	_	
63-8	16218-16229	performance	_	_	
63-9	16230-16241	evaluations	_	_	
63-10	16242-16245	and	_	_	
63-11	16246-16263	cross-comparisons	_	_	
63-12	16264-16266	in	_	_	
63-13	16267-16270	the	_	_	
63-14	16271-16276	realm	_	_	
63-15	16277-16279	of	_	_	
63-16	16280-16287	FinLLMs	_	_	
63-17	16288-16289	5	_	_	
63-18	16289-16290	.	_	_	

#Text=**Application layer**: Showcasing practical applications and demos, this layer highlights the potential capability of FinGPT in the financial sector
64-1	16291-16292	*	_	_	
64-2	16292-16293	*	_	_	
64-3	16293-16304	Application	_	_	
64-4	16305-16310	layer	_	_	
64-5	16310-16311	*	_	_	
64-6	16311-16312	*	_	_	
64-7	16312-16313	:	_	_	
64-8	16314-16324	Showcasing	_	_	
64-9	16325-16334	practical	_	_	
64-10	16335-16347	applications	_	_	
64-11	16348-16351	and	_	_	
64-12	16352-16357	demos	_	_	
64-13	16357-16358	,	_	_	
64-14	16359-16363	this	_	_	
64-15	16364-16369	layer	_	_	
64-16	16370-16380	highlights	_	_	
64-17	16381-16384	the	_	_	
64-18	16385-16394	potential	_	_	
64-19	16395-16405	capability	_	_	
64-20	16406-16408	of	_	_	
64-21	16409-16415	FinGPT	_	_	
64-22	16416-16418	in	_	_	
64-23	16419-16422	the	_	_	
64-24	16423-16432	financial	_	_	
64-25	16433-16439	sector	_	_	

#Text=.
65-1	16439-16440	.	_	_	

#Text=* FinGPT Framework: Open-Source Financial Large Language Models
#Text=
#Text=<div align="center">
#Text=<img align="center" src=figs/FinGPT_framework_20240301.png>
#Text=</div>
#Text=
#Text=* [FinGPT-RAG](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_RAG): We present a retrieval-augmented large language model framework specifically designed for financial sentiment analysis, optimizing information depth and context through external knowledge retrieval, thereby ensuring nuanced predictions.
66-1	16442-16443	*	_	_	
66-2	16444-16450	FinGPT	_	_	
66-3	16451-16460	Framework	_	_	
66-4	16460-16461	:	_	_	
66-5	16462-16473	Open-Source	_	_	
66-6	16474-16483	Financial	_	_	
66-7	16484-16489	Large	_	_	
66-8	16490-16498	Language	_	_	
66-9	16499-16505	Models	_	_	
66-10	16507-16508	<	_	_	
66-11	16508-16511	div	_	_	
66-12	16512-16517	align	_	_	
66-13	16517-16518	=	_	_	
66-14	16518-16519	"	_	_	
66-15	16519-16525	center	_	_	
66-16	16525-16526	"	_	_	
66-17	16526-16527	>	_	_	
66-18	16528-16529	<	_	_	
66-19	16529-16532	img	_	_	
66-20	16533-16538	align	_	_	
66-21	16538-16539	=	_	_	
66-22	16539-16540	"	_	_	
66-23	16540-16546	center	_	_	
66-24	16546-16547	"	_	_	
66-25	16548-16551	src	_	_	
66-26	16551-16552	=	_	_	
66-27	16552-16556	figs	_	_	
66-28	16556-16557	/	_	_	
66-29	16557-16573	FinGPT_framework	_	_	
66-30	16573-16574	_	_	_	
66-31	16574-16582	20240301	_	_	
66-32	16582-16583	.	_	_	
66-33	16583-16586	png	_	_	
66-34	16586-16587	>	_	_	
66-35	16588-16589	<	_	_	
66-36	16589-16590	/	_	_	
66-37	16590-16593	div	_	_	
66-38	16593-16594	>	_	_	
66-39	16596-16597	*	_	_	
66-40	16598-16599	[	_	_	
66-41	16599-16609	FinGPT-RAG	_	_	
66-42	16609-16610	]	_	_	
66-43	16610-16611	(	_	_	
66-44	16611-16616	https	_	_	
66-45	16616-16617	:	_	_	
66-46	16617-16618	/	_	_	
66-47	16618-16619	/	_	_	
66-48	16619-16629	github.com	_	_	
66-49	16629-16630	/	_	_	
66-50	16630-16651	AI4Finance-Foundation	_	_	
66-51	16651-16652	/	_	_	
66-52	16652-16658	FinGPT	_	_	
66-53	16658-16659	/	_	_	
66-54	16659-16663	tree	_	_	
66-55	16663-16664	/	_	_	
66-56	16664-16670	master	_	_	
66-57	16670-16671	/	_	_	
66-58	16671-16677	fingpt	_	_	
66-59	16677-16678	/	_	_	
66-60	16678-16688	FinGPT_RAG	_	_	
66-61	16688-16689	)	_	_	
66-62	16689-16690	:	_	_	
66-63	16691-16693	We	_	_	
66-64	16694-16701	present	_	_	
66-65	16702-16703	a	_	_	
66-66	16704-16723	retrieval-augmented	_	_	
66-67	16724-16729	large	_	_	
66-68	16730-16738	language	_	_	
66-69	16739-16744	model	_	_	
66-70	16745-16754	framework	_	_	
66-71	16755-16767	specifically	_	_	
66-72	16768-16776	designed	_	_	
66-73	16777-16780	for	_	_	
66-74	16781-16790	financial	_	_	
66-75	16791-16800	sentiment	_	_	
66-76	16801-16809	analysis	_	_	
66-77	16809-16810	,	_	_	
66-78	16811-16821	optimizing	_	_	
66-79	16822-16833	information	_	_	
66-80	16834-16839	depth	_	_	
66-81	16840-16843	and	_	_	
66-82	16844-16851	context	_	_	
66-83	16852-16859	through	_	_	
66-84	16860-16868	external	_	_	
66-85	16869-16878	knowledge	_	_	
66-86	16879-16888	retrieval	_	_	
66-87	16888-16889	,	_	_	
66-88	16890-16897	thereby	_	_	
66-89	16898-16906	ensuring	_	_	
66-90	16907-16914	nuanced	_	_	
66-91	16915-16926	predictions	_	_	
66-92	16926-16927	.	_	_	

#Text=<div align="center">
#Text=<img align="center" src=figs/FinGPT_RAG_framework.png>
#Text=</div>
#Text=
#Text=* [FinGPT-FinNLP](https://github.com/AI4Finance-Foundation/FinNLP): FinNLP provides a playground for all people interested in LLMs and NLP in Finance.
67-1	16929-16930	<	_	_	
67-2	16930-16933	div	_	_	
67-3	16934-16939	align	_	_	
67-4	16939-16940	=	_	_	
67-5	16940-16941	"	_	_	
67-6	16941-16947	center	_	_	
67-7	16947-16948	"	_	_	
67-8	16948-16949	>	_	_	
67-9	16950-16951	<	_	_	
67-10	16951-16954	img	_	_	
67-11	16955-16960	align	_	_	
67-12	16960-16961	=	_	_	
67-13	16961-16962	"	_	_	
67-14	16962-16968	center	_	_	
67-15	16968-16969	"	_	_	
67-16	16970-16973	src	_	_	
67-17	16973-16974	=	_	_	
67-18	16974-16978	figs	_	_	
67-19	16978-16979	/	_	_	
67-20	16979-17003	FinGPT_RAG_framework.png	_	_	
67-21	17003-17004	>	_	_	
67-22	17005-17006	<	_	_	
67-23	17006-17007	/	_	_	
67-24	17007-17010	div	_	_	
67-25	17010-17011	>	_	_	
67-26	17013-17014	*	_	_	
67-27	17015-17016	[	_	_	
67-28	17016-17029	FinGPT-FinNLP	_	_	
67-29	17029-17030	]	_	_	
67-30	17030-17031	(	_	_	
67-31	17031-17036	https	_	_	
67-32	17036-17037	:	_	_	
67-33	17037-17038	/	_	_	
67-34	17038-17039	/	_	_	
67-35	17039-17049	github.com	_	_	
67-36	17049-17050	/	_	_	
67-37	17050-17071	AI4Finance-Foundation	_	_	
67-38	17071-17072	/	_	_	
67-39	17072-17078	FinNLP	_	_	
67-40	17078-17079	)	_	_	
67-41	17079-17080	:	_	_	
67-42	17081-17087	FinNLP	_	_	
67-43	17088-17096	provides	_	_	
67-44	17097-17098	a	_	_	
67-45	17099-17109	playground	_	_	
67-46	17110-17113	for	_	_	
67-47	17114-17117	all	_	_	
67-48	17118-17124	people	_	_	
67-49	17125-17135	interested	_	_	
67-50	17136-17138	in	_	_	
67-51	17139-17143	LLMs	_	_	
67-52	17144-17147	and	_	_	
67-53	17148-17151	NLP	_	_	
67-54	17152-17154	in	_	_	
67-55	17155-17162	Finance	_	_	
67-56	17162-17163	.	_	_	

#Text=Here we provide full pipelines for LLM training and finetuning in the field of finance.
68-1	17164-17168	Here	_	_	
68-2	17169-17171	we	_	_	
68-3	17172-17179	provide	_	_	
68-4	17180-17184	full	_	_	
68-5	17185-17194	pipelines	_	_	
68-6	17195-17198	for	_	_	
68-7	17199-17202	LLM	_	_	
68-8	17203-17211	training	_	_	
68-9	17212-17215	and	_	_	
68-10	17216-17226	finetuning	_	_	
68-11	17227-17229	in	_	_	
68-12	17230-17233	the	_	_	
68-13	17234-17239	field	_	_	
68-14	17240-17242	of	_	_	
68-15	17243-17250	finance	_	_	
68-16	17250-17251	.	_	_	

#Text=The full architecture is shown in the following picture.
69-1	17252-17255	The	_	_	
69-2	17256-17260	full	_	_	
69-3	17261-17273	architecture	_	_	
69-4	17274-17276	is	_	_	
69-5	17277-17282	shown	_	_	
69-6	17283-17285	in	_	_	
69-7	17286-17289	the	_	_	
69-8	17290-17299	following	_	_	
69-9	17300-17307	picture	_	_	
69-10	17307-17308	.	_	_	

#Text=Detail codes and introductions can be found [here](https://github.com/AI4Finance-Foundation/FinNLP).
70-1	17309-17315	Detail	_	_	
70-2	17316-17321	codes	_	_	
70-3	17322-17325	and	_	_	
70-4	17326-17339	introductions	_	_	
70-5	17340-17343	can	_	_	
70-6	17344-17346	be	_	_	
70-7	17347-17352	found	_	_	
70-8	17353-17354	[	_	_	
70-9	17354-17358	here	_	_	
70-10	17358-17359	]	_	_	
70-11	17359-17360	(	_	_	
70-12	17360-17365	https	_	_	
70-13	17365-17366	:	_	_	
70-14	17366-17367	/	_	_	
70-15	17367-17368	/	_	_	
70-16	17368-17378	github.com	_	_	
70-17	17378-17379	/	_	_	
70-18	17379-17400	AI4Finance-Foundation	_	_	
70-19	17400-17401	/	_	_	
70-20	17401-17407	FinNLP	_	_	
70-21	17407-17408	)	_	_	
70-22	17408-17409	.	_	_	

#Text=Or you may refer to the [wiki](https://ai4finance-foundation.github.io/FinNLP/)
#Text=
#Text=<div align="center">
#Text=<img align="center" src=figs/FinGPT_FinNLP_data_source.png>
#Text=</div>
#Text=
#Text=* [FinGPT-Benchmark](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark): We introduce a novel Instruction Tuning paradigm optimized for open-source Large Language Models (LLMs) in finance, enhancing their adaptability to diverse financial datasets while also facilitating cost-effective, systematic benchmarking from task-specific, multi-task, and zero-shot instruction tuning tasks.
71-1	17410-17412	Or	_	_	
71-2	17413-17416	you	_	_	
71-3	17417-17420	may	_	_	
71-4	17421-17426	refer	_	_	
71-5	17427-17429	to	_	_	
71-6	17430-17433	the	_	_	
71-7	17434-17435	[	_	_	
71-8	17435-17439	wiki	_	_	
71-9	17439-17440	]	_	_	
71-10	17440-17441	(	_	_	
71-11	17441-17446	https	_	_	
71-12	17446-17447	:	_	_	
71-13	17447-17448	/	_	_	
71-14	17448-17449	/	_	_	
71-15	17449-17480	ai4finance-foundation.github.io	_	_	
71-16	17480-17481	/	_	_	
71-17	17481-17487	FinNLP	_	_	
71-18	17487-17488	/	_	_	
71-19	17488-17489	)	_	_	
71-20	17491-17492	<	_	_	
71-21	17492-17495	div	_	_	
71-22	17496-17501	align	_	_	
71-23	17501-17502	=	_	_	
71-24	17502-17503	"	_	_	
71-25	17503-17509	center	_	_	
71-26	17509-17510	"	_	_	
71-27	17510-17511	>	_	_	
71-28	17512-17513	<	_	_	
71-29	17513-17516	img	_	_	
71-30	17517-17522	align	_	_	
71-31	17522-17523	=	_	_	
71-32	17523-17524	"	_	_	
71-33	17524-17530	center	_	_	
71-34	17530-17531	"	_	_	
71-35	17532-17535	src	_	_	
71-36	17535-17536	=	_	_	
71-37	17536-17540	figs	_	_	
71-38	17540-17541	/	_	_	
71-39	17541-17570	FinGPT_FinNLP_data_source.png	_	_	
71-40	17570-17571	>	_	_	
71-41	17572-17573	<	_	_	
71-42	17573-17574	/	_	_	
71-43	17574-17577	div	_	_	
71-44	17577-17578	>	_	_	
71-45	17580-17581	*	_	_	
71-46	17582-17583	[	_	_	
71-47	17583-17599	FinGPT-Benchmark	_	_	
71-48	17599-17600	]	_	_	
71-49	17600-17601	(	_	_	
71-50	17601-17606	https	_	_	
71-51	17606-17607	:	_	_	
71-52	17607-17608	/	_	_	
71-53	17608-17609	/	_	_	
71-54	17609-17619	github.com	_	_	
71-55	17619-17620	/	_	_	
71-56	17620-17641	AI4Finance-Foundation	_	_	
71-57	17641-17642	/	_	_	
71-58	17642-17648	FinGPT	*	PROJECT	
71-59	17648-17649	/	_	_	
71-60	17649-17653	tree	_	_	
71-61	17653-17654	/	_	_	
71-62	17654-17660	master	_	_	
71-63	17660-17661	/	_	_	
71-64	17661-17667	fingpt	_	_	
71-65	17667-17668	/	_	_	
71-66	17668-17684	FinGPT_Benchmark	_	_	
71-67	17684-17685	)	_	_	
71-68	17685-17686	:	_	_	
71-69	17687-17689	We	_	_	
71-70	17690-17699	introduce	_	_	
71-71	17700-17701	a	_	_	
71-72	17702-17707	novel	_	_	
71-73	17708-17719	Instruction	_	_	
71-74	17720-17726	Tuning	_	_	
71-75	17727-17735	paradigm	_	_	
71-76	17736-17745	optimized	_	_	
71-77	17746-17749	for	_	_	
71-78	17750-17761	open-source	_	_	
71-79	17762-17767	Large	_	_	
71-80	17768-17776	Language	_	_	
71-81	17777-17783	Models	_	_	
71-82	17784-17785	(	_	_	
71-83	17785-17789	LLMs	_	_	
71-84	17789-17790	)	_	_	
71-85	17791-17793	in	_	_	
71-86	17794-17801	finance	_	_	
71-87	17801-17802	,	_	_	
71-88	17803-17812	enhancing	_	_	
71-89	17813-17818	their	_	_	
71-90	17819-17831	adaptability	_	_	
71-91	17832-17834	to	_	_	
71-92	17835-17842	diverse	_	_	
71-93	17843-17852	financial	_	_	
71-94	17853-17861	datasets	_	_	
71-95	17862-17867	while	_	_	
71-96	17868-17872	also	_	_	
71-97	17873-17885	facilitating	_	_	
71-98	17886-17900	cost-effective	_	_	
71-99	17900-17901	,	_	_	
71-100	17902-17912	systematic	_	_	
71-101	17913-17925	benchmarking	_	_	
71-102	17926-17930	from	_	_	
71-103	17931-17944	task-specific	_	_	
71-104	17944-17945	,	_	_	
71-105	17946-17956	multi-task	_	_	
71-106	17956-17957	,	_	_	
71-107	17958-17961	and	_	_	
71-108	17962-17971	zero-shot	_	_	
71-109	17972-17983	instruction	_	_	
71-110	17984-17990	tuning	_	_	
71-111	17991-17996	tasks	_	_	
71-112	17996-17997	.	_	_	

#Text=<div align="center">
#Text=<img align="center" src=figs/FinGPT_Benchmark_20231110.png>
#Text=</div>
#Text=
#Text=
#Text=
#Text=## Open-Source Base Model used in the LLMs layer of FinGPT
#Text=* Feel free to contribute more open-source base models tailored for various language-specific financial markets
72-1	18001-18002	<	_	_	
72-2	18002-18005	div	_	_	
72-3	18006-18011	align	_	_	
72-4	18011-18012	=	_	_	
72-5	18012-18013	"	_	_	
72-6	18013-18019	center	_	_	
72-7	18019-18020	"	_	_	
72-8	18020-18021	>	_	_	
72-9	18022-18023	<	_	_	
72-10	18023-18026	img	_	_	
72-11	18027-18032	align	_	_	
72-12	18032-18033	=	_	_	
72-13	18033-18034	"	_	_	
72-14	18034-18040	center	_	_	
72-15	18040-18041	"	_	_	
72-16	18042-18045	src	_	_	
72-17	18045-18046	=	_	_	
72-18	18046-18050	figs	_	_	
72-19	18050-18051	/	_	_	
72-20	18051-18067	FinGPT_Benchmark	_	_	
72-21	18067-18068	_	_	_	
72-22	18068-18076	20231110	_	_	
72-23	18076-18077	.	_	_	
72-24	18077-18080	png	_	_	
72-25	18080-18081	>	_	_	
72-26	18082-18083	<	_	_	
72-27	18083-18084	/	_	_	
72-28	18084-18087	div	_	_	
72-29	18087-18088	>	_	_	
72-30	18092-18093	#	_	_	
72-31	18093-18094	#	_	_	
72-32	18095-18106	Open-Source	_	_	
72-33	18107-18111	Base	_	_	
72-34	18112-18117	Model	_	_	
72-35	18118-18122	used	_	_	
72-36	18123-18125	in	_	_	
72-37	18126-18129	the	_	_	
72-38	18130-18134	LLMs	_	_	
72-39	18135-18140	layer	_	_	
72-40	18141-18143	of	_	_	
72-41	18144-18150	FinGPT	_	_	
72-42	18151-18152	*	_	_	
72-43	18153-18157	Feel	_	_	
72-44	18158-18162	free	_	_	
72-45	18163-18165	to	_	_	
72-46	18166-18176	contribute	_	_	
72-47	18177-18181	more	_	_	
72-48	18182-18193	open-source	_	_	
72-49	18194-18198	base	_	_	
72-50	18199-18205	models	_	_	
72-51	18206-18214	tailored	_	_	
72-52	18215-18218	for	_	_	
72-53	18219-18226	various	_	_	
72-54	18227-18244	language-specific	_	_	
72-55	18245-18254	financial	_	_	
72-56	18255-18262	markets	_	_	

#Text=.
73-1	18262-18263	.	_	_	

#Text=| Base Model |Pretraining Tokens|Context Length  | Model Advantages |Model Size|Experiment Results |  Applications |
#Text=|  ----  |  ----  |  ----  |   ----  |   ----  |  ----  | ----  |
#Text=| [Llama-2](https://github.com/facebookresearch/llama)|2 Trillion|4096| Llama-2 excels on English-based market data | [llama-2-7b](https://huggingface.co/meta-llama/Llama-2-7b-hf) and [Llama-2-13b](https://huggingface.co/meta-llama/Llama-2-13b-hf) | llama-2 consistently shows superior fine-tuning results  | Financial Sentiment Analysis, Robo-Advisor |
#Text=| [Falcon](https://github.com/falconry/falcon) |1,500B|2048|  Maintains high-quality results while being more resource-efficient | [falcon-7b](https://huggingface.co/tiiuae/falcon-7b) |Good for English market data  | Financial Sentiment Analysis |
#Text=| [MPT](https://github.com/mosaicml/llm-foundry) |1T|2048| MPT models can be trained with high throughput efficiency and stable convergence | [mpt-7b](https://huggingface.co/mosaicml/mpt-7b) |Good for English market data  | Financial Sentiment Analysis |
#Text=| [Bloom](https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml#readme) |366B|2048| World’s largest open multilingual language model  | [bloom-7b1](https://huggingface.co/bigscience/bloom-7b1) |Good for English market data  | Financial Sentiment Analysis |
#Text=| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)|1.4T  |32K |Exceptional capability for Chinese language expression| [chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b) |Shows prowess for Chinese market data  | Financial Sentiment Analysis, Financial Report Summary |
#Text=| [Qwen](https://github.com/QwenLM/Qwen-7B)|2.2T  |8k |Fast response and high accuracy| [qwen-7b](https://huggingface.co/tangger/Qwen-7B-Chat) |Effective for Chinese market data  | Financial Sentiment Analysis|
#Text=| [InternLM](https://github.com/InternLM/InternLM) |1.8T  |8k |Can flexibly and independently construct workflows |[internlm-7b](https://huggingface.co/internlm/internlm-7b) |Effective for Chinese market data  | Financial Sentiment Analysis |
#Text=
#Text=* Benchmark Results for the above open-source Base Models in the financial sentiment analysis task using the same instruction template for SFT (LoRA):
#Text=  | Weighted F1/Acc  |Llama2 |Falcon |  MPT|Bloom |ChatGLM2|Qwen|InternLM |
#Text=  | --------- | ----------------- | ------------ | --------------------- | ---------------- | --------------- | ----------------- |----------------- |
#Text=  | [FPB](https://huggingface.co/datasets/financial_phrasebank) | 0.863/0.863 | 0.846/0.849  | **0.872**/**0.872**   | 0.810/0.810 | 0.850/0.849 |0.854/0.854| 0.709/0.714 |
#Text=  | [FiQA-SA](https://huggingface.co/datasets/pauri32/fiqa-2018)| **0.871**/0.855| 0.840/0.811  | 0.863/0.844 | 0.771/0.753| 0.864/**0.862** | 0.867/0.851  |0.679/0.687 |
#Text=  | [TFNS](https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment) | 0.896/0.895 | 0.893/0.893 | **0.907**/**0.907** | 0.840/0.840 | 0.859/0.858 | 0.883/0.882|0.729/0.731|
#Text=  | [NWGI](https://huggingface.co/datasets/oliverwang15/news_with_gpt_instructions) | **0.649/0.651**   | 0.636/0.638  | 0.640/0.641| 0.573/0.574| 0.619/0.629 |0.638/0.643|0.498/0.503|
#Text=
#Text=### All Thanks To Our Contributors :
#Text=<a href="https://github.com/AI4Finance-Foundation/FinGPT/graphs/contributors">
#Text=  <img src="https://contrib.rocks/image?
74-1	18265-18266	|	_	_	
74-2	18267-18271	Base	_	_	
74-3	18272-18277	Model	_	_	
74-4	18278-18279	|	_	_	
74-5	18279-18290	Pretraining	_	_	
74-6	18291-18297	Tokens	_	_	
74-7	18297-18298	|	_	_	
74-8	18298-18305	Context	_	_	
74-9	18306-18312	Length	_	_	
74-10	18314-18315	|	_	_	
74-11	18316-18321	Model	_	_	
74-12	18322-18332	Advantages	_	_	
74-13	18333-18334	|	_	_	
74-14	18334-18339	Model	_	_	
74-15	18340-18344	Size	_	_	
74-16	18344-18345	|	_	_	
74-17	18345-18355	Experiment	_	_	
74-18	18356-18363	Results	_	_	
74-19	18364-18365	|	_	_	
74-20	18367-18379	Applications	_	_	
74-21	18380-18381	|	_	_	
74-22	18382-18383	|	_	_	
74-23	18385-18386	-	_	_	
74-24	18386-18387	-	_	_	
74-25	18387-18388	-	_	_	
74-26	18388-18389	-	_	_	
74-27	18391-18392	|	_	_	
74-28	18394-18395	-	_	_	
74-29	18395-18396	-	_	_	
74-30	18396-18397	-	_	_	
74-31	18397-18398	-	_	_	
74-32	18400-18401	|	_	_	
74-33	18403-18404	-	_	_	
74-34	18404-18405	-	_	_	
74-35	18405-18406	-	_	_	
74-36	18406-18407	-	_	_	
74-37	18409-18410	|	_	_	
74-38	18413-18414	-	_	_	
74-39	18414-18415	-	_	_	
74-40	18415-18416	-	_	_	
74-41	18416-18417	-	_	_	
74-42	18419-18420	|	_	_	
74-43	18423-18424	-	_	_	
74-44	18424-18425	-	_	_	
74-45	18425-18426	-	_	_	
74-46	18426-18427	-	_	_	
74-47	18429-18430	|	_	_	
74-48	18432-18433	-	_	_	
74-49	18433-18434	-	_	_	
74-50	18434-18435	-	_	_	
74-51	18435-18436	-	_	_	
74-52	18438-18439	|	_	_	
74-53	18440-18441	-	_	_	
74-54	18441-18442	-	_	_	
74-55	18442-18443	-	_	_	
74-56	18443-18444	-	_	_	
74-57	18446-18447	|	_	_	
74-58	18448-18449	|	_	_	
74-59	18450-18451	[	_	_	
74-60	18451-18456	Llama	*[80]	SOFTWARE[80]	
74-61	18456-18457	-	*[80]	SOFTWARE[80]	
74-62	18457-18458	2	*[80]	SOFTWARE[80]	
74-63	18458-18459	]	_	_	
74-64	18459-18460	(	_	_	
74-65	18460-18465	https	_	_	
74-66	18465-18466	:	_	_	
74-67	18466-18467	/	_	_	
74-68	18467-18468	/	_	_	
74-69	18468-18478	github.com	_	_	
74-70	18478-18479	/	_	_	
74-71	18479-18495	facebookresearch	_	_	
74-72	18495-18496	/	_	_	
74-73	18496-18501	llama	*	SOFTWARE	
74-74	18501-18502	)	_	_	
74-75	18502-18503	|	_	_	
74-76	18503-18504	2	_	_	
74-77	18505-18513	Trillion	_	_	
74-78	18513-18514	|	_	_	
74-79	18514-18518	4096	_	_	
74-80	18518-18519	|	_	_	
74-81	18520-18525	Llama	*[81]	SOFTWARE[81]	
74-82	18525-18526	-	*[81]	SOFTWARE[81]	
74-83	18526-18527	2	*[81]	SOFTWARE[81]	
74-84	18528-18534	excels	_	_	
74-85	18535-18537	on	_	_	
74-86	18538-18551	English-based	_	_	
74-87	18552-18558	market	_	_	
74-88	18559-18563	data	_	_	
74-89	18564-18565	|	_	_	
74-90	18566-18567	[	_	_	
74-91	18567-18572	llama	*[82]	SOFTWARE[82]	
74-92	18572-18573	-	*[82]	SOFTWARE[82]	
74-93	18573-18574	2	*[82]	SOFTWARE[82]	
74-94	18574-18575	-	*[82]	SOFTWARE[82]	
74-95	18575-18577	7b	*[82]	SOFTWARE[82]	
74-96	18577-18578	]	_	_	
74-97	18578-18579	(	_	_	
74-98	18579-18584	https	_	_	
74-99	18584-18585	:	_	_	
74-100	18585-18586	/	_	_	
74-101	18586-18587	/	_	_	
74-102	18587-18601	huggingface.co	_	_	
74-103	18601-18602	/	_	_	
74-104	18602-18612	meta-llama	*[83]	SOFTWARE[83]	
74-105	18612-18613	/	*[83]	SOFTWARE[83]	
74-106	18613-18618	Llama	*[83]	SOFTWARE[83]	
74-107	18618-18619	-	*[83]	SOFTWARE[83]	
74-108	18619-18620	2	*[83]	SOFTWARE[83]	
74-109	18620-18621	-	*[83]	SOFTWARE[83]	
74-110	18621-18626	7b-hf	*[83]	SOFTWARE[83]	
74-111	18626-18627	)	_	_	
74-112	18628-18631	and	_	_	
74-113	18632-18633	[	_	_	
74-114	18633-18638	Llama	*[84]	SOFTWARE[84]	
74-115	18638-18639	-	*[84]	SOFTWARE[84]	
74-116	18639-18640	2	*[84]	SOFTWARE[84]	
74-117	18640-18641	-	*[84]	SOFTWARE[84]	
74-118	18641-18644	13b	*[84]	SOFTWARE[84]	
74-119	18644-18645	]	_	_	
74-120	18645-18646	(	_	_	
74-121	18646-18651	https	_	_	
74-122	18651-18652	:	_	_	
74-123	18652-18653	/	_	_	
74-124	18653-18654	/	_	_	
74-125	18654-18668	huggingface.co	_	_	
74-126	18668-18669	/	_	_	
74-127	18669-18679	meta-llama	*[85]	SOFTWARE[85]	
74-128	18679-18680	/	*[85]	SOFTWARE[85]	
74-129	18680-18685	Llama	*[85]	SOFTWARE[85]	
74-130	18685-18686	-	*[85]	SOFTWARE[85]	
74-131	18686-18687	2	*[85]	SOFTWARE[85]	
74-132	18687-18688	-	*[85]	SOFTWARE[85]	
74-133	18688-18694	13b-hf	*[85]	SOFTWARE[85]	
74-134	18694-18695	)	_	_	
74-135	18696-18697	|	_	_	
74-136	18698-18703	llama	*[86]	SOFTWARE[86]	
74-137	18703-18704	-	*[86]	SOFTWARE[86]	
74-138	18704-18705	2	*[86]	SOFTWARE[86]	
74-139	18706-18718	consistently	_	_	
74-140	18719-18724	shows	_	_	
74-141	18725-18733	superior	_	_	
74-142	18734-18745	fine-tuning	_	_	
74-143	18746-18753	results	_	_	
74-144	18755-18756	|	_	_	
74-145	18757-18766	Financial	_	_	
74-146	18767-18776	Sentiment	_	_	
74-147	18777-18785	Analysis	_	_	
74-148	18785-18786	,	_	_	
74-149	18787-18799	Robo-Advisor	_	_	
74-150	18800-18801	|	_	_	
74-151	18802-18803	|	_	_	
74-152	18804-18805	[	_	_	
74-153	18805-18811	Falcon	*	SOFTWARE	
74-154	18811-18812	]	_	_	
74-155	18812-18813	(	_	_	
74-156	18813-18818	https	_	_	
74-157	18818-18819	:	_	_	
74-158	18819-18820	/	_	_	
74-159	18820-18821	/	_	_	
74-160	18821-18831	github.com	_	_	
74-161	18831-18832	/	_	_	
74-162	18832-18840	falconry	_	_	
74-163	18840-18841	/	_	_	
74-164	18841-18847	falcon	*	SOFTWARE	
74-165	18847-18848	)	_	_	
74-166	18849-18850	|	_	_	
74-167	18850-18856	1,500B	_	_	
74-168	18856-18857	|	_	_	
74-169	18857-18861	2048	_	_	
74-170	18861-18862	|	_	_	
74-171	18864-18873	Maintains	_	_	
74-172	18874-18886	high-quality	_	_	
74-173	18887-18894	results	_	_	
74-174	18895-18900	while	_	_	
74-175	18901-18906	being	_	_	
74-176	18907-18911	more	_	_	
74-177	18912-18930	resource-efficient	_	_	
74-178	18931-18932	|	_	_	
74-179	18933-18934	[	_	_	
74-180	18934-18940	falcon	*[87]	SOFTWARE[87]	
74-181	18940-18941	-	*[87]	SOFTWARE[87]	
74-182	18941-18943	7b	*[87]	SOFTWARE[87]	
74-183	18943-18944	]	_	_	
74-184	18944-18945	(	_	_	
74-185	18945-18950	https	_	_	
74-186	18950-18951	:	_	_	
74-187	18951-18952	/	_	_	
74-188	18952-18953	/	_	_	
74-189	18953-18967	huggingface.co	_	_	
74-190	18967-18968	/	_	_	
74-191	18968-18974	tiiuae	*[88]	SOFTWARE[88]	
74-192	18974-18975	/	*[88]	SOFTWARE[88]	
74-193	18975-18981	falcon	*[88]	SOFTWARE[88]	
74-194	18981-18982	-	*[88]	SOFTWARE[88]	
74-195	18982-18984	7b	*[88]	SOFTWARE[88]	
74-196	18984-18985	)	_	_	
74-197	18986-18987	|	_	_	
74-198	18987-18991	Good	_	_	
74-199	18992-18995	for	_	_	
74-200	18996-19003	English	_	_	
74-201	19004-19010	market	_	_	
74-202	19011-19015	data	_	_	
74-203	19017-19018	|	_	_	
74-204	19019-19028	Financial	_	_	
74-205	19029-19038	Sentiment	_	_	
74-206	19039-19047	Analysis	_	_	
74-207	19048-19049	|	_	_	
74-208	19050-19051	|	_	_	
74-209	19052-19053	[	_	_	
74-210	19053-19056	MPT	*	SOFTWARE	
74-211	19056-19057	]	_	_	
74-212	19057-19058	(	_	_	
74-213	19058-19063	https	_	_	
74-214	19063-19064	:	_	_	
74-215	19064-19065	/	_	_	
74-216	19065-19066	/	_	_	
74-217	19066-19076	github.com	_	_	
74-218	19076-19077	/	_	_	
74-219	19077-19085	mosaicml	_	_	
74-220	19085-19086	/	_	_	
74-221	19086-19097	llm-foundry	_	_	
74-222	19097-19098	)	_	_	
74-223	19099-19100	|	_	_	
74-224	19100-19102	1T	_	_	
74-225	19102-19103	|	_	_	
74-226	19103-19107	2048	_	_	
74-227	19107-19108	|	_	_	
74-228	19109-19112	MPT	*	SOFTWARE	
74-229	19113-19119	models	_	_	
74-230	19120-19123	can	_	_	
74-231	19124-19126	be	_	_	
74-232	19127-19134	trained	_	_	
74-233	19135-19139	with	_	_	
74-234	19140-19144	high	_	_	
74-235	19145-19155	throughput	_	_	
74-236	19156-19166	efficiency	_	_	
74-237	19167-19170	and	_	_	
74-238	19171-19177	stable	_	_	
74-239	19178-19189	convergence	_	_	
74-240	19190-19191	|	_	_	
74-241	19192-19193	[	_	_	
74-242	19193-19196	mpt	*[89]	SOFTWARE[89]	
74-243	19196-19197	-	*[89]	SOFTWARE[89]	
74-244	19197-19199	7b	*[89]	SOFTWARE[89]	
74-245	19199-19200	]	_	_	
74-246	19200-19201	(	_	_	
74-247	19201-19206	https	_	_	
74-248	19206-19207	:	_	_	
74-249	19207-19208	/	_	_	
74-250	19208-19209	/	_	_	
74-251	19209-19223	huggingface.co	_	_	
74-252	19223-19224	/	_	_	
74-253	19224-19232	mosaicml	*[90]	SOFTWARE[90]	
74-254	19232-19233	/	*[90]	SOFTWARE[90]	
74-255	19233-19236	mpt	*[90]	SOFTWARE[90]	
74-256	19236-19237	-	*[90]	SOFTWARE[90]	
74-257	19237-19239	7b	*[90]	SOFTWARE[90]	
74-258	19239-19240	)	_	_	
74-259	19241-19242	|	_	_	
74-260	19242-19246	Good	_	_	
74-261	19247-19250	for	_	_	
74-262	19251-19258	English	_	_	
74-263	19259-19265	market	_	_	
74-264	19266-19270	data	_	_	
74-265	19272-19273	|	_	_	
74-266	19274-19283	Financial	_	_	
74-267	19284-19293	Sentiment	_	_	
74-268	19294-19302	Analysis	_	_	
74-269	19303-19304	|	_	_	
74-270	19305-19306	|	_	_	
74-271	19307-19308	[	_	_	
74-272	19308-19313	Bloom	*	SOFTWARE	
74-273	19313-19314	]	_	_	
74-274	19314-19315	(	_	_	
74-275	19315-19320	https	_	_	
74-276	19320-19321	:	_	_	
74-277	19321-19322	/	_	_	
74-278	19322-19323	/	_	_	
74-279	19323-19333	github.com	_	_	
74-280	19333-19334	/	_	_	
74-281	19334-19353	bigscience-workshop	_	_	
74-282	19353-19354	/	_	_	
74-283	19354-19364	bigscience	_	_	
74-284	19364-19365	/	_	_	
74-285	19365-19369	tree	_	_	
74-286	19369-19370	/	_	_	
74-287	19370-19376	master	_	_	
74-288	19376-19377	/	_	_	
74-289	19377-19382	train	_	_	
74-290	19382-19383	/	_	_	
74-291	19383-19387	tr11	_	_	
74-292	19387-19388	-	_	_	
74-293	19388-19395	176B-ml	_	_	
74-294	19395-19396	#	_	_	
74-295	19396-19402	readme	_	_	
74-296	19402-19403	)	_	_	
74-297	19404-19405	|	_	_	
74-298	19405-19409	366B	_	_	
74-299	19409-19410	|	_	_	
74-300	19410-19414	2048	_	_	
74-301	19414-19415	|	_	_	
74-302	19416-19421	World	_	_	
74-303	19421-19422	’	_	_	
74-304	19422-19423	s	_	_	
74-305	19424-19431	largest	_	_	
74-306	19432-19436	open	_	_	
74-307	19437-19449	multilingual	_	_	
74-308	19450-19458	language	_	_	
74-309	19459-19464	model	_	_	
74-310	19466-19467	|	_	_	
74-311	19468-19469	[	_	_	
74-312	19469-19474	bloom	*[91]	SOFTWARE[91]	
74-313	19474-19475	-	*[91]	SOFTWARE[91]	
74-314	19475-19478	7b1	*[91]	SOFTWARE[91]	
74-315	19478-19479	]	_	_	
74-316	19479-19480	(	_	_	
74-317	19480-19485	https	_	_	
74-318	19485-19486	:	_	_	
74-319	19486-19487	/	_	_	
74-320	19487-19488	/	_	_	
74-321	19488-19502	huggingface.co	_	_	
74-322	19502-19503	/	_	_	
74-323	19503-19513	bigscience	_	_	
74-324	19513-19514	/	_	_	
74-325	19514-19519	bloom	*[92]	SOFTWARE[92]	
74-326	19519-19520	-	*[92]	SOFTWARE[92]	
74-327	19520-19523	7b1	*[92]	SOFTWARE[92]	
74-328	19523-19524	)	_	_	
74-329	19525-19526	|	_	_	
74-330	19526-19530	Good	_	_	
74-331	19531-19534	for	_	_	
74-332	19535-19542	English	_	_	
74-333	19543-19549	market	_	_	
74-334	19550-19554	data	_	_	
74-335	19556-19557	|	_	_	
74-336	19558-19567	Financial	_	_	
74-337	19568-19577	Sentiment	_	_	
74-338	19578-19586	Analysis	_	_	
74-339	19587-19588	|	_	_	
74-340	19589-19590	|	_	_	
74-341	19591-19592	[	_	_	
74-342	19592-19600	ChatGLM2	*	SOFTWARE	
74-343	19600-19601	]	_	_	
74-344	19601-19602	(	_	_	
74-345	19602-19607	https	_	_	
74-346	19607-19608	:	_	_	
74-347	19608-19609	/	_	_	
74-348	19609-19610	/	_	_	
74-349	19610-19620	github.com	_	_	
74-350	19620-19621	/	_	_	
74-351	19621-19626	THUDM	_	_	
74-352	19626-19627	/	_	_	
74-353	19627-19635	ChatGLM2	*[93]	SOFTWARE[93]	
74-354	19635-19636	-	*[93]	SOFTWARE[93]	
74-355	19636-19638	6B	*[93]	SOFTWARE[93]	
74-356	19638-19639	)	_	_	
74-357	19639-19640	|	_	_	
74-358	19640-19644	1.4T	_	_	
74-359	19646-19647	|	_	_	
74-360	19647-19650	32K	_	_	
74-361	19651-19652	|	_	_	
74-362	19652-19663	Exceptional	_	_	
74-363	19664-19674	capability	_	_	
74-364	19675-19678	for	_	_	
74-365	19679-19686	Chinese	_	_	
74-366	19687-19695	language	_	_	
74-367	19696-19706	expression	_	_	
74-368	19706-19707	|	_	_	
74-369	19708-19709	[	_	_	
74-370	19709-19717	chatglm2	*[94]	SOFTWARE[94]	
74-371	19717-19718	-	*[94]	SOFTWARE[94]	
74-372	19718-19720	6b	*[94]	SOFTWARE[94]	
74-373	19720-19721	]	_	_	
74-374	19721-19722	(	_	_	
74-375	19722-19727	https	_	_	
74-376	19727-19728	:	_	_	
74-377	19728-19729	/	_	_	
74-378	19729-19730	/	_	_	
74-379	19730-19744	huggingface.co	_	_	
74-380	19744-19745	/	_	_	
74-381	19745-19750	THUDM	_	_	
74-382	19750-19751	/	_	_	
74-383	19751-19759	chatglm2	*[95]	SOFTWARE[95]	
74-384	19759-19760	-	*[95]	SOFTWARE[95]	
74-385	19760-19762	6b	*[95]	SOFTWARE[95]	
74-386	19762-19763	)	_	_	
74-387	19764-19765	|	_	_	
74-388	19765-19770	Shows	_	_	
74-389	19771-19778	prowess	_	_	
74-390	19779-19782	for	_	_	
74-391	19783-19790	Chinese	_	_	
74-392	19791-19797	market	_	_	
74-393	19798-19802	data	_	_	
74-394	19804-19805	|	_	_	
74-395	19806-19815	Financial	_	_	
74-396	19816-19825	Sentiment	_	_	
74-397	19826-19834	Analysis	_	_	
74-398	19834-19835	,	_	_	
74-399	19836-19845	Financial	_	_	
74-400	19846-19852	Report	_	_	
74-401	19853-19860	Summary	_	_	
74-402	19861-19862	|	_	_	
74-403	19863-19864	|	_	_	
74-404	19865-19866	[	_	_	
74-405	19866-19870	Qwen	_	_	
74-406	19870-19871	]	_	_	
74-407	19871-19872	(	_	_	
74-408	19872-19877	https	_	_	
74-409	19877-19878	:	_	_	
74-410	19878-19879	/	_	_	
74-411	19879-19880	/	_	_	
74-412	19880-19890	github.com	_	_	
74-413	19890-19891	/	_	_	
74-414	19891-19897	QwenLM	_	_	
74-415	19897-19898	/	_	_	
74-416	19898-19902	Qwen	_	_	
74-417	19902-19903	-	_	_	
74-418	19903-19905	7B	_	_	
74-419	19905-19906	)	_	_	
74-420	19906-19907	|	_	_	
74-421	19907-19911	2.2T	_	_	
74-422	19913-19914	|	_	_	
74-423	19914-19916	8k	_	_	
74-424	19917-19918	|	_	_	
74-425	19918-19922	Fast	_	_	
74-426	19923-19931	response	_	_	
74-427	19932-19935	and	_	_	
74-428	19936-19940	high	_	_	
74-429	19941-19949	accuracy	*	EVALMETRIC	
74-430	19949-19950	|	_	_	
74-431	19951-19952	[	_	_	
74-432	19952-19956	qwen	*[96]	SOFTWARE[96]	
74-433	19956-19957	-	*[96]	SOFTWARE[96]	
74-434	19957-19959	7b	*[96]	SOFTWARE[96]	
74-435	19959-19960	]	_	_	
74-436	19960-19961	(	_	_	
74-437	19961-19966	https	_	_	
74-438	19966-19967	:	_	_	
74-439	19967-19968	/	_	_	
74-440	19968-19969	/	_	_	
74-441	19969-19983	huggingface.co	_	_	
74-442	19983-19984	/	_	_	
74-443	19984-19991	tangger	*[97]	SOFTWARE[97]	
74-444	19991-19992	/	*[97]	SOFTWARE[97]	
74-445	19992-19996	Qwen	*[97]	SOFTWARE[97]	
74-446	19996-19997	-	*[97]	SOFTWARE[97]	
74-447	19997-20004	7B-Chat	*[97]	SOFTWARE[97]	
74-448	20004-20005	)	_	_	
74-449	20006-20007	|	_	_	
74-450	20007-20016	Effective	_	_	
74-451	20017-20020	for	_	_	
74-452	20021-20028	Chinese	_	_	
74-453	20029-20035	market	_	_	
74-454	20036-20040	data	_	_	
74-455	20042-20043	|	_	_	
74-456	20044-20053	Financial	_	_	
74-457	20054-20063	Sentiment	_	_	
74-458	20064-20072	Analysis	_	_	
74-459	20072-20073	|	_	_	
74-460	20074-20075	|	_	_	
74-461	20076-20077	[	_	_	
74-462	20077-20085	InternLM	*	SOFTWARE	
74-463	20085-20086	]	_	_	
74-464	20086-20087	(	_	_	
74-465	20087-20092	https	_	_	
74-466	20092-20093	:	_	_	
74-467	20093-20094	/	_	_	
74-468	20094-20095	/	_	_	
74-469	20095-20105	github.com	_	_	
74-470	20105-20106	/	_	_	
74-471	20106-20114	InternLM	_	_	
74-472	20114-20115	/	_	_	
74-473	20115-20123	InternLM	*	SOFTWARE	
74-474	20123-20124	)	_	_	
74-475	20125-20126	|	_	_	
74-476	20126-20130	1.8T	_	_	
74-477	20132-20133	|	_	_	
74-478	20133-20135	8k	_	_	
74-479	20136-20137	|	_	_	
74-480	20137-20140	Can	_	_	
74-481	20141-20149	flexibly	_	_	
74-482	20150-20153	and	_	_	
74-483	20154-20167	independently	_	_	
74-484	20168-20177	construct	_	_	
74-485	20178-20187	workflows	_	_	
74-486	20188-20189	|	_	_	
74-487	20189-20190	[	_	_	
74-488	20190-20198	internlm	*[98]	SOFTWARE[98]	
74-489	20198-20199	-	*[98]	SOFTWARE[98]	
74-490	20199-20201	7b	*[98]	SOFTWARE[98]	
74-491	20201-20202	]	_	_	
74-492	20202-20203	(	_	_	
74-493	20203-20208	https	_	_	
74-494	20208-20209	:	_	_	
74-495	20209-20210	/	_	_	
74-496	20210-20211	/	_	_	
74-497	20211-20225	huggingface.co	_	_	
74-498	20225-20226	/	_	_	
74-499	20226-20234	internlm	*[99]	SOFTWARE[99]	
74-500	20234-20235	/	*[99]	SOFTWARE[99]	
74-501	20235-20243	internlm	*[99]	SOFTWARE[99]	
74-502	20243-20244	-	*[99]	SOFTWARE[99]	
74-503	20244-20246	7b	*[99]	SOFTWARE[99]	
74-504	20246-20247	)	_	_	
74-505	20248-20249	|	_	_	
74-506	20249-20258	Effective	_	_	
74-507	20259-20262	for	_	_	
74-508	20263-20270	Chinese	_	_	
74-509	20271-20277	market	_	_	
74-510	20278-20282	data	_	_	
74-511	20284-20285	|	_	_	
74-512	20286-20295	Financial	_	_	
74-513	20296-20305	Sentiment	_	_	
74-514	20306-20314	Analysis	_	_	
74-515	20315-20316	|	_	_	
74-516	20318-20319	*	_	_	
74-517	20320-20329	Benchmark	_	_	
74-518	20330-20337	Results	_	_	
74-519	20338-20341	for	_	_	
74-520	20342-20345	the	_	_	
74-521	20346-20351	above	_	_	
74-522	20352-20363	open-source	_	_	
74-523	20364-20368	Base	_	_	
74-524	20369-20375	Models	_	_	
74-525	20376-20378	in	_	_	
74-526	20379-20382	the	_	_	
74-527	20383-20392	financial	_	_	
74-528	20393-20402	sentiment	_	_	
74-529	20403-20411	analysis	_	_	
74-530	20412-20416	task	_	_	
74-531	20417-20422	using	_	_	
74-532	20423-20426	the	_	_	
74-533	20427-20431	same	_	_	
74-534	20432-20443	instruction	_	_	
74-535	20444-20452	template	_	_	
74-536	20453-20456	for	_	_	
74-537	20457-20460	SFT	_	_	
74-538	20461-20462	(	_	_	
74-539	20462-20466	LoRA	_	_	
74-540	20466-20467	)	_	_	
74-541	20467-20468	:	_	_	
74-542	20471-20472	|	_	_	
74-543	20473-20481	Weighted	*[100]	EVALMETRIC[100]	
74-544	20482-20484	F1	*[100]	EVALMETRIC[100]	
74-545	20484-20485	/	_	_	
74-546	20485-20488	Acc	*	EVALMETRIC	
74-547	20490-20491	|	_	_	
74-548	20491-20497	Llama2	*	SOFTWARE	
74-549	20498-20499	|	_	_	
74-550	20499-20505	Falcon	*	SOFTWARE	
74-551	20506-20507	|	_	_	
74-552	20509-20512	MPT	*	SOFTWARE	
74-553	20512-20513	|	_	_	
74-554	20513-20518	Bloom	*	SOFTWARE	
74-555	20519-20520	|	_	_	
74-556	20520-20528	ChatGLM2	*	SOFTWARE	
74-557	20528-20529	|	_	_	
74-558	20529-20533	Qwen	*	SOFTWARE	
74-559	20533-20534	|	_	_	
74-560	20534-20542	InternLM	*	SOFTWARE	
74-561	20543-20544	|	_	_	
74-562	20547-20548	|	_	_	
74-563	20549-20550	-	_	_	
74-564	20550-20551	-	_	_	
74-565	20551-20552	-	_	_	
74-566	20552-20553	-	_	_	
74-567	20553-20554	-	_	_	
74-568	20554-20555	-	_	_	
74-569	20555-20556	-	_	_	
74-570	20556-20557	-	_	_	
74-571	20557-20558	-	_	_	
74-572	20559-20560	|	_	_	
74-573	20561-20562	-	_	_	
74-574	20562-20563	-	_	_	
74-575	20563-20564	-	_	_	
74-576	20564-20565	-	_	_	
74-577	20565-20566	-	_	_	
74-578	20566-20567	-	_	_	
74-579	20567-20568	-	_	_	
74-580	20568-20569	-	_	_	
74-581	20569-20570	-	_	_	
74-582	20570-20571	-	_	_	
74-583	20571-20572	-	_	_	
74-584	20572-20573	-	_	_	
74-585	20573-20574	-	_	_	
74-586	20574-20575	-	_	_	
74-587	20575-20576	-	_	_	
74-588	20576-20577	-	_	_	
74-589	20577-20578	-	_	_	
74-590	20579-20580	|	_	_	
74-591	20581-20582	-	_	_	
74-592	20582-20583	-	_	_	
74-593	20583-20584	-	_	_	
74-594	20584-20585	-	_	_	
74-595	20585-20586	-	_	_	
74-596	20586-20587	-	_	_	
74-597	20587-20588	-	_	_	
74-598	20588-20589	-	_	_	
74-599	20589-20590	-	_	_	
74-600	20590-20591	-	_	_	
74-601	20591-20592	-	_	_	
74-602	20592-20593	-	_	_	
74-603	20594-20595	|	_	_	
74-604	20596-20597	-	_	_	
74-605	20597-20598	-	_	_	
74-606	20598-20599	-	_	_	
74-607	20599-20600	-	_	_	
74-608	20600-20601	-	_	_	
74-609	20601-20602	-	_	_	
74-610	20602-20603	-	_	_	
74-611	20603-20604	-	_	_	
74-612	20604-20605	-	_	_	
74-613	20605-20606	-	_	_	
74-614	20606-20607	-	_	_	
74-615	20607-20608	-	_	_	
74-616	20608-20609	-	_	_	
74-617	20609-20610	-	_	_	
74-618	20610-20611	-	_	_	
74-619	20611-20612	-	_	_	
74-620	20612-20613	-	_	_	
74-621	20613-20614	-	_	_	
74-622	20614-20615	-	_	_	
74-623	20615-20616	-	_	_	
74-624	20616-20617	-	_	_	
74-625	20618-20619	|	_	_	
74-626	20620-20621	-	_	_	
74-627	20621-20622	-	_	_	
74-628	20622-20623	-	_	_	
74-629	20623-20624	-	_	_	
74-630	20624-20625	-	_	_	
74-631	20625-20626	-	_	_	
74-632	20626-20627	-	_	_	
74-633	20627-20628	-	_	_	
74-634	20628-20629	-	_	_	
74-635	20629-20630	-	_	_	
74-636	20630-20631	-	_	_	
74-637	20631-20632	-	_	_	
74-638	20632-20633	-	_	_	
74-639	20633-20634	-	_	_	
74-640	20634-20635	-	_	_	
74-641	20635-20636	-	_	_	
74-642	20637-20638	|	_	_	
74-643	20639-20640	-	_	_	
74-644	20640-20641	-	_	_	
74-645	20641-20642	-	_	_	
74-646	20642-20643	-	_	_	
74-647	20643-20644	-	_	_	
74-648	20644-20645	-	_	_	
74-649	20645-20646	-	_	_	
74-650	20646-20647	-	_	_	
74-651	20647-20648	-	_	_	
74-652	20648-20649	-	_	_	
74-653	20649-20650	-	_	_	
74-654	20650-20651	-	_	_	
74-655	20651-20652	-	_	_	
74-656	20652-20653	-	_	_	
74-657	20653-20654	-	_	_	
74-658	20655-20656	|	_	_	
74-659	20657-20658	-	_	_	
74-660	20658-20659	-	_	_	
74-661	20659-20660	-	_	_	
74-662	20660-20661	-	_	_	
74-663	20661-20662	-	_	_	
74-664	20662-20663	-	_	_	
74-665	20663-20664	-	_	_	
74-666	20664-20665	-	_	_	
74-667	20665-20666	-	_	_	
74-668	20666-20667	-	_	_	
74-669	20667-20668	-	_	_	
74-670	20668-20669	-	_	_	
74-671	20669-20670	-	_	_	
74-672	20670-20671	-	_	_	
74-673	20671-20672	-	_	_	
74-674	20672-20673	-	_	_	
74-675	20673-20674	-	_	_	
74-676	20675-20676	|	_	_	
74-677	20676-20677	-	_	_	
74-678	20677-20678	-	_	_	
74-679	20678-20679	-	_	_	
74-680	20679-20680	-	_	_	
74-681	20680-20681	-	_	_	
74-682	20681-20682	-	_	_	
74-683	20682-20683	-	_	_	
74-684	20683-20684	-	_	_	
74-685	20684-20685	-	_	_	
74-686	20685-20686	-	_	_	
74-687	20686-20687	-	_	_	
74-688	20687-20688	-	_	_	
74-689	20688-20689	-	_	_	
74-690	20689-20690	-	_	_	
74-691	20690-20691	-	_	_	
74-692	20691-20692	-	_	_	
74-693	20692-20693	-	_	_	
74-694	20694-20695	|	_	_	
74-695	20698-20699	|	_	_	
74-696	20700-20701	[	_	_	
74-697	20701-20704	FPB	*	DATASET	
74-698	20704-20705	]	_	_	
74-699	20705-20706	(	_	_	
74-700	20706-20711	https	_	_	
74-701	20711-20712	:	_	_	
74-702	20712-20713	/	_	_	
74-703	20713-20714	/	_	_	
74-704	20714-20728	huggingface.co	_	_	
74-705	20728-20729	/	_	_	
74-706	20729-20737	datasets	_	_	
74-707	20737-20738	/	_	_	
74-708	20738-20758	financial_phrasebank	*	DATASET	
74-709	20758-20759	)	_	_	
74-710	20760-20761	|	_	_	
74-711	20762-20767	0.863	_	_	
74-712	20767-20768	/	_	_	
74-713	20768-20773	0.863	_	_	
74-714	20774-20775	|	_	_	
74-715	20776-20781	0.846	_	_	
74-716	20781-20782	/	_	_	
74-717	20782-20787	0.849	_	_	
74-718	20789-20790	|	_	_	
74-719	20791-20792	*	_	_	
74-720	20792-20793	*	_	_	
74-721	20793-20798	0.872	_	_	
74-722	20798-20799	*	_	_	
74-723	20799-20800	*	_	_	
74-724	20800-20801	/	_	_	
74-725	20801-20802	*	_	_	
74-726	20802-20803	*	_	_	
74-727	20803-20808	0.872	_	_	
74-728	20808-20809	*	_	_	
74-729	20809-20810	*	_	_	
74-730	20813-20814	|	_	_	
74-731	20815-20820	0.810	_	_	
74-732	20820-20821	/	_	_	
74-733	20821-20826	0.810	_	_	
74-734	20827-20828	|	_	_	
74-735	20829-20834	0.850	_	_	
74-736	20834-20835	/	_	_	
74-737	20835-20840	0.849	_	_	
74-738	20841-20842	|	_	_	
74-739	20842-20847	0.854	_	_	
74-740	20847-20848	/	_	_	
74-741	20848-20853	0.854	_	_	
74-742	20853-20854	|	_	_	
74-743	20855-20860	0.709	_	_	
74-744	20860-20861	/	_	_	
74-745	20861-20866	0.714	_	_	
74-746	20867-20868	|	_	_	
74-747	20871-20872	|	_	_	
74-748	20873-20874	[	_	_	
74-749	20874-20881	FiQA-SA	*	DATASET	
74-750	20881-20882	]	_	_	
74-751	20882-20883	(	_	_	
74-752	20883-20888	https	_	_	
74-753	20888-20889	:	_	_	
74-754	20889-20890	/	_	_	
74-755	20890-20891	/	_	_	
74-756	20891-20905	huggingface.co	_	_	
74-757	20905-20906	/	_	_	
74-758	20906-20914	datasets	_	_	
74-759	20914-20915	/	_	_	
74-760	20915-20922	pauri32	*[101]	DATASET[101]	
74-761	20922-20923	/	*[101]	DATASET[101]	
74-762	20923-20927	fiqa	*[101]	DATASET[101]	
74-763	20927-20928	-	*[101]	DATASET[101]	
74-764	20928-20932	2018	*[101]	DATASET[101]	
74-765	20932-20933	)	_	_	
74-766	20933-20934	|	_	_	
74-767	20935-20936	*	_	_	
74-768	20936-20937	*	_	_	
74-769	20937-20942	0.871	_	_	
74-770	20942-20943	*	_	_	
74-771	20943-20944	*	_	_	
74-772	20944-20945	/	_	_	
74-773	20945-20950	0.855	_	_	
74-774	20950-20951	|	_	_	
74-775	20952-20957	0.840	_	_	
74-776	20957-20958	/	_	_	
74-777	20958-20963	0.811	_	_	
74-778	20965-20966	|	_	_	
74-779	20967-20972	0.863	_	_	
74-780	20972-20973	/	_	_	
74-781	20973-20978	0.844	_	_	
74-782	20979-20980	|	_	_	
74-783	20981-20986	0.771	_	_	
74-784	20986-20987	/	_	_	
74-785	20987-20992	0.753	_	_	
74-786	20992-20993	|	_	_	
74-787	20994-20999	0.864	_	_	
74-788	20999-21000	/	_	_	
74-789	21000-21001	*	_	_	
74-790	21001-21002	*	_	_	
74-791	21002-21007	0.862	_	_	
74-792	21007-21008	*	_	_	
74-793	21008-21009	*	_	_	
74-794	21010-21011	|	_	_	
74-795	21012-21017	0.867	_	_	
74-796	21017-21018	/	_	_	
74-797	21018-21023	0.851	_	_	
74-798	21025-21026	|	_	_	
74-799	21026-21031	0.679	_	_	
74-800	21031-21032	/	_	_	
74-801	21032-21037	0.687	_	_	
74-802	21038-21039	|	_	_	
74-803	21042-21043	|	_	_	
74-804	21044-21045	[	_	_	
74-805	21045-21049	TFNS	*	DATASET	
74-806	21049-21050	]	_	_	
74-807	21050-21051	(	_	_	
74-808	21051-21056	https	_	_	
74-809	21056-21057	:	_	_	
74-810	21057-21058	/	_	_	
74-811	21058-21059	/	_	_	
74-812	21059-21073	huggingface.co	_	_	
74-813	21073-21074	/	_	_	
74-814	21074-21082	datasets	_	_	
74-815	21082-21083	/	_	_	
74-816	21083-21091	zeroshot	*[102]	DATASET[102]	
74-817	21091-21092	/	*[102]	DATASET[102]	
74-818	21092-21124	twitter-financial-news-sentiment	*[102]	DATASET[102]	
74-819	21124-21125	)	_	_	
74-820	21126-21127	|	_	_	
74-821	21128-21133	0.896	_	_	
74-822	21133-21134	/	_	_	
74-823	21134-21139	0.895	_	_	
74-824	21140-21141	|	_	_	
74-825	21142-21147	0.893	_	_	
74-826	21147-21148	/	_	_	
74-827	21148-21153	0.893	_	_	
74-828	21154-21155	|	_	_	
74-829	21156-21157	*	_	_	
74-830	21157-21158	*	_	_	
74-831	21158-21163	0.907	_	_	
74-832	21163-21164	*	_	_	
74-833	21164-21165	*	_	_	
74-834	21165-21166	/	_	_	
74-835	21166-21167	*	_	_	
74-836	21167-21168	*	_	_	
74-837	21168-21173	0.907	_	_	
74-838	21173-21174	*	_	_	
74-839	21174-21175	*	_	_	
74-840	21176-21177	|	_	_	
74-841	21178-21183	0.840	_	_	
74-842	21183-21184	/	_	_	
74-843	21184-21189	0.840	_	_	
74-844	21190-21191	|	_	_	
74-845	21192-21197	0.859	_	_	
74-846	21197-21198	/	_	_	
74-847	21198-21203	0.858	_	_	
74-848	21204-21205	|	_	_	
74-849	21206-21211	0.883	_	_	
74-850	21211-21212	/	_	_	
74-851	21212-21217	0.882	_	_	
74-852	21217-21218	|	_	_	
74-853	21218-21223	0.729	_	_	
74-854	21223-21224	/	_	_	
74-855	21224-21229	0.731	_	_	
74-856	21229-21230	|	_	_	
74-857	21233-21234	|	_	_	
74-858	21235-21236	[	_	_	
74-859	21236-21240	NWGI	*	DATASET	
74-860	21240-21241	]	_	_	
74-861	21241-21242	(	_	_	
74-862	21242-21247	https	_	_	
74-863	21247-21248	:	_	_	
74-864	21248-21249	/	_	_	
74-865	21249-21250	/	_	_	
74-866	21250-21264	huggingface.co	_	_	
74-867	21264-21265	/	_	_	
74-868	21265-21273	datasets	_	_	
74-869	21273-21274	/	_	_	
74-870	21274-21286	oliverwang15	*[103]	DATASET[103]	
74-871	21286-21287	/	*[103]	DATASET[103]	
74-872	21287-21313	news_with_gpt_instructions	*[103]	DATASET[103]	
74-873	21313-21314	)	_	_	
74-874	21315-21316	|	_	_	
74-875	21317-21318	*	_	_	
74-876	21318-21319	*	_	_	
74-877	21319-21324	0.649	_	_	
74-878	21324-21325	/	_	_	
74-879	21325-21330	0.651	_	_	
74-880	21330-21331	*	_	_	
74-881	21331-21332	*	_	_	
74-882	21335-21336	|	_	_	
74-883	21337-21342	0.636	_	_	
74-884	21342-21343	/	_	_	
74-885	21343-21348	0.638	_	_	
74-886	21350-21351	|	_	_	
74-887	21352-21357	0.640	_	_	
74-888	21357-21358	/	_	_	
74-889	21358-21363	0.641	_	_	
74-890	21363-21364	|	_	_	
74-891	21365-21370	0.573	_	_	
74-892	21370-21371	/	_	_	
74-893	21371-21376	0.574	_	_	
74-894	21376-21377	|	_	_	
74-895	21378-21383	0.619	_	_	
74-896	21383-21384	/	_	_	
74-897	21384-21389	0.629	_	_	
74-898	21390-21391	|	_	_	
74-899	21391-21396	0.638	_	_	
74-900	21396-21397	/	_	_	
74-901	21397-21402	0.643	_	_	
74-902	21402-21403	|	_	_	
74-903	21403-21408	0.498	_	_	
74-904	21408-21409	/	_	_	
74-905	21409-21414	0.503	_	_	
74-906	21414-21415	|	_	_	
74-907	21417-21418	#	_	_	
74-908	21418-21419	#	_	_	
74-909	21419-21420	#	_	_	
74-910	21421-21424	All	_	_	
74-911	21425-21431	Thanks	_	_	
74-912	21432-21434	To	_	_	
74-913	21435-21438	Our	_	_	
74-914	21439-21451	Contributors	_	_	
74-915	21452-21453	:	_	_	
74-916	21454-21455	<	_	_	
74-917	21455-21456	a	_	_	
74-918	21457-21461	href	_	_	
74-919	21461-21462	=	_	_	
74-920	21462-21463	"	_	_	
74-921	21463-21468	https	_	_	
74-922	21468-21469	:	_	_	
74-923	21469-21470	/	_	_	
74-924	21470-21471	/	_	_	
74-925	21471-21481	github.com	_	_	
74-926	21481-21482	/	_	_	
74-927	21482-21503	AI4Finance-Foundation	_	_	
74-928	21503-21504	/	_	_	
74-929	21504-21510	FinGPT	*	PROJECT	
74-930	21510-21511	/	_	_	
74-931	21511-21517	graphs	_	_	
74-932	21517-21518	/	_	_	
74-933	21518-21530	contributors	_	_	
74-934	21530-21531	"	_	_	
74-935	21531-21532	>	_	_	
74-936	21535-21536	<	_	_	
74-937	21536-21539	img	_	_	
74-938	21540-21543	src	_	_	
74-939	21543-21544	=	_	_	
74-940	21544-21545	"	_	_	
74-941	21545-21550	https	_	_	
74-942	21550-21551	:	_	_	
74-943	21551-21552	/	_	_	
74-944	21552-21553	/	_	_	
74-945	21553-21566	contrib.rocks	_	_	
74-946	21566-21567	/	_	_	
74-947	21567-21572	image	_	_	
74-948	21572-21573	?	_	_	

#Text=repo=AI4Finance-Foundation/FinGPT" />
#Text=</a>
#Text=
#Text=## News
#Text=
#Text=+ [Columbia Perspectives on ChatGPT](https://datascience.columbia.edu/news/2023/columbia-perspectives-on-chatgpt/?
75-1	21573-21577	repo	_	_	
75-2	21577-21578	=	_	_	
75-3	21578-21599	AI4Finance-Foundation	_	_	
75-4	21599-21600	/	_	_	
75-5	21600-21606	FinGPT	*	PROJECT	
75-6	21606-21607	"	_	_	
75-7	21608-21609	/	_	_	
75-8	21609-21610	>	_	_	
75-9	21611-21612	<	_	_	
75-10	21612-21613	/	_	_	
75-11	21613-21614	a	_	_	
75-12	21614-21615	>	_	_	
75-13	21617-21618	#	_	_	
75-14	21618-21619	#	_	_	
75-15	21620-21624	News	_	_	
75-16	21626-21627	+	_	_	
75-17	21628-21629	[	_	_	
75-18	21629-21637	Columbia	_	_	
75-19	21638-21650	Perspectives	_	_	
75-20	21651-21653	on	_	_	
75-21	21654-21661	ChatGPT	*	SOFTWARE	
75-22	21661-21662	]	_	_	
75-23	21662-21663	(	_	_	
75-24	21663-21668	https	_	_	
75-25	21668-21669	:	_	_	
75-26	21669-21670	/	_	_	
75-27	21670-21671	/	_	_	
75-28	21671-21695	datascience.columbia.edu	_	_	
75-29	21695-21696	/	_	_	
75-30	21696-21700	news	_	_	
75-31	21700-21701	/	_	_	
75-32	21701-21705	2023	_	_	
75-33	21705-21706	/	_	_	
75-34	21706-21738	columbia-perspectives-on-chatgpt	_	_	
75-34.1	21731-21738	chatgpt	*	SOFTWARE	
75-35	21738-21739	/	_	_	
75-36	21739-21740	?	_	_	

#Text=utm_source=sendinblue&utm_campaign=DSI%20Newsletter%20April%202023&utm_medium=email)
#Text=+ [MIT Technology Review] [ChatGPT is about to revolutionize the economy.
76-1	21740-21750	utm_source	_	_	
76-2	21750-21751	=	_	_	
76-3	21751-21761	sendinblue	_	_	
76-4	21761-21762	&	_	_	
76-5	21762-21774	utm_campaign	_	_	
76-6	21774-21775	=	_	_	
76-7	21775-21778	DSI	_	_	
76-8	21778-21779	%	_	_	
76-9	21779-21791	20Newsletter	_	_	
76-10	21791-21792	%	_	_	
76-11	21792-21799	20April	_	_	
76-12	21799-21800	%	_	_	
76-13	21800-21807	202023&	_	_	
76-14	21807-21817	utm_medium	_	_	
76-15	21817-21818	=	_	_	
76-16	21818-21823	email	_	_	
76-17	21823-21824	)	_	_	
76-18	21825-21826	+	_	_	
76-19	21827-21828	[	_	_	
76-20	21828-21831	MIT	_	_	
76-21	21832-21842	Technology	_	_	
76-22	21843-21849	Review	_	_	
76-23	21849-21850	]	_	_	
76-24	21851-21852	[	_	_	
76-25	21852-21859	ChatGPT	*	SOFTWARE	
76-26	21860-21862	is	_	_	
76-27	21863-21868	about	_	_	
76-28	21869-21871	to	_	_	
76-29	21872-21885	revolutionize	_	_	
76-30	21886-21889	the	_	_	
76-31	21890-21897	economy	_	_	
76-32	21897-21898	.	_	_	

#Text=We need to decide what that looks like](https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/)
#Text=+ [BloombergGPT] [BloombergGPT: A Large Language Model for Finance](https://arxiv.org/abs/2303.17564)
#Text=+ [Finextra] [ChatGPT and Bing AI to sit as panellists at fintech conference](https://www.finextra.com/newsarticle/41973/chatgpt-and-bing-ai-to-sit-as-panellists-at-fintech-conference)
#Text=
#Text=## ChatGPT at AI4Finance
#Text=
#Text=+ [YouTube video] [I Built a Trading Bot with ChatGPT](https://www.youtube.com/watch?
77-1	21899-21901	We	_	_	
77-2	21902-21906	need	_	_	
77-3	21907-21909	to	_	_	
77-4	21910-21916	decide	_	_	
77-5	21917-21921	what	_	_	
77-6	21922-21926	that	_	_	
77-7	21927-21932	looks	_	_	
77-8	21933-21937	like	_	_	
77-9	21937-21938	]	_	_	
77-10	21938-21939	(	_	_	
77-11	21939-21944	https	_	_	
77-12	21944-21945	:	_	_	
77-13	21945-21946	/	_	_	
77-14	21946-21947	/	_	_	
77-15	21947-21971	www.technologyreview.com	_	_	
77-16	21971-21972	/	_	_	
77-17	21972-21976	2023	_	_	
77-18	21976-21977	/	_	_	
77-19	21977-21979	03	_	_	
77-20	21979-21980	/	_	_	
77-21	21980-21982	25	_	_	
77-22	21982-21983	/	_	_	
77-23	21983-21990	1070275	_	_	
77-24	21990-21991	/	_	_	
77-25	21991-22043	chatgpt-revolutionize-economy-decide-what-looks-like	_	_	
77-25.1	21991-21998	chatgpt	*	SOFTWARE	
77-26	22043-22044	/	_	_	
77-27	22044-22045	)	_	_	
77-28	22046-22047	+	_	_	
77-29	22048-22049	[	_	_	
77-30	22049-22061	BloombergGPT	*	SOFTWARE	
77-31	22061-22062	]	_	_	
77-32	22063-22064	[	_	_	
77-33	22064-22076	BloombergGPT	*[104]	PUBLICATION[104]	
77-34	22076-22077	:	*[104]	PUBLICATION[104]	
77-35	22078-22079	A	*[104]	PUBLICATION[104]	
77-36	22080-22085	Large	*[104]	PUBLICATION[104]	
77-37	22086-22094	Language	*[104]	PUBLICATION[104]	
77-38	22095-22100	Model	*[104]	PUBLICATION[104]	
77-39	22101-22104	for	*[104]	PUBLICATION[104]	
77-40	22105-22112	Finance	*[104]	PUBLICATION[104]	
77-41	22112-22113	]	_	_	
77-42	22113-22114	(	_	_	
77-43	22114-22119	https	_	_	
77-44	22119-22120	:	_	_	
77-45	22120-22121	/	_	_	
77-46	22121-22122	/	_	_	
77-47	22122-22131	arxiv.org	_	_	
77-48	22131-22132	/	_	_	
77-49	22132-22135	abs	_	_	
77-50	22135-22136	/	_	_	
77-51	22136-22146	2303.17564	_	_	
77-52	22146-22147	)	_	_	
77-53	22148-22149	+	_	_	
77-54	22150-22151	[	_	_	
77-55	22151-22159	Finextra	_	_	
77-56	22159-22160	]	_	_	
77-57	22161-22162	[	_	_	
77-58	22162-22169	ChatGPT	*	SOFTWARE	
77-59	22170-22173	and	_	_	
77-60	22174-22178	Bing	_	_	
77-61	22179-22181	AI	_	_	
77-62	22182-22184	to	_	_	
77-63	22185-22188	sit	_	_	
77-64	22189-22191	as	_	_	
77-65	22192-22202	panellists	_	_	
77-66	22203-22205	at	_	_	
77-67	22206-22213	fintech	_	_	
77-68	22214-22224	conference	_	_	
77-69	22224-22225	]	_	_	
77-70	22225-22226	(	_	_	
77-71	22226-22231	https	_	_	
77-72	22231-22232	:	_	_	
77-73	22232-22233	/	_	_	
77-74	22233-22234	/	_	_	
77-75	22234-22250	www.finextra.com	_	_	
77-76	22250-22251	/	_	_	
77-77	22251-22262	newsarticle	_	_	
77-78	22262-22263	/	_	_	
77-79	22263-22268	41973	_	_	
77-80	22268-22269	/	_	_	
77-81	22269-22331	chatgpt-and-bing-ai-to-sit-as-panellists-at-fintech-conference	_	_	
77-81.1	22269-22276	chatgpt	*	SOFTWARE	
77-82	22331-22332	)	_	_	
77-83	22334-22335	#	_	_	
77-84	22335-22336	#	_	_	
77-85	22337-22344	ChatGPT	*	SOFTWARE	
77-86	22345-22347	at	_	_	
77-87	22348-22358	AI4Finance	_	_	
77-88	22360-22361	+	_	_	
77-89	22362-22363	[	_	_	
77-90	22363-22370	YouTube	_	_	
77-91	22371-22376	video	_	_	
77-92	22376-22377	]	_	_	
77-93	22378-22379	[	_	_	
77-94	22379-22380	I	_	_	
77-95	22381-22386	Built	_	_	
77-96	22387-22388	a	_	_	
77-97	22389-22396	Trading	_	_	
77-98	22397-22400	Bot	_	_	
77-99	22401-22405	with	_	_	
77-100	22406-22413	ChatGPT	*	SOFTWARE	
77-101	22413-22414	]	_	_	
77-102	22414-22415	(	_	_	
77-103	22415-22420	https	_	_	
77-104	22420-22421	:	_	_	
77-105	22421-22422	/	_	_	
77-106	22422-22423	/	_	_	
77-107	22423-22438	www.youtube.com	_	_	
77-108	22438-22439	/	_	_	
77-109	22439-22444	watch	_	_	
77-110	22444-22445	?	_	_	

#Text=v=fhBw3j_O9LE), combining ChatGPT and FinRL.
#Text=+ [Hey, ChatGPT!
78-1	22445-22446	v	_	_	
78-2	22446-22447	=	_	_	
78-3	22447-22458	fhBw3j_O9LE	_	_	
78-4	22458-22459	)	_	_	
78-5	22459-22460	,	_	_	
78-6	22461-22470	combining	_	_	
78-7	22471-22478	ChatGPT	*	SOFTWARE	
78-8	22479-22482	and	_	_	
78-9	22483-22488	FinRL	_	_	
78-10	22488-22489	.	_	_	
78-11	22490-22491	+	_	_	
78-12	22492-22493	[	_	_	
78-13	22493-22496	Hey	_	_	
78-14	22496-22497	,	_	_	
78-15	22498-22505	ChatGPT	*	SOFTWARE	
78-16	22505-22506	!	_	_	

#Text=Explain FinRL code to me!]
79-1	22507-22514	Explain	_	_	
79-2	22515-22520	FinRL	_	_	
79-3	22521-22525	code	_	_	
79-4	22526-22528	to	_	_	
79-5	22529-22531	me	_	_	
79-6	22531-22532	!	_	_	
79-7	22532-22533	]	_	_	

#Text=(https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f)
#Text=
#Text=## Introductory
#Text=
#Text=+ [Sparks of artificial general intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)
#Text=+ [GPT-4] [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)
#Text=+ [InstructGPT] [Training language models to follow instructions with human feedback](https://openreview.net/forum?
80-1	22533-22534	(	_	_	
80-2	22534-22539	https	_	_	
80-3	22539-22540	:	_	_	
80-4	22540-22541	/	_	_	
80-5	22541-22542	/	_	_	
80-6	22542-22552	medium.com	_	_	
80-7	22552-22553	/	_	_	
80-8	22553-22554	@	_	_	
80-9	22554-22564	ai4finance	_	_	
80-10	22564-22565	/	_	_	
80-11	22565-22601	hey-chatgpt-explain-finrl-code-to-me	_	_	
80-12	22601-22602	-	_	_	
80-13	22602-22614	6a91d612296f	_	_	
80-14	22614-22615	)	_	_	
80-15	22617-22618	#	_	_	
80-16	22618-22619	#	_	_	
80-17	22620-22632	Introductory	_	_	
80-18	22634-22635	+	_	_	
80-19	22636-22637	[	_	_	
80-20	22637-22643	Sparks	*[105]	PUBLICATION[105]	
80-21	22644-22646	of	*[105]	PUBLICATION[105]	
80-22	22647-22657	artificial	*[105]	PUBLICATION[105]	
80-23	22658-22665	general	*[105]	PUBLICATION[105]	
80-24	22666-22678	intelligence	*[105]	PUBLICATION[105]	
80-25	22678-22679	:	*[105]	PUBLICATION[105]	
80-26	22680-22685	Early	*[105]	PUBLICATION[105]	
80-27	22686-22697	experiments	*[105]	PUBLICATION[105]	
80-28	22698-22702	with	*[105]	PUBLICATION[105]	
80-29	22703-22706	GPT	*[105]|*[106]	PUBLICATION[105]|SOFTWARE[106]	
80-30	22706-22707	-	*[105]|*[106]	PUBLICATION[105]|SOFTWARE[106]	
80-31	22707-22708	4	*[105]|*[106]	PUBLICATION[105]|SOFTWARE[106]	
80-32	22708-22709	]	_	_	
80-33	22709-22710	(	_	_	
80-34	22710-22715	https	_	_	
80-35	22715-22716	:	_	_	
80-36	22716-22717	/	_	_	
80-37	22717-22718	/	_	_	
80-38	22718-22727	arxiv.org	_	_	
80-39	22727-22728	/	_	_	
80-40	22728-22731	abs	_	_	
80-41	22731-22732	/	_	_	
80-42	22732-22742	2303.12712	_	_	
80-43	22742-22743	)	_	_	
80-44	22744-22745	+	_	_	
80-45	22746-22747	[	_	_	
80-46	22747-22750	GPT	*[107]	SOFTWARE[107]	
80-47	22750-22751	-	*[107]	SOFTWARE[107]	
80-48	22751-22752	4	*[107]	SOFTWARE[107]	
80-49	22752-22753	]	_	_	
80-50	22754-22755	[	_	_	
80-51	22755-22758	GPT	*[108]|*[109]	PUBLICATION[108]|SOFTWARE[109]	
80-52	22758-22759	-	*[108]|*[109]	PUBLICATION[108]|SOFTWARE[109]	
80-53	22759-22760	4	*[108]|*[109]	PUBLICATION[108]|SOFTWARE[109]	
80-54	22761-22770	Technical	*[108]	PUBLICATION[108]	
80-55	22771-22777	Report	*[108]	PUBLICATION[108]	
80-56	22777-22778	]	_	_	
80-57	22778-22779	(	_	_	
80-58	22779-22784	https	_	_	
80-59	22784-22785	:	_	_	
80-60	22785-22786	/	_	_	
80-61	22786-22787	/	_	_	
80-62	22787-22796	arxiv.org	_	_	
80-63	22796-22797	/	_	_	
80-64	22797-22800	abs	_	_	
80-65	22800-22801	/	_	_	
80-66	22801-22811	2303.08774	_	_	
80-67	22811-22812	)	_	_	
80-68	22813-22814	+	_	_	
80-69	22815-22816	[	_	_	
80-70	22816-22827	InstructGPT	*	SOFTWARE	
80-71	22827-22828	]	_	_	
80-72	22829-22830	[	_	_	
80-73	22830-22838	Training	*[110]	PUBLICATION[110]	
80-74	22839-22847	language	*[110]	PUBLICATION[110]	
80-75	22848-22854	models	*[110]	PUBLICATION[110]	
80-76	22855-22857	to	*[110]	PUBLICATION[110]	
80-77	22858-22864	follow	*[110]	PUBLICATION[110]	
80-78	22865-22877	instructions	*[110]	PUBLICATION[110]	
80-79	22878-22882	with	*[110]	PUBLICATION[110]	
80-80	22883-22888	human	*[110]	PUBLICATION[110]	
80-81	22889-22897	feedback	*[110]	PUBLICATION[110]	
80-82	22897-22898	]	_	_	
80-83	22898-22899	(	_	_	
80-84	22899-22904	https	_	_	
80-85	22904-22905	:	_	_	
80-86	22905-22906	/	_	_	
80-87	22906-22907	/	_	_	
80-88	22907-22921	openreview.net	_	_	
80-89	22921-22922	/	_	_	
80-90	22922-22927	forum	_	_	
80-91	22927-22928	?	_	_	

#Text=id=TG8KACxEON) NeurIPS 2022.
81-1	22928-22930	id	_	_	
81-2	22930-22931	=	_	_	
81-3	22931-22941	TG8KACxEON	_	_	
81-4	22941-22942	)	_	_	
81-5	22943-22950	NeurIPS	*[111]	CONFERENCE[111]	
81-6	22951-22955	2022	*[111]	CONFERENCE[111]	
81-7	22955-22956	.	_	_	

#Text=[The Journey of Open AI GPT models](https://medium.com/walmartglobaltech/the-journey-of-open-ai-gpt-models-32d95b7b7fb2).
82-1	22958-22959	[	_	_	
82-2	22959-22962	The	_	_	
82-3	22963-22970	Journey	_	_	
82-4	22971-22973	of	_	_	
82-5	22974-22978	Open	_	_	
82-6	22979-22981	AI	_	_	
82-7	22982-22985	GPT	_	_	
82-8	22986-22992	models	_	_	
82-9	22992-22993	]	_	_	
82-10	22993-22994	(	_	_	
82-11	22994-22999	https	_	_	
82-12	22999-23000	:	_	_	
82-13	23000-23001	/	_	_	
82-14	23001-23002	/	_	_	
82-15	23002-23012	medium.com	_	_	
82-16	23012-23013	/	_	_	
82-17	23013-23030	walmartglobaltech	_	_	
82-18	23030-23031	/	_	_	
82-19	23031-23064	the-journey-of-open-ai-gpt-models	_	_	
82-20	23064-23065	-	_	_	
82-21	23065-23077	32d95b7b7fb2	_	_	
82-22	23077-23078	)	_	_	
82-23	23078-23079	.	_	_	

#Text=GPT models explained.
83-1	23081-23084	GPT	_	_	
83-2	23085-23091	models	_	_	
83-3	23092-23101	explained	_	_	
83-4	23101-23102	.	_	_	

#Text=Open AI's GPT-1, GPT-2, GPT-3
84-1	23103-23107	Open	_	_	
84-2	23108-23112	AI's	_	_	
84-3	23113-23116	GPT	*[112]	SOFTWARE[112]	
84-4	23116-23117	-	*[112]	SOFTWARE[112]	
84-5	23117-23118	1	*[112]	SOFTWARE[112]	
84-6	23118-23119	,	_	_	
84-7	23120-23123	GPT	*[113]	SOFTWARE[113]	
84-8	23123-23124	-	*[113]	SOFTWARE[113]	
84-9	23124-23125	2	*[113]	SOFTWARE[113]	
84-10	23125-23126	,	_	_	
84-11	23127-23130	GPT	*[114]	SOFTWARE[114]	
84-12	23130-23131	-	*[114]	SOFTWARE[114]	
84-13	23131-23132	3	*[114]	SOFTWARE[114]	

#Text=.
85-1	23132-23133	.	_	_	

#Text=+ [GPT-3] [Language models are few-shot learners](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html) NeurIPS 2020.
#Text=+ [GPT-2] [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
#Text=+ [GPT-1] [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
#Text=+ [Transformer] [Attention is All you Need](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html) NeurIPS 2017.
#Text=
#Text=## (Financial) Big Data
#Text=
#Text=+ [BloombergGPT] [BloombergGPT: A Large Language Model for Finance](https://arxiv.org/abs/2303.17564)
#Text=
#Text=+ [WHAT’S IN MY AI?]
86-1	23135-23136	+	_	_	
86-2	23137-23138	[	_	_	
86-3	23138-23141	GPT	_	_	
86-4	23141-23142	-	_	_	
86-5	23142-23143	3	_	_	
86-6	23143-23144	]	_	_	
86-7	23145-23146	[	_	_	
86-8	23146-23154	Language	*[115]	PUBLICATION[115]	
86-9	23155-23161	models	*[115]	PUBLICATION[115]	
86-10	23162-23165	are	*[115]	PUBLICATION[115]	
86-11	23166-23174	few-shot	*[115]	PUBLICATION[115]	
86-12	23175-23183	learners	*[115]	PUBLICATION[115]	
86-13	23183-23184	]	_	_	
86-14	23184-23185	(	_	_	
86-15	23185-23190	https	_	_	
86-16	23190-23191	:	_	_	
86-17	23191-23192	/	_	_	
86-18	23192-23193	/	_	_	
86-19	23193-23215	proceedings.neurips.cc	_	_	
86-19.1	23205-23212	neurips	*	CONFERENCE	
86-20	23215-23216	/	_	_	
86-21	23216-23221	paper	_	_	
86-22	23221-23222	/	_	_	
86-23	23222-23226	2020	_	_	
86-24	23226-23227	/	_	_	
86-25	23227-23231	hash	_	_	
86-26	23231-23232	/	_	_	
86-27	23232-23278	1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html	_	_	
86-28	23278-23279	)	_	_	
86-29	23280-23287	NeurIPS	*[116]	CONFERENCE[116]	
86-30	23288-23292	2020	*[116]	CONFERENCE[116]	
86-31	23292-23293	.	_	_	
86-32	23294-23295	+	_	_	
86-33	23296-23297	[	_	_	
86-34	23297-23300	GPT	_	_	
86-35	23300-23301	-	_	_	
86-36	23301-23302	2	_	_	
86-37	23302-23303	]	_	_	
86-38	23304-23305	[	_	_	
86-39	23305-23313	Language	*[117]	PUBLICATION[117]	
86-40	23314-23320	Models	*[117]	PUBLICATION[117]	
86-41	23321-23324	are	*[117]	PUBLICATION[117]	
86-42	23325-23337	Unsupervised	*[117]	PUBLICATION[117]	
86-43	23338-23347	Multitask	*[117]	PUBLICATION[117]	
86-44	23348-23356	Learners	*[117]	PUBLICATION[117]	
86-45	23356-23357	]	_	_	
86-46	23357-23358	(	_	_	
86-47	23358-23363	https	_	_	
86-48	23363-23364	:	_	_	
86-49	23364-23365	/	_	_	
86-50	23365-23366	/	_	_	
86-51	23366-23380	cdn.openai.com	_	_	
86-52	23380-23381	/	_	_	
86-53	23381-23403	better-language-models	_	_	
86-54	23403-23404	/	_	_	
86-55	23404-23459	language_models_are_unsupervised_multitask_learners.pdf	_	_	
86-56	23459-23460	)	_	_	
86-57	23461-23462	+	_	_	
86-58	23463-23464	[	_	_	
86-59	23464-23467	GPT	_	_	
86-60	23467-23468	-	_	_	
86-61	23468-23469	1	_	_	
86-62	23469-23470	]	_	_	
86-63	23471-23472	[	_	_	
86-64	23472-23481	Improving	_	_	
86-65	23482-23490	Language	_	_	
86-66	23491-23504	Understanding	*[118]	PUBLICATION[118]	
86-67	23505-23507	by	*[118]	PUBLICATION[118]	
86-68	23508-23518	Generative	*[118]	PUBLICATION[118]	
86-69	23519-23531	Pre-Training	*[118]	PUBLICATION[118]	
86-70	23531-23532	]	_	_	
86-71	23532-23533	(	_	_	
86-72	23533-23538	https	_	_	
86-73	23538-23539	:	_	_	
86-74	23539-23540	/	_	_	
86-75	23540-23541	/	_	_	
86-76	23541-23555	cdn.openai.com	_	_	
86-77	23555-23556	/	_	_	
86-78	23556-23571	research-covers	_	_	
86-79	23571-23572	/	_	_	
86-80	23572-23593	language-unsupervised	_	_	
86-81	23593-23594	/	_	_	
86-82	23594-23626	language_understanding_paper.pdf	_	_	
86-83	23626-23627	)	_	_	
86-84	23628-23629	+	_	_	
86-85	23630-23631	[	_	_	
86-86	23631-23642	Transformer	_	_	
86-87	23642-23643	]	_	_	
86-88	23644-23645	[	_	_	
86-89	23645-23654	Attention	*[119]	PUBLICATION[119]	
86-90	23655-23657	is	*[119]	PUBLICATION[119]	
86-91	23658-23661	All	*[119]	PUBLICATION[119]	
86-92	23662-23665	you	*[119]	PUBLICATION[119]	
86-93	23666-23670	Need	*[119]	PUBLICATION[119]	
86-94	23670-23671	]	_	_	
86-95	23671-23672	(	_	_	
86-96	23672-23677	https	_	_	
86-97	23677-23678	:	_	_	
86-98	23678-23679	/	_	_	
86-99	23679-23680	/	_	_	
86-100	23680-23702	proceedings.neurips.cc	_	_	
86-100.1	23692-23699	neurips	*	CONFERENCE	
86-101	23702-23703	/	_	_	
86-102	23703-23708	paper	_	_	
86-103	23708-23709	/	_	_	
86-104	23709-23713	2017	_	_	
86-105	23713-23714	/	_	_	
86-106	23714-23718	hash	_	_	
86-107	23718-23719	/	_	_	
86-108	23719-23765	3f5ee243547dee91fbd053c1c4a845aa-Abstract.html	_	_	
86-109	23765-23766	)	_	_	
86-110	23767-23774	NeurIPS	*[120]	CONFERENCE[120]	
86-111	23775-23779	2017	*[120]	CONFERENCE[120]	
86-112	23779-23780	.	_	_	
86-113	23782-23783	#	_	_	
86-114	23783-23784	#	_	_	
86-115	23785-23786	(	_	_	
86-116	23786-23795	Financial	_	_	
86-117	23795-23796	)	_	_	
86-118	23797-23800	Big	_	_	
86-119	23801-23805	Data	_	_	
86-120	23807-23808	+	_	_	
86-121	23809-23810	[	_	_	
86-122	23810-23822	BloombergGPT	_	_	
86-123	23822-23823	]	_	_	
86-124	23824-23825	[	_	_	
86-125	23825-23837	BloombergGPT	*[121]	PUBLICATION[121]	
86-126	23837-23838	:	*[121]	PUBLICATION[121]	
86-127	23839-23840	A	*[121]	PUBLICATION[121]	
86-128	23841-23846	Large	*[121]	PUBLICATION[121]	
86-129	23847-23855	Language	*[121]	PUBLICATION[121]	
86-130	23856-23861	Model	*[121]	PUBLICATION[121]	
86-131	23862-23865	for	*[121]	PUBLICATION[121]	
86-132	23866-23873	Finance	*[121]	PUBLICATION[121]	
86-133	23873-23874	]	_	_	
86-134	23874-23875	(	_	_	
86-135	23875-23880	https	_	_	
86-136	23880-23881	:	_	_	
86-137	23881-23882	/	_	_	
86-138	23882-23883	/	_	_	
86-139	23883-23892	arxiv.org	_	_	
86-140	23892-23893	/	_	_	
86-141	23893-23896	abs	_	_	
86-142	23896-23897	/	_	_	
86-143	23897-23907	2303.17564	_	_	
86-144	23907-23908	)	_	_	
86-145	23910-23911	+	_	_	
86-146	23912-23913	[	_	_	
86-147	23913-23917	WHAT	*[122]	PUBLICATION[122]	
86-148	23917-23918	’	*[122]	PUBLICATION[122]	
86-149	23918-23919	S	*[122]	PUBLICATION[122]	
86-150	23920-23922	IN	*[122]	PUBLICATION[122]	
86-151	23923-23925	MY	*[122]	PUBLICATION[122]	
86-152	23926-23928	AI	*[122]	PUBLICATION[122]	
86-153	23928-23929	?	*[122]	PUBLICATION[122]	
86-154	23929-23930	]	_	_	

#Text=(https://lifearchitect.ai/whats-in-my-ai/) A Comprehensive Analysis of Datasets Used to Train GPT-1, GPT-2, GPT-3, GPT-NeoX-20B, Megatron-11B, MT-NLG, and Gopher
#Text=
#Text=+ [FinRL-Meta Repo](https://github.com/AI4Finance-Foundation/FinRL-Meta) and paper [FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning](https://proceedings.neurips.cc/paper_files/paper/2022/hash/0bf54b80686d2c4dc0808c2e98d430f7-Abstract-Datasets_and_Benchmarks.html).
87-1	23930-23931	(	_	_	
87-2	23931-23936	https	_	_	
87-3	23936-23937	:	_	_	
87-4	23937-23938	/	_	_	
87-5	23938-23939	/	_	_	
87-6	23939-23955	lifearchitect.ai	_	_	
87-7	23955-23956	/	_	_	
87-8	23956-23970	whats-in-my-ai	_	_	
87-9	23970-23971	/	_	_	
87-10	23971-23972	)	_	_	
87-11	23973-23974	A	_	_	
87-12	23975-23988	Comprehensive	_	_	
87-13	23989-23997	Analysis	_	_	
87-14	23998-24000	of	_	_	
87-15	24001-24009	Datasets	_	_	
87-16	24010-24014	Used	_	_	
87-17	24015-24017	to	_	_	
87-18	24018-24023	Train	_	_	
87-19	24024-24027	GPT	*[123]	SOFTWARE[123]	
87-20	24027-24028	-	*[123]	SOFTWARE[123]	
87-21	24028-24029	1	*[123]	SOFTWARE[123]	
87-22	24029-24030	,	_	_	
87-23	24031-24034	GPT	*[124]	SOFTWARE[124]	
87-24	24034-24035	-	*[124]	SOFTWARE[124]	
87-25	24035-24036	2	*[124]	SOFTWARE[124]	
87-26	24036-24037	,	_	_	
87-27	24038-24041	GPT	*[125]	SOFTWARE[125]	
87-28	24041-24042	-	*[125]	SOFTWARE[125]	
87-29	24042-24043	3	*[125]	SOFTWARE[125]	
87-30	24043-24044	,	_	_	
87-31	24045-24053	GPT-NeoX	*[126]	SOFTWARE[126]	
87-32	24053-24054	-	*[126]	SOFTWARE[126]	
87-33	24054-24057	20B	*[126]	SOFTWARE[126]	
87-34	24057-24058	,	_	_	
87-35	24059-24067	Megatron	*[127]	SOFTWARE[127]	
87-36	24067-24068	-	*[127]	SOFTWARE[127]	
87-37	24068-24071	11B	*[127]	SOFTWARE[127]	
87-38	24071-24072	,	_	_	
87-39	24073-24079	MT-NLG	*	SOFTWARE	
87-40	24079-24080	,	_	_	
87-41	24081-24084	and	_	_	
87-42	24085-24091	Gopher	*	SOFTWARE	
87-43	24093-24094	+	_	_	
87-44	24095-24096	[	_	_	
87-45	24096-24106	FinRL-Meta	_	_	
87-46	24107-24111	Repo	_	_	
87-47	24111-24112	]	_	_	
87-48	24112-24113	(	_	_	
87-49	24113-24118	https	_	_	
87-50	24118-24119	:	_	_	
87-51	24119-24120	/	_	_	
87-52	24120-24121	/	_	_	
87-53	24121-24131	github.com	_	_	
87-54	24131-24132	/	_	_	
87-55	24132-24153	AI4Finance-Foundation	_	_	
87-56	24153-24154	/	_	_	
87-57	24154-24164	FinRL-Meta	_	_	
87-58	24164-24165	)	_	_	
87-59	24166-24169	and	_	_	
87-60	24170-24175	paper	_	_	
87-61	24176-24177	[	_	_	
87-62	24177-24187	FinRL-Meta	*[128]	PUBLICATION[128]	
87-63	24187-24188	:	*[128]	PUBLICATION[128]	
87-64	24189-24195	Market	*[128]	PUBLICATION[128]	
87-65	24196-24208	Environments	*[128]	PUBLICATION[128]	
87-66	24209-24212	and	*[128]	PUBLICATION[128]	
87-67	24213-24223	Benchmarks	*[128]	PUBLICATION[128]	
87-68	24224-24227	for	*[128]	PUBLICATION[128]	
87-69	24228-24239	Data-Driven	*[128]	PUBLICATION[128]	
87-70	24240-24249	Financial	*[128]	PUBLICATION[128]	
87-71	24250-24263	Reinforcement	*[128]	PUBLICATION[128]	
87-72	24264-24272	Learning	*[128]	PUBLICATION[128]	
87-73	24272-24273	]	_	_	
87-74	24273-24274	(	_	_	
87-75	24274-24279	https	_	_	
87-76	24279-24280	:	_	_	
87-77	24280-24281	/	_	_	
87-78	24281-24282	/	_	_	
87-79	24282-24304	proceedings.neurips.cc	_	_	
87-79.1	24294-24301	neurips	*	CONFERENCE	
87-80	24304-24305	/	_	_	
87-81	24305-24316	paper_files	_	_	
87-82	24316-24317	/	_	_	
87-83	24317-24322	paper	_	_	
87-84	24322-24323	/	_	_	
87-85	24323-24327	2022	_	_	
87-86	24327-24328	/	_	_	
87-87	24328-24332	hash	_	_	
87-88	24332-24333	/	_	_	
87-89	24333-24365	0bf54b80686d2c4dc0808c2e98d430f7	_	_	
87-90	24365-24366	-	_	_	
87-91	24366-24403	Abstract-Datasets_and_Benchmarks.html	_	_	
87-92	24403-24404	)	_	_	
87-93	24404-24405	.	_	_	

#Text=Advances in Neural Information Processing Systems, 2022
88-1	24406-24414	Advances	*[129]	PUBLICATION[129]	
88-2	24415-24417	in	*[129]	PUBLICATION[129]	
88-3	24418-24424	Neural	*[129]|*[130]	PUBLICATION[129]|CONFERENCE[130]	
88-4	24425-24436	Information	*[129]|*[130]	PUBLICATION[129]|CONFERENCE[130]	
88-5	24437-24447	Processing	*[129]|*[130]	PUBLICATION[129]|CONFERENCE[130]	
88-6	24448-24455	Systems	*[129]|*[130]	PUBLICATION[129]|CONFERENCE[130]	
88-7	24455-24456	,	*[129]	PUBLICATION[129]	
88-8	24457-24461	2022	*[129]	PUBLICATION[129]	

#Text=.
89-1	24461-24462	.	_	_	

#Text=+ [AI4Finance] [FinNLP](https://github.com/AI4Finance-Foundation/FinNLP) Democratizing Internet-scale financial data.
#Text=
#Text=## Interesting Demos
#Text=
#Text=+ [GPT-3 Creative Fiction](https://gwern.net/gpt-3#prompts-as-programming) Creative writing by OpenAI’s GPT-3 model, demonstrating poetry, dialogue, puns, literary parodies, and storytelling.
90-1	24464-24465	+	_	_	
90-2	24466-24467	[	_	_	
90-3	24467-24477	AI4Finance	_	_	
90-4	24477-24478	]	_	_	
90-5	24479-24480	[	_	_	
90-6	24480-24486	FinNLP	_	_	
90-7	24486-24487	]	_	_	
90-8	24487-24488	(	_	_	
90-9	24488-24493	https	_	_	
90-10	24493-24494	:	_	_	
90-11	24494-24495	/	_	_	
90-12	24495-24496	/	_	_	
90-13	24496-24506	github.com	_	_	
90-14	24506-24507	/	_	_	
90-15	24507-24528	AI4Finance-Foundation	_	_	
90-16	24528-24529	/	_	_	
90-17	24529-24535	FinNLP	_	_	
90-18	24535-24536	)	_	_	
90-19	24537-24550	Democratizing	_	_	
90-20	24551-24565	Internet-scale	_	_	
90-21	24566-24575	financial	_	_	
90-22	24576-24580	data	_	_	
90-23	24580-24581	.	_	_	
90-24	24583-24584	#	_	_	
90-25	24584-24585	#	_	_	
90-26	24586-24597	Interesting	_	_	
90-27	24598-24603	Demos	_	_	
90-28	24605-24606	+	_	_	
90-29	24607-24608	[	_	_	
90-30	24608-24611	GPT	_	_	
90-31	24611-24612	-	_	_	
90-32	24612-24613	3	_	_	
90-33	24614-24622	Creative	_	_	
90-34	24623-24630	Fiction	_	_	
90-35	24630-24631	]	_	_	
90-36	24631-24632	(	_	_	
90-37	24632-24637	https	_	_	
90-38	24637-24638	:	_	_	
90-39	24638-24639	/	_	_	
90-40	24639-24640	/	_	_	
90-41	24640-24649	gwern.net	_	_	
90-42	24649-24650	/	_	_	
90-43	24650-24653	gpt	_	_	
90-44	24653-24654	-	_	_	
90-45	24654-24655	3	_	_	
90-46	24655-24656	#	_	_	
90-47	24656-24678	prompts-as-programming	_	_	
90-48	24678-24679	)	_	_	
90-49	24680-24688	Creative	_	_	
90-50	24689-24696	writing	_	_	
90-51	24697-24699	by	_	_	
90-52	24700-24706	OpenAI	_	_	
90-53	24706-24707	’	_	_	
90-54	24707-24708	s	_	_	
90-55	24709-24712	GPT	_	_	
90-56	24712-24713	-	_	_	
90-57	24713-24714	3	_	_	
90-58	24715-24720	model	_	_	
90-59	24720-24721	,	_	_	
90-60	24722-24735	demonstrating	_	_	
90-61	24736-24742	poetry	_	_	
90-62	24742-24743	,	_	_	
90-63	24744-24752	dialogue	_	_	
90-64	24752-24753	,	_	_	
90-65	24754-24758	puns	_	_	
90-66	24758-24759	,	_	_	
90-67	24760-24768	literary	_	_	
90-68	24769-24777	parodies	_	_	
90-69	24777-24778	,	_	_	
90-70	24779-24782	and	_	_	
90-71	24783-24795	storytelling	_	_	
90-72	24795-24796	.	_	_	

#Text=Plus advice on effective GPT-3 prompt programming & avoiding common errors.
#Text=
#Text=## ChatGPT for FinTech
#Text=
#Text=**ChatGPT Trading Bot**
#Text=+ [YouTube video] [ChatGPT Trading strategy 20097% returns](https://www.youtube.com/watch?
91-1	24797-24801	Plus	_	_	
91-2	24802-24808	advice	_	_	
91-3	24809-24811	on	_	_	
91-4	24812-24821	effective	_	_	
91-5	24822-24825	GPT	*[131]	SOFTWARE[131]	
91-6	24825-24826	-	*[131]	SOFTWARE[131]	
91-7	24826-24827	3	*[131]	SOFTWARE[131]	
91-8	24828-24834	prompt	_	_	
91-9	24835-24846	programming	_	_	
91-10	24847-24848	&	_	_	
91-11	24849-24857	avoiding	_	_	
91-12	24858-24864	common	_	_	
91-13	24865-24871	errors	_	_	
91-14	24871-24872	.	_	_	
91-15	24874-24875	#	_	_	
91-16	24875-24876	#	_	_	
91-17	24877-24884	ChatGPT	*	SOFTWARE	
91-18	24885-24888	for	_	_	
91-19	24889-24896	FinTech	_	_	
91-20	24898-24899	*	_	_	
91-21	24899-24900	*	_	_	
91-22	24900-24907	ChatGPT	*	SOFTWARE	
91-23	24908-24915	Trading	_	_	
91-24	24916-24919	Bot	_	_	
91-25	24919-24920	*	_	_	
91-26	24920-24921	*	_	_	
91-27	24922-24923	+	_	_	
91-28	24924-24925	[	_	_	
91-29	24925-24932	YouTube	_	_	
91-30	24933-24938	video	_	_	
91-31	24938-24939	]	_	_	
91-32	24940-24941	[	_	_	
91-33	24941-24948	ChatGPT	*	SOFTWARE	
91-34	24949-24956	Trading	_	_	
91-35	24957-24965	strategy	_	_	
91-36	24966-24972	20097%	_	_	
91-37	24973-24980	returns	_	_	
91-38	24980-24981	]	_	_	
91-39	24981-24982	(	_	_	
91-40	24982-24987	https	_	_	
91-41	24987-24988	:	_	_	
91-42	24988-24989	/	_	_	
91-43	24989-24990	/	_	_	
91-44	24990-25005	www.youtube.com	_	_	
91-45	25005-25006	/	_	_	
91-46	25006-25011	watch	_	_	
91-47	25011-25012	?	_	_	

#Text=v=unsa_gXPAJ4)
#Text=+ [YouTube video] [ChatGPT Coding - Make A Profitable Trading Strategy In Five Minutes!]
92-1	25012-25013	v	_	_	
92-2	25013-25014	=	_	_	
92-3	25014-25025	unsa_gXPAJ4	_	_	
92-4	25025-25026	)	_	_	
92-5	25027-25028	+	_	_	
92-6	25029-25030	[	_	_	
92-7	25030-25037	YouTube	_	_	
92-8	25038-25043	video	_	_	
92-9	25043-25044	]	_	_	
92-10	25045-25046	[	_	_	
92-11	25046-25053	ChatGPT	*	SOFTWARE	
92-12	25054-25060	Coding	_	_	
92-13	25061-25062	-	_	_	
92-14	25063-25067	Make	_	_	
92-15	25068-25069	A	_	_	
92-16	25070-25080	Profitable	_	_	
92-17	25081-25088	Trading	_	_	
92-18	25089-25097	Strategy	_	_	
92-19	25098-25100	In	_	_	
92-20	25101-25105	Five	_	_	
92-21	25106-25113	Minutes	_	_	
92-22	25113-25114	!	_	_	
92-23	25114-25115	]	_	_	

#Text=(https://www.youtube.com/watch?
93-1	25115-25116	(	_	_	
93-2	25116-25121	https	_	_	
93-3	25121-25122	:	_	_	
93-4	25122-25123	/	_	_	
93-5	25123-25124	/	_	_	
93-6	25124-25139	www.youtube.com	_	_	
93-7	25139-25140	/	_	_	
93-8	25140-25145	watch	_	_	
93-9	25145-25146	?	_	_	

#Text=v=4SG2884RcDY)
#Text=+ [YouTube video] [Easy Automated Live Trading using ChatGPT (+9660.3% hands free)](https://www.youtube.com/watch?
94-1	25146-25147	v	_	_	
94-2	25147-25148	=	_	_	
94-3	25148-25159	4SG2884RcDY	_	_	
94-4	25159-25160	)	_	_	
94-5	25161-25162	+	_	_	
94-6	25163-25164	[	_	_	
94-7	25164-25171	YouTube	_	_	
94-8	25172-25177	video	_	_	
94-9	25177-25178	]	_	_	
94-10	25179-25180	[	_	_	
94-11	25180-25184	Easy	_	_	
94-12	25185-25194	Automated	_	_	
94-13	25195-25199	Live	_	_	
94-14	25200-25207	Trading	_	_	
94-15	25208-25213	using	_	_	
94-16	25214-25221	ChatGPT	*	SOFTWARE	
94-17	25222-25223	(	_	_	
94-18	25223-25224	+	_	_	
94-19	25224-25231	9660.3%	_	_	
94-20	25232-25237	hands	_	_	
94-21	25238-25242	free	_	_	
94-22	25242-25243	)	_	_	
94-23	25243-25244	]	_	_	
94-24	25244-25245	(	_	_	
94-25	25245-25250	https	_	_	
94-26	25250-25251	:	_	_	
94-27	25251-25252	/	_	_	
94-28	25252-25253	/	_	_	
94-29	25253-25268	www.youtube.com	_	_	
94-30	25268-25269	/	_	_	
94-31	25269-25274	watch	_	_	
94-32	25274-25275	?	_	_	

#Text=v=dIEZVPVOZPQ)
#Text=+ [YouTube video] [ChatGPT Trading Strategy 893% Returns](https://www.youtube.com/watch?
95-1	25275-25276	v	_	_	
95-2	25276-25277	=	_	_	
95-3	25277-25288	dIEZVPVOZPQ	_	_	
95-4	25288-25289	)	_	_	
95-5	25290-25291	+	_	_	
95-6	25292-25293	[	_	_	
95-7	25293-25300	YouTube	_	_	
95-8	25301-25306	video	_	_	
95-9	25306-25307	]	_	_	
95-10	25308-25309	[	_	_	
95-11	25309-25316	ChatGPT	*	SOFTWARE	
95-12	25317-25324	Trading	_	_	
95-13	25325-25333	Strategy	_	_	
95-14	25334-25338	893%	_	_	
95-15	25339-25346	Returns	_	_	
95-16	25346-25347	]	_	_	
95-17	25347-25348	(	_	_	
95-18	25348-25353	https	_	_	
95-19	25353-25354	:	_	_	
95-20	25354-25355	/	_	_	
95-21	25355-25356	/	_	_	
95-22	25356-25371	www.youtube.com	_	_	
95-23	25371-25372	/	_	_	
95-24	25372-25377	watch	_	_	
95-25	25377-25378	?	_	_	

#Text=v=YxjvjK5AD2M)
#Text=+ [YouTube video] [ChatGPT 10 Million Trading Strategy](https://www.youtube.com/watch?
96-1	25378-25379	v	_	_	
96-2	25379-25380	=	_	_	
96-3	25380-25391	YxjvjK5AD2M	_	_	
96-4	25391-25392	)	_	_	
96-5	25393-25394	+	_	_	
96-6	25395-25396	[	_	_	
96-7	25396-25403	YouTube	_	_	
96-8	25404-25409	video	_	_	
96-9	25409-25410	]	_	_	
96-10	25411-25412	[	_	_	
96-11	25412-25419	ChatGPT	*	SOFTWARE	
96-12	25420-25422	10	_	_	
96-13	25423-25430	Million	_	_	
96-14	25431-25438	Trading	_	_	
96-15	25439-25447	Strategy	_	_	
96-16	25447-25448	]	_	_	
96-17	25448-25449	(	_	_	
96-18	25449-25454	https	_	_	
96-19	25454-25455	:	_	_	
96-20	25455-25456	/	_	_	
96-21	25456-25457	/	_	_	
96-22	25457-25472	www.youtube.com	_	_	
96-23	25472-25473	/	_	_	
96-24	25473-25478	watch	_	_	
96-25	25478-25479	?	_	_	

#Text=v=9VPfd08uU4Q)
#Text=+ [YouTube video] [ChatGPT: Your Crypto Assistant](https://www.youtube.com/watch?
97-1	25479-25480	v	_	_	
97-2	25480-25481	=	_	_	
97-3	25481-25492	9VPfd08uU4Q	_	_	
97-4	25492-25493	)	_	_	
97-5	25494-25495	+	_	_	
97-6	25496-25497	[	_	_	
97-7	25497-25504	YouTube	_	_	
97-8	25505-25510	video	_	_	
97-9	25510-25511	]	_	_	
97-10	25512-25513	[	_	_	
97-11	25513-25520	ChatGPT	*	SOFTWARE	
97-12	25520-25521	:	_	_	
97-13	25522-25526	Your	_	_	
97-14	25527-25533	Crypto	_	_	
97-15	25534-25543	Assistant	_	_	
97-16	25543-25544	]	_	_	
97-17	25544-25545	(	_	_	
97-18	25545-25550	https	_	_	
97-19	25550-25551	:	_	_	
97-20	25551-25552	/	_	_	
97-21	25552-25553	/	_	_	
97-22	25553-25568	www.youtube.com	_	_	
97-23	25568-25569	/	_	_	
97-24	25569-25574	watch	_	_	
97-25	25574-25575	?	_	_	

#Text=v=LpzeshX6s2w)
#Text=+ [YouTube video] [Generate Insane Trading Returns with ChatGPT and TradingView](https://www.youtube.com/watch?
98-1	25575-25576	v	_	_	
98-2	25576-25577	=	_	_	
98-3	25577-25588	LpzeshX6s2w	_	_	
98-4	25588-25589	)	_	_	
98-5	25590-25591	+	_	_	
98-6	25592-25593	[	_	_	
98-7	25593-25600	YouTube	_	_	
98-8	25601-25606	video	_	_	
98-9	25606-25607	]	_	_	
98-10	25608-25609	[	_	_	
98-11	25609-25617	Generate	_	_	
98-12	25618-25624	Insane	_	_	
98-13	25625-25632	Trading	_	_	
98-14	25633-25640	Returns	_	_	
98-15	25641-25645	with	_	_	
98-16	25646-25653	ChatGPT	*	SOFTWARE	
98-17	25654-25657	and	_	_	
98-18	25658-25669	TradingView	*	SOFTWARE	
98-19	25669-25670	]	_	_	
98-20	25670-25671	(	_	_	
98-21	25671-25676	https	_	_	
98-22	25676-25677	:	_	_	
98-23	25677-25678	/	_	_	
98-24	25678-25679	/	_	_	
98-25	25679-25694	www.youtube.com	_	_	
98-26	25694-25695	/	_	_	
98-27	25695-25700	watch	_	_	
98-28	25700-25701	?	_	_	

#Text=v=ekz6ugJE1h0&t=3s)
#Text=
#Text=<!
99-1	25701-25702	v	_	_	
99-2	25702-25703	=	_	_	
99-3	25703-25715	ekz6ugJE1h0&	_	_	
99-4	25715-25716	t	_	_	
99-5	25716-25717	=	_	_	
99-6	25717-25719	3s	_	_	
99-7	25719-25720	)	_	_	
99-8	25722-25723	<	_	_	
99-9	25723-25724	!	_	_	

#Text=--- 
#Text=**(Fast and accurate) Sentiment Analysis**
#Text=
#Text=   GPT-3 can help study customer surveys, social media tweets from customers/users.
100-1	25724-25725	-	_	_	
100-2	25725-25726	-	_	_	
100-3	25726-25727	-	_	_	
100-4	25729-25730	*	_	_	
100-5	25730-25731	*	_	_	
100-6	25731-25732	(	_	_	
100-7	25732-25736	Fast	_	_	
100-8	25737-25740	and	_	_	
100-9	25741-25749	accurate	*	EVALMETRIC	
100-10	25749-25750	)	_	_	
100-11	25751-25760	Sentiment	_	_	
100-12	25761-25769	Analysis	_	_	
100-13	25769-25770	*	_	_	
100-14	25770-25771	*	_	_	
100-15	25776-25779	GPT	*[132]	SOFTWARE[132]	
100-16	25779-25780	-	*[132]	SOFTWARE[132]	
100-17	25780-25781	3	*[132]	SOFTWARE[132]	
100-18	25782-25785	can	_	_	
100-19	25786-25790	help	_	_	
100-20	25791-25796	study	_	_	
100-21	25797-25805	customer	_	_	
100-22	25806-25813	surveys	_	_	
100-23	25813-25814	,	_	_	
100-24	25815-25821	social	_	_	
100-25	25822-25827	media	_	_	
100-26	25828-25834	tweets	_	_	
100-27	25835-25839	from	_	_	
100-28	25840-25849	customers	_	_	
100-29	25849-25850	/	_	_	
100-30	25850-25855	users	_	_	
100-31	25855-25856	.	_	_	

#Text=Tweets
#Text=+ [Tweet Classifier](https://platform.openai.com/playground/p/default-tweet-classifier?
101-1	25861-25867	Tweets	_	_	
101-2	25868-25869	+	_	_	
101-3	25870-25871	[	_	_	
101-4	25871-25876	Tweet	_	_	
101-5	25877-25887	Classifier	_	_	
101-6	25887-25888	]	_	_	
101-7	25888-25889	(	_	_	
101-8	25889-25894	https	_	_	
101-9	25894-25895	:	_	_	
101-10	25895-25896	/	_	_	
101-11	25896-25897	/	_	_	
101-12	25897-25916	platform.openai.com	_	_	
101-13	25916-25917	/	_	_	
101-14	25917-25927	playground	_	_	
101-15	25927-25928	/	_	_	
101-16	25928-25929	p	_	_	
101-17	25929-25930	/	_	_	
101-18	25930-25954	default-tweet-classifier	_	_	
101-19	25954-25955	?	_	_	

#Text=model=text-davinci-003)
#Text=+ [Advanced Tweet Classifier](https://platform.openai.com/playground/p/default-adv-tweet-classifier?
102-1	25955-25960	model	_	_	
102-2	25960-25961	=	_	_	
102-3	25961-25973	text-davinci	_	_	
102-4	25973-25974	-	_	_	
102-5	25974-25977	003	_	_	
102-6	25977-25978	)	_	_	
102-7	25979-25980	+	_	_	
102-8	25981-25982	[	_	_	
102-9	25982-25990	Advanced	_	_	
102-10	25991-25996	Tweet	_	_	
102-11	25997-26007	Classifier	_	_	
102-12	26007-26008	]	_	_	
102-13	26008-26009	(	_	_	
102-14	26009-26014	https	_	_	
102-15	26014-26015	:	_	_	
102-16	26015-26016	/	_	_	
102-17	26016-26017	/	_	_	
102-18	26017-26036	platform.openai.com	_	_	
102-19	26036-26037	/	_	_	
102-20	26037-26047	playground	_	_	
102-21	26047-26048	/	_	_	
102-22	26048-26049	p	_	_	
102-23	26049-26050	/	_	_	
102-24	26050-26078	default-adv-tweet-classifier	_	_	
102-25	26078-26079	?	_	_	

#Text=model=text-davinci-003)
#Text=
#Text=  Financial News
#Text=+ [Algorithmic Trading using Sentiment Analysis on News Articles](https://towardsdatascience.com/https-towardsdatascience-com-algorithmic-trading-using-sentiment-analysis-on-news-articles-83db77966704)
#Text=+ [Accessing Historical Financial News Headlines with Python](https://python.plainenglish.io/access-historical-financial-news-headlines-with-python-be1b8faaea9f)
#Text=
#Text=**PromptNet** Analogy to ImageNet and WordNet, it is critical to build a PromptNet
103-1	26079-26084	model	_	_	
103-2	26084-26085	=	_	_	
103-3	26085-26097	text-davinci	*[133]	SOFTWARE[133]	
103-4	26097-26098	-	*[133]	SOFTWARE[133]	
103-5	26098-26101	003	*[133]	SOFTWARE[133]	
103-6	26101-26102	)	_	_	
103-7	26106-26115	Financial	_	_	
103-8	26116-26120	News	_	_	
103-9	26121-26122	+	_	_	
103-10	26123-26124	[	_	_	
103-11	26124-26135	Algorithmic	_	_	
103-12	26136-26143	Trading	_	_	
103-13	26144-26149	using	_	_	
103-14	26150-26159	Sentiment	_	_	
103-15	26160-26168	Analysis	_	_	
103-16	26169-26171	on	_	_	
103-17	26172-26176	News	_	_	
103-18	26177-26185	Articles	_	_	
103-19	26185-26186	]	_	_	
103-20	26186-26187	(	_	_	
103-21	26187-26192	https	_	_	
103-22	26192-26193	:	_	_	
103-23	26193-26194	/	_	_	
103-24	26194-26195	/	_	_	
103-25	26195-26217	towardsdatascience.com	_	_	
103-26	26217-26218	/	_	_	
103-27	26218-26308	https-towardsdatascience-com-algorithmic-trading-using-sentiment-analysis-on-news-articles	_	_	
103-28	26308-26309	-	_	_	
103-29	26309-26321	83db77966704	_	_	
103-30	26321-26322	)	_	_	
103-31	26323-26324	+	_	_	
103-32	26325-26326	[	_	_	
103-33	26326-26335	Accessing	_	_	
103-34	26336-26346	Historical	_	_	
103-35	26347-26356	Financial	_	_	
103-36	26357-26361	News	_	_	
103-37	26362-26371	Headlines	_	_	
103-38	26372-26376	with	_	_	
103-39	26377-26383	Python	*	PROGLANG	
103-40	26383-26384	]	_	_	
103-41	26384-26385	(	_	_	
103-42	26385-26390	https	_	_	
103-43	26390-26391	:	_	_	
103-44	26391-26392	/	_	_	
103-45	26392-26393	/	_	_	
103-46	26393-26415	python.plainenglish.io	_	_	
103-46.1	26393-26399	python	*	PROGLANG	
103-47	26415-26416	/	_	_	
103-48	26416-26483	access-historical-financial-news-headlines-with-python-be1b8faaea9f	_	_	
103-48.1	26464-26470	python	*	PROGLANG	
103-49	26483-26484	)	_	_	
103-50	26486-26487	*	_	_	
103-51	26487-26488	*	_	_	
103-52	26488-26497	PromptNet	*	DATASET	
103-53	26497-26498	*	_	_	
103-54	26498-26499	*	_	_	
103-55	26500-26507	Analogy	_	_	
103-56	26508-26510	to	_	_	
103-57	26511-26519	ImageNet	*	DATASET	
103-58	26520-26523	and	_	_	
103-59	26524-26531	WordNet	*	DATASET	
103-60	26531-26532	,	_	_	
103-61	26533-26535	it	_	_	
103-62	26536-26538	is	_	_	
103-63	26539-26547	critical	_	_	
103-64	26548-26550	to	_	_	
103-65	26551-26556	build	_	_	
103-66	26557-26558	a	_	_	
103-67	26559-26568	PromptNet	*	DATASET	

#Text=.
104-1	26568-26569	.	_	_	

#Text=+ [Awesome_Prompting_Papers_in_Computer_Vision](https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision)
#Text=+ [OpenPrompt](https://github.com/thunlp/OpenPrompt)
#Text=+ [promptsource](https://github.com/bigscience-workshop/promptsource)
#Text=
#Text=**Robo-advisor**
#Text=
#Text=**Coding-tutor**
#Text=
#Text=+ [Hey, ChatGPT!
105-1	26571-26572	+	_	_	
105-2	26573-26574	[	_	_	
105-3	26574-26617	Awesome_Prompting_Papers_in_Computer_Vision	_	_	
105-4	26617-26618	]	_	_	
105-5	26618-26619	(	_	_	
105-6	26619-26624	https	_	_	
105-7	26624-26625	:	_	_	
105-8	26625-26626	/	_	_	
105-9	26626-26627	/	_	_	
105-10	26627-26637	github.com	_	_	
105-11	26637-26638	/	_	_	
105-12	26638-26647	ttengwang	_	_	
105-13	26647-26648	/	_	_	
105-14	26648-26691	Awesome_Prompting_Papers_in_Computer_Vision	_	_	
105-15	26691-26692	)	_	_	
105-16	26693-26694	+	_	_	
105-17	26695-26696	[	_	_	
105-18	26696-26706	OpenPrompt	_	_	
105-19	26706-26707	]	_	_	
105-20	26707-26708	(	_	_	
105-21	26708-26713	https	_	_	
105-22	26713-26714	:	_	_	
105-23	26714-26715	/	_	_	
105-24	26715-26716	/	_	_	
105-25	26716-26726	github.com	_	_	
105-26	26726-26727	/	_	_	
105-27	26727-26733	thunlp	_	_	
105-28	26733-26734	/	_	_	
105-29	26734-26744	OpenPrompt	_	_	
105-30	26744-26745	)	_	_	
105-31	26746-26747	+	_	_	
105-32	26748-26749	[	_	_	
105-33	26749-26761	promptsource	_	_	
105-34	26761-26762	]	_	_	
105-35	26762-26763	(	_	_	
105-36	26763-26768	https	_	_	
105-37	26768-26769	:	_	_	
105-38	26769-26770	/	_	_	
105-39	26770-26771	/	_	_	
105-40	26771-26781	github.com	_	_	
105-41	26781-26782	/	_	_	
105-42	26782-26801	bigscience-workshop	_	_	
105-43	26801-26802	/	_	_	
105-44	26802-26814	promptsource	_	_	
105-45	26814-26815	)	_	_	
105-46	26817-26818	*	_	_	
105-47	26818-26819	*	_	_	
105-48	26819-26831	Robo-advisor	_	_	
105-49	26831-26832	*	_	_	
105-50	26832-26833	*	_	_	
105-51	26835-26836	*	_	_	
105-52	26836-26837	*	_	_	
105-53	26837-26849	Coding-tutor	_	_	
105-54	26849-26850	*	_	_	
105-55	26850-26851	*	_	_	
105-56	26853-26854	+	_	_	
105-57	26855-26856	[	_	_	
105-58	26856-26859	Hey	_	_	
105-59	26859-26860	,	_	_	
105-60	26861-26868	ChatGPT	*	SOFTWARE	
105-61	26868-26869	!	_	_	

#Text=Explain FinRL code to me!]
106-1	26870-26877	Explain	_	_	
106-2	26878-26883	FinRL	_	_	
106-3	26884-26888	code	_	_	
106-4	26889-26891	to	_	_	
106-5	26892-26894	me	_	_	
106-6	26894-26895	!	_	_	
106-7	26895-26896	]	_	_	

#Text=(https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f)
#Text=
#Text=**Blogs about ChatGPT for FinTech**
#Text=
#Text=## ChatGPT APIs
#Text=
#Text=Prompting as a new programming paradigm!
107-1	26896-26897	(	_	_	
107-2	26897-26902	https	_	_	
107-3	26902-26903	:	_	_	
107-4	26903-26904	/	_	_	
107-5	26904-26905	/	_	_	
107-6	26905-26915	medium.com	_	_	
107-7	26915-26916	/	_	_	
107-8	26916-26917	@	_	_	
107-9	26917-26927	ai4finance	_	_	
107-10	26927-26928	/	_	_	
107-11	26928-26964	hey-chatgpt-explain-finrl-code-to-me	_	_	
107-11.1	26932-26939	chatgpt	*	SOFTWARE	
107-12	26964-26965	-	_	_	
107-13	26965-26977	6a91d612296f	_	_	
107-14	26977-26978	)	_	_	
107-15	26980-26981	*	_	_	
107-16	26981-26982	*	_	_	
107-17	26982-26987	Blogs	_	_	
107-18	26988-26993	about	_	_	
107-19	26994-27001	ChatGPT	*	SOFTWARE	
107-20	27002-27005	for	_	_	
107-21	27006-27013	FinTech	_	_	
107-22	27013-27014	*	_	_	
107-23	27014-27015	*	_	_	
107-24	27017-27018	#	_	_	
107-25	27018-27019	#	_	_	
107-26	27020-27027	ChatGPT	*	SOFTWARE	
107-27	27028-27032	APIs	_	_	
107-28	27034-27043	Prompting	_	_	
107-29	27044-27046	as	_	_	
107-30	27047-27048	a	_	_	
107-31	27049-27052	new	_	_	
107-32	27053-27064	programming	_	_	
107-33	27065-27073	paradigm	_	_	
107-34	27073-27074	!	_	_	

#Text=+ [Towards Data Science] [GPT-3: Creative Potential of NLP](https://towardsdatascience.com/gpt-3-creative-potential-of-nlp-d5ccae16c1ab)
#Text=+ [YouTube video] [OpenAI GPT-3 - Prompt Engineering For Financial NLP](https://www.youtube.com/watch?
108-1	27075-27076	+	_	_	
108-2	27077-27078	[	_	_	
108-3	27078-27085	Towards	_	_	
108-4	27086-27090	Data	_	_	
108-5	27091-27098	Science	_	_	
108-6	27098-27099	]	_	_	
108-7	27100-27101	[	_	_	
108-8	27101-27104	GPT	*[134]	SOFTWARE[134]	
108-9	27104-27105	-	*[134]	SOFTWARE[134]	
108-10	27105-27106	3	*[134]	SOFTWARE[134]	
108-11	27106-27107	:	_	_	
108-12	27108-27116	Creative	_	_	
108-13	27117-27126	Potential	_	_	
108-14	27127-27129	of	_	_	
108-15	27130-27133	NLP	_	_	
108-16	27133-27134	]	_	_	
108-17	27134-27135	(	_	_	
108-18	27135-27140	https	_	_	
108-19	27140-27141	:	_	_	
108-20	27141-27142	/	_	_	
108-21	27142-27143	/	_	_	
108-22	27143-27165	towardsdatascience.com	_	_	
108-23	27165-27166	/	_	_	
108-24	27166-27169	gpt	_	_	
108-25	27169-27170	-	_	_	
108-26	27170-27171	3	_	_	
108-27	27171-27172	-	_	_	
108-28	27172-27210	creative-potential-of-nlp-d5ccae16c1ab	_	_	
108-29	27210-27211	)	_	_	
108-30	27212-27213	+	_	_	
108-31	27214-27215	[	_	_	
108-32	27215-27222	YouTube	_	_	
108-33	27223-27228	video	_	_	
108-34	27228-27229	]	_	_	
108-35	27230-27231	[	_	_	
108-36	27231-27237	OpenAI	_	_	
108-37	27238-27241	GPT	*[135]	SOFTWARE[135]	
108-38	27241-27242	-	*[135]	SOFTWARE[135]	
108-39	27242-27243	3	*[135]	SOFTWARE[135]	
108-40	27244-27245	-	_	_	
108-41	27246-27252	Prompt	_	_	
108-42	27253-27264	Engineering	_	_	
108-43	27265-27268	For	_	_	
108-44	27269-27278	Financial	_	_	
108-45	27279-27282	NLP	_	_	
108-46	27282-27283	]	_	_	
108-47	27283-27284	(	_	_	
108-48	27284-27289	https	_	_	
108-49	27289-27290	:	_	_	
108-50	27290-27291	/	_	_	
108-51	27291-27292	/	_	_	
108-52	27292-27307	www.youtube.com	_	_	
108-53	27307-27308	/	_	_	
108-54	27308-27313	watch	_	_	
108-55	27313-27314	?	_	_	

#Text=v=Nl2Cdbao5Ws)
#Text=
#Text=+ [OpenAI API for GPT-3](https://platform.openai.com/docs/models/gpt-3)
#Text=+ [ChatGPT-wrapper: python and shell](https://github.com/mmabrouk/chatgpt-wrapper)
#Text=+ [OpenAI Examples Library](https://platform.openai.com/examples)
#Text=+ [GPT-3 Sandbox (Github)](https://github.com/shreyashankar/gpt3-sandbox) Enable users to create cool web demos using OpenAI GPT-3 API.
#Text=+ [Exploring the Capabilities of the ChatGPT API: A Beginner’s Guide](https://levelup.gitconnected.com/exploring-the-capabilities-of-the-chatgpt-api-a-beginners-guide-e9089d49961f)
#Text=+ [Reverse engineered ChatGPT API](https://github.com/acheong08/ChatGPT)
#Text=
#Text=**Prompting programming**
#Text=
#Text=## ChatGPT relatives: 
#Text=
#Text=[A Release Timeline](https://github.com/osanseviero/ml_timeline) of many LLMs.
109-1	27314-27315	v	_	_	
109-2	27315-27316	=	_	_	
109-3	27316-27327	Nl2Cdbao5Ws	_	_	
109-4	27327-27328	)	_	_	
109-5	27330-27331	+	_	_	
109-6	27332-27333	[	_	_	
109-7	27333-27339	OpenAI	_	_	
109-8	27340-27343	API	_	_	
109-9	27344-27347	for	_	_	
109-10	27348-27351	GPT	*[136]	SOFTWARE[136]	
109-11	27351-27352	-	*[136]	SOFTWARE[136]	
109-12	27352-27353	3	*[136]	SOFTWARE[136]	
109-13	27353-27354	]	_	_	
109-14	27354-27355	(	_	_	
109-15	27355-27360	https	_	_	
109-16	27360-27361	:	_	_	
109-17	27361-27362	/	_	_	
109-18	27362-27363	/	_	_	
109-19	27363-27382	platform.openai.com	_	_	
109-20	27382-27383	/	_	_	
109-21	27383-27387	docs	_	_	
109-22	27387-27388	/	_	_	
109-23	27388-27394	models	_	_	
109-24	27394-27395	/	_	_	
109-25	27395-27398	gpt	*[137]	SOFTWARE[137]	
109-26	27398-27399	-	*[137]	SOFTWARE[137]	
109-27	27399-27400	3	*[137]	SOFTWARE[137]	
109-28	27400-27401	)	_	_	
109-29	27402-27403	+	_	_	
109-30	27404-27405	[	_	_	
109-31	27405-27420	ChatGPT-wrapper	_	_	
109-31.1	27405-27412	ChatGPT	*	SOFTWARE	
109-32	27420-27421	:	_	_	
109-33	27422-27428	python	*	PROGLANG	
109-34	27429-27432	and	_	_	
109-35	27433-27438	shell	*	PROGLANG	
109-36	27438-27439	]	_	_	
109-37	27439-27440	(	_	_	
109-38	27440-27445	https	_	_	
109-39	27445-27446	:	_	_	
109-40	27446-27447	/	_	_	
109-41	27447-27448	/	_	_	
109-42	27448-27458	github.com	_	_	
109-43	27458-27459	/	_	_	
109-44	27459-27467	mmabrouk	_	_	
109-45	27467-27468	/	_	_	
109-46	27468-27483	chatgpt-wrapper	_	_	
109-46.1	27468-27475	chatgpt	*	SOFTWARE	
109-47	27483-27484	)	_	_	
109-48	27485-27486	+	_	_	
109-49	27487-27488	[	_	_	
109-50	27488-27494	OpenAI	_	_	
109-51	27495-27503	Examples	_	_	
109-52	27504-27511	Library	_	_	
109-53	27511-27512	]	_	_	
109-54	27512-27513	(	_	_	
109-55	27513-27518	https	_	_	
109-56	27518-27519	:	_	_	
109-57	27519-27520	/	_	_	
109-58	27520-27521	/	_	_	
109-59	27521-27540	platform.openai.com	_	_	
109-60	27540-27541	/	_	_	
109-61	27541-27549	examples	_	_	
109-62	27549-27550	)	_	_	
109-63	27551-27552	+	_	_	
109-64	27553-27554	[	_	_	
109-65	27554-27557	GPT	*[138]	SOFTWARE[138]	
109-66	27557-27558	-	*[138]	SOFTWARE[138]	
109-67	27558-27559	3	*[138]	SOFTWARE[138]	
109-68	27560-27567	Sandbox	_	_	
109-69	27568-27569	(	_	_	
109-70	27569-27575	Github	_	_	
109-71	27575-27576	)	_	_	
109-72	27576-27577	]	_	_	
109-73	27577-27578	(	_	_	
109-74	27578-27583	https	_	_	
109-75	27583-27584	:	_	_	
109-76	27584-27585	/	_	_	
109-77	27585-27586	/	_	_	
109-78	27586-27596	github.com	_	_	
109-79	27596-27597	/	_	_	
109-80	27597-27610	shreyashankar	_	_	
109-81	27610-27611	/	_	_	
109-82	27611-27615	gpt3	_	_	
109-83	27615-27616	-	_	_	
109-84	27616-27623	sandbox	_	_	
109-85	27623-27624	)	_	_	
109-86	27625-27631	Enable	_	_	
109-87	27632-27637	users	_	_	
109-88	27638-27640	to	_	_	
109-89	27641-27647	create	_	_	
109-90	27648-27652	cool	_	_	
109-91	27653-27656	web	_	_	
109-92	27657-27662	demos	_	_	
109-93	27663-27668	using	_	_	
109-94	27669-27675	OpenAI	_	_	
109-95	27676-27679	GPT	*[139]	SOFTWARE[139]	
109-96	27679-27680	-	*[139]	SOFTWARE[139]	
109-97	27680-27681	3	*[139]	SOFTWARE[139]	
109-98	27682-27685	API	_	_	
109-99	27685-27686	.	_	_	
109-100	27687-27688	+	_	_	
109-101	27689-27690	[	_	_	
109-102	27690-27699	Exploring	_	_	
109-103	27700-27703	the	_	_	
109-104	27704-27716	Capabilities	_	_	
109-105	27717-27719	of	_	_	
109-106	27720-27723	the	_	_	
109-107	27724-27731	ChatGPT	*	SOFTWARE	
109-108	27732-27735	API	_	_	
109-109	27735-27736	:	_	_	
109-110	27737-27738	A	_	_	
109-111	27739-27747	Beginner	_	_	
109-112	27747-27748	’	_	_	
109-113	27748-27749	s	_	_	
109-114	27750-27755	Guide	_	_	
109-115	27755-27756	]	_	_	
109-116	27756-27757	(	_	_	
109-117	27757-27762	https	_	_	
109-118	27762-27763	:	_	_	
109-119	27763-27764	/	_	_	
109-120	27764-27765	/	_	_	
109-121	27765-27789	levelup.gitconnected.com	_	_	
109-121.1	27773-27776	git	*	SOFTWARE	
109-122	27789-27790	/	_	_	
109-123	27790-27866	exploring-the-capabilities-of-the-chatgpt-api-a-beginners-guide-e9089d49961f	_	_	
109-124	27866-27867	)	_	_	
109-125	27868-27869	+	_	_	
109-126	27870-27871	[	_	_	
109-127	27871-27878	Reverse	_	_	
109-128	27879-27889	engineered	_	_	
109-129	27890-27897	ChatGPT	*	SOFTWARE	
109-130	27898-27901	API	_	_	
109-131	27901-27902	]	_	_	
109-132	27902-27903	(	_	_	
109-133	27903-27908	https	_	_	
109-134	27908-27909	:	_	_	
109-135	27909-27910	/	_	_	
109-136	27910-27911	/	_	_	
109-137	27911-27921	github.com	_	_	
109-138	27921-27922	/	_	_	
109-139	27922-27931	acheong08	_	_	
109-140	27931-27932	/	_	_	
109-141	27932-27939	ChatGPT	*	SOFTWARE	
109-142	27939-27940	)	_	_	
109-143	27942-27943	*	_	_	
109-144	27943-27944	*	_	_	
109-145	27944-27953	Prompting	_	_	
109-146	27954-27965	programming	_	_	
109-147	27965-27966	*	_	_	
109-148	27966-27967	*	_	_	
109-149	27969-27970	#	_	_	
109-150	27970-27971	#	_	_	
109-151	27972-27979	ChatGPT	*	SOFTWARE	
109-152	27980-27989	relatives	_	_	
109-153	27989-27990	:	_	_	
109-154	27993-27994	[	_	_	
109-155	27994-27995	A	_	_	
109-156	27996-28003	Release	_	_	
109-157	28004-28012	Timeline	_	_	
109-158	28012-28013	]	_	_	
109-159	28013-28014	(	_	_	
109-160	28014-28019	https	_	_	
109-161	28019-28020	:	_	_	
109-162	28020-28021	/	_	_	
109-163	28021-28022	/	_	_	
109-164	28022-28032	github.com	_	_	
109-165	28032-28033	/	_	_	
109-166	28033-28044	osanseviero	_	_	
109-167	28044-28045	/	_	_	
109-168	28045-28056	ml_timeline	_	_	
109-169	28056-28057	)	_	_	
109-170	28058-28060	of	_	_	
109-171	28061-28065	many	_	_	
109-172	28066-28070	LLMs	_	_	
109-173	28070-28071	.	_	_	

#Text=[PaLM](https://arxiv.org/abs/2204.02311)
#Text=
#Text=[Chincella](https://arxiv.org/abs/2203.15556)
#Text=
#Text=Interesting evaluations:
#Text=+ [RLHF for pretraining](https://arxiv.org/abs/2302.08582)
#Text=
#Text=+ [Compare ChatGPT with GPT3.5](https://arxiv.org/pdf/2302.06476.pdf)
#Text=
#Text=+ [Is ChatGPT A Good Translator?
110-1	28073-28074	[	_	_	
110-2	28074-28078	PaLM	*	SOFTWARE	
110-3	28078-28079	]	_	_	
110-4	28079-28080	(	_	_	
110-5	28080-28085	https	_	_	
110-6	28085-28086	:	_	_	
110-7	28086-28087	/	_	_	
110-8	28087-28088	/	_	_	
110-9	28088-28097	arxiv.org	_	_	
110-10	28097-28098	/	_	_	
110-11	28098-28101	abs	_	_	
110-12	28101-28102	/	_	_	
110-13	28102-28112	2204.02311	_	_	
110-14	28112-28113	)	_	_	
110-15	28115-28116	[	_	_	
110-16	28116-28125	Chincella	_	_	
110-17	28125-28126	]	_	_	
110-18	28126-28127	(	_	_	
110-19	28127-28132	https	_	_	
110-20	28132-28133	:	_	_	
110-21	28133-28134	/	_	_	
110-22	28134-28135	/	_	_	
110-23	28135-28144	arxiv.org	_	_	
110-24	28144-28145	/	_	_	
110-25	28145-28148	abs	_	_	
110-26	28148-28149	/	_	_	
110-27	28149-28159	2203.15556	_	_	
110-28	28159-28160	)	_	_	
110-29	28162-28173	Interesting	_	_	
110-30	28174-28185	evaluations	_	_	
110-31	28185-28186	:	_	_	
110-32	28187-28188	+	_	_	
110-33	28189-28190	[	_	_	
110-34	28190-28194	RLHF	*[140]	PUBLICATION[140]	
110-35	28195-28198	for	*[140]	PUBLICATION[140]	
110-36	28199-28210	pretraining	*[140]	PUBLICATION[140]	
110-37	28210-28211	]	_	_	
110-38	28211-28212	(	_	_	
110-39	28212-28217	https	_	_	
110-40	28217-28218	:	_	_	
110-41	28218-28219	/	_	_	
110-42	28219-28220	/	_	_	
110-43	28220-28229	arxiv.org	_	_	
110-44	28229-28230	/	_	_	
110-45	28230-28233	abs	_	_	
110-46	28233-28234	/	_	_	
110-47	28234-28244	2302.08582	_	_	
110-48	28244-28245	)	_	_	
110-49	28247-28248	+	_	_	
110-50	28249-28250	[	_	_	
110-51	28250-28257	Compare	_	_	
110-52	28258-28265	ChatGPT	*	SOFTWARE	
110-53	28266-28270	with	_	_	
110-54	28271-28277	GPT3.5	*	SOFTWARE	
110-55	28277-28278	]	_	_	
110-56	28278-28279	(	_	_	
110-57	28279-28284	https	_	_	
110-58	28284-28285	:	_	_	
110-59	28285-28286	/	_	_	
110-60	28286-28287	/	_	_	
110-61	28287-28296	arxiv.org	_	_	
110-62	28296-28297	/	_	_	
110-63	28297-28300	pdf	_	_	
110-64	28300-28301	/	_	_	
110-65	28301-28311	2302.06476	_	_	
110-66	28311-28312	.	_	_	
110-67	28312-28315	pdf	_	_	
110-68	28315-28316	)	_	_	
110-69	28318-28319	+	_	_	
110-70	28320-28321	[	_	_	
110-71	28321-28323	Is	*[141]	PUBLICATION[141]	
110-72	28324-28331	ChatGPT	*[141]|*[142]	PUBLICATION[141]|SOFTWARE[142]	
110-73	28332-28333	A	*[141]	PUBLICATION[141]	
110-74	28334-28338	Good	*[141]	PUBLICATION[141]	
110-75	28339-28349	Translator	*[141]	PUBLICATION[141]	
110-76	28349-28350	?	*[141]	PUBLICATION[141]	

#Text=A Preliminary Study](https://arxiv.org/pdf/2301.08745.pdf)
#Text=
#Text=+ [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT
#Text=on Reasoning, Hallucination, and Interactivity](https://arxiv.org/pdf/2302.04023.pdf)
#Text=
#Text=[YouTube video] [Physics Solution: ChatGPT vs.
111-1	28351-28352	A	*[141]	PUBLICATION[141]	
111-2	28353-28364	Preliminary	*[141]	PUBLICATION[141]	
111-3	28365-28370	Study	*[141]	PUBLICATION[141]	
111-4	28370-28371	]	_	_	
111-5	28371-28372	(	_	_	
111-6	28372-28377	https	_	_	
111-7	28377-28378	:	_	_	
111-8	28378-28379	/	_	_	
111-9	28379-28380	/	_	_	
111-10	28380-28389	arxiv.org	_	_	
111-11	28389-28390	/	_	_	
111-12	28390-28393	pdf	_	_	
111-13	28393-28394	/	_	_	
111-14	28394-28404	2301.08745	_	_	
111-15	28404-28405	.	_	_	
111-16	28405-28408	pdf	_	_	
111-17	28408-28409	)	_	_	
111-18	28411-28412	+	_	_	
111-19	28413-28414	[	_	_	
111-20	28414-28415	A	*[143]	PUBLICATION[143]	
111-21	28416-28425	Multitask	*[143]	PUBLICATION[143]	
111-22	28425-28426	,	*[143]	PUBLICATION[143]	
111-23	28427-28439	Multilingual	*[143]	PUBLICATION[143]	
111-24	28439-28440	,	*[143]	PUBLICATION[143]	
111-25	28441-28451	Multimodal	*[143]	PUBLICATION[143]	
111-26	28452-28462	Evaluation	*[143]	PUBLICATION[143]	
111-27	28463-28465	of	*[143]	PUBLICATION[143]	
111-28	28466-28473	ChatGPT	*[143]|*[144]	PUBLICATION[143]|SOFTWARE[144]	
111-29	28474-28476	on	*[143]	PUBLICATION[143]	
111-30	28477-28486	Reasoning	*[143]	PUBLICATION[143]	
111-31	28486-28487	,	*[143]	PUBLICATION[143]	
111-32	28488-28501	Hallucination	*[143]	PUBLICATION[143]	
111-33	28501-28502	,	*[143]	PUBLICATION[143]	
111-34	28503-28506	and	*[143]	PUBLICATION[143]	
111-35	28507-28520	Interactivity	*[143]	PUBLICATION[143]	
111-36	28520-28521	]	_	_	
111-37	28521-28522	(	_	_	
111-38	28522-28527	https	_	_	
111-39	28527-28528	:	_	_	
111-40	28528-28529	/	_	_	
111-41	28529-28530	/	_	_	
111-42	28530-28539	arxiv.org	_	_	
111-43	28539-28540	/	_	_	
111-44	28540-28543	pdf	_	_	
111-45	28543-28544	/	_	_	
111-46	28544-28554	2302.04023	_	_	
111-47	28554-28555	.	_	_	
111-48	28555-28558	pdf	_	_	
111-49	28558-28559	)	_	_	
111-50	28561-28562	[	_	_	
111-51	28562-28569	YouTube	_	_	
111-52	28570-28575	video	_	_	
111-53	28575-28576	]	_	_	
111-54	28577-28578	[	_	_	
111-55	28578-28585	Physics	_	_	
111-56	28586-28594	Solution	_	_	
111-57	28594-28595	:	_	_	
111-58	28596-28603	ChatGPT	*	SOFTWARE	
111-59	28604-28606	vs	_	_	
111-60	28606-28607	.	_	_	

#Text=Google](https://www.youtube.com/watch?
112-1	28608-28614	Google	_	_	
112-2	28614-28615	]	_	_	
112-3	28615-28616	(	_	_	
112-4	28616-28621	https	_	_	
112-5	28621-28622	:	_	_	
112-6	28622-28623	/	_	_	
112-7	28623-28624	/	_	_	
112-8	28624-28639	www.youtube.com	_	_	
112-9	28639-28640	/	_	_	
112-10	28640-28645	watch	_	_	
112-11	28645-28646	?	_	_	

#Text=v=x4dIx9VYQoM)
#Text=---> 
#Text=
#Text=## Citing FinGPT
#Text=```
#Text=@article{yang2023fingpt,
#Text=  title={FinGPT: Open-Source Financial Large Language Models},
#Text=  author={Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
#Text=  journal={FinLLM Symposium at IJCAI 2023},
#Text=  year={2023}
#Text=}
#Text=@article{zhang2023instructfingpt,
#Text=      title={Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models}, 
#Text=      author={Boyu Zhang and Hongyang Yang and Xiao-Yang Liu},
#Text=      journal={FinLLM Symposium at IJCAI 2023},
#Text=      year={2023}
#Text=}
#Text=@article{zhang2023fingptrag,
#Text=  title={Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models},
#Text=  author={Zhang, Boyu and Yang, Hongyang and Zhou, tianyu and Babar, Ali and Liu, Xiao-Yang},
#Text= journal = {ACM International Conference on AI in Finance (ICAIF)},
#Text=  year={2023}
#Text=}
#Text=
#Text=@article{wang2023fingptbenchmark,
#Text=  title={FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets},
#Text=  author={Wang, Neng and Yang, Hongyang and Wang, Christina Dan},
#Text=  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
#Text=  year={2023}
#Text=}
#Text=@article{2023finnlp,
#Text=  title={Data-centric FinGPT: Democratizing Internet-scale Data for Financial Large Language Models},
#Text=  author={Liu, Xiao-Yang and Wang, Guoxuan and Yang, Hongyang and Zha, Daochen},
#Text=  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
#Text=  year={2023}
#Text=}
#Text=
#Text=```
#Text=
#Text=<div align="center">
#Text=<a href="https://finllm.github.io/workshop/#/fcb" target="_blank">
#Text=<img align="center" src=figs/fingpt_best_presentation.png width="65%">
#Text=</div>
#Text=
#Text=
#Text=## LICENSE
#Text=
#Text=MIT License
#Text=
#Text=**Disclaimer: We are sharing codes for academic purposes under the MIT education license.
113-1	28646-28647	v	_	_	
113-2	28647-28648	=	_	_	
113-3	28648-28659	x4dIx9VYQoM	_	_	
113-4	28659-28660	)	_	_	
113-5	28661-28662	-	_	_	
113-6	28662-28663	-	_	_	
113-7	28663-28664	-	_	_	
113-8	28664-28665	>	_	_	
113-9	28668-28669	#	_	_	
113-10	28669-28670	#	_	_	
113-11	28671-28677	Citing	_	_	
113-12	28678-28684	FinGPT	_	_	
113-13	28685-28686	`	_	_	
113-14	28686-28687	`	_	_	
113-15	28687-28688	`	_	_	
113-16	28689-28690	@	_	_	
113-17	28690-28697	article	_	_	
113-18	28697-28698	{	_	_	
113-19	28698-28712	yang2023fingpt	_	_	
113-20	28712-28713	,	_	_	
113-21	28716-28721	title	_	_	
113-22	28721-28722	=	_	_	
113-23	28722-28723	{	_	_	
113-24	28723-28729	FinGPT	*[145]|*[146]	PUBLICATION[145]|PROJECT[146]	
113-25	28729-28730	:	*[145]	PUBLICATION[145]	
113-26	28731-28742	Open-Source	*[145]	PUBLICATION[145]	
113-27	28743-28752	Financial	*[145]	PUBLICATION[145]	
113-28	28753-28758	Large	*[145]	PUBLICATION[145]	
113-29	28759-28767	Language	*[145]	PUBLICATION[145]	
113-30	28768-28774	Models	*[145]	PUBLICATION[145]	
113-31	28774-28775	}	_	_	
113-32	28775-28776	,	_	_	
113-33	28779-28785	author	_	_	
113-34	28785-28786	=	_	_	
113-35	28786-28787	{	_	_	
113-36	28787-28791	Yang	_	_	
113-37	28791-28792	,	_	_	
113-38	28793-28801	Hongyang	_	_	
113-39	28802-28805	and	_	_	
113-40	28806-28809	Liu	_	_	
113-41	28809-28810	,	_	_	
113-42	28811-28820	Xiao-Yang	_	_	
113-43	28821-28824	and	_	_	
113-44	28825-28829	Wang	_	_	
113-45	28829-28830	,	_	_	
113-46	28831-28840	Christina	_	_	
113-47	28841-28844	Dan	_	_	
113-48	28844-28845	}	_	_	
113-49	28845-28846	,	_	_	
113-50	28849-28856	journal	_	_	
113-51	28856-28857	=	_	_	
113-52	28857-28858	{	_	_	
113-53	28858-28864	FinLLM	*[147]	PUBLICATION[147]	
113-54	28865-28874	Symposium	*[147]	PUBLICATION[147]	
113-55	28875-28877	at	*[147]	PUBLICATION[147]	
113-56	28878-28883	IJCAI	*[147]|*[148]	PUBLICATION[147]|CONFERENCE[148]	
113-57	28884-28888	2023	*[147]|*[148]	PUBLICATION[147]|CONFERENCE[148]	
113-58	28888-28889	}	_	_	
113-59	28889-28890	,	_	_	
113-60	28893-28897	year	_	_	
113-61	28897-28898	=	_	_	
113-62	28898-28899	{	_	_	
113-63	28899-28903	2023	_	_	
113-64	28903-28904	}	_	_	
113-65	28905-28906	}	_	_	
113-66	28907-28908	@	_	_	
113-67	28908-28915	article	_	_	
113-68	28915-28916	{	_	_	
113-69	28916-28939	zhang2023instructfingpt	_	_	
113-70	28939-28940	,	_	_	
113-71	28947-28952	title	_	_	
113-72	28952-28953	=	_	_	
113-73	28953-28954	{	_	_	
113-74	28954-28969	Instruct-FinGPT	*[149]	PUBLICATION[149]	
113-75	28969-28970	:	*[149]	PUBLICATION[149]	
113-76	28971-28980	Financial	*[149]	PUBLICATION[149]	
113-77	28981-28990	Sentiment	*[149]	PUBLICATION[149]	
113-78	28991-28999	Analysis	*[149]	PUBLICATION[149]	
113-79	29000-29002	by	*[149]	PUBLICATION[149]	
113-80	29003-29014	Instruction	*[149]	PUBLICATION[149]	
113-81	29015-29021	Tuning	*[149]	PUBLICATION[149]	
113-82	29022-29024	of	*[149]	PUBLICATION[149]	
113-83	29025-29040	General-Purpose	*[149]	PUBLICATION[149]	
113-84	29041-29046	Large	*[149]	PUBLICATION[149]	
113-85	29047-29055	Language	*[149]	PUBLICATION[149]	
113-86	29056-29062	Models	*[149]	PUBLICATION[149]	
113-87	29062-29063	}	_	_	
113-88	29063-29064	,	_	_	
113-89	29072-29078	author	_	_	
113-90	29078-29079	=	_	_	
113-91	29079-29080	{	_	_	
113-92	29080-29084	Boyu	_	_	
113-93	29085-29090	Zhang	_	_	
113-94	29091-29094	and	_	_	
113-95	29095-29103	Hongyang	_	_	
113-96	29104-29108	Yang	_	_	
113-97	29109-29112	and	_	_	
113-98	29113-29122	Xiao-Yang	_	_	
113-99	29123-29126	Liu	_	_	
113-100	29126-29127	}	_	_	
113-101	29127-29128	,	_	_	
113-102	29135-29142	journal	_	_	
113-103	29142-29143	=	_	_	
113-104	29143-29144	{	_	_	
113-105	29144-29150	FinLLM	*[150]	PUBLICATION[150]	
113-106	29151-29160	Symposium	*[150]	PUBLICATION[150]	
113-107	29161-29163	at	*[150]	PUBLICATION[150]	
113-108	29164-29169	IJCAI	*[150]|*[151]	PUBLICATION[150]|CONFERENCE[151]	
113-109	29170-29174	2023	*[150]|*[151]	PUBLICATION[150]|CONFERENCE[151]	
113-110	29174-29175	}	_	_	
113-111	29175-29176	,	_	_	
113-112	29183-29187	year	_	_	
113-113	29187-29188	=	_	_	
113-114	29188-29189	{	_	_	
113-115	29189-29193	2023	_	_	
113-116	29193-29194	}	_	_	
113-117	29195-29196	}	_	_	
113-118	29197-29198	@	_	_	
113-119	29198-29205	article	_	_	
113-120	29205-29206	{	_	_	
113-121	29206-29224	zhang2023fingptrag	_	_	
113-122	29224-29225	,	_	_	
113-123	29228-29233	title	_	_	
113-124	29233-29234	=	_	_	
113-125	29234-29235	{	_	_	
113-126	29235-29244	Enhancing	*[152]	PUBLICATION[152]	
113-127	29245-29254	Financial	*[152]	PUBLICATION[152]	
113-128	29255-29264	Sentiment	*[152]	PUBLICATION[152]	
113-129	29265-29273	Analysis	*[152]	PUBLICATION[152]	
113-130	29274-29277	via	*[152]	PUBLICATION[152]	
113-131	29278-29287	Retrieval	*[152]	PUBLICATION[152]	
113-132	29288-29297	Augmented	*[152]	PUBLICATION[152]	
113-133	29298-29303	Large	*[152]	PUBLICATION[152]	
113-134	29304-29312	Language	*[152]	PUBLICATION[152]	
113-135	29313-29319	Models	*[152]	PUBLICATION[152]	
113-136	29319-29320	}	_	_	
113-137	29320-29321	,	_	_	
113-138	29324-29330	author	_	_	
113-139	29330-29331	=	_	_	
113-140	29331-29332	{	_	_	
113-141	29332-29337	Zhang	_	_	
113-142	29337-29338	,	_	_	
113-143	29339-29343	Boyu	_	_	
113-144	29344-29347	and	_	_	
113-145	29348-29352	Yang	_	_	
113-146	29352-29353	,	_	_	
113-147	29354-29362	Hongyang	_	_	
113-148	29363-29366	and	_	_	
113-149	29367-29371	Zhou	_	_	
113-150	29371-29372	,	_	_	
113-151	29373-29379	tianyu	_	_	
113-152	29380-29383	and	_	_	
113-153	29384-29389	Babar	_	_	
113-154	29389-29390	,	_	_	
113-155	29391-29394	Ali	_	_	
113-156	29395-29398	and	_	_	
113-157	29399-29402	Liu	_	_	
113-158	29402-29403	,	_	_	
113-159	29404-29413	Xiao-Yang	_	_	
113-160	29413-29414	}	_	_	
113-161	29414-29415	,	_	_	
113-162	29417-29424	journal	_	_	
113-163	29425-29426	=	_	_	
113-164	29427-29428	{	_	_	
113-165	29428-29431	ACM	*[153]	PUBLICATION[153]	
113-166	29432-29445	International	*[153]	PUBLICATION[153]	
113-167	29446-29456	Conference	*[153]	PUBLICATION[153]	
113-168	29457-29459	on	*[153]	PUBLICATION[153]	
113-169	29460-29462	AI	*[153]	PUBLICATION[153]	
113-170	29463-29465	in	*[153]	PUBLICATION[153]	
113-171	29466-29473	Finance	*[153]	PUBLICATION[153]	
113-172	29474-29475	(	_	_	
113-173	29475-29480	ICAIF	*	CONFERENCE	
113-174	29480-29481	)	_	_	
113-175	29481-29482	}	_	_	
113-176	29482-29483	,	_	_	
113-177	29486-29490	year	_	_	
113-178	29490-29491	=	_	_	
113-179	29491-29492	{	_	_	
113-180	29492-29496	2023	_	_	
113-181	29496-29497	}	_	_	
113-182	29498-29499	}	_	_	
113-183	29501-29502	@	_	_	
113-184	29502-29509	article	_	_	
113-185	29509-29510	{	_	_	
113-186	29510-29533	wang2023fingptbenchmark	_	_	
113-187	29533-29534	,	_	_	
113-188	29537-29542	title	_	_	
113-189	29542-29543	=	_	_	
113-190	29543-29544	{	_	_	
113-191	29544-29550	FinGPT	*[154]	PUBLICATION[154]	
113-192	29550-29551	:	*[154]	PUBLICATION[154]	
113-193	29552-29563	Instruction	*[154]	PUBLICATION[154]	
113-194	29564-29570	Tuning	*[154]	PUBLICATION[154]	
113-195	29571-29580	Benchmark	*[154]	PUBLICATION[154]	
113-196	29581-29584	for	*[154]	PUBLICATION[154]	
113-197	29585-29596	Open-Source	*[154]	PUBLICATION[154]	
113-198	29597-29602	Large	*[154]	PUBLICATION[154]	
113-199	29603-29611	Language	*[154]	PUBLICATION[154]	
113-200	29612-29618	Models	*[154]	PUBLICATION[154]	
113-201	29619-29621	in	*[154]	PUBLICATION[154]	
113-202	29622-29631	Financial	*[154]	PUBLICATION[154]	
113-203	29632-29640	Datasets	*[154]	PUBLICATION[154]	
113-204	29640-29641	}	_	_	
113-205	29641-29642	,	_	_	
113-206	29645-29651	author	_	_	
113-207	29651-29652	=	_	_	
113-208	29652-29653	{	_	_	
113-209	29653-29657	Wang	_	_	
113-210	29657-29658	,	_	_	
113-211	29659-29663	Neng	_	_	
113-212	29664-29667	and	_	_	
113-213	29668-29672	Yang	_	_	
113-214	29672-29673	,	_	_	
113-215	29674-29682	Hongyang	_	_	
113-216	29683-29686	and	_	_	
113-217	29687-29691	Wang	_	_	
113-218	29691-29692	,	_	_	
113-219	29693-29702	Christina	_	_	
113-220	29703-29706	Dan	_	_	
113-221	29706-29707	}	_	_	
113-222	29707-29708	,	_	_	
113-223	29711-29718	journal	_	_	
113-224	29718-29719	=	_	_	
113-225	29719-29720	{	_	_	
113-226	29720-29727	NeurIPS	*[155]|*[156]|*[157]	PUBLICATION[155]|WORKSHOP[156]|CONFERENCE[157]	
113-227	29728-29736	Workshop	*[155]|*[156]	PUBLICATION[155]|WORKSHOP[156]	
113-228	29737-29739	on	*[155]	PUBLICATION[155]	
113-229	29740-29751	Instruction	*[155]	PUBLICATION[155]	
113-230	29752-29758	Tuning	*[155]	PUBLICATION[155]	
113-231	29759-29762	and	*[155]	PUBLICATION[155]	
113-232	29763-29774	Instruction	*[155]	PUBLICATION[155]	
113-233	29775-29784	Following	*[155]	PUBLICATION[155]	
113-234	29784-29785	}	_	_	
113-235	29785-29786	,	_	_	
113-236	29789-29793	year	_	_	
113-237	29793-29794	=	_	_	
113-238	29794-29795	{	_	_	
113-239	29795-29799	2023	_	_	
113-240	29799-29800	}	_	_	
113-241	29801-29802	}	_	_	
113-242	29803-29804	@	_	_	
113-243	29804-29811	article	_	_	
113-244	29811-29812	{	_	_	
113-245	29812-29822	2023finnlp	_	_	
113-246	29822-29823	,	_	_	
113-247	29826-29831	title	_	_	
113-248	29831-29832	=	_	_	
113-249	29832-29833	{	_	_	
113-250	29833-29845	Data-centric	*[158]	PUBLICATION[158]	
113-251	29846-29852	FinGPT	*[158]	PUBLICATION[158]	
113-252	29852-29853	:	*[158]	PUBLICATION[158]	
113-253	29854-29867	Democratizing	*[158]	PUBLICATION[158]	
113-254	29868-29882	Internet-scale	*[158]	PUBLICATION[158]	
113-255	29883-29887	Data	*[158]	PUBLICATION[158]	
113-256	29888-29891	for	*[158]	PUBLICATION[158]	
113-257	29892-29901	Financial	*[158]	PUBLICATION[158]	
113-258	29902-29907	Large	*[158]	PUBLICATION[158]	
113-259	29908-29916	Language	*[158]	PUBLICATION[158]	
113-260	29917-29923	Models	*[158]	PUBLICATION[158]	
113-261	29923-29924	}	_	_	
113-262	29924-29925	,	_	_	
113-263	29928-29934	author	_	_	
113-264	29934-29935	=	_	_	
113-265	29935-29936	{	_	_	
113-266	29936-29939	Liu	_	_	
113-267	29939-29940	,	_	_	
113-268	29941-29950	Xiao-Yang	_	_	
113-269	29951-29954	and	_	_	
113-270	29955-29959	Wang	_	_	
113-271	29959-29960	,	_	_	
113-272	29961-29968	Guoxuan	_	_	
113-273	29969-29972	and	_	_	
113-274	29973-29977	Yang	_	_	
113-275	29977-29978	,	_	_	
113-276	29979-29987	Hongyang	_	_	
113-277	29988-29991	and	_	_	
113-278	29992-29995	Zha	_	_	
113-279	29995-29996	,	_	_	
113-280	29997-30004	Daochen	_	_	
113-281	30004-30005	}	_	_	
113-282	30005-30006	,	_	_	
113-283	30009-30016	journal	_	_	
113-284	30016-30017	=	_	_	
113-285	30017-30018	{	_	_	
113-286	30018-30025	NeurIPS	*[159]|*[160]	PUBLICATION[159]|WORKSHOP[160]	
113-287	30026-30034	Workshop	*[159]|*[160]	PUBLICATION[159]|WORKSHOP[160]	
113-288	30035-30037	on	*[159]	PUBLICATION[159]	
113-289	30038-30049	Instruction	*[159]	PUBLICATION[159]	
113-290	30050-30056	Tuning	*[159]	PUBLICATION[159]	
113-291	30057-30060	and	*[159]	PUBLICATION[159]	
113-292	30061-30072	Instruction	*[159]	PUBLICATION[159]	
113-293	30073-30082	Following	*[159]	PUBLICATION[159]	
113-294	30082-30083	}	_	_	
113-295	30083-30084	,	_	_	
113-296	30087-30091	year	_	_	
113-297	30091-30092	=	_	_	
113-298	30092-30093	{	_	_	
113-299	30093-30097	2023	_	_	
113-300	30097-30098	}	_	_	
113-301	30099-30100	}	_	_	
113-302	30102-30103	`	_	_	
113-303	30103-30104	`	_	_	
113-304	30104-30105	`	_	_	
113-305	30107-30108	<	_	_	
113-306	30108-30111	div	_	_	
113-307	30112-30117	align	_	_	
113-308	30117-30118	=	_	_	
113-309	30118-30119	"	_	_	
113-310	30119-30125	center	_	_	
113-311	30125-30126	"	_	_	
113-312	30126-30127	>	_	_	
113-313	30128-30129	<	_	_	
113-314	30129-30130	a	_	_	
113-315	30131-30135	href	_	_	
113-316	30135-30136	=	_	_	
113-317	30136-30137	"	_	_	
113-318	30137-30142	https	_	_	
113-319	30142-30143	:	_	_	
113-320	30143-30144	/	_	_	
113-321	30144-30145	/	_	_	
113-322	30145-30161	finllm.github.io	_	_	
113-323	30161-30162	/	_	_	
113-324	30162-30170	workshop	_	_	
113-325	30170-30171	/	_	_	
113-326	30171-30172	#	_	_	
113-327	30172-30173	/	_	_	
113-328	30173-30176	fcb	_	_	
113-329	30176-30177	"	_	_	
113-330	30178-30184	target	_	_	
113-331	30184-30185	=	_	_	
113-332	30185-30186	"	_	_	
113-333	30186-30187	_	_	_	
113-334	30187-30192	blank	_	_	
113-335	30192-30193	"	_	_	
113-336	30193-30194	>	_	_	
113-337	30195-30196	<	_	_	
113-338	30196-30199	img	_	_	
113-339	30200-30205	align	_	_	
113-340	30205-30206	=	_	_	
113-341	30206-30207	"	_	_	
113-342	30207-30213	center	_	_	
113-343	30213-30214	"	_	_	
113-344	30215-30218	src	_	_	
113-345	30218-30219	=	_	_	
113-346	30219-30223	figs	_	_	
113-347	30223-30224	/	_	_	
113-348	30224-30252	fingpt_best_presentation.png	_	_	
113-349	30253-30258	width	_	_	
113-350	30258-30259	=	_	_	
113-351	30259-30260	"	_	_	
113-352	30260-30263	65%	_	_	
113-353	30263-30264	"	_	_	
113-354	30264-30265	>	_	_	
113-355	30266-30267	<	_	_	
113-356	30267-30268	/	_	_	
113-357	30268-30271	div	_	_	
113-358	30271-30272	>	_	_	
113-359	30275-30276	#	_	_	
113-360	30276-30277	#	_	_	
113-361	30278-30285	LICENSE	_	_	
113-362	30287-30290	MIT	*[161]	LICENSE[161]	
113-363	30291-30298	License	*[161]	LICENSE[161]	
113-364	30300-30301	*	_	_	
113-365	30301-30302	*	_	_	
113-366	30302-30312	Disclaimer	_	_	
113-367	30312-30313	:	_	_	
113-368	30314-30316	We	_	_	
113-369	30317-30320	are	_	_	
113-370	30321-30328	sharing	_	_	
113-371	30329-30334	codes	_	_	
113-372	30335-30338	for	_	_	
113-373	30339-30347	academic	_	_	
113-374	30348-30356	purposes	_	_	
113-375	30357-30362	under	_	_	
113-376	30363-30366	the	_	_	
113-377	30367-30370	MIT	_	_	
113-378	30371-30380	education	_	_	
113-379	30381-30388	license	_	_	
113-380	30388-30389	.	_	_	

#Text=Nothing herein is financial advice, and NOT a recommendation to trade real money.
114-1	30390-30397	Nothing	_	_	
114-2	30398-30404	herein	_	_	
114-3	30405-30407	is	_	_	
114-4	30408-30417	financial	_	_	
114-5	30418-30424	advice	_	_	
114-6	30424-30425	,	_	_	
114-7	30426-30429	and	_	_	
114-8	30430-30433	NOT	_	_	
114-9	30434-30435	a	_	_	
114-10	30436-30450	recommendation	_	_	
114-11	30451-30453	to	_	_	
114-12	30454-30459	trade	_	_	
114-13	30460-30464	real	_	_	
114-14	30465-30470	money	_	_	
114-15	30470-30471	.	_	_	

#Text=Please use common sense and always first consult a professional before trading or investing.**
115-1	30472-30478	Please	_	_	
115-2	30479-30482	use	_	_	
115-3	30483-30489	common	_	_	
115-4	30490-30495	sense	_	_	
115-5	30496-30499	and	_	_	
115-6	30500-30506	always	_	_	
115-7	30507-30512	first	_	_	
115-8	30513-30520	consult	_	_	
115-9	30521-30522	a	_	_	
115-10	30523-30535	professional	_	_	
115-11	30536-30542	before	_	_	
115-12	30543-30550	trading	_	_	
115-13	30551-30553	or	_	_	
115-14	30554-30563	investing	_	_	
115-15	30563-30564	.	_	_	
115-16	30564-30565	*	_	_	
115-17	30565-30566	*	_	_	
