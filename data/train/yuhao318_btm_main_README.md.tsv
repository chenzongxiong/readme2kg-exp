#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# BTM
#Text=**Reviving Undersampling for Long-Tailed Learning**
#Text=
#Text=**Authors**: Hao Yu, Yingxiao Du, Jianxin Wu
#Text=
#Text=[[`arXiv`](https://arxiv.org/pdf/2401.16811.pdf)] [[`bibtex`](#Citation)]
#Text=
#Text=
#Text=**Introduction**: This repository provides an implementation for the paper: "[Reviving Undersampling for Long-Tailed Learning](https://arxiv.org/pdf/2401.16811.pdf)" based on [MiSLAS](https://github.com/dvlab-research/MiSLAS).
1-1	0-1	#	_	_	
1-2	2-5	BTM	*	SOFTWARE	
1-3	6-7	*	_	_	
1-4	7-8	*	_	_	
1-5	8-16	Reviving	*[1]	PUBLICATION[1]	
1-6	17-30	Undersampling	*[1]	PUBLICATION[1]	
1-7	31-34	for	*[1]	PUBLICATION[1]	
1-8	35-46	Long-Tailed	*[1]	PUBLICATION[1]	
1-9	47-55	Learning	*[1]	PUBLICATION[1]	
1-10	55-56	*	_	_	
1-11	56-57	*	_	_	
1-12	59-60	*	_	_	
1-13	60-61	*	_	_	
1-14	61-68	Authors	_	_	
1-15	68-69	*	_	_	
1-16	69-70	*	_	_	
1-17	70-71	:	_	_	
1-18	72-75	Hao	_	_	
1-19	76-78	Yu	_	_	
1-20	78-79	,	_	_	
1-21	80-88	Yingxiao	_	_	
1-22	89-91	Du	_	_	
1-23	91-92	,	_	_	
1-24	93-100	Jianxin	_	_	
1-25	101-103	Wu	_	_	
1-26	105-106	[	_	_	
1-27	106-107	[	_	_	
1-28	107-108	`	_	_	
1-29	108-113	arXiv	_	_	
1-30	113-114	`	_	_	
1-31	114-115	]	_	_	
1-32	115-116	(	_	_	
1-33	116-121	https	_	_	
1-34	121-122	:	_	_	
1-35	122-123	/	_	_	
1-36	123-124	/	_	_	
1-37	124-133	arxiv.org	_	_	
1-38	133-134	/	_	_	
1-39	134-137	pdf	_	_	
1-40	137-138	/	_	_	
1-41	138-148	2401.16811	_	_	
1-42	148-149	.	_	_	
1-43	149-152	pdf	_	_	
1-44	152-153	)	_	_	
1-45	153-154	]	_	_	
1-46	155-156	[	_	_	
1-47	156-157	[	_	_	
1-48	157-158	`	_	_	
1-49	158-164	bibtex	_	_	
1-50	164-165	`	_	_	
1-51	165-166	]	_	_	
1-52	166-167	(	_	_	
1-53	167-168	#	_	_	
1-54	168-176	Citation	_	_	
1-55	176-177	)	_	_	
1-56	177-178	]	_	_	
1-57	181-182	*	_	_	
1-58	182-183	*	_	_	
1-59	183-195	Introduction	_	_	
1-60	195-196	*	_	_	
1-61	196-197	*	_	_	
1-62	197-198	:	_	_	
1-63	199-203	This	_	_	
1-64	204-214	repository	_	_	
1-65	215-223	provides	_	_	
1-66	224-226	an	_	_	
1-67	227-241	implementation	_	_	
1-68	242-245	for	_	_	
1-69	246-249	the	_	_	
1-70	250-255	paper	_	_	
1-71	255-256	:	_	_	
1-72	257-258	"	_	_	
1-73	258-259	[	_	_	
1-74	259-267	Reviving	*[2]	PUBLICATION[2]	
1-75	268-281	Undersampling	*[2]	PUBLICATION[2]	
1-76	282-285	for	*[2]	PUBLICATION[2]	
1-77	286-297	Long-Tailed	*[2]	PUBLICATION[2]	
1-78	298-306	Learning	*[2]	PUBLICATION[2]	
1-79	306-307	]	_	_	
1-80	307-308	(	_	_	
1-81	308-313	https	_	_	
1-82	313-314	:	_	_	
1-83	314-315	/	_	_	
1-84	315-316	/	_	_	
1-85	316-325	arxiv.org	_	_	
1-86	325-326	/	_	_	
1-87	326-329	pdf	_	_	
1-88	329-330	/	_	_	
1-89	330-340	2401.16811	_	_	
1-90	340-341	.	_	_	
1-91	341-344	pdf	_	_	
1-92	344-345	)	_	_	
1-93	345-346	"	_	_	
1-94	347-352	based	_	_	
1-95	353-355	on	_	_	
1-96	356-357	[	_	_	
1-97	357-363	MiSLAS	_	_	
1-98	363-364	]	_	_	
1-99	364-365	(	_	_	
1-100	365-370	https	_	_	
1-101	370-371	:	_	_	
1-102	371-372	/	_	_	
1-103	372-373	/	_	_	
1-104	373-383	github.com	_	_	
1-105	383-384	/	_	_	
1-106	384-398	dvlab-research	_	_	
1-107	398-399	/	_	_	
1-108	399-405	MiSLAS	_	_	
1-109	405-406	)	_	_	
1-110	406-407	.	_	_	

#Text=*We aim to enhance the accuracy of the worst-performing categories and utilize the harmonic mean and geometric mean to assess the model's performance.
2-1	408-409	*	_	_	
2-2	409-411	We	_	_	
2-3	412-415	aim	_	_	
2-4	416-418	to	_	_	
2-5	419-426	enhance	_	_	
2-6	427-430	the	_	_	
2-7	431-439	accuracy	_	_	
2-8	440-442	of	_	_	
2-9	443-446	the	_	_	
2-10	447-463	worst-performing	_	_	
2-11	464-474	categories	_	_	
2-12	475-478	and	_	_	
2-13	479-486	utilize	_	_	
2-14	487-490	the	_	_	
2-15	491-499	harmonic	_	_	
2-16	500-504	mean	_	_	
2-17	505-508	and	_	_	
2-18	509-518	geometric	_	_	
2-19	519-523	mean	_	_	
2-20	524-526	to	_	_	
2-21	527-533	assess	_	_	
2-22	534-537	the	_	_	
2-23	538-545	model's	_	_	
2-24	546-557	performance	_	_	
2-25	557-558	.	_	_	

#Text=We revive the balanced undersampling produces a more equitable distribution of accuracy across categories, and devise a straightforward model ensemble strategy, which does not result in any additional overhead and achieves improved harmonic and geometric mean while keeping the average accuracy.* BTM is a simple, and efficient framework for long-tailed recognition.
#Text=
#Text=## Installation
#Text=
#Text=**Requirements**
#Text=
#Text=* Python 3.8
#Text=* torchvision 0.13.0
#Text=* Pytorch 1.12.0
#Text=
#Text=**Dataset Preparation**
#Text=* [ImageNet-LT](http://image-net.org/index)
#Text=* [iNaturalist 2018](https://github.com/visipedia/inat_comp/tree/master/2018)
#Text=* [Places-LT](http://places2.csail.mit.edu/download.html)
#Text=
#Text=Change the `data_path` in `config/*/*.yaml` accordingly.
#Text=
#Text=## Training
#Text=
#Text=**Stage-1**:
#Text=
#Text=To get a model of Stage-1, you can directly download from [MiSLAS](https://github.com/dvlab-research/MiSLAS), or run:
#Text=
#Text=```
#Text=python train_stage1.py --cfg .
3-1	559-561	We	_	_	
3-2	562-568	revive	_	_	
3-3	569-572	the	_	_	
3-4	573-581	balanced	_	_	
3-5	582-595	undersampling	_	_	
3-6	596-604	produces	_	_	
3-7	605-606	a	_	_	
3-8	607-611	more	_	_	
3-9	612-621	equitable	_	_	
3-10	622-634	distribution	_	_	
3-11	635-637	of	_	_	
3-12	638-646	accuracy	_	_	
3-13	647-653	across	_	_	
3-14	654-664	categories	_	_	
3-15	664-665	,	_	_	
3-16	666-669	and	_	_	
3-17	670-676	devise	_	_	
3-18	677-678	a	_	_	
3-19	679-694	straightforward	_	_	
3-20	695-700	model	_	_	
3-21	701-709	ensemble	_	_	
3-22	710-718	strategy	_	_	
3-23	718-719	,	_	_	
3-24	720-725	which	_	_	
3-25	726-730	does	_	_	
3-26	731-734	not	_	_	
3-27	735-741	result	_	_	
3-28	742-744	in	_	_	
3-29	745-748	any	_	_	
3-30	749-759	additional	_	_	
3-31	760-768	overhead	_	_	
3-32	769-772	and	_	_	
3-33	773-781	achieves	_	_	
3-34	782-790	improved	_	_	
3-35	791-799	harmonic	_	_	
3-36	800-803	and	_	_	
3-37	804-813	geometric	_	_	
3-38	814-818	mean	_	_	
3-39	819-824	while	_	_	
3-40	825-832	keeping	_	_	
3-41	833-836	the	_	_	
3-42	837-844	average	_	_	
3-43	845-853	accuracy	_	_	
3-44	853-854	.	_	_	
3-45	854-855	*	_	_	
3-46	856-859	BTM	*	SOFTWARE	
3-47	860-862	is	_	_	
3-48	863-864	a	_	_	
3-49	865-871	simple	_	_	
3-50	871-872	,	_	_	
3-51	873-876	and	_	_	
3-52	877-886	efficient	_	_	
3-53	887-896	framework	_	_	
3-54	897-900	for	_	_	
3-55	901-912	long-tailed	_	_	
3-56	913-924	recognition	_	_	
3-57	924-925	.	_	_	
3-58	927-928	#	_	_	
3-59	928-929	#	_	_	
3-60	930-942	Installation	_	_	
3-61	944-945	*	_	_	
3-62	945-946	*	_	_	
3-63	946-958	Requirements	_	_	
3-64	958-959	*	_	_	
3-65	959-960	*	_	_	
3-66	962-963	*	_	_	
3-67	964-970	Python	*[3]	SOFTWARE[3]	
3-68	971-974	3.8	*[3]	SOFTWARE[3]	
3-69	975-976	*	_	_	
3-70	977-988	torchvision	*[4]	SOFTWARE[4]	
3-71	989-995	0.13.0	*[4]	SOFTWARE[4]	
3-72	996-997	*	_	_	
3-73	998-1005	Pytorch	*[5]	SOFTWARE[5]	
3-74	1006-1012	1.12.0	*[5]	SOFTWARE[5]	
3-75	1014-1015	*	_	_	
3-76	1015-1016	*	_	_	
3-77	1016-1023	Dataset	_	_	
3-78	1024-1035	Preparation	_	_	
3-79	1035-1036	*	_	_	
3-80	1036-1037	*	_	_	
3-81	1038-1039	*	_	_	
3-82	1040-1041	[	_	_	
3-83	1041-1052	ImageNet-LT	*	DATASET	
3-84	1052-1053	]	_	_	
3-85	1053-1054	(	_	_	
3-86	1054-1058	http	_	_	
3-87	1058-1059	:	_	_	
3-88	1059-1060	/	_	_	
3-89	1060-1061	/	_	_	
3-90	1061-1074	image-net.org	_	_	
3-91	1074-1075	/	_	_	
3-92	1075-1080	index	_	_	
3-93	1080-1081	)	_	_	
3-94	1082-1083	*	_	_	
3-95	1084-1085	[	_	_	
3-96	1085-1096	iNaturalist	*[6]	DATASET[6]	
3-97	1097-1101	2018	*[6]	DATASET[6]	
3-98	1101-1102	]	_	_	
3-99	1102-1103	(	_	_	
3-100	1103-1108	https	_	_	
3-101	1108-1109	:	_	_	
3-102	1109-1110	/	_	_	
3-103	1110-1111	/	_	_	
3-104	1111-1121	github.com	_	_	
3-105	1121-1122	/	_	_	
3-106	1122-1131	visipedia	_	_	
3-107	1131-1132	/	_	_	
3-108	1132-1141	inat_comp	_	_	
3-109	1141-1142	/	_	_	
3-110	1142-1146	tree	_	_	
3-111	1146-1147	/	_	_	
3-112	1147-1153	master	_	_	
3-113	1153-1154	/	_	_	
3-114	1154-1158	2018	_	_	
3-115	1158-1159	)	_	_	
3-116	1160-1161	*	_	_	
3-117	1162-1163	[	_	_	
3-118	1163-1172	Places-LT	*	DATASET	
3-119	1172-1173	]	_	_	
3-120	1173-1174	(	_	_	
3-121	1174-1178	http	_	_	
3-122	1178-1179	:	_	_	
3-123	1179-1180	/	_	_	
3-124	1180-1181	/	_	_	
3-125	1181-1188	places2	_	_	
3-126	1188-1189	.	_	_	
3-127	1189-1202	csail.mit.edu	_	_	
3-128	1202-1203	/	_	_	
3-129	1203-1216	download.html	_	_	
3-130	1216-1217	)	_	_	
3-131	1219-1225	Change	_	_	
3-132	1226-1229	the	_	_	
3-133	1230-1231	`	_	_	
3-134	1231-1240	data_path	_	_	
3-135	1240-1241	`	_	_	
3-136	1242-1244	in	_	_	
3-137	1245-1246	`	_	_	
3-138	1246-1252	config	_	_	
3-139	1252-1253	/	_	_	
3-140	1253-1254	*	_	_	
3-141	1254-1255	/	_	_	
3-142	1255-1256	*	_	_	
3-143	1256-1257	.	_	_	
3-144	1257-1261	yaml	_	_	
3-145	1261-1262	`	_	_	
3-146	1263-1274	accordingly	_	_	
3-147	1274-1275	.	_	_	
3-148	1277-1278	#	_	_	
3-149	1278-1279	#	_	_	
3-150	1280-1288	Training	_	_	
3-151	1290-1291	*	_	_	
3-152	1291-1292	*	_	_	
3-153	1292-1297	Stage	_	_	
3-154	1297-1298	-	_	_	
3-155	1298-1299	1	_	_	
3-156	1299-1300	*	_	_	
3-157	1300-1301	*	_	_	
3-158	1301-1302	:	_	_	
3-159	1304-1306	To	_	_	
3-160	1307-1310	get	_	_	
3-161	1311-1312	a	_	_	
3-162	1313-1318	model	_	_	
3-163	1319-1321	of	_	_	
3-164	1322-1327	Stage	_	_	
3-165	1327-1328	-	_	_	
3-166	1328-1329	1	_	_	
3-167	1329-1330	,	_	_	
3-168	1331-1334	you	_	_	
3-169	1335-1338	can	_	_	
3-170	1339-1347	directly	_	_	
3-171	1348-1356	download	_	_	
3-172	1357-1361	from	_	_	
3-173	1362-1363	[	_	_	
3-174	1363-1369	MiSLAS	_	_	
3-175	1369-1370	]	_	_	
3-176	1370-1371	(	_	_	
3-177	1371-1376	https	_	_	
3-178	1376-1377	:	_	_	
3-179	1377-1378	/	_	_	
3-180	1378-1379	/	_	_	
3-181	1379-1389	github.com	_	_	
3-182	1389-1390	/	_	_	
3-183	1390-1404	dvlab-research	_	_	
3-184	1404-1405	/	_	_	
3-185	1405-1411	MiSLAS	_	_	
3-186	1411-1412	)	_	_	
3-187	1412-1413	,	_	_	
3-188	1414-1416	or	_	_	
3-189	1417-1420	run	_	_	
3-190	1420-1421	:	_	_	
3-191	1423-1424	`	_	_	
3-192	1424-1425	`	_	_	
3-193	1425-1426	`	_	_	
3-194	1427-1433	python	*	SOFTWARE	
3-195	1434-1446	train_stage1	_	_	
3-196	1446-1447	.	_	_	
3-197	1447-1449	py	_	_	
3-198	1450-1451	-	_	_	
3-199	1451-1452	-	_	_	
3-200	1452-1455	cfg	_	_	
3-201	1456-1457	.	_	_	

#Text=/config/DATASETNAME/DATASETNAME_ARCH_stage1_mixup.yaml
#Text=```
#Text=
#Text=`DATASETNAME` can be selected from `imagenet`, `ina2018`, and `places`.
4-1	1457-1458	/	_	_	
4-2	1458-1464	config	_	_	
4-3	1464-1465	/	_	_	
4-4	1465-1476	DATASETNAME	_	_	
4-5	1476-1477	/	_	_	
4-6	1477-1500	DATASETNAME_ARCH_stage1	_	_	
4-7	1500-1501	_	_	_	
4-8	1501-1511	mixup.yaml	_	_	
4-9	1512-1513	`	_	_	
4-10	1513-1514	`	_	_	
4-11	1514-1515	`	_	_	
4-12	1517-1518	`	_	_	
4-13	1518-1529	DATASETNAME	_	_	
4-14	1529-1530	`	_	_	
4-15	1531-1534	can	_	_	
4-16	1535-1537	be	_	_	
4-17	1538-1546	selected	_	_	
4-18	1547-1551	from	_	_	
4-19	1552-1553	`	_	_	
4-20	1553-1561	imagenet	_	_	
4-21	1561-1562	`	_	_	
4-22	1562-1563	,	_	_	
4-23	1564-1565	`	_	_	
4-24	1565-1572	ina2018	_	_	
4-25	1572-1573	`	_	_	
4-26	1573-1574	,	_	_	
4-27	1575-1578	and	_	_	
4-28	1579-1580	`	_	_	
4-29	1580-1586	places	_	_	
4-30	1586-1587	`	_	_	
4-31	1587-1588	.	_	_	

#Text=`ARCH` can be `resnet50/101/152` for `imagenet`, `resnet50` for `ina2018`, and `resnet152` for `places`, respectively.
5-1	1590-1591	`	_	_	
5-2	1591-1595	ARCH	_	_	
5-3	1595-1596	`	_	_	
5-4	1597-1600	can	_	_	
5-5	1601-1603	be	_	_	
5-6	1604-1605	`	_	_	
5-7	1605-1613	resnet50	_	_	
5-8	1613-1614	/	_	_	
5-9	1614-1617	101	_	_	
5-10	1617-1618	/	_	_	
5-11	1618-1621	152	_	_	
5-12	1621-1622	`	_	_	
5-13	1623-1626	for	_	_	
5-14	1627-1628	`	_	_	
5-15	1628-1636	imagenet	_	_	
5-16	1636-1637	`	_	_	
5-17	1637-1638	,	_	_	
5-18	1639-1640	`	_	_	
5-19	1640-1648	resnet50	_	_	
5-20	1648-1649	`	_	_	
5-21	1650-1653	for	_	_	
5-22	1654-1655	`	_	_	
5-23	1655-1662	ina2018	_	_	
5-24	1662-1663	`	_	_	
5-25	1663-1664	,	_	_	
5-26	1665-1668	and	_	_	
5-27	1669-1670	`	_	_	
5-28	1670-1679	resnet152	_	_	
5-29	1679-1680	`	_	_	
5-30	1681-1684	for	_	_	
5-31	1685-1686	`	_	_	
5-32	1686-1692	places	_	_	
5-33	1692-1693	`	_	_	
5-34	1693-1694	,	_	_	
5-35	1695-1707	respectively	_	_	
5-36	1707-1708	.	_	_	

#Text=**BTM**:
#Text=
#Text=To training a model with undersamping, run:
#Text=```
#Text=python train_stage1_bl_10_classifier.py --cfg .
6-1	1710-1711	*	_	_	
6-2	1711-1712	*	_	_	
6-3	1712-1715	BTM	*	SOFTWARE	
6-4	1715-1716	*	_	_	
6-5	1716-1717	*	_	_	
6-6	1717-1718	:	_	_	
6-7	1720-1722	To	_	_	
6-8	1723-1731	training	_	_	
6-9	1732-1733	a	_	_	
6-10	1734-1739	model	_	_	
6-11	1740-1744	with	_	_	
6-12	1745-1757	undersamping	_	_	
6-13	1757-1758	,	_	_	
6-14	1759-1762	run	_	_	
6-15	1762-1763	:	_	_	
6-16	1764-1765	`	_	_	
6-17	1765-1766	`	_	_	
6-18	1766-1767	`	_	_	
6-19	1768-1774	python	*	SOFTWARE	
6-20	1775-1787	train_stage1	_	_	
6-21	1787-1788	_	_	_	
6-22	1788-1790	bl	_	_	
6-23	1790-1791	_	_	_	
6-24	1791-1793	10	_	_	
6-25	1793-1794	_	_	_	
6-26	1794-1807	classifier.py	_	_	
6-27	1808-1809	-	_	_	
6-28	1809-1810	-	_	_	
6-29	1810-1813	cfg	_	_	
6-30	1814-1815	.	_	_	

#Text=/config/DATASETNAME/DATASETNAME_ARCH_stage1_mixup_bl_10_calssifier.yaml
#Text=```
#Text=
#Text=Modify Line221 `train_loader = dataset.bl_train_10_0_instance` to `bl_train_10_1_instance`, `bl_train_10_2_instance` etc. for getting different balance-training models.
7-1	1815-1816	/	_	_	
7-2	1816-1822	config	_	_	
7-3	1822-1823	/	_	_	
7-4	1823-1834	DATASETNAME	_	_	
7-5	1834-1835	/	_	_	
7-6	1835-1858	DATASETNAME_ARCH_stage1	_	_	
7-7	1858-1859	_	_	_	
7-8	1859-1867	mixup_bl	_	_	
7-9	1867-1868	_	_	_	
7-10	1868-1870	10	_	_	
7-11	1870-1871	_	_	_	
7-12	1871-1886	calssifier.yaml	_	_	
7-13	1887-1888	`	_	_	
7-14	1888-1889	`	_	_	
7-15	1889-1890	`	_	_	
7-16	1892-1898	Modify	_	_	
7-17	1899-1906	Line221	_	_	
7-18	1907-1908	`	_	_	
7-19	1908-1920	train_loader	_	_	
7-20	1921-1922	=	_	_	
7-21	1923-1939	dataset.bl_train	_	_	
7-22	1939-1940	_	_	_	
7-23	1940-1942	10	_	_	
7-24	1942-1943	_	_	_	
7-25	1943-1944	0	_	_	
7-26	1944-1945	_	_	_	
7-27	1945-1953	instance	_	_	
7-28	1953-1954	`	_	_	
7-29	1955-1957	to	_	_	
7-30	1958-1959	`	_	_	
7-31	1959-1967	bl_train	_	_	
7-32	1967-1968	_	_	_	
7-33	1968-1970	10	_	_	
7-34	1970-1971	_	_	_	
7-35	1971-1972	1	_	_	
7-36	1972-1973	_	_	_	
7-37	1973-1981	instance	_	_	
7-38	1981-1982	`	_	_	
7-39	1982-1983	,	_	_	
7-40	1984-1985	`	_	_	
7-41	1985-1993	bl_train	_	_	
7-42	1993-1994	_	_	_	
7-43	1994-1996	10	_	_	
7-44	1996-1997	_	_	_	
7-45	1997-1998	2	_	_	
7-46	1998-1999	_	_	_	
7-47	1999-2007	instance	_	_	
7-48	2007-2008	`	_	_	
7-49	2009-2012	etc	_	_	
7-50	2012-2013	.	_	_	
7-51	2014-2017	for	_	_	
7-52	2018-2025	getting	_	_	
7-53	2026-2035	different	_	_	
7-54	2036-2052	balance-training	_	_	
7-55	2053-2059	models	_	_	
7-56	2059-2060	.	_	_	

#Text=Then run 
#Text=```
#Text=python merge.py
#Text=```
#Text=
#Text=for getting the fusion model.
8-1	2062-2066	Then	_	_	
8-2	2067-2070	run	_	_	
8-3	2072-2073	`	_	_	
8-4	2073-2074	`	_	_	
8-5	2074-2075	`	_	_	
8-6	2076-2082	python	*	SOFTWARE	
8-7	2083-2091	merge.py	_	_	
8-8	2092-2093	`	_	_	
8-9	2093-2094	`	_	_	
8-10	2094-2095	`	_	_	
8-11	2097-2100	for	_	_	
8-12	2101-2108	getting	_	_	
8-13	2109-2112	the	_	_	
8-14	2113-2119	fusion	_	_	
8-15	2120-2125	model	_	_	
8-16	2125-2126	.	_	_	

#Text=Modify Line19-28 to the real model checkpoint path.
9-1	2127-2133	Modify	_	_	
9-2	2134-2140	Line19	_	_	
9-3	2140-2141	-	_	_	
9-4	2141-2143	28	_	_	
9-5	2144-2146	to	_	_	
9-6	2147-2150	the	_	_	
9-7	2151-2155	real	_	_	
9-8	2156-2161	model	_	_	
9-9	2162-2172	checkpoint	_	_	
9-10	2173-2177	path	_	_	
9-11	2177-2178	.	_	_	

#Text=**Stage-2**:
#Text=
#Text=To train a model for Stage-2, run:
#Text=
#Text=```
#Text=python train_stage2.py --cfg .
10-1	2182-2183	*	_	_	
10-2	2183-2184	*	_	_	
10-3	2184-2189	Stage	_	_	
10-4	2189-2190	-	_	_	
10-5	2190-2191	2	_	_	
10-6	2191-2192	*	_	_	
10-7	2192-2193	*	_	_	
10-8	2193-2194	:	_	_	
10-9	2196-2198	To	_	_	
10-10	2199-2204	train	_	_	
10-11	2205-2206	a	_	_	
10-12	2207-2212	model	_	_	
10-13	2213-2216	for	_	_	
10-14	2217-2222	Stage	_	_	
10-15	2222-2223	-	_	_	
10-16	2223-2224	2	_	_	
10-17	2224-2225	,	_	_	
10-18	2226-2229	run	_	_	
10-19	2229-2230	:	_	_	
10-20	2232-2233	`	_	_	
10-21	2233-2234	`	_	_	
10-22	2234-2235	`	_	_	
10-23	2236-2242	python	*	SOFTWARE	
10-24	2243-2255	train_stage2	_	_	
10-25	2255-2256	.	_	_	
10-26	2256-2258	py	_	_	
10-27	2259-2260	-	_	_	
10-28	2260-2261	-	_	_	
10-29	2261-2264	cfg	_	_	
10-30	2265-2266	.	_	_	

#Text=/config/DATASETNAME/DATASETNAME_ARCH_stage2_mislas.yaml resume /path/to/checkpoint/BTM
#Text=```
#Text=
#Text=The saved folder (including logs and checkpoints) is organized as follows.
#Text=```
#Text=MiSLAS
#Text=├── saved
#Text=│   ├── modelname_date
#Text=│   │   ├── ckps
#Text=│   │   │   ├── current.pth.tar
#Text=│   │   │   └── model_best.pth.tar
#Text=│   │   └── logs
#Text=│   │       └── modelname.txt
#Text=│   ...   
#Text=```
#Text=## Evaluation
#Text=
#Text=To evaluate a trained model, run:
#Text=
#Text=```
#Text=python eval.py --cfg .
11-1	2266-2267	/	_	_	
11-2	2267-2273	config	_	_	
11-3	2273-2274	/	_	_	
11-4	2274-2285	DATASETNAME	_	_	
11-5	2285-2286	/	_	_	
11-6	2286-2309	DATASETNAME_ARCH_stage2	_	_	
11-7	2309-2310	_	_	_	
11-8	2310-2321	mislas.yaml	_	_	
11-9	2322-2328	resume	_	_	
11-10	2329-2330	/	_	_	
11-11	2330-2334	path	_	_	
11-12	2334-2335	/	_	_	
11-13	2335-2337	to	_	_	
11-14	2337-2338	/	_	_	
11-15	2338-2348	checkpoint	_	_	
11-16	2348-2349	/	_	_	
11-17	2349-2352	BTM	_	_	
11-18	2353-2354	`	_	_	
11-19	2354-2355	`	_	_	
11-20	2355-2356	`	_	_	
11-21	2358-2361	The	_	_	
11-22	2362-2367	saved	_	_	
11-23	2368-2374	folder	_	_	
11-24	2375-2376	(	_	_	
11-25	2376-2385	including	_	_	
11-26	2386-2390	logs	_	_	
11-27	2391-2394	and	_	_	
11-28	2395-2406	checkpoints	_	_	
11-29	2406-2407	)	_	_	
11-30	2408-2410	is	_	_	
11-31	2411-2420	organized	_	_	
11-32	2421-2423	as	_	_	
11-33	2424-2431	follows	_	_	
11-34	2431-2432	.	_	_	
11-35	2433-2434	`	_	_	
11-36	2434-2435	`	_	_	
11-37	2435-2436	`	_	_	
11-38	2437-2443	MiSLAS	_	_	
11-39	2444-2445	├	_	_	
11-40	2445-2446	─	_	_	
11-41	2446-2447	─	_	_	
11-42	2448-2453	saved	_	_	
11-43	2454-2455	│	_	_	
11-44	2458-2459	├	_	_	
11-45	2459-2460	─	_	_	
11-46	2460-2461	─	_	_	
11-47	2462-2476	modelname_date	_	_	
11-48	2477-2478	│	_	_	
11-49	2481-2482	│	_	_	
11-50	2485-2486	├	_	_	
11-51	2486-2487	─	_	_	
11-52	2487-2488	─	_	_	
11-53	2489-2493	ckps	_	_	
11-54	2494-2495	│	_	_	
11-55	2498-2499	│	_	_	
11-56	2502-2503	│	_	_	
11-57	2506-2507	├	_	_	
11-58	2507-2508	─	_	_	
11-59	2508-2509	─	_	_	
11-60	2510-2525	current.pth.tar	_	_	
11-61	2526-2527	│	_	_	
11-62	2530-2531	│	_	_	
11-63	2534-2535	│	_	_	
11-64	2538-2539	└	_	_	
11-65	2539-2540	─	_	_	
11-66	2540-2541	─	_	_	
11-67	2542-2560	model_best.pth.tar	_	_	
11-68	2561-2562	│	_	_	
11-69	2565-2566	│	_	_	
11-70	2569-2570	└	_	_	
11-71	2570-2571	─	_	_	
11-72	2571-2572	─	_	_	
11-73	2573-2577	logs	_	_	
11-74	2578-2579	│	_	_	
11-75	2582-2583	│	_	_	
11-76	2590-2591	└	_	_	
11-77	2591-2592	─	_	_	
11-78	2592-2593	─	_	_	
11-79	2594-2607	modelname.txt	_	_	
11-80	2608-2609	│	_	_	
11-81	2612-2613	.	_	_	
11-82	2613-2614	.	_	_	
11-83	2614-2615	.	_	_	
11-84	2619-2620	`	_	_	
11-85	2620-2621	`	_	_	
11-86	2621-2622	`	_	_	
11-87	2623-2624	#	_	_	
11-88	2624-2625	#	_	_	
11-89	2626-2636	Evaluation	_	_	
11-90	2638-2640	To	_	_	
11-91	2641-2649	evaluate	_	_	
11-92	2650-2651	a	_	_	
11-93	2652-2659	trained	_	_	
11-94	2660-2665	model	_	_	
11-95	2665-2666	,	_	_	
11-96	2667-2670	run	_	_	
11-97	2670-2671	:	_	_	
11-98	2673-2674	`	_	_	
11-99	2674-2675	`	_	_	
11-100	2675-2676	`	_	_	
11-101	2677-2683	python	*	SOFTWARE	
11-102	2684-2691	eval.py	_	_	
11-103	2692-2693	-	_	_	
11-104	2693-2694	-	_	_	
11-105	2694-2697	cfg	_	_	
11-106	2698-2699	.	_	_	

#Text=/config/DATASETNAME/DATASETNAME_ARCH_stage1_mixup.yaml  resume /path/to/checkpoint/stage1
#Text=python eval.py --cfg .
12-1	2699-2700	/	_	_	
12-2	2700-2706	config	_	_	
12-3	2706-2707	/	_	_	
12-4	2707-2718	DATASETNAME	_	_	
12-5	2718-2719	/	_	_	
12-6	2719-2742	DATASETNAME_ARCH_stage1	_	_	
12-7	2742-2743	_	_	_	
12-8	2743-2753	mixup.yaml	_	_	
12-9	2755-2761	resume	_	_	
12-10	2762-2763	/	_	_	
12-11	2763-2767	path	_	_	
12-12	2767-2768	/	_	_	
12-13	2768-2770	to	_	_	
12-14	2770-2771	/	_	_	
12-15	2771-2781	checkpoint	_	_	
12-16	2781-2782	/	_	_	
12-17	2782-2788	stage1	_	_	
12-18	2789-2795	python	*	SOFTWARE	
12-19	2796-2803	eval.py	_	_	
12-20	2804-2805	-	_	_	
12-21	2805-2806	-	_	_	
12-22	2806-2809	cfg	_	_	
12-23	2810-2811	.	_	_	

#Text=/config/DATASETNAME/DATASETNAME_ARCH_stage2_mislas.yaml resume /path/to/checkpoint/stage2
#Text=```
#Text=
#Text=## <a name="Citation"></a>Citation
#Text=
#Text=```bib
#Text=@article{yu2024reviving,
#Text=  title={Reviving Undersampling for Long-Tailed Learning},
#Text=  author={Yu, Hao and Du, Yingxiao and Wu, Jianxin},
#Text=  journal={arXiv preprint arXiv:2401.16811},
#Text=  year={2024}
#Text=}
#Text=```
#Text=
#Text=## Contact
#Text=
#Text=If you have any questions about our work, feel free to contact us through email (Hao Yu: yuh@lamda.nju.edu.cn) or Github issues.
13-1	2811-2812	/	_	_	
13-2	2812-2818	config	_	_	
13-3	2818-2819	/	_	_	
13-4	2819-2830	DATASETNAME	_	_	
13-5	2830-2831	/	_	_	
13-6	2831-2854	DATASETNAME_ARCH_stage2	_	_	
13-7	2854-2855	_	_	_	
13-8	2855-2866	mislas.yaml	_	_	
13-9	2867-2873	resume	_	_	
13-10	2874-2875	/	_	_	
13-11	2875-2879	path	_	_	
13-12	2879-2880	/	_	_	
13-13	2880-2882	to	_	_	
13-14	2882-2883	/	_	_	
13-15	2883-2893	checkpoint	_	_	
13-16	2893-2894	/	_	_	
13-17	2894-2900	stage2	_	_	
13-18	2901-2902	`	_	_	
13-19	2902-2903	`	_	_	
13-20	2903-2904	`	_	_	
13-21	2906-2907	#	_	_	
13-22	2907-2908	#	_	_	
13-23	2909-2910	<	_	_	
13-24	2910-2911	a	_	_	
13-25	2912-2916	name	_	_	
13-26	2916-2917	=	_	_	
13-27	2917-2918	"	_	_	
13-28	2918-2926	Citation	_	_	
13-29	2926-2927	"	_	_	
13-30	2927-2928	>	_	_	
13-31	2928-2929	<	_	_	
13-32	2929-2930	/	_	_	
13-33	2930-2931	a	_	_	
13-34	2931-2932	>	_	_	
13-35	2932-2940	Citation	_	_	
13-36	2942-2943	`	_	_	
13-37	2943-2944	`	_	_	
13-38	2944-2945	`	_	_	
13-39	2945-2948	bib	_	_	
13-40	2949-2950	@	_	_	
13-41	2950-2957	article	_	_	
13-42	2957-2958	{	_	_	
13-43	2958-2972	yu2024reviving	_	_	
13-44	2972-2973	,	_	_	
13-45	2976-2981	title	_	_	
13-46	2981-2982	=	_	_	
13-47	2982-2983	{	_	_	
13-48	2983-2991	Reviving	*[7]	PUBLICATION[7]	
13-49	2992-3005	Undersampling	*[7]	PUBLICATION[7]	
13-50	3006-3009	for	*[7]	PUBLICATION[7]	
13-51	3010-3021	Long-Tailed	*[7]	PUBLICATION[7]	
13-52	3022-3030	Learning	*[7]	PUBLICATION[7]	
13-53	3030-3031	}	_	_	
13-54	3031-3032	,	_	_	
13-55	3035-3041	author	_	_	
13-56	3041-3042	=	_	_	
13-57	3042-3043	{	_	_	
13-58	3043-3045	Yu	_	_	
13-59	3045-3046	,	_	_	
13-60	3047-3050	Hao	_	_	
13-61	3051-3054	and	_	_	
13-62	3055-3057	Du	_	_	
13-63	3057-3058	,	_	_	
13-64	3059-3067	Yingxiao	_	_	
13-65	3068-3071	and	_	_	
13-66	3072-3074	Wu	_	_	
13-67	3074-3075	,	_	_	
13-68	3076-3083	Jianxin	_	_	
13-69	3083-3084	}	_	_	
13-70	3084-3085	,	_	_	
13-71	3088-3095	journal	_	_	
13-72	3095-3096	=	_	_	
13-73	3096-3097	{	_	_	
13-74	3097-3102	arXiv	_	_	
13-75	3103-3111	preprint	_	_	
13-76	3112-3117	arXiv	_	_	
13-77	3117-3118	:	_	_	
13-78	3118-3128	2401.16811	_	_	
13-79	3128-3129	}	_	_	
13-80	3129-3130	,	_	_	
13-81	3133-3137	year	_	_	
13-82	3137-3138	=	_	_	
13-83	3138-3139	{	_	_	
13-84	3139-3143	2024	_	_	
13-85	3143-3144	}	_	_	
13-86	3145-3146	}	_	_	
13-87	3147-3148	`	_	_	
13-88	3148-3149	`	_	_	
13-89	3149-3150	`	_	_	
13-90	3152-3153	#	_	_	
13-91	3153-3154	#	_	_	
13-92	3155-3162	Contact	_	_	
13-93	3164-3166	If	_	_	
13-94	3167-3170	you	_	_	
13-95	3171-3175	have	_	_	
13-96	3176-3179	any	_	_	
13-97	3180-3189	questions	_	_	
13-98	3190-3195	about	_	_	
13-99	3196-3199	our	_	_	
13-100	3200-3204	work	_	_	
13-101	3204-3205	,	_	_	
13-102	3206-3210	feel	_	_	
13-103	3211-3215	free	_	_	
13-104	3216-3218	to	_	_	
13-105	3219-3226	contact	_	_	
13-106	3227-3229	us	_	_	
13-107	3230-3237	through	_	_	
13-108	3238-3243	email	_	_	
13-109	3244-3245	(	_	_	
13-110	3245-3248	Hao	_	_	
13-111	3249-3251	Yu	_	_	
13-112	3251-3252	:	_	_	
13-113	3253-3256	yuh	_	_	
13-114	3256-3257	@	_	_	
13-115	3257-3273	lamda.nju.edu.cn	_	_	
13-116	3273-3274	)	_	_	
13-117	3275-3277	or	_	_	
13-118	3278-3284	Github	_	_	
13-119	3285-3291	issues	_	_	
13-120	3291-3292	.	_	_	
