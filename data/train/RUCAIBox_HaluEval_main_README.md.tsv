#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# HaluEval: A Hallucination Evaluation Benchmark for LLMs
#Text=
#Text=This is the repo for our paper: [HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2305.11747).
1-1	0-1	#	_	_	
1-2	2-10	HaluEval	*	DATASET	
1-3	10-11	:	_	_	
1-4	12-13	A	_	_	
1-5	14-27	Hallucination	_	_	
1-6	28-38	Evaluation	_	_	
1-7	39-48	Benchmark	_	_	
1-8	49-52	for	_	_	
1-9	53-57	LLMs	_	_	
1-10	59-63	This	_	_	
1-11	64-66	is	_	_	
1-12	67-70	the	_	_	
1-13	71-75	repo	_	_	
1-14	76-79	for	_	_	
1-15	80-83	our	_	_	
1-16	84-89	paper	_	_	
1-17	89-90	:	_	_	
1-18	91-92	[	_	_	
1-19	92-100	HaluEval	*[1]|*[2]	PUBLICATION[1]|DATASET[2]	
1-20	100-101	:	*[1]	PUBLICATION[1]	
1-21	102-103	A	*[1]	PUBLICATION[1]	
1-22	104-115	Large-Scale	*[1]	PUBLICATION[1]	
1-23	116-129	Hallucination	*[1]	PUBLICATION[1]	
1-24	130-140	Evaluation	*[1]	PUBLICATION[1]	
1-25	141-150	Benchmark	*[1]	PUBLICATION[1]	
1-26	151-154	for	*[1]	PUBLICATION[1]	
1-27	155-160	Large	*[1]	PUBLICATION[1]	
1-28	161-169	Language	*[1]	PUBLICATION[1]	
1-29	170-176	Models	*[1]	PUBLICATION[1]	
1-30	176-177	]	_	_	
1-31	177-178	(	_	_	
1-32	178-183	https	_	_	
1-33	183-184	:	_	_	
1-34	184-185	/	_	_	
1-35	185-186	/	_	_	
1-36	186-195	arxiv.org	_	_	
1-37	195-196	/	_	_	
1-38	196-199	abs	_	_	
1-39	199-200	/	_	_	
1-40	200-210	2305.11747	_	_	
1-41	210-211	)	_	_	
1-42	211-212	.	_	_	

#Text=The repo contains:
#Text=
#Text=- The [35K data](#data-release) used for evaluating the LLM.
#Text=- The code for [generating the data](#data-generation-process).
#Text=- The code for [evaluating the model](#evaluation).
#Text=- The code for [analyzing the model](#analysis).
#Text=
#Text=## Overview
#Text=
#Text=HaluEval includes 5,000 general user queries with ChatGPT responses and  30,000 task-specific examples from three tasks, i.e.,
#Text=question answering, knowledge-grounded dialogue, and text summarization.
2-1	213-216	The	_	_	
2-2	217-221	repo	_	_	
2-3	222-230	contains	_	_	
2-4	230-231	:	_	_	
2-5	233-234	-	_	_	
2-6	235-238	The	_	_	
2-7	239-240	[	_	_	
2-8	240-243	35K	_	_	
2-9	244-248	data	_	_	
2-10	248-249	]	_	_	
2-11	249-250	(	_	_	
2-12	250-251	#	_	_	
2-13	251-263	data-release	_	_	
2-14	263-264	)	_	_	
2-15	265-269	used	_	_	
2-16	270-273	for	_	_	
2-17	274-284	evaluating	_	_	
2-18	285-288	the	_	_	
2-19	289-292	LLM	_	_	
2-20	292-293	.	_	_	
2-21	294-295	-	_	_	
2-22	296-299	The	_	_	
2-23	300-304	code	_	_	
2-24	305-308	for	_	_	
2-25	309-310	[	_	_	
2-26	310-320	generating	_	_	
2-27	321-324	the	_	_	
2-28	325-329	data	_	_	
2-29	329-330	]	_	_	
2-30	330-331	(	_	_	
2-31	331-332	#	_	_	
2-32	332-355	data-generation-process	_	_	
2-33	355-356	)	_	_	
2-34	356-357	.	_	_	
2-35	358-359	-	_	_	
2-36	360-363	The	_	_	
2-37	364-368	code	_	_	
2-38	369-372	for	_	_	
2-39	373-374	[	_	_	
2-40	374-384	evaluating	_	_	
2-41	385-388	the	_	_	
2-42	389-394	model	_	_	
2-43	394-395	]	_	_	
2-44	395-396	(	_	_	
2-45	396-397	#	_	_	
2-46	397-407	evaluation	_	_	
2-47	407-408	)	_	_	
2-48	408-409	.	_	_	
2-49	410-411	-	_	_	
2-50	412-415	The	_	_	
2-51	416-420	code	_	_	
2-52	421-424	for	_	_	
2-53	425-426	[	_	_	
2-54	426-435	analyzing	_	_	
2-55	436-439	the	_	_	
2-56	440-445	model	_	_	
2-57	445-446	]	_	_	
2-58	446-447	(	_	_	
2-59	447-448	#	_	_	
2-60	448-456	analysis	_	_	
2-61	456-457	)	_	_	
2-62	457-458	.	_	_	
2-63	460-461	#	_	_	
2-64	461-462	#	_	_	
2-65	463-471	Overview	_	_	
2-66	473-481	HaluEval	*	DATASET	
2-67	482-490	includes	_	_	
2-68	491-496	5,000	_	_	
2-69	497-504	general	_	_	
2-70	505-509	user	_	_	
2-71	510-517	queries	_	_	
2-72	518-522	with	_	_	
2-73	523-530	ChatGPT	*	SOFTWARE	
2-74	531-540	responses	_	_	
2-75	541-544	and	_	_	
2-76	546-552	30,000	_	_	
2-77	553-566	task-specific	_	_	
2-78	567-575	examples	_	_	
2-79	576-580	from	_	_	
2-80	581-586	three	_	_	
2-81	587-592	tasks	_	_	
2-82	592-593	,	_	_	
2-83	594-597	i.e	_	_	
2-84	597-598	.	_	_	
2-85	598-599	,	_	_	
2-86	600-608	question	_	_	
2-87	609-618	answering	_	_	
2-88	618-619	,	_	_	
2-89	620-638	knowledge-grounded	_	_	
2-90	639-647	dialogue	_	_	
2-91	647-648	,	_	_	
2-92	649-652	and	_	_	
2-93	653-657	text	_	_	
2-94	658-671	summarization	_	_	
2-95	671-672	.	_	_	

#Text=For general user queries, we adopt the 52K instruction tuning dataset from [Alpaca](https://github.com/tatsu-lab/stanford_alpaca).
3-1	675-678	For	_	_	
3-2	679-686	general	_	_	
3-3	687-691	user	_	_	
3-4	692-699	queries	_	_	
3-5	699-700	,	_	_	
3-6	701-703	we	_	_	
3-7	704-709	adopt	_	_	
3-8	710-713	the	_	_	
3-9	714-717	52K	_	_	
3-10	718-729	instruction	_	_	
3-11	730-736	tuning	_	_	
3-12	737-744	dataset	_	_	
3-13	745-749	from	_	_	
3-14	750-751	[	_	_	
3-15	751-757	Alpaca	_	_	
3-16	757-758	]	_	_	
3-17	758-759	(	_	_	
3-18	759-764	https	_	_	
3-19	764-765	:	_	_	
3-20	765-766	/	_	_	
3-21	766-767	/	_	_	
3-22	767-777	github.com	_	_	
3-23	777-778	/	_	_	
3-24	778-787	tatsu-lab	_	_	
3-25	787-788	/	_	_	
3-26	788-803	stanford_alpaca	_	_	
3-27	803-804	)	_	_	
3-28	804-805	.	_	_	

#Text=To further screen user queries where LLMs are most likely to produce hallucinations, we use ChatGPT to sample three responses 
#Text=for each query and finally retain the queries with low-similarity responses for human labeling.
4-1	806-808	To	_	_	
4-2	809-816	further	_	_	
4-3	817-823	screen	_	_	
4-4	824-828	user	_	_	
4-5	829-836	queries	_	_	
4-6	837-842	where	_	_	
4-7	843-847	LLMs	_	_	
4-8	848-851	are	_	_	
4-9	852-856	most	_	_	
4-10	857-863	likely	_	_	
4-11	864-866	to	_	_	
4-12	867-874	produce	_	_	
4-13	875-889	hallucinations	_	_	
4-14	889-890	,	_	_	
4-15	891-893	we	_	_	
4-16	894-897	use	_	_	
4-17	898-905	ChatGPT	*	SOFTWARE	
4-18	906-908	to	_	_	
4-19	909-915	sample	_	_	
4-20	916-921	three	_	_	
4-21	922-931	responses	_	_	
4-22	933-936	for	_	_	
4-23	937-941	each	_	_	
4-24	942-947	query	_	_	
4-25	948-951	and	_	_	
4-26	952-959	finally	_	_	
4-27	960-966	retain	_	_	
4-28	967-970	the	_	_	
4-29	971-978	queries	_	_	
4-30	979-983	with	_	_	
4-31	984-998	low-similarity	_	_	
4-32	999-1008	responses	_	_	
4-33	1009-1012	for	_	_	
4-34	1013-1018	human	_	_	
4-35	1019-1027	labeling	_	_	
4-36	1027-1028	.	_	_	

#Text=Furthermore, for the task-specific examples in HaluEval, we design an automatic approach to generate hallucinated samples.
5-1	1030-1041	Furthermore	_	_	
5-2	1041-1042	,	_	_	
5-3	1043-1046	for	_	_	
5-4	1047-1050	the	_	_	
5-5	1051-1064	task-specific	_	_	
5-6	1065-1073	examples	_	_	
5-7	1074-1076	in	_	_	
5-8	1077-1085	HaluEval	*	DATASET	
5-9	1085-1086	,	_	_	
5-10	1087-1089	we	_	_	
5-11	1090-1096	design	_	_	
5-12	1097-1099	an	_	_	
5-13	1100-1109	automatic	_	_	
5-14	1110-1118	approach	_	_	
5-15	1119-1121	to	_	_	
5-16	1122-1130	generate	_	_	
5-17	1131-1143	hallucinated	_	_	
5-18	1144-1151	samples	_	_	
5-19	1151-1152	.	_	_	

#Text=First, based on existing task datasets (e.g., HotpotQA) as seed data, we design task-specific instructions for ChatGPT
#Text=to generate hallucinated samples in two methods, i.e., one-pass and conversational.
6-1	1154-1159	First	_	_	
6-2	1159-1160	,	_	_	
6-3	1161-1166	based	_	_	
6-4	1167-1169	on	_	_	
6-5	1170-1178	existing	_	_	
6-6	1179-1183	task	_	_	
6-7	1184-1192	datasets	_	_	
6-8	1193-1194	(	_	_	
6-9	1194-1197	e.g	_	_	
6-10	1197-1198	.	_	_	
6-11	1198-1199	,	_	_	
6-12	1200-1208	HotpotQA	*	DATASET	
6-13	1208-1209	)	_	_	
6-14	1210-1212	as	_	_	
6-15	1213-1217	seed	_	_	
6-16	1218-1222	data	_	_	
6-17	1222-1223	,	_	_	
6-18	1224-1226	we	_	_	
6-19	1227-1233	design	_	_	
6-20	1234-1247	task-specific	_	_	
6-21	1248-1260	instructions	_	_	
6-22	1261-1264	for	_	_	
6-23	1265-1272	ChatGPT	*	SOFTWARE	
6-24	1273-1275	to	_	_	
6-25	1276-1284	generate	_	_	
6-26	1285-1297	hallucinated	_	_	
6-27	1298-1305	samples	_	_	
6-28	1306-1308	in	_	_	
6-29	1309-1312	two	_	_	
6-30	1313-1320	methods	_	_	
6-31	1320-1321	,	_	_	
6-32	1322-1325	i.e	_	_	
6-33	1325-1326	.	_	_	
6-34	1326-1327	,	_	_	
6-35	1328-1336	one-pass	_	_	
6-36	1337-1340	and	_	_	
6-37	1341-1355	conversational	_	_	
6-38	1355-1356	.	_	_	

#Text=Second, to select
#Text=the most plausible and difficult hallucinated sample for LLMs evaluation, we elaborate the filtering instruction enhanced 
#Text=by ground-truth examples and leverage ChatGPT for sample selection.
7-1	1357-1363	Second	_	_	
7-2	1363-1364	,	_	_	
7-3	1365-1367	to	_	_	
7-4	1368-1374	select	_	_	
7-5	1375-1378	the	_	_	
7-6	1379-1383	most	_	_	
7-7	1384-1393	plausible	_	_	
7-8	1394-1397	and	_	_	
7-9	1398-1407	difficult	_	_	
7-10	1408-1420	hallucinated	_	_	
7-11	1421-1427	sample	_	_	
7-12	1428-1431	for	_	_	
7-13	1432-1436	LLMs	_	_	
7-14	1437-1447	evaluation	_	_	
7-15	1447-1448	,	_	_	
7-16	1449-1451	we	_	_	
7-17	1452-1461	elaborate	_	_	
7-18	1462-1465	the	_	_	
7-19	1466-1475	filtering	_	_	
7-20	1476-1487	instruction	_	_	
7-21	1488-1496	enhanced	_	_	
7-22	1498-1500	by	_	_	
7-23	1501-1513	ground-truth	_	_	
7-24	1514-1522	examples	_	_	
7-25	1523-1526	and	_	_	
7-26	1527-1535	leverage	_	_	
7-27	1536-1543	ChatGPT	*	SOFTWARE	
7-28	1544-1547	for	_	_	
7-29	1548-1554	sample	_	_	
7-30	1555-1564	selection	_	_	
7-31	1564-1565	.	_	_	

#Text=<a href="https://github.com/RUCAIBox/HaluEval" target="_blank"><img src="assets/pipeline.png" alt="HaluEval" style="width: 90%; min-width: 300px; display: block; margin: auto;"></a>
#Text=
#Text=## Data Release
#Text=
#Text=The directory [`data`](.
8-1	1567-1568	<	_	_	
8-2	1568-1569	a	_	_	
8-3	1570-1574	href	_	_	
8-4	1574-1575	=	_	_	
8-5	1575-1576	"	_	_	
8-6	1576-1581	https	_	_	
8-7	1581-1582	:	_	_	
8-8	1582-1583	/	_	_	
8-9	1583-1584	/	_	_	
8-10	1584-1594	github.com	_	_	
8-11	1594-1595	/	_	_	
8-12	1595-1603	RUCAIBox	_	_	
8-13	1603-1604	/	_	_	
8-14	1604-1612	HaluEval	*	DATASET	
8-15	1612-1613	"	_	_	
8-16	1614-1620	target	_	_	
8-17	1620-1621	=	_	_	
8-18	1621-1622	"	_	_	
8-19	1622-1623	_	_	_	
8-20	1623-1628	blank	_	_	
8-21	1628-1629	"	_	_	
8-22	1629-1630	>	_	_	
8-23	1630-1631	<	_	_	
8-24	1631-1634	img	_	_	
8-25	1635-1638	src	_	_	
8-26	1638-1639	=	_	_	
8-27	1639-1640	"	_	_	
8-28	1640-1646	assets	_	_	
8-29	1646-1647	/	_	_	
8-30	1647-1659	pipeline.png	_	_	
8-31	1659-1660	"	_	_	
8-32	1661-1664	alt	_	_	
8-33	1664-1665	=	_	_	
8-34	1665-1666	"	_	_	
8-35	1666-1674	HaluEval	*	DATASET	
8-36	1674-1675	"	_	_	
8-37	1676-1681	style	_	_	
8-38	1681-1682	=	_	_	
8-39	1682-1683	"	_	_	
8-40	1683-1688	width	_	_	
8-41	1688-1689	:	_	_	
8-42	1690-1693	90%	_	_	
8-43	1693-1694	;	_	_	
8-44	1695-1704	min-width	_	_	
8-45	1704-1705	:	_	_	
8-46	1706-1711	300px	_	_	
8-47	1711-1712	;	_	_	
8-48	1713-1720	display	_	_	
8-49	1720-1721	:	_	_	
8-50	1722-1727	block	_	_	
8-51	1727-1728	;	_	_	
8-52	1729-1735	margin	_	_	
8-53	1735-1736	:	_	_	
8-54	1737-1741	auto	_	_	
8-55	1741-1742	;	_	_	
8-56	1742-1743	"	_	_	
8-57	1743-1744	>	_	_	
8-58	1744-1745	<	_	_	
8-59	1745-1746	/	_	_	
8-60	1746-1747	a	_	_	
8-61	1747-1748	>	_	_	
8-62	1750-1751	#	_	_	
8-63	1751-1752	#	_	_	
8-64	1753-1757	Data	_	_	
8-65	1758-1765	Release	_	_	
8-66	1767-1770	The	_	_	
8-67	1771-1780	directory	_	_	
8-68	1781-1782	[	_	_	
8-69	1782-1783	`	_	_	
8-70	1783-1787	data	_	_	
8-71	1787-1788	`	_	_	
8-72	1788-1789	]	_	_	
8-73	1789-1790	(	_	_	
8-74	1790-1791	.	_	_	

#Text=/data) contains 35K generated and human-annotated hallucinated samples we used in our experiments.
9-1	1791-1792	/	_	_	
9-2	1792-1796	data	_	_	
9-3	1796-1797	)	_	_	
9-4	1798-1806	contains	_	_	
9-5	1807-1810	35K	_	_	
9-6	1811-1820	generated	_	_	
9-7	1821-1824	and	_	_	
9-8	1825-1840	human-annotated	_	_	
9-9	1841-1853	hallucinated	_	_	
9-10	1854-1861	samples	_	_	
9-11	1862-1864	we	_	_	
9-12	1865-1869	used	_	_	
9-13	1870-1872	in	_	_	
9-14	1873-1876	our	_	_	
9-15	1877-1888	experiments	_	_	
9-16	1888-1889	.	_	_	

#Text=There are four JSON files as follows:
#Text=
#Text=- [`qa_data.json`](.
10-1	1890-1895	There	_	_	
10-2	1896-1899	are	_	_	
10-3	1900-1904	four	_	_	
10-4	1905-1909	JSON	_	_	
10-5	1910-1915	files	_	_	
10-6	1916-1918	as	_	_	
10-7	1919-1926	follows	_	_	
10-8	1926-1927	:	_	_	
10-9	1929-1930	-	_	_	
10-10	1931-1932	[	_	_	
10-11	1932-1933	`	_	_	
10-12	1933-1945	qa_data.json	_	_	
10-13	1945-1946	`	_	_	
10-14	1946-1947	]	_	_	
10-15	1947-1948	(	_	_	
10-16	1948-1949	.	_	_	

#Text=/data/qa_data.json): 10K hallucinated samples for QA based on [HotpotQA](https://hotpotqa.github.io/) as seed data.
11-1	1949-1950	/	_	_	
11-2	1950-1954	data	_	_	
11-3	1954-1955	/	_	_	
11-4	1955-1967	qa_data.json	_	_	
11-5	1967-1968	)	_	_	
11-6	1968-1969	:	_	_	
11-7	1970-1973	10K	_	_	
11-8	1974-1986	hallucinated	_	_	
11-9	1987-1994	samples	_	_	
11-10	1995-1998	for	_	_	
11-11	1999-2001	QA	_	_	
11-12	2002-2007	based	_	_	
11-13	2008-2010	on	_	_	
11-14	2011-2012	[	_	_	
11-15	2012-2020	HotpotQA	*	DATASET	
11-16	2020-2021	]	_	_	
11-17	2021-2022	(	_	_	
11-18	2022-2027	https	_	_	
11-19	2027-2028	:	_	_	
11-20	2028-2029	/	_	_	
11-21	2029-2030	/	_	_	
11-22	2030-2048	hotpotqa.github.io	_	_	
11-22.1	2030-2038	hotpotqa	*	DATASET	
11-23	2048-2049	/	_	_	
11-24	2049-2050	)	_	_	
11-25	2051-2053	as	_	_	
11-26	2054-2058	seed	_	_	
11-27	2059-2063	data	_	_	
11-28	2063-2064	.	_	_	

#Text=For each sample dictionary, the fields `knowledge`, `question`, and `right_answer` refer to the knowledge from Wikipedia, question text, and ground-truth answer collected from HotpotQA.
12-1	2066-2069	For	_	_	
12-2	2070-2074	each	_	_	
12-3	2075-2081	sample	_	_	
12-4	2082-2092	dictionary	_	_	
12-5	2092-2093	,	_	_	
12-6	2094-2097	the	_	_	
12-7	2098-2104	fields	_	_	
12-8	2105-2106	`	_	_	
12-9	2106-2115	knowledge	_	_	
12-10	2115-2116	`	_	_	
12-11	2116-2117	,	_	_	
12-12	2118-2119	`	_	_	
12-13	2119-2127	question	_	_	
12-14	2127-2128	`	_	_	
12-15	2128-2129	,	_	_	
12-16	2130-2133	and	_	_	
12-17	2134-2135	`	_	_	
12-18	2135-2147	right_answer	_	_	
12-19	2147-2148	`	_	_	
12-20	2149-2154	refer	_	_	
12-21	2155-2157	to	_	_	
12-22	2158-2161	the	_	_	
12-23	2162-2171	knowledge	_	_	
12-24	2172-2176	from	_	_	
12-25	2177-2186	Wikipedia	_	_	
12-26	2186-2187	,	_	_	
12-27	2188-2196	question	_	_	
12-28	2197-2201	text	_	_	
12-29	2201-2202	,	_	_	
12-30	2203-2206	and	_	_	
12-31	2207-2219	ground-truth	_	_	
12-32	2220-2226	answer	_	_	
12-33	2227-2236	collected	_	_	
12-34	2237-2241	from	_	_	
12-35	2242-2250	HotpotQA	*	DATASET	
12-36	2250-2251	.	_	_	

#Text=The field `hallucinated_answer` is the generated hallucinated answer correspondingly.
#Text=- [`dialogue_data.json`](.
13-1	2252-2255	The	_	_	
13-2	2256-2261	field	_	_	
13-3	2262-2263	`	_	_	
13-4	2263-2282	hallucinated_answer	_	_	
13-5	2282-2283	`	_	_	
13-6	2284-2286	is	_	_	
13-7	2287-2290	the	_	_	
13-8	2291-2300	generated	_	_	
13-9	2301-2313	hallucinated	_	_	
13-10	2314-2320	answer	_	_	
13-11	2321-2336	correspondingly	_	_	
13-12	2336-2337	.	_	_	
13-13	2338-2339	-	_	_	
13-14	2340-2341	[	_	_	
13-15	2341-2342	`	_	_	
13-16	2342-2360	dialogue_data.json	_	_	
13-17	2360-2361	`	_	_	
13-18	2361-2362	]	_	_	
13-19	2362-2363	(	_	_	
13-20	2363-2364	.	_	_	

#Text=/data/dialogue_data.json): 10K hallucinated samples for dialogue based on [OpenDialKG](https://github.com/facebookresearch/opendialkg) as seed data.
14-1	2364-2365	/	_	_	
14-2	2365-2369	data	_	_	
14-3	2369-2370	/	_	_	
14-4	2370-2388	dialogue_data.json	_	_	
14-5	2388-2389	)	_	_	
14-6	2389-2390	:	_	_	
14-7	2391-2394	10K	_	_	
14-8	2395-2407	hallucinated	_	_	
14-9	2408-2415	samples	_	_	
14-10	2416-2419	for	_	_	
14-11	2420-2428	dialogue	_	_	
14-12	2429-2434	based	_	_	
14-13	2435-2437	on	_	_	
14-14	2438-2439	[	_	_	
14-15	2439-2449	OpenDialKG	*	DATASET	
14-16	2449-2450	]	_	_	
14-17	2450-2451	(	_	_	
14-18	2451-2456	https	_	_	
14-19	2456-2457	:	_	_	
14-20	2457-2458	/	_	_	
14-21	2458-2459	/	_	_	
14-22	2459-2469	github.com	_	_	
14-23	2469-2470	/	_	_	
14-24	2470-2486	facebookresearch	_	_	
14-25	2486-2487	/	_	_	
14-26	2487-2497	opendialkg	*	DATASET	
14-27	2497-2498	)	_	_	
14-28	2499-2501	as	_	_	
14-29	2502-2506	seed	_	_	
14-30	2507-2511	data	_	_	
14-31	2511-2512	.	_	_	

#Text=For each sample dictionary, the fields `knowledge`, `dialogue_history`, and `right_response` refer to the knowledge from Wikipedia, dialogue history, and ground-truth response collected from OpenDialKG.
15-1	2514-2517	For	_	_	
15-2	2518-2522	each	_	_	
15-3	2523-2529	sample	_	_	
15-4	2530-2540	dictionary	_	_	
15-5	2540-2541	,	_	_	
15-6	2542-2545	the	_	_	
15-7	2546-2552	fields	_	_	
15-8	2553-2554	`	_	_	
15-9	2554-2563	knowledge	_	_	
15-10	2563-2564	`	_	_	
15-11	2564-2565	,	_	_	
15-12	2566-2567	`	_	_	
15-13	2567-2583	dialogue_history	_	_	
15-14	2583-2584	`	_	_	
15-15	2584-2585	,	_	_	
15-16	2586-2589	and	_	_	
15-17	2590-2591	`	_	_	
15-18	2591-2605	right_response	_	_	
15-19	2605-2606	`	_	_	
15-20	2607-2612	refer	_	_	
15-21	2613-2615	to	_	_	
15-22	2616-2619	the	_	_	
15-23	2620-2629	knowledge	_	_	
15-24	2630-2634	from	_	_	
15-25	2635-2644	Wikipedia	_	_	
15-26	2644-2645	,	_	_	
15-27	2646-2654	dialogue	_	_	
15-28	2655-2662	history	_	_	
15-29	2662-2663	,	_	_	
15-30	2664-2667	and	_	_	
15-31	2668-2680	ground-truth	_	_	
15-32	2681-2689	response	_	_	
15-33	2690-2699	collected	_	_	
15-34	2700-2704	from	_	_	
15-35	2705-2715	OpenDialKG	*	DATASET	
15-36	2715-2716	.	_	_	

#Text=The field `hallucinated_response` is the generated hallucinated response correspondingly.
#Text=- [`summarization_data.json`](.
16-1	2717-2720	The	_	_	
16-2	2721-2726	field	_	_	
16-3	2727-2728	`	_	_	
16-4	2728-2749	hallucinated_response	_	_	
16-5	2749-2750	`	_	_	
16-6	2751-2753	is	_	_	
16-7	2754-2757	the	_	_	
16-8	2758-2767	generated	_	_	
16-9	2768-2780	hallucinated	_	_	
16-10	2781-2789	response	_	_	
16-11	2790-2805	correspondingly	_	_	
16-12	2805-2806	.	_	_	
16-13	2807-2808	-	_	_	
16-14	2809-2810	[	_	_	
16-15	2810-2811	`	_	_	
16-16	2811-2834	summarization_data.json	_	_	
16-17	2834-2835	`	_	_	
16-18	2835-2836	]	_	_	
16-19	2836-2837	(	_	_	
16-20	2837-2838	.	_	_	

#Text=/data/summarization_data.json): 10K hallucinated samples for summarization based on [CNN/Daily Mail](https://github.com/abisee/cnn-dailymail) as seed data.
17-1	2838-2839	/	_	_	
17-2	2839-2843	data	_	_	
17-3	2843-2844	/	_	_	
17-4	2844-2867	summarization_data.json	_	_	
17-5	2867-2868	)	_	_	
17-6	2868-2869	:	_	_	
17-7	2870-2873	10K	_	_	
17-8	2874-2886	hallucinated	_	_	
17-9	2887-2894	samples	_	_	
17-10	2895-2898	for	_	_	
17-11	2899-2912	summarization	_	_	
17-12	2913-2918	based	_	_	
17-13	2919-2921	on	_	_	
17-14	2922-2923	[	_	_	
17-15	2923-2926	CNN	*[3]	DATASET[3]	
17-16	2926-2927	/	*[3]	DATASET[3]	
17-17	2927-2932	Daily	*[3]	DATASET[3]	
17-18	2933-2937	Mail	*[3]	DATASET[3]	
17-19	2937-2938	]	_	_	
17-20	2938-2939	(	_	_	
17-21	2939-2944	https	_	_	
17-22	2944-2945	:	_	_	
17-23	2945-2946	/	_	_	
17-24	2946-2947	/	_	_	
17-25	2947-2957	github.com	_	_	
17-26	2957-2958	/	_	_	
17-27	2958-2964	abisee	_	_	
17-28	2964-2965	/	_	_	
17-29	2965-2978	cnn-dailymail	*	DATASET	
17-30	2978-2979	)	_	_	
17-31	2980-2982	as	_	_	
17-32	2983-2987	seed	_	_	
17-33	2988-2992	data	_	_	
17-34	2992-2993	.	_	_	

#Text=For each sample dictionary, the fields `document` and `right_summary` refer to the document and ground-truth summary collected from CNN/Daily Mail.
18-1	2995-2998	For	_	_	
18-2	2999-3003	each	_	_	
18-3	3004-3010	sample	_	_	
18-4	3011-3021	dictionary	_	_	
18-5	3021-3022	,	_	_	
18-6	3023-3026	the	_	_	
18-7	3027-3033	fields	_	_	
18-8	3034-3035	`	_	_	
18-9	3035-3043	document	_	_	
18-10	3043-3044	`	_	_	
18-11	3045-3048	and	_	_	
18-12	3049-3050	`	_	_	
18-13	3050-3063	right_summary	_	_	
18-14	3063-3064	`	_	_	
18-15	3065-3070	refer	_	_	
18-16	3071-3073	to	_	_	
18-17	3074-3077	the	_	_	
18-18	3078-3086	document	_	_	
18-19	3087-3090	and	_	_	
18-20	3091-3103	ground-truth	_	_	
18-21	3104-3111	summary	_	_	
18-22	3112-3121	collected	_	_	
18-23	3122-3126	from	_	_	
18-24	3127-3130	CNN	*[4]	DATASET[4]	
18-25	3130-3131	/	*[4]	DATASET[4]	
18-26	3131-3136	Daily	*[4]	DATASET[4]	
18-27	3137-3141	Mail	*[4]	DATASET[4]	
18-28	3141-3142	.	_	_	

#Text=The field `hallucinated_summary` is the generated hallucinated summary correspondingly.
#Text=- [`general_data.json`](.
19-1	3143-3146	The	_	_	
19-2	3147-3152	field	_	_	
19-3	3153-3154	`	_	_	
19-4	3154-3174	hallucinated_summary	_	_	
19-5	3174-3175	`	_	_	
19-6	3176-3178	is	_	_	
19-7	3179-3182	the	_	_	
19-8	3183-3192	generated	_	_	
19-9	3193-3205	hallucinated	_	_	
19-10	3206-3213	summary	_	_	
19-11	3214-3229	correspondingly	_	_	
19-12	3229-3230	.	_	_	
19-13	3231-3232	-	_	_	
19-14	3233-3234	[	_	_	
19-15	3234-3235	`	_	_	
19-16	3235-3252	general_data.json	_	_	
19-17	3252-3253	`	_	_	
19-18	3253-3254	]	_	_	
19-19	3254-3255	(	_	_	
19-20	3255-3256	.	_	_	

#Text=/data/general_data.json): 5K human-annotated samples for ChatGPT responses to general user queries from [Alpaca](https://github.com/tatsu-lab/stanford_alpaca).
20-1	3256-3257	/	_	_	
20-2	3257-3261	data	_	_	
20-3	3261-3262	/	_	_	
20-4	3262-3279	general_data.json	_	_	
20-5	3279-3280	)	_	_	
20-6	3280-3281	:	_	_	
20-7	3282-3284	5K	_	_	
20-8	3285-3300	human-annotated	_	_	
20-9	3301-3308	samples	_	_	
20-10	3309-3312	for	_	_	
20-11	3313-3320	ChatGPT	*	SOFTWARE	
20-12	3321-3330	responses	_	_	
20-13	3331-3333	to	_	_	
20-14	3334-3341	general	_	_	
20-15	3342-3346	user	_	_	
20-16	3347-3354	queries	_	_	
20-17	3355-3359	from	_	_	
20-18	3360-3361	[	_	_	
20-19	3361-3367	Alpaca	*	PROJECT	
20-20	3367-3368	]	_	_	
20-21	3368-3369	(	_	_	
20-22	3369-3374	https	_	_	
20-23	3374-3375	:	_	_	
20-24	3375-3376	/	_	_	
20-25	3376-3377	/	_	_	
20-26	3377-3387	github.com	_	_	
20-27	3387-3388	/	_	_	
20-28	3388-3397	tatsu-lab	_	_	
20-29	3397-3398	/	_	_	
20-30	3398-3413	stanford_alpaca	_	_	
20-30.1	3407-3413	alpaca	*	PROJECT	
20-31	3413-3414	)	_	_	
20-32	3414-3415	.	_	_	

#Text=For each sample dictionary, the fields `user_query`, `chatgpt_response`, and `hallucination_label` refer to the posed user query, ChatGPT response, and hallucination label (Yes/No) annotated by humans.
21-1	3416-3419	For	_	_	
21-2	3420-3424	each	_	_	
21-3	3425-3431	sample	_	_	
21-4	3432-3442	dictionary	_	_	
21-5	3442-3443	,	_	_	
21-6	3444-3447	the	_	_	
21-7	3448-3454	fields	_	_	
21-8	3455-3456	`	_	_	
21-9	3456-3466	user_query	_	_	
21-10	3466-3467	`	_	_	
21-11	3467-3468	,	_	_	
21-12	3469-3470	`	_	_	
21-13	3470-3486	chatgpt_response	_	_	
21-13.1	3470-3477	chatgpt	*	SOFTWARE	
21-14	3486-3487	`	_	_	
21-15	3487-3488	,	_	_	
21-16	3489-3492	and	_	_	
21-17	3493-3494	`	_	_	
21-18	3494-3513	hallucination_label	_	_	
21-19	3513-3514	`	_	_	
21-20	3515-3520	refer	_	_	
21-21	3521-3523	to	_	_	
21-22	3524-3527	the	_	_	
21-23	3528-3533	posed	_	_	
21-24	3534-3538	user	_	_	
21-25	3539-3544	query	_	_	
21-26	3544-3545	,	_	_	
21-27	3546-3553	ChatGPT	*	SOFTWARE	
21-28	3554-3562	response	_	_	
21-29	3562-3563	,	_	_	
21-30	3564-3567	and	_	_	
21-31	3568-3581	hallucination	_	_	
21-32	3582-3587	label	_	_	
21-33	3588-3589	(	_	_	
21-34	3589-3592	Yes	_	_	
21-35	3592-3593	/	_	_	
21-36	3593-3595	No	_	_	
21-37	3595-3596	)	_	_	
21-38	3597-3606	annotated	_	_	
21-39	3607-3609	by	_	_	
21-40	3610-3616	humans	_	_	
21-41	3616-3617	.	_	_	

#Text=Based on these data, you can evaluate the ability of LLMs to recognize hallucinations and analyze what type of contents/topics LLMs tend to hallucinate (or fail to recognize the contained hallucination). 
#Text=
#Text=## Data Generation Process
#Text=
#Text=We executed the data generation pipeline via ChatGPT according to the following steps:
#Text=
#Text=- First, we download the training sets of HotpotQA, OpenDialKG, and CNN/Daily Mail.
#Text=
#Text=```
#Text=cd generation
#Text=wget http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json
#Text=wget https://raw.githubusercontent.com/facebookresearch/opendialkg/main/data/opendialkg.csv
#Text=wget https://huggingface.co/datasets/ccdv/cnn_dailymail/blob/main/cnn_stories.tgz
#Text=```
#Text=
#Text=- Second, we sample 10K samples and generate their hallucinated counterparts by setting the task
#Text=and sampling strategy
22-1	3619-3624	Based	_	_	
22-2	3625-3627	on	_	_	
22-3	3628-3633	these	_	_	
22-4	3634-3638	data	_	_	
22-5	3638-3639	,	_	_	
22-6	3640-3643	you	_	_	
22-7	3644-3647	can	_	_	
22-8	3648-3656	evaluate	_	_	
22-9	3657-3660	the	_	_	
22-10	3661-3668	ability	_	_	
22-11	3669-3671	of	_	_	
22-12	3672-3676	LLMs	_	_	
22-13	3677-3679	to	_	_	
22-14	3680-3689	recognize	_	_	
22-15	3690-3704	hallucinations	_	_	
22-16	3705-3708	and	_	_	
22-17	3709-3716	analyze	_	_	
22-18	3717-3721	what	_	_	
22-19	3722-3726	type	_	_	
22-20	3727-3729	of	_	_	
22-21	3730-3738	contents	_	_	
22-22	3738-3739	/	_	_	
22-23	3739-3745	topics	_	_	
22-24	3746-3750	LLMs	_	_	
22-25	3751-3755	tend	_	_	
22-26	3756-3758	to	_	_	
22-27	3759-3770	hallucinate	_	_	
22-28	3771-3772	(	_	_	
22-29	3772-3774	or	_	_	
22-30	3775-3779	fail	_	_	
22-31	3780-3782	to	_	_	
22-32	3783-3792	recognize	_	_	
22-33	3793-3796	the	_	_	
22-34	3797-3806	contained	_	_	
22-35	3807-3820	hallucination	_	_	
22-36	3820-3821	)	_	_	
22-37	3821-3822	.	_	_	
22-38	3825-3826	#	_	_	
22-39	3826-3827	#	_	_	
22-40	3828-3832	Data	_	_	
22-41	3833-3843	Generation	_	_	
22-42	3844-3851	Process	_	_	
22-43	3853-3855	We	_	_	
22-44	3856-3864	executed	_	_	
22-45	3865-3868	the	_	_	
22-46	3869-3873	data	_	_	
22-47	3874-3884	generation	_	_	
22-48	3885-3893	pipeline	_	_	
22-49	3894-3897	via	_	_	
22-50	3898-3905	ChatGPT	*	SOFTWARE	
22-51	3906-3915	according	_	_	
22-52	3916-3918	to	_	_	
22-53	3919-3922	the	_	_	
22-54	3923-3932	following	_	_	
22-55	3933-3938	steps	_	_	
22-56	3938-3939	:	_	_	
22-57	3941-3942	-	_	_	
22-58	3943-3948	First	_	_	
22-59	3948-3949	,	_	_	
22-60	3950-3952	we	_	_	
22-61	3953-3961	download	_	_	
22-62	3962-3965	the	_	_	
22-63	3966-3974	training	_	_	
22-64	3975-3979	sets	_	_	
22-65	3980-3982	of	_	_	
22-66	3983-3991	HotpotQA	*	DATASET	
22-67	3991-3992	,	_	_	
22-68	3993-4003	OpenDialKG	*	DATASET	
22-69	4003-4004	,	_	_	
22-70	4005-4008	and	_	_	
22-71	4009-4012	CNN	*[5]	DATASET[5]	
22-72	4012-4013	/	*[5]	DATASET[5]	
22-73	4013-4018	Daily	*[5]	DATASET[5]	
22-74	4019-4023	Mail	*[5]	DATASET[5]	
22-75	4023-4024	.	_	_	
22-76	4026-4027	`	_	_	
22-77	4027-4028	`	_	_	
22-78	4028-4029	`	_	_	
22-79	4030-4032	cd	_	_	
22-80	4033-4043	generation	_	_	
22-81	4044-4048	wget	*	SOFTWARE	
22-82	4049-4053	http	_	_	
22-83	4053-4054	:	_	_	
22-84	4054-4055	/	_	_	
22-85	4055-4056	/	_	_	
22-86	4056-4073	curtis.ml.cmu.edu	_	_	
22-87	4073-4074	/	_	_	
22-88	4074-4082	datasets	_	_	
22-89	4082-4083	/	_	_	
22-90	4083-4089	hotpot	*[6]	DATASET[6]	
22-91	4089-4090	/	*[6]	DATASET[6]	
22-92	4090-4107	hotpot_train_v1.1	*[6]	DATASET[6]	
22-93	4107-4108	.	_	_	
22-94	4108-4112	json	_	_	
22-95	4113-4117	wget	*	SOFTWARE	
22-96	4118-4123	https	_	_	
22-97	4123-4124	:	_	_	
22-98	4124-4125	/	_	_	
22-99	4125-4126	/	_	_	
22-100	4126-4151	raw.githubusercontent.com	_	_	
22-101	4151-4152	/	_	_	
22-102	4152-4168	facebookresearch	_	_	
22-103	4168-4169	/	_	_	
22-104	4169-4179	opendialkg	*	DATASET	
22-105	4179-4180	/	_	_	
22-106	4180-4184	main	_	_	
22-107	4184-4185	/	_	_	
22-108	4185-4189	data	_	_	
22-109	4189-4190	/	_	_	
22-110	4190-4204	opendialkg.csv	_	_	
22-110.1	4190-4200	opendialkg	*	DATASET	
22-111	4205-4209	wget	_	_	
22-112	4210-4215	https	_	_	
22-113	4215-4216	:	_	_	
22-114	4216-4217	/	_	_	
22-115	4217-4218	/	_	_	
22-116	4218-4232	huggingface.co	_	_	
22-117	4232-4233	/	_	_	
22-118	4233-4241	datasets	_	_	
22-119	4241-4242	/	_	_	
22-120	4242-4246	ccdv	*[7]	DATASET[7]	
22-121	4246-4247	/	*[7]	DATASET[7]	
22-122	4247-4260	cnn_dailymail	*[7]	DATASET[7]	
22-123	4260-4261	/	_	_	
22-124	4261-4265	blob	_	_	
22-125	4265-4266	/	_	_	
22-126	4266-4270	main	_	_	
22-127	4270-4271	/	_	_	
22-128	4271-4286	cnn_stories.tgz	_	_	
22-129	4287-4288	`	_	_	
22-130	4288-4289	`	_	_	
22-131	4289-4290	`	_	_	
22-132	4292-4293	-	_	_	
22-133	4294-4300	Second	_	_	
22-134	4300-4301	,	_	_	
22-135	4302-4304	we	_	_	
22-136	4305-4311	sample	_	_	
22-137	4312-4315	10K	_	_	
22-138	4316-4323	samples	_	_	
22-139	4324-4327	and	_	_	
22-140	4328-4336	generate	_	_	
22-141	4337-4342	their	_	_	
22-142	4343-4355	hallucinated	_	_	
22-143	4356-4368	counterparts	_	_	
22-144	4369-4371	by	_	_	
22-145	4372-4379	setting	_	_	
22-146	4380-4383	the	_	_	
22-147	4384-4388	task	_	_	
22-148	4389-4392	and	_	_	
22-149	4393-4401	sampling	_	_	
22-150	4402-4410	strategy	_	_	

#Text=.
23-1	4410-4411	.	_	_	

#Text=- `seed_data`: the downloaded training sets of HotpotQA, OpenDialKG, and CNN/Daily Mail
24-1	4414-4415	-	_	_	
24-2	4416-4417	`	_	_	
24-3	4417-4426	seed_data	_	_	
24-4	4426-4427	`	_	_	
24-5	4427-4428	:	_	_	
24-6	4429-4432	the	_	_	
24-7	4433-4443	downloaded	_	_	
24-8	4444-4452	training	_	_	
24-9	4453-4457	sets	_	_	
24-10	4458-4460	of	_	_	
24-11	4461-4469	HotpotQA	*	DATASET	
24-12	4469-4470	,	_	_	
24-13	4471-4481	OpenDialKG	*	DATASET	
24-14	4481-4482	,	_	_	
24-15	4483-4486	and	_	_	
24-16	4487-4490	CNN	*[8]	DATASET[8]	
24-17	4490-4491	/	*[8]	DATASET[8]	
24-18	4491-4496	Daily	*[8]	DATASET[8]	
24-19	4497-4501	Mail	*[8]	DATASET[8]	

#Text=.
25-1	4501-4502	.	_	_	

#Text=- `task`: sampled tasks, i.e., `qa`, `dialogue`, or `summarization`
26-1	4505-4506	-	_	_	
26-2	4507-4508	`	_	_	
26-3	4508-4512	task	_	_	
26-4	4512-4513	`	_	_	
26-5	4513-4514	:	_	_	
26-6	4515-4522	sampled	_	_	
26-7	4523-4528	tasks	_	_	
26-8	4528-4529	,	_	_	
26-9	4530-4533	i.e	_	_	
26-10	4533-4534	.	_	_	
26-11	4534-4535	,	_	_	
26-12	4536-4537	`	_	_	
26-13	4537-4539	qa	_	_	
26-14	4539-4540	`	_	_	
26-15	4540-4541	,	_	_	
26-16	4542-4543	`	_	_	
26-17	4543-4551	dialogue	_	_	
26-18	4551-4552	`	_	_	
26-19	4552-4553	,	_	_	
26-20	4554-4556	or	_	_	
26-21	4557-4558	`	_	_	
26-22	4558-4571	summarization	_	_	
26-23	4571-4572	`	_	_	

#Text=.
27-1	4572-4573	.	_	_	

#Text=- `strategy`: sampling strategy, i.e., `one-turn` or `multi-turn`.
28-1	4576-4577	-	_	_	
28-2	4578-4579	`	_	_	
28-3	4579-4587	strategy	_	_	
28-4	4587-4588	`	_	_	
28-5	4588-4589	:	_	_	
28-6	4590-4598	sampling	_	_	
28-7	4599-4607	strategy	_	_	
28-8	4607-4608	,	_	_	
28-9	4609-4612	i.e	_	_	
28-10	4612-4613	.	_	_	
28-11	4613-4614	,	_	_	
28-12	4615-4616	`	_	_	
28-13	4616-4624	one-turn	_	_	
28-14	4624-4625	`	_	_	
28-15	4626-4628	or	_	_	
28-16	4629-4630	`	_	_	
28-17	4630-4640	multi-turn	_	_	
28-18	4640-4641	`	_	_	
28-19	4641-4642	.	_	_	

#Text=(one-pass and conversational in our paper)
#Text=```
#Text=python generate.py --seed_data hotpot_train_v1.1.json --task qa --strategy one-turn
#Text=```
#Text=
#Text=- Finally, we select the most plausible and difficult hallucinated sample from these two sampling methods.
29-1	4643-4644	(	_	_	
29-2	4644-4652	one-pass	_	_	
29-3	4653-4656	and	_	_	
29-4	4657-4671	conversational	_	_	
29-5	4672-4674	in	_	_	
29-6	4675-4678	our	_	_	
29-7	4679-4684	paper	_	_	
29-8	4684-4685	)	_	_	
29-9	4686-4687	`	_	_	
29-10	4687-4688	`	_	_	
29-11	4688-4689	`	_	_	
29-12	4690-4696	python	_	_	
29-13	4697-4708	generate.py	_	_	
29-14	4709-4710	-	_	_	
29-15	4710-4711	-	_	_	
29-16	4711-4720	seed_data	_	_	
29-17	4721-4738	hotpot_train_v1.1	*	DATASET	
29-18	4738-4739	.	_	_	
29-19	4739-4743	json	_	_	
29-20	4744-4745	-	_	_	
29-21	4745-4746	-	_	_	
29-22	4746-4750	task	_	_	
29-23	4751-4753	qa	_	_	
29-24	4754-4755	-	_	_	
29-25	4755-4756	-	_	_	
29-26	4756-4764	strategy	_	_	
29-27	4765-4773	one-turn	_	_	
29-28	4774-4775	`	_	_	
29-29	4775-4776	`	_	_	
29-30	4776-4777	`	_	_	
29-31	4779-4780	-	_	_	
29-32	4781-4788	Finally	_	_	
29-33	4788-4789	,	_	_	
29-34	4790-4792	we	_	_	
29-35	4793-4799	select	_	_	
29-36	4800-4803	the	_	_	
29-37	4804-4808	most	_	_	
29-38	4809-4818	plausible	_	_	
29-39	4819-4822	and	_	_	
29-40	4823-4832	difficult	_	_	
29-41	4833-4845	hallucinated	_	_	
29-42	4846-4852	sample	_	_	
29-43	4853-4857	from	_	_	
29-44	4858-4863	these	_	_	
29-45	4864-4867	two	_	_	
29-46	4868-4876	sampling	_	_	
29-47	4877-4884	methods	_	_	
29-48	4884-4885	.	_	_	

#Text=The final selected samples will be stored in the `data` directory
30-1	4887-4890	The	_	_	
30-2	4891-4896	final	_	_	
30-3	4897-4905	selected	_	_	
30-4	4906-4913	samples	_	_	
30-5	4914-4918	will	_	_	
30-6	4919-4921	be	_	_	
30-7	4922-4928	stored	_	_	
30-8	4929-4931	in	_	_	
30-9	4932-4935	the	_	_	
30-10	4936-4937	`	_	_	
30-11	4937-4941	data	_	_	
30-12	4941-4942	`	_	_	
30-13	4943-4952	directory	_	_	

#Text=.
31-1	4952-4953	.	_	_	

#Text=- `task`: filtered task, i.e., `qa`, `dialogue`, or `summarization`.
#Text=
#Text=```
#Text=python filtering.py --task qa
#Text=```
#Text=
#Text=Users can use our provided instructions and codes on their own datasets to generate hallucinated samples.
#Text=
#Text=## Evaluation
#Text=
#Text=In evaluation, we randomly sample a ground-truth or a hallucinated output for each data.
32-1	4957-4958	-	_	_	
32-2	4959-4960	`	_	_	
32-3	4960-4964	task	_	_	
32-4	4964-4965	`	_	_	
32-5	4965-4966	:	_	_	
32-6	4967-4975	filtered	_	_	
32-7	4976-4980	task	_	_	
32-8	4980-4981	,	_	_	
32-9	4982-4985	i.e	_	_	
32-10	4985-4986	.	_	_	
32-11	4986-4987	,	_	_	
32-12	4988-4989	`	_	_	
32-13	4989-4991	qa	_	_	
32-14	4991-4992	`	_	_	
32-15	4992-4993	,	_	_	
32-16	4994-4995	`	_	_	
32-17	4995-5003	dialogue	_	_	
32-18	5003-5004	`	_	_	
32-19	5004-5005	,	_	_	
32-20	5006-5008	or	_	_	
32-21	5009-5010	`	_	_	
32-22	5010-5023	summarization	_	_	
32-23	5023-5024	`	_	_	
32-24	5024-5025	.	_	_	
32-25	5027-5028	`	_	_	
32-26	5028-5029	`	_	_	
32-27	5029-5030	`	_	_	
32-28	5031-5037	python	_	_	
32-29	5038-5050	filtering.py	_	_	
32-30	5051-5052	-	_	_	
32-31	5052-5053	-	_	_	
32-32	5053-5057	task	_	_	
32-33	5058-5060	qa	_	_	
32-34	5061-5062	`	_	_	
32-35	5062-5063	`	_	_	
32-36	5063-5064	`	_	_	
32-37	5066-5071	Users	_	_	
32-38	5072-5075	can	_	_	
32-39	5076-5079	use	_	_	
32-40	5080-5083	our	_	_	
32-41	5084-5092	provided	_	_	
32-42	5093-5105	instructions	_	_	
32-43	5106-5109	and	_	_	
32-44	5110-5115	codes	_	_	
32-45	5116-5118	on	_	_	
32-46	5119-5124	their	_	_	
32-47	5125-5128	own	_	_	
32-48	5129-5137	datasets	_	_	
32-49	5138-5140	to	_	_	
32-50	5141-5149	generate	_	_	
32-51	5150-5162	hallucinated	_	_	
32-52	5163-5170	samples	_	_	
32-53	5170-5171	.	_	_	
32-54	5173-5174	#	_	_	
32-55	5174-5175	#	_	_	
32-56	5176-5186	Evaluation	_	_	
32-57	5188-5190	In	_	_	
32-58	5191-5201	evaluation	_	_	
32-59	5201-5202	,	_	_	
32-60	5203-5205	we	_	_	
32-61	5206-5214	randomly	_	_	
32-62	5215-5221	sample	_	_	
32-63	5222-5223	a	_	_	
32-64	5224-5236	ground-truth	_	_	
32-65	5237-5239	or	_	_	
32-66	5240-5241	a	_	_	
32-67	5242-5254	hallucinated	_	_	
32-68	5255-5261	output	_	_	
32-69	5262-5265	for	_	_	
32-70	5266-5270	each	_	_	
32-71	5271-5275	data	_	_	
32-72	5275-5276	.	_	_	

#Text=For example, if the text is a hallucinated answer, the LLM should recognize the hallucination and output "Yes", which means the text contains hallucinations.
33-1	5277-5280	For	_	_	
33-2	5281-5288	example	_	_	
33-3	5288-5289	,	_	_	
33-4	5290-5292	if	_	_	
33-5	5293-5296	the	_	_	
33-6	5297-5301	text	_	_	
33-7	5302-5304	is	_	_	
33-8	5305-5306	a	_	_	
33-9	5307-5319	hallucinated	_	_	
33-10	5320-5326	answer	_	_	
33-11	5326-5327	,	_	_	
33-12	5328-5331	the	_	_	
33-13	5332-5335	LLM	_	_	
33-14	5336-5342	should	_	_	
33-15	5343-5352	recognize	_	_	
33-16	5353-5356	the	_	_	
33-17	5357-5370	hallucination	_	_	
33-18	5371-5374	and	_	_	
33-19	5375-5381	output	_	_	
33-20	5382-5383	"	_	_	
33-21	5383-5386	Yes	_	_	
33-22	5386-5387	"	_	_	
33-23	5387-5388	,	_	_	
33-24	5389-5394	which	_	_	
33-25	5395-5400	means	_	_	
33-26	5401-5404	the	_	_	
33-27	5405-5409	text	_	_	
33-28	5410-5418	contains	_	_	
33-29	5419-5433	hallucinations	_	_	
33-30	5433-5434	.	_	_	

#Text=If the text is a ground-truth answer, the LLM should output "No" indicating that there is no hallucination
34-1	5435-5437	If	_	_	
34-2	5438-5441	the	_	_	
34-3	5442-5446	text	_	_	
34-4	5447-5449	is	_	_	
34-5	5450-5451	a	_	_	
34-6	5452-5464	ground-truth	_	_	
34-7	5465-5471	answer	_	_	
34-8	5471-5472	,	_	_	
34-9	5473-5476	the	_	_	
34-10	5477-5480	LLM	_	_	
34-11	5481-5487	should	_	_	
34-12	5488-5494	output	_	_	
34-13	5495-5496	"	_	_	
34-14	5496-5498	No	_	_	
34-15	5498-5499	"	_	_	
34-16	5500-5510	indicating	_	_	
34-17	5511-5515	that	_	_	
34-18	5516-5521	there	_	_	
34-19	5522-5524	is	_	_	
34-20	5525-5527	no	_	_	
34-21	5528-5541	hallucination	_	_	

#Text=.
35-1	5541-5542	.	_	_	

#Text=- `task`: evaluated task, i.e., `qa`, `dialogue`, or `summarization`.
#Text=- `model`: evaluated model, e.g., ChatGPT (`gpt-3.5-turbo`), GPT-3 (`davinci`).
#Text=
#Text=```
#Text=cd evaluation
#Text=python evaluate.py --task qa --model gpt-3.5-turbo
#Text=```
#Text=
#Text=
#Text=## Analysis
#Text=
#Text=Based on the samples that LLMs succeed or fail to recognize, we can analyze the topics of these samples using LDA
36-1	5548-5549	-	_	_	
36-2	5550-5551	`	_	_	
36-3	5551-5555	task	_	_	
36-4	5555-5556	`	_	_	
36-5	5556-5557	:	_	_	
36-6	5558-5567	evaluated	_	_	
36-7	5568-5572	task	_	_	
36-8	5572-5573	,	_	_	
36-9	5574-5577	i.e	_	_	
36-10	5577-5578	.	_	_	
36-11	5578-5579	,	_	_	
36-12	5580-5581	`	_	_	
36-13	5581-5583	qa	_	_	
36-14	5583-5584	`	_	_	
36-15	5584-5585	,	_	_	
36-16	5586-5587	`	_	_	
36-17	5587-5595	dialogue	_	_	
36-18	5595-5596	`	_	_	
36-19	5596-5597	,	_	_	
36-20	5598-5600	or	_	_	
36-21	5601-5602	`	_	_	
36-22	5602-5615	summarization	_	_	
36-23	5615-5616	`	_	_	
36-24	5616-5617	.	_	_	
36-25	5618-5619	-	_	_	
36-26	5620-5621	`	_	_	
36-27	5621-5626	model	_	_	
36-28	5626-5627	`	_	_	
36-29	5627-5628	:	_	_	
36-30	5629-5638	evaluated	_	_	
36-31	5639-5644	model	_	_	
36-32	5644-5645	,	_	_	
36-33	5646-5649	e.g	_	_	
36-34	5649-5650	.	_	_	
36-35	5650-5651	,	_	_	
36-36	5652-5659	ChatGPT	_	_	
36-37	5660-5661	(	_	_	
36-38	5661-5662	`	_	_	
36-39	5662-5665	gpt	_	_	
36-40	5665-5666	-	_	_	
36-41	5666-5669	3.5	_	_	
36-42	5669-5670	-	_	_	
36-43	5670-5675	turbo	_	_	
36-44	5675-5676	`	_	_	
36-45	5676-5677	)	_	_	
36-46	5677-5678	,	_	_	
36-47	5679-5682	GPT	_	_	
36-48	5682-5683	-	_	_	
36-49	5683-5684	3	_	_	
36-50	5685-5686	(	_	_	
36-51	5686-5687	`	_	_	
36-52	5687-5694	davinci	_	_	
36-53	5694-5695	`	_	_	
36-54	5695-5696	)	_	_	
36-55	5696-5697	.	_	_	
36-56	5699-5700	`	_	_	
36-57	5700-5701	`	_	_	
36-58	5701-5702	`	_	_	
36-59	5703-5705	cd	_	_	
36-60	5706-5716	evaluation	_	_	
36-61	5717-5723	python	_	_	
36-62	5724-5735	evaluate.py	_	_	
36-63	5736-5737	-	_	_	
36-64	5737-5738	-	_	_	
36-65	5738-5742	task	_	_	
36-66	5743-5745	qa	_	_	
36-67	5746-5747	-	_	_	
36-68	5747-5748	-	_	_	
36-69	5748-5753	model	_	_	
36-70	5754-5757	gpt	_	_	
36-71	5757-5758	-	_	_	
36-72	5758-5761	3.5	_	_	
36-73	5761-5762	-	_	_	
36-74	5762-5767	turbo	_	_	
36-75	5768-5769	`	_	_	
36-76	5769-5770	`	_	_	
36-77	5770-5771	`	_	_	
36-78	5774-5775	#	_	_	
36-79	5775-5776	#	_	_	
36-80	5777-5785	Analysis	_	_	
36-81	5787-5792	Based	_	_	
36-82	5793-5795	on	_	_	
36-83	5796-5799	the	_	_	
36-84	5800-5807	samples	_	_	
36-85	5808-5812	that	_	_	
36-86	5813-5817	LLMs	_	_	
36-87	5818-5825	succeed	_	_	
36-88	5826-5828	or	_	_	
36-89	5829-5833	fail	_	_	
36-90	5834-5836	to	_	_	
36-91	5837-5846	recognize	_	_	
36-92	5846-5847	,	_	_	
36-93	5848-5850	we	_	_	
36-94	5851-5854	can	_	_	
36-95	5855-5862	analyze	_	_	
36-96	5863-5866	the	_	_	
36-97	5867-5873	topics	_	_	
36-98	5874-5876	of	_	_	
36-99	5877-5882	these	_	_	
36-100	5883-5890	samples	_	_	
36-101	5891-5896	using	_	_	
36-102	5897-5900	LDA	_	_	

#Text=.
37-1	5900-5901	.	_	_	

#Text=- `task`: analyzed task, i.e., `qa`, `dialogue`, or `summarization`.
#Text=- `result`: the file of recognition results at the evaluation stage.
#Text=- `category`: `all` (all task samples), `failed` (task samples that LLMs fail to recognize hallucinations)
#Text=
#Text=```
#Text=cd analysis
#Text=python analyze.py --task qa --result ..
38-1	5903-5904	-	_	_	
38-2	5905-5906	`	_	_	
38-3	5906-5910	task	_	_	
38-4	5910-5911	`	_	_	
38-5	5911-5912	:	_	_	
38-6	5913-5921	analyzed	_	_	
38-7	5922-5926	task	_	_	
38-8	5926-5927	,	_	_	
38-9	5928-5931	i.e	_	_	
38-10	5931-5932	.	_	_	
38-11	5932-5933	,	_	_	
38-12	5934-5935	`	_	_	
38-13	5935-5937	qa	_	_	
38-14	5937-5938	`	_	_	
38-15	5938-5939	,	_	_	
38-16	5940-5941	`	_	_	
38-17	5941-5949	dialogue	_	_	
38-18	5949-5950	`	_	_	
38-19	5950-5951	,	_	_	
38-20	5952-5954	or	_	_	
38-21	5955-5956	`	_	_	
38-22	5956-5969	summarization	_	_	
38-23	5969-5970	`	_	_	
38-24	5970-5971	.	_	_	
38-25	5972-5973	-	_	_	
38-26	5974-5975	`	_	_	
38-27	5975-5981	result	_	_	
38-28	5981-5982	`	_	_	
38-29	5982-5983	:	_	_	
38-30	5984-5987	the	_	_	
38-31	5988-5992	file	_	_	
38-32	5993-5995	of	_	_	
38-33	5996-6007	recognition	_	_	
38-34	6008-6015	results	_	_	
38-35	6016-6018	at	_	_	
38-36	6019-6022	the	_	_	
38-37	6023-6033	evaluation	_	_	
38-38	6034-6039	stage	_	_	
38-39	6039-6040	.	_	_	
38-40	6041-6042	-	_	_	
38-41	6043-6044	`	_	_	
38-42	6044-6052	category	_	_	
38-43	6052-6053	`	_	_	
38-44	6053-6054	:	_	_	
38-45	6055-6056	`	_	_	
38-46	6056-6059	all	_	_	
38-47	6059-6060	`	_	_	
38-48	6061-6062	(	_	_	
38-49	6062-6065	all	_	_	
38-50	6066-6070	task	_	_	
38-51	6071-6078	samples	_	_	
38-52	6078-6079	)	_	_	
38-53	6079-6080	,	_	_	
38-54	6081-6082	`	_	_	
38-55	6082-6088	failed	_	_	
38-56	6088-6089	`	_	_	
38-57	6090-6091	(	_	_	
38-58	6091-6095	task	_	_	
38-59	6096-6103	samples	_	_	
38-60	6104-6108	that	_	_	
38-61	6109-6113	LLMs	_	_	
38-62	6114-6118	fail	_	_	
38-63	6119-6121	to	_	_	
38-64	6122-6131	recognize	_	_	
38-65	6132-6146	hallucinations	_	_	
38-66	6146-6147	)	_	_	
38-67	6149-6150	`	_	_	
38-68	6150-6151	`	_	_	
38-69	6151-6152	`	_	_	
38-70	6153-6155	cd	_	_	
38-71	6156-6164	analysis	_	_	
38-72	6165-6171	python	_	_	
38-73	6172-6182	analyze.py	_	_	
38-74	6183-6184	-	_	_	
38-75	6184-6185	-	_	_	
38-76	6185-6189	task	_	_	
38-77	6190-6192	qa	_	_	
38-78	6193-6194	-	_	_	
38-79	6194-6195	-	_	_	
38-80	6195-6201	result	_	_	
38-81	6202-6203	.	_	_	
38-82	6203-6204	.	_	_	

#Text=/evaluation/qa/qa_gpt-3.5-turbo_result.json --category all
#Text=```
#Text=
#Text=## License
#Text=
#Text=HaluEval uses [MIT License](.
39-1	6204-6205	/	_	_	
39-2	6205-6215	evaluation	_	_	
39-3	6215-6216	/	_	_	
39-4	6216-6218	qa	_	_	
39-5	6218-6219	/	_	_	
39-6	6219-6225	qa_gpt	_	_	
39-7	6225-6226	-	_	_	
39-8	6226-6229	3.5	_	_	
39-9	6229-6230	-	_	_	
39-10	6230-6247	turbo_result.json	_	_	
39-11	6248-6249	-	_	_	
39-12	6249-6250	-	_	_	
39-13	6250-6258	category	_	_	
39-14	6259-6262	all	_	_	
39-15	6263-6264	`	_	_	
39-16	6264-6265	`	_	_	
39-17	6265-6266	`	_	_	
39-18	6268-6269	#	_	_	
39-19	6269-6270	#	_	_	
39-20	6271-6278	License	_	_	
39-21	6280-6288	HaluEval	*	DATASET	
39-22	6289-6293	uses	_	_	
39-23	6294-6295	[	_	_	
39-24	6295-6298	MIT	*[9]	LICENSE[9]	
39-25	6299-6306	License	*[9]	LICENSE[9]	
39-26	6306-6307	]	_	_	
39-27	6307-6308	(	_	_	
39-28	6308-6309	.	_	_	

#Text=/LICENSE).
#Text=
#Text=## Reference
#Text=
#Text=Please cite the repo if you use the data or code in this repo.
#Text=
#Text=```
#Text=@misc{HaluEval,
#Text=  author = {Junyi Li and Xiaoxue Cheng and Wayne Xin Zhao and Jian-Yun Nie and Ji-Rong Wen },
#Text=  title = {HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models},
#Text=  year = {2023},
#Text=  journal={arXiv preprint arXiv:2305.11747},
#Text=  url={https://arxiv.org/abs/2305.11747}
#Text=}
#Text=```
40-1	6309-6310	/	_	_	
40-2	6310-6317	LICENSE	_	_	
40-3	6317-6318	)	_	_	
40-4	6318-6319	.	_	_	
40-5	6321-6322	#	_	_	
40-6	6322-6323	#	_	_	
40-7	6324-6333	Reference	_	_	
40-8	6335-6341	Please	_	_	
40-9	6342-6346	cite	_	_	
40-10	6347-6350	the	_	_	
40-11	6351-6355	repo	_	_	
40-12	6356-6358	if	_	_	
40-13	6359-6362	you	_	_	
40-14	6363-6366	use	_	_	
40-15	6367-6370	the	_	_	
40-16	6371-6375	data	_	_	
40-17	6376-6378	or	_	_	
40-18	6379-6383	code	_	_	
40-19	6384-6386	in	_	_	
40-20	6387-6391	this	_	_	
40-21	6392-6396	repo	_	_	
40-22	6396-6397	.	_	_	
40-23	6399-6400	`	_	_	
40-24	6400-6401	`	_	_	
40-25	6401-6402	`	_	_	
40-26	6403-6404	@	_	_	
40-27	6404-6408	misc	_	_	
40-28	6408-6409	{	_	_	
40-29	6409-6417	HaluEval	*	DATASET	
40-30	6417-6418	,	_	_	
40-31	6421-6427	author	_	_	
40-32	6428-6429	=	_	_	
40-33	6430-6431	{	_	_	
40-34	6431-6436	Junyi	_	_	
40-35	6437-6439	Li	_	_	
40-36	6440-6443	and	_	_	
40-37	6444-6451	Xiaoxue	_	_	
40-38	6452-6457	Cheng	_	_	
40-39	6458-6461	and	_	_	
40-40	6462-6467	Wayne	_	_	
40-41	6468-6471	Xin	_	_	
40-42	6472-6476	Zhao	_	_	
40-43	6477-6480	and	_	_	
40-44	6481-6489	Jian-Yun	_	_	
40-45	6490-6493	Nie	_	_	
40-46	6494-6497	and	_	_	
40-47	6498-6505	Ji-Rong	_	_	
40-48	6506-6509	Wen	_	_	
40-49	6510-6511	}	_	_	
40-50	6511-6512	,	_	_	
40-51	6515-6520	title	_	_	
40-52	6521-6522	=	_	_	
40-53	6523-6524	{	_	_	
40-54	6524-6532	HaluEval	*[10]|*[11]	PUBLICATION[10]|DATASET[11]	
40-55	6532-6533	:	*[10]	PUBLICATION[10]	
40-56	6534-6535	A	*[10]	PUBLICATION[10]	
40-57	6536-6547	Large-Scale	*[10]	PUBLICATION[10]	
40-58	6548-6561	Hallucination	*[10]	PUBLICATION[10]	
40-59	6562-6572	Evaluation	*[10]	PUBLICATION[10]	
40-60	6573-6582	Benchmark	*[10]	PUBLICATION[10]	
40-61	6583-6586	for	*[10]	PUBLICATION[10]	
40-62	6587-6592	Large	*[10]	PUBLICATION[10]	
40-63	6593-6601	Language	*[10]	PUBLICATION[10]	
40-64	6602-6608	Models	*[10]	PUBLICATION[10]	
40-65	6608-6609	}	_	_	
40-66	6609-6610	,	_	_	
40-67	6613-6617	year	_	_	
40-68	6618-6619	=	_	_	
40-69	6620-6621	{	_	_	
40-70	6621-6625	2023	_	_	
40-71	6625-6626	}	_	_	
40-72	6626-6627	,	_	_	
40-73	6630-6637	journal	_	_	
40-74	6637-6638	=	_	_	
40-75	6638-6639	{	_	_	
40-76	6639-6644	arXiv	_	_	
40-77	6645-6653	preprint	_	_	
40-78	6654-6659	arXiv	_	_	
40-79	6659-6660	:	_	_	
40-80	6660-6670	2305.11747	_	_	
40-81	6670-6671	}	_	_	
40-82	6671-6672	,	_	_	
40-83	6675-6678	url	_	_	
40-84	6678-6679	=	_	_	
40-85	6679-6680	{	_	_	
40-86	6680-6685	https	_	_	
40-87	6685-6686	:	_	_	
40-88	6686-6687	/	_	_	
40-89	6687-6688	/	_	_	
40-90	6688-6697	arxiv.org	_	_	
40-91	6697-6698	/	_	_	
40-92	6698-6701	abs	_	_	
40-93	6701-6702	/	_	_	
40-94	6702-6712	2305.11747	_	_	
40-95	6712-6713	}	_	_	
40-96	6714-6715	}	_	_	
40-97	6716-6717	`	_	_	
40-98	6717-6718	`	_	_	
40-99	6718-6719	`	_	_	
