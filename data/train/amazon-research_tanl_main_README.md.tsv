#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# TANL: Structured Prediction as Translation between Augmented Natural Languages
#Text=
#Text=Code for the paper "[Structured Prediction as Translation between Augmented Natural Languages](http://arxiv.org/abs/2101.05779)" (ICLR 2021) and [fine-tuned multi-task model](#fine-tuned-multi-task-model).
1-1	0-1	#	_	_	
1-2	2-6	TANL	*	PROJECT	
1-3	6-7	:	_	_	
1-4	8-18	Structured	*[1]	PUBLICATION[1]	
1-5	19-29	Prediction	*[1]	PUBLICATION[1]	
1-6	30-32	as	*[1]	PUBLICATION[1]	
1-7	33-44	Translation	*[1]	PUBLICATION[1]	
1-8	45-52	between	*[1]	PUBLICATION[1]	
1-9	53-62	Augmented	*[1]	PUBLICATION[1]	
1-10	63-70	Natural	*[1]	PUBLICATION[1]	
1-11	71-80	Languages	*[1]	PUBLICATION[1]	
1-12	82-86	Code	_	_	
1-13	87-90	for	_	_	
1-14	91-94	the	_	_	
1-15	95-100	paper	_	_	
1-16	101-102	"	_	_	
1-17	102-103	[	_	_	
1-18	103-113	Structured	*[2]	PUBLICATION[2]	
1-19	114-124	Prediction	*[2]	PUBLICATION[2]	
1-20	125-127	as	*[2]	PUBLICATION[2]	
1-21	128-139	Translation	*[2]	PUBLICATION[2]	
1-22	140-147	between	*[2]	PUBLICATION[2]	
1-23	148-157	Augmented	*[2]	PUBLICATION[2]	
1-24	158-165	Natural	*[2]	PUBLICATION[2]	
1-25	166-175	Languages	*[2]	PUBLICATION[2]	
1-26	175-176	]	_	_	
1-27	176-177	(	_	_	
1-28	177-181	http	_	_	
1-29	181-182	:	_	_	
1-30	182-183	/	_	_	
1-31	183-184	/	_	_	
1-32	184-193	arxiv.org	_	_	
1-33	193-194	/	_	_	
1-34	194-197	abs	_	_	
1-35	197-198	/	_	_	
1-36	198-208	2101.05779	_	_	
1-37	208-209	)	_	_	
1-38	209-210	"	_	_	
1-39	211-212	(	_	_	
1-40	212-216	ICLR	*[3]	CONFERENCE[3]	
1-41	217-221	2021	*[3]	CONFERENCE[3]	
1-42	221-222	)	_	_	
1-43	223-226	and	_	_	
1-44	227-228	[	_	_	
1-45	228-238	fine-tuned	_	_	
1-46	239-249	multi-task	_	_	
1-47	250-255	model	_	_	
1-48	255-256	]	_	_	
1-49	256-257	(	_	_	
1-50	257-258	#	_	_	
1-51	258-285	fine-tuned-multi-task-model	_	_	
1-52	285-286	)	_	_	
1-53	286-287	.	_	_	

#Text=If you use this code, please cite the paper using the bibtex reference below.
#Text=```
#Text=@inproceedings{tanl,
#Text=    title={Structured Prediction as Translation between Augmented Natural Languages},
#Text=    author={Giovanni Paolini and Ben Athiwaratkun and Jason Krone and Jie Ma and Alessandro Achille and Rishita Anubhai and Cicero Nogueira dos Santos and Bing Xiang and Stefano Soatto},
#Text=    booktitle={9th International Conference on Learning Representations, {ICLR} 2021},
#Text=    year={2021},
#Text=}
#Text=```
#Text=
#Text=
#Text=## Requirements
#Text=
#Text=- Python 3.6+
#Text=- PyTorch (tested with version 1.7.1)
#Text=- Transformers (tested with version 4.0.0)
#Text=- NetworkX (tested with version 2.5, only used in coreference resolution)
#Text=
#Text=You can install all required Python packages with `pip install -r requirements.txt`
#Text=
#Text=
#Text=## Datasets
#Text=
#Text=By default, datasets are expected to be in `data/DATASET_NAME`.
2-1	289-291	If	_	_	
2-2	292-295	you	_	_	
2-3	296-299	use	_	_	
2-4	300-304	this	_	_	
2-5	305-309	code	_	_	
2-6	309-310	,	_	_	
2-7	311-317	please	_	_	
2-8	318-322	cite	_	_	
2-9	323-326	the	_	_	
2-10	327-332	paper	_	_	
2-11	333-338	using	_	_	
2-12	339-342	the	_	_	
2-13	343-349	bibtex	_	_	
2-14	350-359	reference	_	_	
2-15	360-365	below	_	_	
2-16	365-366	.	_	_	
2-17	367-368	`	_	_	
2-18	368-369	`	_	_	
2-19	369-370	`	_	_	
2-20	371-372	@	_	_	
2-21	372-385	inproceedings	_	_	
2-22	385-386	{	_	_	
2-23	386-390	tanl	*	PROJECT	
2-24	390-391	,	_	_	
2-25	396-401	title	_	_	
2-26	401-402	=	_	_	
2-27	402-403	{	_	_	
2-28	403-413	Structured	*[4]	PUBLICATION[4]	
2-29	414-424	Prediction	*[4]	PUBLICATION[4]	
2-30	425-427	as	*[4]	PUBLICATION[4]	
2-31	428-439	Translation	*[4]	PUBLICATION[4]	
2-32	440-447	between	*[4]	PUBLICATION[4]	
2-33	448-457	Augmented	*[4]	PUBLICATION[4]	
2-34	458-465	Natural	*[4]	PUBLICATION[4]	
2-35	466-475	Languages	*[4]	PUBLICATION[4]	
2-36	475-476	}	_	_	
2-37	476-477	,	_	_	
2-38	482-488	author	_	_	
2-39	488-489	=	_	_	
2-40	489-490	{	_	_	
2-41	490-498	Giovanni	_	_	
2-42	499-506	Paolini	_	_	
2-43	507-510	and	_	_	
2-44	511-514	Ben	_	_	
2-45	515-527	Athiwaratkun	_	_	
2-46	528-531	and	_	_	
2-47	532-537	Jason	_	_	
2-48	538-543	Krone	_	_	
2-49	544-547	and	_	_	
2-50	548-551	Jie	_	_	
2-51	552-554	Ma	_	_	
2-52	555-558	and	_	_	
2-53	559-569	Alessandro	_	_	
2-54	570-577	Achille	_	_	
2-55	578-581	and	_	_	
2-56	582-589	Rishita	_	_	
2-57	590-597	Anubhai	_	_	
2-58	598-601	and	_	_	
2-59	602-608	Cicero	_	_	
2-60	609-617	Nogueira	_	_	
2-61	618-621	dos	_	_	
2-62	622-628	Santos	_	_	
2-63	629-632	and	_	_	
2-64	633-637	Bing	_	_	
2-65	638-643	Xiang	_	_	
2-66	644-647	and	_	_	
2-67	648-655	Stefano	_	_	
2-68	656-662	Soatto	_	_	
2-69	662-663	}	_	_	
2-70	663-664	,	_	_	
2-71	669-678	booktitle	_	_	
2-72	678-679	=	_	_	
2-73	679-680	{	_	_	
2-74	680-683	9th	*[5]	PUBLICATION[5]	
2-75	684-697	International	*[5]|*[6]	PUBLICATION[5]|CONFERENCE[6]	
2-76	698-708	Conference	*[5]|*[6]	PUBLICATION[5]|CONFERENCE[6]	
2-77	709-711	on	*[5]|*[6]	PUBLICATION[5]|CONFERENCE[6]	
2-78	712-720	Learning	*[5]|*[6]	PUBLICATION[5]|CONFERENCE[6]	
2-79	721-736	Representations	*[5]|*[6]	PUBLICATION[5]|CONFERENCE[6]	
2-80	736-737	,	_	_	
2-81	738-739	{	*[7]	CONFERENCE[7]	
2-82	739-743	ICLR	*[7]	CONFERENCE[7]	
2-83	743-744	}	*[7]	CONFERENCE[7]	
2-84	745-749	2021	*[7]	CONFERENCE[7]	
2-85	749-750	}	_	_	
2-86	750-751	,	_	_	
2-87	756-760	year	_	_	
2-88	760-761	=	_	_	
2-89	761-762	{	_	_	
2-90	762-766	2021	_	_	
2-91	766-767	}	_	_	
2-92	767-768	,	_	_	
2-93	769-770	}	_	_	
2-94	771-772	`	_	_	
2-95	772-773	`	_	_	
2-96	773-774	`	_	_	
2-97	777-778	#	_	_	
2-98	778-779	#	_	_	
2-99	780-792	Requirements	_	_	
2-100	794-795	-	_	_	
2-101	796-802	Python	*[8]	SOFTWARE[8]	
2-102	803-806	3.6	*[8]	SOFTWARE[8]	
2-103	806-807	+	*[8]	SOFTWARE[8]	
2-104	808-809	-	_	_	
2-105	810-817	PyTorch	*	SOFTWARE	
2-106	818-819	(	_	_	
2-107	819-825	tested	_	_	
2-108	826-830	with	_	_	
2-109	831-838	version	_	_	
2-110	839-844	1.7.1	_	_	
2-111	844-845	)	_	_	
2-112	846-847	-	_	_	
2-113	848-860	Transformers	*	SOFTWARE	
2-114	861-862	(	_	_	
2-115	862-868	tested	_	_	
2-116	869-873	with	_	_	
2-117	874-881	version	_	_	
2-118	882-887	4.0.0	_	_	
2-119	887-888	)	_	_	
2-120	889-890	-	_	_	
2-121	891-899	NetworkX	*	SOFTWARE	
2-122	900-901	(	_	_	
2-123	901-907	tested	_	_	
2-124	908-912	with	_	_	
2-125	913-920	version	_	_	
2-126	921-924	2.5	_	_	
2-127	924-925	,	_	_	
2-128	926-930	only	_	_	
2-129	931-935	used	_	_	
2-130	936-938	in	_	_	
2-131	939-950	coreference	_	_	
2-132	951-961	resolution	_	_	
2-133	961-962	)	_	_	
2-134	964-967	You	_	_	
2-135	968-971	can	_	_	
2-136	972-979	install	_	_	
2-137	980-983	all	_	_	
2-138	984-992	required	_	_	
2-139	993-999	Python	*	PROGLANG	
2-140	1000-1008	packages	_	_	
2-141	1009-1013	with	_	_	
2-142	1014-1015	`	_	_	
2-143	1015-1018	pip	*	SOFTWARE	
2-144	1019-1026	install	_	_	
2-145	1027-1028	-	_	_	
2-146	1028-1029	r	_	_	
2-147	1030-1046	requirements.txt	_	_	
2-148	1046-1047	`	_	_	
2-149	1050-1051	#	_	_	
2-150	1051-1052	#	_	_	
2-151	1053-1061	Datasets	_	_	
2-152	1063-1065	By	_	_	
2-153	1066-1073	default	_	_	
2-154	1073-1074	,	_	_	
2-155	1075-1083	datasets	_	_	
2-156	1084-1087	are	_	_	
2-157	1088-1096	expected	_	_	
2-158	1097-1099	to	_	_	
2-159	1100-1102	be	_	_	
2-160	1103-1105	in	_	_	
2-161	1106-1107	`	_	_	
2-162	1107-1111	data	_	_	
2-163	1111-1112	/	_	_	
2-164	1112-1124	DATASET_NAME	_	_	
2-165	1124-1125	`	_	_	
2-166	1125-1126	.	_	_	

#Text=Dataset-specific code is in [datasets.py](datasets.py).
3-1	1127-1143	Dataset-specific	_	_	
3-2	1144-1148	code	_	_	
3-3	1149-1151	is	_	_	
3-4	1152-1154	in	_	_	
3-5	1155-1156	[	_	_	
3-6	1156-1167	datasets.py	_	_	
3-7	1167-1168	]	_	_	
3-8	1168-1169	(	_	_	
3-9	1169-1180	datasets.py	_	_	
3-10	1180-1181	)	_	_	
3-11	1181-1182	.	_	_	

#Text=The CoNLL04 and ADE datasets (joint entity and relation extraction) in the correct format can be downloaded using https://github.com/markus-eberts/spert/blob/master/scripts/fetch_datasets.sh.
4-1	1184-1187	The	_	_	
4-2	1188-1195	CoNLL04	*	DATASET	
4-3	1196-1199	and	_	_	
4-4	1200-1203	ADE	*	DATASET	
4-5	1204-1212	datasets	_	_	
4-6	1213-1214	(	_	_	
4-7	1214-1219	joint	_	_	
4-8	1220-1226	entity	_	_	
4-9	1227-1230	and	_	_	
4-10	1231-1239	relation	_	_	
4-11	1240-1250	extraction	_	_	
4-12	1250-1251	)	_	_	
4-13	1252-1254	in	_	_	
4-14	1255-1258	the	_	_	
4-15	1259-1266	correct	_	_	
4-16	1267-1273	format	_	_	
4-17	1274-1277	can	_	_	
4-18	1278-1280	be	_	_	
4-19	1281-1291	downloaded	_	_	
4-20	1292-1297	using	_	_	
4-21	1298-1303	https	_	_	
4-22	1303-1304	:	_	_	
4-23	1304-1305	/	_	_	
4-24	1305-1306	/	_	_	
4-25	1306-1316	github.com	_	_	
4-26	1316-1317	/	_	_	
4-27	1317-1330	markus-eberts	_	_	
4-28	1330-1331	/	_	_	
4-29	1331-1336	spert	_	_	
4-30	1336-1337	/	_	_	
4-31	1337-1341	blob	_	_	
4-32	1341-1342	/	_	_	
4-33	1342-1348	master	_	_	
4-34	1348-1349	/	_	_	
4-35	1349-1356	scripts	_	_	
4-36	1356-1357	/	_	_	
4-37	1357-1374	fetch_datasets.sh	_	_	
4-38	1374-1375	.	_	_	

#Text=For other datasets, we provide sample processing code which does not necessarily match the format of publicly available versions (we do not plan to adapt the code to load datasets in other formats).
#Text=
#Text=
#Text=
#Text=## Running the code
#Text=
#Text=Use the following command:
#Text=`python run.py JOB`
#Text=
#Text=The `JOB` argument refers to a section of the config file, which by default is `config.ini`.
5-1	1376-1379	For	_	_	
5-2	1380-1385	other	_	_	
5-3	1386-1394	datasets	_	_	
5-4	1394-1395	,	_	_	
5-5	1396-1398	we	_	_	
5-6	1399-1406	provide	_	_	
5-7	1407-1413	sample	_	_	
5-8	1414-1424	processing	_	_	
5-9	1425-1429	code	_	_	
5-10	1430-1435	which	_	_	
5-11	1436-1440	does	_	_	
5-12	1441-1444	not	_	_	
5-13	1445-1456	necessarily	_	_	
5-14	1457-1462	match	_	_	
5-15	1463-1466	the	_	_	
5-16	1467-1473	format	_	_	
5-17	1474-1476	of	_	_	
5-18	1477-1485	publicly	_	_	
5-19	1486-1495	available	_	_	
5-20	1496-1504	versions	_	_	
5-21	1505-1506	(	_	_	
5-22	1506-1508	we	_	_	
5-23	1509-1511	do	_	_	
5-24	1512-1515	not	_	_	
5-25	1516-1520	plan	_	_	
5-26	1521-1523	to	_	_	
5-27	1524-1529	adapt	_	_	
5-28	1530-1533	the	_	_	
5-29	1534-1538	code	_	_	
5-30	1539-1541	to	_	_	
5-31	1542-1546	load	_	_	
5-32	1547-1555	datasets	_	_	
5-33	1556-1558	in	_	_	
5-34	1559-1564	other	_	_	
5-35	1565-1572	formats	_	_	
5-36	1572-1573	)	_	_	
5-37	1573-1574	.	_	_	
5-38	1578-1579	#	_	_	
5-39	1579-1580	#	_	_	
5-40	1581-1588	Running	_	_	
5-41	1589-1592	the	_	_	
5-42	1593-1597	code	_	_	
5-43	1599-1602	Use	_	_	
5-44	1603-1606	the	_	_	
5-45	1607-1616	following	_	_	
5-46	1617-1624	command	_	_	
5-47	1624-1625	:	_	_	
5-48	1626-1627	`	_	_	
5-49	1627-1633	python	_	_	
5-50	1634-1640	run.py	_	_	
5-51	1641-1644	JOB	_	_	
5-52	1644-1645	`	_	_	
5-53	1647-1650	The	_	_	
5-54	1651-1652	`	_	_	
5-55	1652-1655	JOB	_	_	
5-56	1655-1656	`	_	_	
5-57	1657-1665	argument	_	_	
5-58	1666-1672	refers	_	_	
5-59	1673-1675	to	_	_	
5-60	1676-1677	a	_	_	
5-61	1678-1685	section	_	_	
5-62	1686-1688	of	_	_	
5-63	1689-1692	the	_	_	
5-64	1693-1699	config	_	_	
5-65	1700-1704	file	_	_	
5-66	1704-1705	,	_	_	
5-67	1706-1711	which	_	_	
5-68	1712-1714	by	_	_	
5-69	1715-1722	default	_	_	
5-70	1723-1725	is	_	_	
5-71	1726-1727	`	_	_	
5-72	1727-1737	config.ini	_	_	
5-73	1737-1738	`	_	_	
5-74	1738-1739	.	_	_	

#Text=A [sample config file](config.ini) is provided, with settings that allow for a faster training and less memory usage than the settings used to obtain the final results in the paper.
6-1	1740-1741	A	_	_	
6-2	1742-1743	[	_	_	
6-3	1743-1749	sample	_	_	
6-4	1750-1756	config	_	_	
6-5	1757-1761	file	_	_	
6-6	1761-1762	]	_	_	
6-7	1762-1763	(	_	_	
6-8	1763-1773	config.ini	_	_	
6-9	1773-1774	)	_	_	
6-10	1775-1777	is	_	_	
6-11	1778-1786	provided	_	_	
6-12	1786-1787	,	_	_	
6-13	1788-1792	with	_	_	
6-14	1793-1801	settings	_	_	
6-15	1802-1806	that	_	_	
6-16	1807-1812	allow	_	_	
6-17	1813-1816	for	_	_	
6-18	1817-1818	a	_	_	
6-19	1819-1825	faster	_	_	
6-20	1826-1834	training	_	_	
6-21	1835-1838	and	_	_	
6-22	1839-1843	less	_	_	
6-23	1844-1850	memory	_	_	
6-24	1851-1856	usage	_	_	
6-25	1857-1861	than	_	_	
6-26	1862-1865	the	_	_	
6-27	1866-1874	settings	_	_	
6-28	1875-1879	used	_	_	
6-29	1880-1882	to	_	_	
6-30	1883-1889	obtain	_	_	
6-31	1890-1893	the	_	_	
6-32	1894-1899	final	_	_	
6-33	1900-1907	results	_	_	
6-34	1908-1910	in	_	_	
6-35	1911-1914	the	_	_	
6-36	1915-1920	paper	_	_	
6-37	1920-1921	.	_	_	

#Text=For example, to replicate the paper's results on CoNLL04, have the following section in the config file:
#Text=```
#Text=[conll04_final]
#Text=datasets = conll04
#Text=model_name_or_path = t5-base
#Text=num_train_epochs = 200
#Text=max_seq_length = 256
#Text=max_seq_length_eval = 512
#Text=train_split = train,dev
#Text=per_device_train_batch_size = 8
#Text=per_device_eval_batch_size = 16
#Text=do_train = True
#Text=do_eval = False
#Text=do_predict = True
#Text=episodes = 1-10
#Text=num_beams = 8
#Text=```
#Text=Then run `python run.py conll04_final`.
7-1	1923-1926	For	_	_	
7-2	1927-1934	example	_	_	
7-3	1934-1935	,	_	_	
7-4	1936-1938	to	_	_	
7-5	1939-1948	replicate	_	_	
7-6	1949-1952	the	_	_	
7-7	1953-1960	paper's	_	_	
7-8	1961-1968	results	_	_	
7-9	1969-1971	on	_	_	
7-10	1972-1979	CoNLL04	*	DATASET	
7-11	1979-1980	,	_	_	
7-12	1981-1985	have	_	_	
7-13	1986-1989	the	_	_	
7-14	1990-1999	following	_	_	
7-15	2000-2007	section	_	_	
7-16	2008-2010	in	_	_	
7-17	2011-2014	the	_	_	
7-18	2015-2021	config	_	_	
7-19	2022-2026	file	_	_	
7-20	2026-2027	:	_	_	
7-21	2028-2029	`	_	_	
7-22	2029-2030	`	_	_	
7-23	2030-2031	`	_	_	
7-24	2032-2033	[	_	_	
7-25	2033-2040	conll04	*	DATASET	
7-26	2040-2041	_	_	_	
7-27	2041-2046	final	_	_	
7-28	2046-2047	]	_	_	
7-29	2048-2056	datasets	_	_	
7-30	2057-2058	=	_	_	
7-31	2059-2066	conll04	*	DATASET	
7-32	2067-2085	model_name_or_path	_	_	
7-33	2086-2087	=	_	_	
7-34	2088-2090	t5	_	_	
7-35	2090-2091	-	_	_	
7-36	2091-2095	base	_	_	
7-37	2096-2112	num_train_epochs	_	_	
7-38	2113-2114	=	_	_	
7-39	2115-2118	200	_	_	
7-40	2119-2133	max_seq_length	_	_	
7-41	2134-2135	=	_	_	
7-42	2136-2139	256	_	_	
7-43	2140-2159	max_seq_length_eval	_	_	
7-44	2160-2161	=	_	_	
7-45	2162-2165	512	_	_	
7-46	2166-2177	train_split	_	_	
7-47	2178-2179	=	_	_	
7-48	2180-2185	train	_	_	
7-49	2185-2186	,	_	_	
7-50	2186-2189	dev	_	_	
7-51	2190-2217	per_device_train_batch_size	_	_	
7-52	2218-2219	=	_	_	
7-53	2220-2221	8	_	_	
7-54	2222-2248	per_device_eval_batch_size	_	_	
7-55	2249-2250	=	_	_	
7-56	2251-2253	16	_	_	
7-57	2254-2262	do_train	_	_	
7-58	2263-2264	=	_	_	
7-59	2265-2269	True	_	_	
7-60	2270-2277	do_eval	_	_	
7-61	2278-2279	=	_	_	
7-62	2280-2285	False	_	_	
7-63	2286-2296	do_predict	_	_	
7-64	2297-2298	=	_	_	
7-65	2299-2303	True	_	_	
7-66	2304-2312	episodes	_	_	
7-67	2313-2314	=	_	_	
7-68	2315-2316	1	_	_	
7-69	2316-2317	-	_	_	
7-70	2317-2319	10	_	_	
7-71	2320-2329	num_beams	_	_	
7-72	2330-2331	=	_	_	
7-73	2332-2333	8	_	_	
7-74	2334-2335	`	_	_	
7-75	2335-2336	`	_	_	
7-76	2336-2337	`	_	_	
7-77	2338-2342	Then	_	_	
7-78	2343-2346	run	_	_	
7-79	2347-2348	`	_	_	
7-80	2348-2354	python	_	_	
7-81	2355-2361	run.py	_	_	
7-82	2362-2369	conll04	*	DATASET	
7-83	2369-2370	_	_	_	
7-84	2370-2375	final	_	_	
7-85	2375-2376	`	_	_	
7-86	2376-2377	.	_	_	

#Text=Note that the final results will differ slightly from the ones reported in the paper, due to small code changes and randomness.
8-1	2378-2382	Note	_	_	
8-2	2383-2387	that	_	_	
8-3	2388-2391	the	_	_	
8-4	2392-2397	final	_	_	
8-5	2398-2405	results	_	_	
8-6	2406-2410	will	_	_	
8-7	2411-2417	differ	_	_	
8-8	2418-2426	slightly	_	_	
8-9	2427-2431	from	_	_	
8-10	2432-2435	the	_	_	
8-11	2436-2440	ones	_	_	
8-12	2441-2449	reported	_	_	
8-13	2450-2452	in	_	_	
8-14	2453-2456	the	_	_	
8-15	2457-2462	paper	_	_	
8-16	2462-2463	,	_	_	
8-17	2464-2467	due	_	_	
8-18	2468-2470	to	_	_	
8-19	2471-2476	small	_	_	
8-20	2477-2481	code	_	_	
8-21	2482-2489	changes	_	_	
8-22	2490-2493	and	_	_	
8-23	2494-2504	randomness	_	_	
8-24	2504-2505	.	_	_	

#Text=Config arguments can be overwritten by command line arguments.
9-1	2507-2513	Config	_	_	
9-2	2514-2523	arguments	_	_	
9-3	2524-2527	can	_	_	
9-4	2528-2530	be	_	_	
9-5	2531-2542	overwritten	_	_	
9-6	2543-2545	by	_	_	
9-7	2546-2553	command	_	_	
9-8	2554-2558	line	_	_	
9-9	2559-2568	arguments	_	_	
9-10	2568-2569	.	_	_	

#Text=For example: `python run.py conll04_final --num_train_epochs 50`.
#Text=
#Text=
#Text=### Additional details
#Text=
#Text=If `do_train = True`, the model is trained on the given train split (e.g., `'train'`) of the given datasets.
10-1	2570-2573	For	_	_	
10-2	2574-2581	example	_	_	
10-3	2581-2582	:	_	_	
10-4	2583-2584	`	_	_	
10-5	2584-2590	python	_	_	
10-6	2591-2597	run.py	_	_	
10-7	2598-2605	conll04	_	_	
10-8	2605-2606	_	_	_	
10-9	2606-2611	final	_	_	
10-10	2612-2613	-	_	_	
10-11	2613-2614	-	_	_	
10-12	2614-2630	num_train_epochs	_	_	
10-13	2631-2633	50	_	_	
10-14	2633-2634	`	_	_	
10-15	2634-2635	.	_	_	
10-16	2638-2639	#	_	_	
10-17	2639-2640	#	_	_	
10-18	2640-2641	#	_	_	
10-19	2642-2652	Additional	_	_	
10-20	2653-2660	details	_	_	
10-21	2662-2664	If	_	_	
10-22	2665-2666	`	_	_	
10-23	2666-2674	do_train	_	_	
10-24	2675-2676	=	_	_	
10-25	2677-2681	True	_	_	
10-26	2681-2682	`	_	_	
10-27	2682-2683	,	_	_	
10-28	2684-2687	the	_	_	
10-29	2688-2693	model	_	_	
10-30	2694-2696	is	_	_	
10-31	2697-2704	trained	_	_	
10-32	2705-2707	on	_	_	
10-33	2708-2711	the	_	_	
10-34	2712-2717	given	_	_	
10-35	2718-2723	train	_	_	
10-36	2724-2729	split	_	_	
10-37	2730-2731	(	_	_	
10-38	2731-2734	e.g	_	_	
10-39	2734-2735	.	_	_	
10-40	2735-2736	,	_	_	
10-41	2737-2738	`	_	_	
10-42	2738-2739	'	_	_	
10-43	2739-2744	train	_	_	
10-44	2744-2745	'	_	_	
10-45	2745-2746	`	_	_	
10-46	2746-2747	)	_	_	
10-47	2748-2750	of	_	_	
10-48	2751-2754	the	_	_	
10-49	2755-2760	given	_	_	
10-50	2761-2769	datasets	_	_	
10-51	2769-2770	.	_	_	

#Text=The final weights and intermediate checkpoints are written in a directory such as `experiments/conll04_final-t5-base-ep200-len256-b8-train`, with one subdirectory per episode.
11-1	2771-2774	The	_	_	
11-2	2775-2780	final	_	_	
11-3	2781-2788	weights	_	_	
11-4	2789-2792	and	_	_	
11-5	2793-2805	intermediate	_	_	
11-6	2806-2817	checkpoints	_	_	
11-7	2818-2821	are	_	_	
11-8	2822-2829	written	_	_	
11-9	2830-2832	in	_	_	
11-10	2833-2834	a	_	_	
11-11	2835-2844	directory	_	_	
11-12	2845-2849	such	_	_	
11-13	2850-2852	as	_	_	
11-14	2853-2854	`	_	_	
11-15	2854-2865	experiments	_	_	
11-16	2865-2866	/	_	_	
11-17	2866-2873	conll04	*	DATASET	
11-18	2873-2874	_	_	_	
11-19	2874-2882	final-t5	_	_	
11-19.1	2880-2882	t5	*[9]	SOFTWARE[9]	
11-20	2882-2883	-	*[9]	SOFTWARE[9]	
11-21	2883-2893	base-ep200	_	_	
11-21.1	2883-2887	base	*[9]	SOFTWARE[9]	
11-22	2893-2894	-	_	_	
11-23	2894-2900	len256	_	_	
11-24	2900-2901	-	_	_	
11-25	2901-2903	b8	_	_	
11-26	2903-2904	-	_	_	
11-27	2904-2909	train	_	_	
11-28	2909-2910	`	_	_	
11-29	2910-2911	,	_	_	
11-30	2912-2916	with	_	_	
11-31	2917-2920	one	_	_	
11-32	2921-2933	subdirectory	_	_	
11-33	2934-2937	per	_	_	
11-34	2938-2945	episode	_	_	
11-35	2945-2946	.	_	_	

#Text=Results in JSON format are also going to be saved there.
12-1	2947-2954	Results	_	_	
12-2	2955-2957	in	_	_	
12-3	2958-2962	JSON	_	_	
12-4	2963-2969	format	_	_	
12-5	2970-2973	are	_	_	
12-6	2974-2978	also	_	_	
12-7	2979-2984	going	_	_	
12-8	2985-2987	to	_	_	
12-9	2988-2990	be	_	_	
12-10	2991-2996	saved	_	_	
12-11	2997-3002	there	_	_	
12-12	3002-3003	.	_	_	

#Text=In every episode, the model is trained on a different (random) permutation of the training set.
13-1	3005-3007	In	_	_	
13-2	3008-3013	every	_	_	
13-3	3014-3021	episode	_	_	
13-4	3021-3022	,	_	_	
13-5	3023-3026	the	_	_	
13-6	3027-3032	model	_	_	
13-7	3033-3035	is	_	_	
13-8	3036-3043	trained	_	_	
13-9	3044-3046	on	_	_	
13-10	3047-3048	a	_	_	
13-11	3049-3058	different	_	_	
13-12	3059-3060	(	_	_	
13-13	3060-3066	random	_	_	
13-14	3066-3067	)	_	_	
13-15	3068-3079	permutation	_	_	
13-16	3080-3082	of	_	_	
13-17	3083-3086	the	_	_	
13-18	3087-3095	training	_	_	
13-19	3096-3099	set	_	_	
13-20	3099-3100	.	_	_	

#Text=The random seed is given by the episode number, so that every episode always produces the same exact model.
14-1	3101-3104	The	_	_	
14-2	3105-3111	random	_	_	
14-3	3112-3116	seed	_	_	
14-4	3117-3119	is	_	_	
14-5	3120-3125	given	_	_	
14-6	3126-3128	by	_	_	
14-7	3129-3132	the	_	_	
14-8	3133-3140	episode	_	_	
14-9	3141-3147	number	_	_	
14-10	3147-3148	,	_	_	
14-11	3149-3151	so	_	_	
14-12	3152-3156	that	_	_	
14-13	3157-3162	every	_	_	
14-14	3163-3170	episode	_	_	
14-15	3171-3177	always	_	_	
14-16	3178-3186	produces	_	_	
14-17	3187-3190	the	_	_	
14-18	3191-3195	same	_	_	
14-19	3196-3201	exact	_	_	
14-20	3202-3207	model	_	_	
14-21	3207-3208	.	_	_	

#Text=Once a model is trained, it is possible to evaluate it without training again.
15-1	3210-3214	Once	_	_	
15-2	3215-3216	a	_	_	
15-3	3217-3222	model	_	_	
15-4	3223-3225	is	_	_	
15-5	3226-3233	trained	_	_	
15-6	3233-3234	,	_	_	
15-7	3235-3237	it	_	_	
15-8	3238-3240	is	_	_	
15-9	3241-3249	possible	_	_	
15-10	3250-3252	to	_	_	
15-11	3253-3261	evaluate	_	_	
15-12	3262-3264	it	_	_	
15-13	3265-3272	without	_	_	
15-14	3273-3281	training	_	_	
15-15	3282-3287	again	_	_	
15-16	3287-3288	.	_	_	

#Text=For this, set `do_train = False` or (more easily) provide the `-e` command-line argument: `python run.py conll04_final -e`.
16-1	3289-3292	For	_	_	
16-2	3293-3297	this	_	_	
16-3	3297-3298	,	_	_	
16-4	3299-3302	set	_	_	
16-5	3303-3304	`	_	_	
16-6	3304-3312	do_train	_	_	
16-7	3313-3314	=	_	_	
16-8	3315-3320	False	_	_	
16-9	3320-3321	`	_	_	
16-10	3322-3324	or	_	_	
16-11	3325-3326	(	_	_	
16-12	3326-3330	more	_	_	
16-13	3331-3337	easily	_	_	
16-14	3337-3338	)	_	_	
16-15	3339-3346	provide	_	_	
16-16	3347-3350	the	_	_	
16-17	3351-3352	`	_	_	
16-18	3352-3353	-	_	_	
16-19	3353-3354	e	_	_	
16-20	3354-3355	`	_	_	
16-21	3356-3368	command-line	_	_	
16-22	3369-3377	argument	_	_	
16-23	3377-3378	:	_	_	
16-24	3379-3380	`	_	_	
16-25	3380-3386	python	_	_	
16-26	3387-3393	run.py	_	_	
16-27	3394-3401	conll04	*	DATASET	
16-28	3401-3402	_	_	_	
16-29	3402-3407	final	_	_	
16-30	3408-3409	-	_	_	
16-31	3409-3410	e	_	_	
16-32	3410-3411	`	_	_	
16-33	3411-3412	.	_	_	

#Text=If `do_eval = True`, the model is evaluated on the `'dev'` split.
17-1	3414-3416	If	_	_	
17-2	3417-3418	`	_	_	
17-3	3418-3425	do_eval	_	_	
17-4	3426-3427	=	_	_	
17-5	3428-3432	True	_	_	
17-6	3432-3433	`	_	_	
17-7	3433-3434	,	_	_	
17-8	3435-3438	the	_	_	
17-9	3439-3444	model	_	_	
17-10	3445-3447	is	_	_	
17-11	3448-3457	evaluated	_	_	
17-12	3458-3460	on	_	_	
17-13	3461-3464	the	_	_	
17-14	3465-3466	`	_	_	
17-15	3466-3467	'	_	_	
17-16	3467-3470	dev	_	_	
17-17	3470-3471	'	_	_	
17-18	3471-3472	`	_	_	
17-19	3473-3478	split	_	_	
17-20	3478-3479	.	_	_	

#Text=If `do_predict = True`, the model is evaluated on the `'test'` split.
#Text=
#Text=
#Text=### Arguments
#Text=
#Text=The following are the most important command-line arguments for the `run.py` script.
18-1	3480-3482	If	_	_	
18-2	3483-3484	`	_	_	
18-3	3484-3494	do_predict	_	_	
18-4	3495-3496	=	_	_	
18-5	3497-3501	True	_	_	
18-6	3501-3502	`	_	_	
18-7	3502-3503	,	_	_	
18-8	3504-3507	the	_	_	
18-9	3508-3513	model	_	_	
18-10	3514-3516	is	_	_	
18-11	3517-3526	evaluated	_	_	
18-12	3527-3529	on	_	_	
18-13	3530-3533	the	_	_	
18-14	3534-3535	`	_	_	
18-15	3535-3536	'	_	_	
18-16	3536-3540	test	_	_	
18-17	3540-3541	'	_	_	
18-18	3541-3542	`	_	_	
18-19	3543-3548	split	_	_	
18-20	3548-3549	.	_	_	
18-21	3552-3553	#	_	_	
18-22	3553-3554	#	_	_	
18-23	3554-3555	#	_	_	
18-24	3556-3565	Arguments	_	_	
18-25	3567-3570	The	_	_	
18-26	3571-3580	following	_	_	
18-27	3581-3584	are	_	_	
18-28	3585-3588	the	_	_	
18-29	3589-3593	most	_	_	
18-30	3594-3603	important	_	_	
18-31	3604-3616	command-line	_	_	
18-32	3617-3626	arguments	_	_	
18-33	3627-3630	for	_	_	
18-34	3631-3634	the	_	_	
18-35	3635-3636	`	_	_	
18-36	3636-3642	run.py	_	_	
18-37	3642-3643	`	_	_	
18-38	3644-3650	script	_	_	
18-39	3650-3651	.	_	_	

#Text=Run `python run.py -h` for the full list
19-1	3652-3655	Run	_	_	
19-2	3656-3657	`	_	_	
19-3	3657-3663	python	_	_	
19-4	3664-3670	run.py	_	_	
19-5	3671-3672	-	_	_	
19-6	3672-3673	h	_	_	
19-7	3673-3674	`	_	_	
19-8	3675-3678	for	_	_	
19-9	3679-3682	the	_	_	
19-10	3683-3687	full	_	_	
19-11	3688-3692	list	_	_	

#Text=.
20-1	3692-3693	.	_	_	

#Text=- `-c CONFIG_FILE`: specify config file to use (default is `config.ini`)
#Text=- `-e`: only run evaluation (overwrites the setting `do_train` in the config file)
#Text=- `-a`: evaluate also intermediate checkpoints, in addition to the final model
#Text=- `-v` : print results for each evaluation run
#Text=- `-g GPU`: specify which GPU to use for evaluation
#Text=
#Text=The following are the most important arguments for the config file.
21-1	3695-3696	-	_	_	
21-2	3697-3698	`	_	_	
21-3	3698-3699	-	_	_	
21-4	3699-3700	c	_	_	
21-5	3701-3712	CONFIG_FILE	_	_	
21-6	3712-3713	`	_	_	
21-7	3713-3714	:	_	_	
21-8	3715-3722	specify	_	_	
21-9	3723-3729	config	_	_	
21-10	3730-3734	file	_	_	
21-11	3735-3737	to	_	_	
21-12	3738-3741	use	_	_	
21-13	3742-3743	(	_	_	
21-14	3743-3750	default	_	_	
21-15	3751-3753	is	_	_	
21-16	3754-3755	`	_	_	
21-17	3755-3765	config.ini	_	_	
21-18	3765-3766	`	_	_	
21-19	3766-3767	)	_	_	
21-20	3768-3769	-	_	_	
21-21	3770-3771	`	_	_	
21-22	3771-3772	-	_	_	
21-23	3772-3773	e	_	_	
21-24	3773-3774	`	_	_	
21-25	3774-3775	:	_	_	
21-26	3776-3780	only	_	_	
21-27	3781-3784	run	_	_	
21-28	3785-3795	evaluation	_	_	
21-29	3796-3797	(	_	_	
21-30	3797-3807	overwrites	_	_	
21-31	3808-3811	the	_	_	
21-32	3812-3819	setting	_	_	
21-33	3820-3821	`	_	_	
21-34	3821-3829	do_train	_	_	
21-35	3829-3830	`	_	_	
21-36	3831-3833	in	_	_	
21-37	3834-3837	the	_	_	
21-38	3838-3844	config	_	_	
21-39	3845-3849	file	_	_	
21-40	3849-3850	)	_	_	
21-41	3851-3852	-	_	_	
21-42	3853-3854	`	_	_	
21-43	3854-3855	-	_	_	
21-44	3855-3856	a	_	_	
21-45	3856-3857	`	_	_	
21-46	3857-3858	:	_	_	
21-47	3859-3867	evaluate	_	_	
21-48	3868-3872	also	_	_	
21-49	3873-3885	intermediate	_	_	
21-50	3886-3897	checkpoints	_	_	
21-51	3897-3898	,	_	_	
21-52	3899-3901	in	_	_	
21-53	3902-3910	addition	_	_	
21-54	3911-3913	to	_	_	
21-55	3914-3917	the	_	_	
21-56	3918-3923	final	_	_	
21-57	3924-3929	model	_	_	
21-58	3930-3931	-	_	_	
21-59	3932-3933	`	_	_	
21-60	3933-3934	-	_	_	
21-61	3934-3935	v	_	_	
21-62	3935-3936	`	_	_	
21-63	3937-3938	:	_	_	
21-64	3939-3944	print	_	_	
21-65	3945-3952	results	_	_	
21-66	3953-3956	for	_	_	
21-67	3957-3961	each	_	_	
21-68	3962-3972	evaluation	_	_	
21-69	3973-3976	run	_	_	
21-70	3977-3978	-	_	_	
21-71	3979-3980	`	_	_	
21-72	3980-3981	-	_	_	
21-73	3981-3982	g	_	_	
21-74	3983-3986	GPU	_	_	
21-75	3986-3987	`	_	_	
21-76	3987-3988	:	_	_	
21-77	3989-3996	specify	_	_	
21-78	3997-4002	which	_	_	
21-79	4003-4006	GPU	_	_	
21-80	4007-4009	to	_	_	
21-81	4010-4013	use	_	_	
21-82	4014-4017	for	_	_	
21-83	4018-4028	evaluation	_	_	
21-84	4030-4033	The	_	_	
21-85	4034-4043	following	_	_	
21-86	4044-4047	are	_	_	
21-87	4048-4051	the	_	_	
21-88	4052-4056	most	_	_	
21-89	4057-4066	important	_	_	
21-90	4067-4076	arguments	_	_	
21-91	4077-4080	for	_	_	
21-92	4081-4084	the	_	_	
21-93	4085-4091	config	_	_	
21-94	4092-4096	file	_	_	
21-95	4096-4097	.	_	_	

#Text=See the [sample config file](config.ini) to understand the format
22-1	4099-4102	See	_	_	
22-2	4103-4106	the	_	_	
22-3	4107-4108	[	_	_	
22-4	4108-4114	sample	_	_	
22-5	4115-4121	config	_	_	
22-6	4122-4126	file	_	_	
22-7	4126-4127	]	_	_	
22-8	4127-4128	(	_	_	
22-9	4128-4138	config.ini	_	_	
22-10	4138-4139	)	_	_	
22-11	4140-4142	to	_	_	
22-12	4143-4153	understand	_	_	
22-13	4154-4157	the	_	_	
22-14	4158-4164	format	_	_	

#Text=.
23-1	4164-4165	.	_	_	

#Text=- `datasets` (str): comma-separated list of datasets for training
#Text=- `eval_datasets` (str): comma-separated list of datasets for evaluation (default is the same as for training)
#Text=- `model_name_or_path` (str): path to pretrained model or model identifier from [huggingface.co/models](https://huggingface.co/models) (e.g.
24-1	4167-4168	-	_	_	
24-2	4169-4170	`	_	_	
24-3	4170-4178	datasets	_	_	
24-4	4178-4179	`	_	_	
24-5	4180-4181	(	_	_	
24-6	4181-4184	str	_	_	
24-7	4184-4185	)	_	_	
24-8	4185-4186	:	_	_	
24-9	4187-4202	comma-separated	_	_	
24-10	4203-4207	list	_	_	
24-11	4208-4210	of	_	_	
24-12	4211-4219	datasets	_	_	
24-13	4220-4223	for	_	_	
24-14	4224-4232	training	_	_	
24-15	4233-4234	-	_	_	
24-16	4235-4236	`	_	_	
24-17	4236-4249	eval_datasets	_	_	
24-18	4249-4250	`	_	_	
24-19	4251-4252	(	_	_	
24-20	4252-4255	str	_	_	
24-21	4255-4256	)	_	_	
24-22	4256-4257	:	_	_	
24-23	4258-4273	comma-separated	_	_	
24-24	4274-4278	list	_	_	
24-25	4279-4281	of	_	_	
24-26	4282-4290	datasets	_	_	
24-27	4291-4294	for	_	_	
24-28	4295-4305	evaluation	_	_	
24-29	4306-4307	(	_	_	
24-30	4307-4314	default	_	_	
24-31	4315-4317	is	_	_	
24-32	4318-4321	the	_	_	
24-33	4322-4326	same	_	_	
24-34	4327-4329	as	_	_	
24-35	4330-4333	for	_	_	
24-36	4334-4342	training	_	_	
24-37	4342-4343	)	_	_	
24-38	4344-4345	-	_	_	
24-39	4346-4347	`	_	_	
24-40	4347-4365	model_name_or_path	_	_	
24-41	4365-4366	`	_	_	
24-42	4367-4368	(	_	_	
24-43	4368-4371	str	_	_	
24-44	4371-4372	)	_	_	
24-45	4372-4373	:	_	_	
24-46	4374-4378	path	_	_	
24-47	4379-4381	to	_	_	
24-48	4382-4392	pretrained	_	_	
24-49	4393-4398	model	_	_	
24-50	4399-4401	or	_	_	
24-51	4402-4407	model	_	_	
24-52	4408-4418	identifier	_	_	
24-53	4419-4423	from	_	_	
24-54	4424-4425	[	_	_	
24-55	4425-4439	huggingface.co	_	_	
24-56	4439-4440	/	_	_	
24-57	4440-4446	models	_	_	
24-58	4446-4447	]	_	_	
24-59	4447-4448	(	_	_	
24-60	4448-4453	https	_	_	
24-61	4453-4454	:	_	_	
24-62	4454-4455	/	_	_	
24-63	4455-4456	/	_	_	
24-64	4456-4470	huggingface.co	_	_	
24-65	4470-4471	/	_	_	
24-66	4471-4477	models	_	_	
24-67	4477-4478	)	_	_	
24-68	4479-4480	(	_	_	
24-69	4480-4483	e.g	_	_	
24-70	4483-4484	.	_	_	

#Text=`t5-base`)
#Text=- `do_train` (bool): whether to run training (default is False)
#Text=- `do_eval` (bool): whether to run evaluation on the `dev` set (default is False)
#Text=- `do_predict` (bool): whether to run evaluation on the `test` set (default is False)
#Text=- `train_split` (str): comma-separated list of data splits for training (default is `train`)
#Text=- `num_train_epochs` (int): number of train epochs
#Text=- `learning_rate` (float): initial learning rate (default is 5e-4)
#Text=- `train_subset` (float > 0 and <=1): portion of training data to effectively use during training (default is 1, i.e., use all training data)
#Text=- `per_device_train_batch_size` (int): batch size per GPU during training (default is 8)
#Text=- `per_device_eval_batch_size` (int): batch size during evaluation (default is 8; only one GPU is used for evaluation)
#Text=- `max_seq_length` (int): maximum input sequence length after tokenization; longer sequences are truncated
#Text=- `max_output_seq_length` (int): maximum output sequence length (default is `max_seq_length`)
#Text=- `max_seq_length_eval` (int): maximum input sequence length for evaluation (default is `max_seq_length`)
#Text=- `max_output_seq_length_eval` (int): maximum output sequence length for evaluation (default is `max_output_seq_length` or `max_seq_length_eval` or `max_seq_length`)
#Text=- `episodes` (str): episodes to run (default is `0`; an interval can be specified, such as `1-4`; the episode number is used as the random seed)
#Text=- `num_beams` (int): number of beams for beam search during generation (default is 1)
#Text=- `multitask` (bool): if True, the name of the dataset is prepended to each input sentence (default is False)
#Text=
#Text=See [arguments.py](arguments.py) and [transformers.TrainingArguments](https://github.com/huggingface/transformers/blob/master/src/transformers/training_args.py) for additional config arguments.
#Text=
#Text=
#Text=## Fine-tuned multi-task model
#Text=
#Text=The weights of our multi-task model (released under the [CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/)) can be downloaded here: https://tanl.s3.amazonaws.com/tanl-multitask.zip
#Text=
#Text=Extract the zip file in the `experiments/` directory.
25-1	4485-4486	`	_	_	
25-2	4486-4488	t5	*[10]	SOFTWARE[10]	
25-3	4488-4489	-	*[10]	SOFTWARE[10]	
25-4	4489-4493	base	*[10]	SOFTWARE[10]	
25-5	4493-4494	`	_	_	
25-6	4494-4495	)	_	_	
25-7	4496-4497	-	_	_	
25-8	4498-4499	`	_	_	
25-9	4499-4507	do_train	_	_	
25-10	4507-4508	`	_	_	
25-11	4509-4510	(	_	_	
25-12	4510-4514	bool	_	_	
25-13	4514-4515	)	_	_	
25-14	4515-4516	:	_	_	
25-15	4517-4524	whether	_	_	
25-16	4525-4527	to	_	_	
25-17	4528-4531	run	_	_	
25-18	4532-4540	training	_	_	
25-19	4541-4542	(	_	_	
25-20	4542-4549	default	_	_	
25-21	4550-4552	is	_	_	
25-22	4553-4558	False	_	_	
25-23	4558-4559	)	_	_	
25-24	4560-4561	-	_	_	
25-25	4562-4563	`	_	_	
25-26	4563-4570	do_eval	_	_	
25-27	4570-4571	`	_	_	
25-28	4572-4573	(	_	_	
25-29	4573-4577	bool	_	_	
25-30	4577-4578	)	_	_	
25-31	4578-4579	:	_	_	
25-32	4580-4587	whether	_	_	
25-33	4588-4590	to	_	_	
25-34	4591-4594	run	_	_	
25-35	4595-4605	evaluation	_	_	
25-36	4606-4608	on	_	_	
25-37	4609-4612	the	_	_	
25-38	4613-4614	`	_	_	
25-39	4614-4617	dev	_	_	
25-40	4617-4618	`	_	_	
25-41	4619-4622	set	_	_	
25-42	4623-4624	(	_	_	
25-43	4624-4631	default	_	_	
25-44	4632-4634	is	_	_	
25-45	4635-4640	False	_	_	
25-46	4640-4641	)	_	_	
25-47	4642-4643	-	_	_	
25-48	4644-4645	`	_	_	
25-49	4645-4655	do_predict	_	_	
25-50	4655-4656	`	_	_	
25-51	4657-4658	(	_	_	
25-52	4658-4662	bool	_	_	
25-53	4662-4663	)	_	_	
25-54	4663-4664	:	_	_	
25-55	4665-4672	whether	_	_	
25-56	4673-4675	to	_	_	
25-57	4676-4679	run	_	_	
25-58	4680-4690	evaluation	_	_	
25-59	4691-4693	on	_	_	
25-60	4694-4697	the	_	_	
25-61	4698-4699	`	_	_	
25-62	4699-4703	test	_	_	
25-63	4703-4704	`	_	_	
25-64	4705-4708	set	_	_	
25-65	4709-4710	(	_	_	
25-66	4710-4717	default	_	_	
25-67	4718-4720	is	_	_	
25-68	4721-4726	False	_	_	
25-69	4726-4727	)	_	_	
25-70	4728-4729	-	_	_	
25-71	4730-4731	`	_	_	
25-72	4731-4742	train_split	_	_	
25-73	4742-4743	`	_	_	
25-74	4744-4745	(	_	_	
25-75	4745-4748	str	_	_	
25-76	4748-4749	)	_	_	
25-77	4749-4750	:	_	_	
25-78	4751-4766	comma-separated	_	_	
25-79	4767-4771	list	_	_	
25-80	4772-4774	of	_	_	
25-81	4775-4779	data	_	_	
25-82	4780-4786	splits	_	_	
25-83	4787-4790	for	_	_	
25-84	4791-4799	training	_	_	
25-85	4800-4801	(	_	_	
25-86	4801-4808	default	_	_	
25-87	4809-4811	is	_	_	
25-88	4812-4813	`	_	_	
25-89	4813-4818	train	_	_	
25-90	4818-4819	`	_	_	
25-91	4819-4820	)	_	_	
25-92	4821-4822	-	_	_	
25-93	4823-4824	`	_	_	
25-94	4824-4840	num_train_epochs	_	_	
25-95	4840-4841	`	_	_	
25-96	4842-4843	(	_	_	
25-97	4843-4846	int	_	_	
25-98	4846-4847	)	_	_	
25-99	4847-4848	:	_	_	
25-100	4849-4855	number	_	_	
25-101	4856-4858	of	_	_	
25-102	4859-4864	train	_	_	
25-103	4865-4871	epochs	_	_	
25-104	4872-4873	-	_	_	
25-105	4874-4875	`	_	_	
25-106	4875-4888	learning_rate	_	_	
25-107	4888-4889	`	_	_	
25-108	4890-4891	(	_	_	
25-109	4891-4896	float	_	_	
25-110	4896-4897	)	_	_	
25-111	4897-4898	:	_	_	
25-112	4899-4906	initial	_	_	
25-113	4907-4915	learning	_	_	
25-114	4916-4920	rate	_	_	
25-115	4921-4922	(	_	_	
25-116	4922-4929	default	_	_	
25-117	4930-4932	is	_	_	
25-118	4933-4935	5e	_	_	
25-119	4935-4936	-	_	_	
25-120	4936-4937	4	_	_	
25-121	4937-4938	)	_	_	
25-122	4939-4940	-	_	_	
25-123	4941-4942	`	_	_	
25-124	4942-4954	train_subset	_	_	
25-125	4954-4955	`	_	_	
25-126	4956-4957	(	_	_	
25-127	4957-4962	float	_	_	
25-128	4963-4964	>	_	_	
25-129	4965-4966	0	_	_	
25-130	4967-4970	and	_	_	
25-131	4971-4972	<	_	_	
25-132	4972-4973	=	_	_	
25-133	4973-4974	1	_	_	
25-134	4974-4975	)	_	_	
25-135	4975-4976	:	_	_	
25-136	4977-4984	portion	_	_	
25-137	4985-4987	of	_	_	
25-138	4988-4996	training	_	_	
25-139	4997-5001	data	_	_	
25-140	5002-5004	to	_	_	
25-141	5005-5016	effectively	_	_	
25-142	5017-5020	use	_	_	
25-143	5021-5027	during	_	_	
25-144	5028-5036	training	_	_	
25-145	5037-5038	(	_	_	
25-146	5038-5045	default	_	_	
25-147	5046-5048	is	_	_	
25-148	5049-5050	1	_	_	
25-149	5050-5051	,	_	_	
25-150	5052-5055	i.e	_	_	
25-151	5055-5056	.	_	_	
25-152	5056-5057	,	_	_	
25-153	5058-5061	use	_	_	
25-154	5062-5065	all	_	_	
25-155	5066-5074	training	_	_	
25-156	5075-5079	data	_	_	
25-157	5079-5080	)	_	_	
25-158	5081-5082	-	_	_	
25-159	5083-5084	`	_	_	
25-160	5084-5111	per_device_train_batch_size	_	_	
25-161	5111-5112	`	_	_	
25-162	5113-5114	(	_	_	
25-163	5114-5117	int	_	_	
25-164	5117-5118	)	_	_	
25-165	5118-5119	:	_	_	
25-166	5120-5125	batch	_	_	
25-167	5126-5130	size	_	_	
25-168	5131-5134	per	_	_	
25-169	5135-5138	GPU	_	_	
25-170	5139-5145	during	_	_	
25-171	5146-5154	training	_	_	
25-172	5155-5156	(	_	_	
25-173	5156-5163	default	_	_	
25-174	5164-5166	is	_	_	
25-175	5167-5168	8	_	_	
25-176	5168-5169	)	_	_	
25-177	5170-5171	-	_	_	
25-178	5172-5173	`	_	_	
25-179	5173-5199	per_device_eval_batch_size	_	_	
25-180	5199-5200	`	_	_	
25-181	5201-5202	(	_	_	
25-182	5202-5205	int	_	_	
25-183	5205-5206	)	_	_	
25-184	5206-5207	:	_	_	
25-185	5208-5213	batch	_	_	
25-186	5214-5218	size	_	_	
25-187	5219-5225	during	_	_	
25-188	5226-5236	evaluation	_	_	
25-189	5237-5238	(	_	_	
25-190	5238-5245	default	_	_	
25-191	5246-5248	is	_	_	
25-192	5249-5250	8	_	_	
25-193	5250-5251	;	_	_	
25-194	5252-5256	only	_	_	
25-195	5257-5260	one	_	_	
25-196	5261-5264	GPU	_	_	
25-197	5265-5267	is	_	_	
25-198	5268-5272	used	_	_	
25-199	5273-5276	for	_	_	
25-200	5277-5287	evaluation	_	_	
25-201	5287-5288	)	_	_	
25-202	5289-5290	-	_	_	
25-203	5291-5292	`	_	_	
25-204	5292-5306	max_seq_length	_	_	
25-205	5306-5307	`	_	_	
25-206	5308-5309	(	_	_	
25-207	5309-5312	int	_	_	
25-208	5312-5313	)	_	_	
25-209	5313-5314	:	_	_	
25-210	5315-5322	maximum	_	_	
25-211	5323-5328	input	_	_	
25-212	5329-5337	sequence	_	_	
25-213	5338-5344	length	_	_	
25-214	5345-5350	after	_	_	
25-215	5351-5363	tokenization	_	_	
25-216	5363-5364	;	_	_	
25-217	5365-5371	longer	_	_	
25-218	5372-5381	sequences	_	_	
25-219	5382-5385	are	_	_	
25-220	5386-5395	truncated	_	_	
25-221	5396-5397	-	_	_	
25-222	5398-5399	`	_	_	
25-223	5399-5420	max_output_seq_length	_	_	
25-224	5420-5421	`	_	_	
25-225	5422-5423	(	_	_	
25-226	5423-5426	int	_	_	
25-227	5426-5427	)	_	_	
25-228	5427-5428	:	_	_	
25-229	5429-5436	maximum	_	_	
25-230	5437-5443	output	_	_	
25-231	5444-5452	sequence	_	_	
25-232	5453-5459	length	_	_	
25-233	5460-5461	(	_	_	
25-234	5461-5468	default	_	_	
25-235	5469-5471	is	_	_	
25-236	5472-5473	`	_	_	
25-237	5473-5487	max_seq_length	_	_	
25-238	5487-5488	`	_	_	
25-239	5488-5489	)	_	_	
25-240	5490-5491	-	_	_	
25-241	5492-5493	`	_	_	
25-242	5493-5512	max_seq_length_eval	_	_	
25-243	5512-5513	`	_	_	
25-244	5514-5515	(	_	_	
25-245	5515-5518	int	_	_	
25-246	5518-5519	)	_	_	
25-247	5519-5520	:	_	_	
25-248	5521-5528	maximum	_	_	
25-249	5529-5534	input	_	_	
25-250	5535-5543	sequence	_	_	
25-251	5544-5550	length	_	_	
25-252	5551-5554	for	_	_	
25-253	5555-5565	evaluation	_	_	
25-254	5566-5567	(	_	_	
25-255	5567-5574	default	_	_	
25-256	5575-5577	is	_	_	
25-257	5578-5579	`	_	_	
25-258	5579-5593	max_seq_length	_	_	
25-259	5593-5594	`	_	_	
25-260	5594-5595	)	_	_	
25-261	5596-5597	-	_	_	
25-262	5598-5599	`	_	_	
25-263	5599-5625	max_output_seq_length_eval	_	_	
25-264	5625-5626	`	_	_	
25-265	5627-5628	(	_	_	
25-266	5628-5631	int	_	_	
25-267	5631-5632	)	_	_	
25-268	5632-5633	:	_	_	
25-269	5634-5641	maximum	_	_	
25-270	5642-5648	output	_	_	
25-271	5649-5657	sequence	_	_	
25-272	5658-5664	length	_	_	
25-273	5665-5668	for	_	_	
25-274	5669-5679	evaluation	_	_	
25-275	5680-5681	(	_	_	
25-276	5681-5688	default	_	_	
25-277	5689-5691	is	_	_	
25-278	5692-5693	`	_	_	
25-279	5693-5714	max_output_seq_length	_	_	
25-280	5714-5715	`	_	_	
25-281	5716-5718	or	_	_	
25-282	5719-5720	`	_	_	
25-283	5720-5739	max_seq_length_eval	_	_	
25-284	5739-5740	`	_	_	
25-285	5741-5743	or	_	_	
25-286	5744-5745	`	_	_	
25-287	5745-5759	max_seq_length	_	_	
25-288	5759-5760	`	_	_	
25-289	5760-5761	)	_	_	
25-290	5762-5763	-	_	_	
25-291	5764-5765	`	_	_	
25-292	5765-5773	episodes	_	_	
25-293	5773-5774	`	_	_	
25-294	5775-5776	(	_	_	
25-295	5776-5779	str	_	_	
25-296	5779-5780	)	_	_	
25-297	5780-5781	:	_	_	
25-298	5782-5790	episodes	_	_	
25-299	5791-5793	to	_	_	
25-300	5794-5797	run	_	_	
25-301	5798-5799	(	_	_	
25-302	5799-5806	default	_	_	
25-303	5807-5809	is	_	_	
25-304	5810-5811	`	_	_	
25-305	5811-5812	0	_	_	
25-306	5812-5813	`	_	_	
25-307	5813-5814	;	_	_	
25-308	5815-5817	an	_	_	
25-309	5818-5826	interval	_	_	
25-310	5827-5830	can	_	_	
25-311	5831-5833	be	_	_	
25-312	5834-5843	specified	_	_	
25-313	5843-5844	,	_	_	
25-314	5845-5849	such	_	_	
25-315	5850-5852	as	_	_	
25-316	5853-5854	`	_	_	
25-317	5854-5855	1	_	_	
25-318	5855-5856	-	_	_	
25-319	5856-5857	4	_	_	
25-320	5857-5858	`	_	_	
25-321	5858-5859	;	_	_	
25-322	5860-5863	the	_	_	
25-323	5864-5871	episode	_	_	
25-324	5872-5878	number	_	_	
25-325	5879-5881	is	_	_	
25-326	5882-5886	used	_	_	
25-327	5887-5889	as	_	_	
25-328	5890-5893	the	_	_	
25-329	5894-5900	random	_	_	
25-330	5901-5905	seed	_	_	
25-331	5905-5906	)	_	_	
25-332	5907-5908	-	_	_	
25-333	5909-5910	`	_	_	
25-334	5910-5919	num_beams	_	_	
25-335	5919-5920	`	_	_	
25-336	5921-5922	(	_	_	
25-337	5922-5925	int	_	_	
25-338	5925-5926	)	_	_	
25-339	5926-5927	:	_	_	
25-340	5928-5934	number	_	_	
25-341	5935-5937	of	_	_	
25-342	5938-5943	beams	_	_	
25-343	5944-5947	for	_	_	
25-344	5948-5952	beam	_	_	
25-345	5953-5959	search	_	_	
25-346	5960-5966	during	_	_	
25-347	5967-5977	generation	_	_	
25-348	5978-5979	(	_	_	
25-349	5979-5986	default	_	_	
25-350	5987-5989	is	_	_	
25-351	5990-5991	1	_	_	
25-352	5991-5992	)	_	_	
25-353	5993-5994	-	_	_	
25-354	5995-5996	`	_	_	
25-355	5996-6005	multitask	_	_	
25-356	6005-6006	`	_	_	
25-357	6007-6008	(	_	_	
25-358	6008-6012	bool	_	_	
25-359	6012-6013	)	_	_	
25-360	6013-6014	:	_	_	
25-361	6015-6017	if	_	_	
25-362	6018-6022	True	_	_	
25-363	6022-6023	,	_	_	
25-364	6024-6027	the	_	_	
25-365	6028-6032	name	_	_	
25-366	6033-6035	of	_	_	
25-367	6036-6039	the	_	_	
25-368	6040-6047	dataset	_	_	
25-369	6048-6050	is	_	_	
25-370	6051-6060	prepended	_	_	
25-371	6061-6063	to	_	_	
25-372	6064-6068	each	_	_	
25-373	6069-6074	input	_	_	
25-374	6075-6083	sentence	_	_	
25-375	6084-6085	(	_	_	
25-376	6085-6092	default	_	_	
25-377	6093-6095	is	_	_	
25-378	6096-6101	False	_	_	
25-379	6101-6102	)	_	_	
25-380	6104-6107	See	_	_	
25-381	6108-6109	[	_	_	
25-382	6109-6121	arguments.py	_	_	
25-383	6121-6122	]	_	_	
25-384	6122-6123	(	_	_	
25-385	6123-6135	arguments.py	_	_	
25-386	6135-6136	)	_	_	
25-387	6137-6140	and	_	_	
25-388	6141-6142	[	_	_	
25-389	6142-6172	transformers.TrainingArguments	_	_	
25-389.1	6142-6154	transformers	*	SOFTWARE	
25-390	6172-6173	]	_	_	
25-391	6173-6174	(	_	_	
25-392	6174-6179	https	_	_	
25-393	6179-6180	:	_	_	
25-394	6180-6181	/	_	_	
25-395	6181-6182	/	_	_	
25-396	6182-6192	github.com	_	_	
25-397	6192-6193	/	_	_	
25-398	6193-6204	huggingface	_	_	
25-399	6204-6205	/	_	_	
25-400	6205-6217	transformers	*	SOFTWARE	
25-401	6217-6218	/	_	_	
25-402	6218-6222	blob	_	_	
25-403	6222-6223	/	_	_	
25-404	6223-6229	master	_	_	
25-405	6229-6230	/	_	_	
25-406	6230-6233	src	_	_	
25-407	6233-6234	/	_	_	
25-408	6234-6246	transformers	*	SOFTWARE	
25-409	6246-6247	/	_	_	
25-410	6247-6263	training_args.py	_	_	
25-411	6263-6264	)	_	_	
25-412	6265-6268	for	_	_	
25-413	6269-6279	additional	_	_	
25-414	6280-6286	config	_	_	
25-415	6287-6296	arguments	_	_	
25-416	6296-6297	.	_	_	
25-417	6300-6301	#	_	_	
25-418	6301-6302	#	_	_	
25-419	6303-6313	Fine-tuned	_	_	
25-420	6314-6324	multi-task	_	_	
25-421	6325-6330	model	_	_	
25-422	6332-6335	The	_	_	
25-423	6336-6343	weights	_	_	
25-424	6344-6346	of	_	_	
25-425	6347-6350	our	_	_	
25-426	6351-6361	multi-task	_	_	
25-427	6362-6367	model	_	_	
25-428	6368-6369	(	_	_	
25-429	6369-6377	released	_	_	
25-430	6378-6383	under	_	_	
25-431	6384-6387	the	_	_	
25-432	6388-6389	[	_	_	
25-433	6389-6391	CC	*[11]	LICENSE[11]	
25-434	6392-6394	BY	*[11]	LICENSE[11]	
25-435	6395-6398	4.0	*[11]	LICENSE[11]	
25-436	6399-6406	license	_	_	
25-437	6406-6407	]	_	_	
25-438	6407-6408	(	_	_	
25-439	6408-6413	https	_	_	
25-440	6413-6414	:	_	_	
25-441	6414-6415	/	_	_	
25-442	6415-6416	/	_	_	
25-443	6416-6435	creativecommons.org	_	_	
25-444	6435-6436	/	_	_	
25-445	6436-6444	licenses	_	_	
25-446	6444-6445	/	_	_	
25-447	6445-6447	by	_	_	
25-448	6447-6448	/	_	_	
25-449	6448-6451	4.0	_	_	
25-450	6451-6452	/	_	_	
25-451	6452-6453	)	_	_	
25-452	6453-6454	)	_	_	
25-453	6455-6458	can	_	_	
25-454	6459-6461	be	_	_	
25-455	6462-6472	downloaded	_	_	
25-456	6473-6477	here	_	_	
25-457	6477-6478	:	_	_	
25-458	6479-6484	https	_	_	
25-459	6484-6485	:	_	_	
25-460	6485-6486	/	_	_	
25-461	6486-6487	/	_	_	
25-462	6487-6494	tanl.s3	_	_	
25-462.1	6487-6491	tanl	*	PROJECT	
25-463	6494-6495	.	_	_	
25-464	6495-6508	amazonaws.com	_	_	
25-465	6508-6509	/	_	_	
25-466	6509-6527	tanl-multitask.zip	_	_	
25-466.1	6509-6513	tanl	*	PROJECT	
25-467	6529-6536	Extract	_	_	
25-468	6537-6540	the	_	_	
25-469	6541-6544	zip	_	_	
25-470	6545-6549	file	_	_	
25-471	6550-6552	in	_	_	
25-472	6553-6556	the	_	_	
25-473	6557-6558	`	_	_	
25-474	6558-6569	experiments	_	_	
25-475	6569-6570	/	_	_	
25-476	6570-6571	`	_	_	
25-477	6572-6581	directory	_	_	
25-478	6581-6582	.	_	_	

#Text=This will create a subdirectory called `multitask-t5-base-ep50-len512-b8-train,dev-overlap96`.
26-1	6583-6587	This	_	_	
26-2	6588-6592	will	_	_	
26-3	6593-6599	create	_	_	
26-4	6600-6601	a	_	_	
26-5	6602-6614	subdirectory	_	_	
26-6	6615-6621	called	_	_	
26-7	6622-6623	`	_	_	
26-8	6623-6635	multitask-t5	_	_	
26-8.1	6633-6635	t5	*[12]	SOFTWARE[12]	
26-9	6635-6636	-	*[12]	SOFTWARE[12]	
26-10	6636-6645	base-ep50	_	_	
26-10.1	6636-6640	base	*[12]	SOFTWARE[12]	
26-11	6645-6646	-	_	_	
26-12	6646-6652	len512	_	_	
26-13	6652-6653	-	_	_	
26-14	6653-6655	b8	_	_	
26-15	6655-6656	-	_	_	
26-16	6656-6661	train	_	_	
26-17	6661-6662	,	_	_	
26-18	6662-6675	dev-overlap96	_	_	
26-19	6675-6676	`	_	_	
26-20	6676-6677	.	_	_	

#Text=For example, to test the multi-task model on the CoNLL04 dataset, run `python run.py multitask -e --eval_datasets conll04`.
27-1	6678-6681	For	_	_	
27-2	6682-6689	example	_	_	
27-3	6689-6690	,	_	_	
27-4	6691-6693	to	_	_	
27-5	6694-6698	test	_	_	
27-6	6699-6702	the	_	_	
27-7	6703-6713	multi-task	_	_	
27-8	6714-6719	model	_	_	
27-9	6720-6722	on	_	_	
27-10	6723-6726	the	_	_	
27-11	6727-6734	CoNLL04	*	DATASET	
27-12	6735-6742	dataset	_	_	
27-13	6742-6743	,	_	_	
27-14	6744-6747	run	_	_	
27-15	6748-6749	`	_	_	
27-16	6749-6755	python	_	_	
27-17	6756-6762	run.py	_	_	
27-18	6763-6772	multitask	_	_	
27-19	6773-6774	-	_	_	
27-20	6774-6775	e	_	_	
27-21	6776-6777	-	_	_	
27-22	6777-6778	-	_	_	
27-23	6778-6791	eval_datasets	_	_	
27-24	6792-6799	conll04	*	DATASET	
27-25	6799-6800	`	_	_	
27-26	6800-6801	.	_	_	

#Text=Note that: the `multitask` job is defined in [config.ini](config.ini); the `-e` flag is used to skip training and run evaluation only; the name of the subdirectory containing the weights is compatible with the definition of the `multitask` job.
28-1	6803-6807	Note	_	_	
28-2	6808-6812	that	_	_	
28-3	6812-6813	:	_	_	
28-4	6814-6817	the	_	_	
28-5	6818-6819	`	_	_	
28-6	6819-6828	multitask	_	_	
28-7	6828-6829	`	_	_	
28-8	6830-6833	job	_	_	
28-9	6834-6836	is	_	_	
28-10	6837-6844	defined	_	_	
28-11	6845-6847	in	_	_	
28-12	6848-6849	[	_	_	
28-13	6849-6859	config.ini	_	_	
28-14	6859-6860	]	_	_	
28-15	6860-6861	(	_	_	
28-16	6861-6871	config.ini	_	_	
28-17	6871-6872	)	_	_	
28-18	6872-6873	;	_	_	
28-19	6874-6877	the	_	_	
28-20	6878-6879	`	_	_	
28-21	6879-6880	-	_	_	
28-22	6880-6881	e	_	_	
28-23	6881-6882	`	_	_	
28-24	6883-6887	flag	_	_	
28-25	6888-6890	is	_	_	
28-26	6891-6895	used	_	_	
28-27	6896-6898	to	_	_	
28-28	6899-6903	skip	_	_	
28-29	6904-6912	training	_	_	
28-30	6913-6916	and	_	_	
28-31	6917-6920	run	_	_	
28-32	6921-6931	evaluation	_	_	
28-33	6932-6936	only	_	_	
28-34	6936-6937	;	_	_	
28-35	6938-6941	the	_	_	
28-36	6942-6946	name	_	_	
28-37	6947-6949	of	_	_	
28-38	6950-6953	the	_	_	
28-39	6954-6966	subdirectory	_	_	
28-40	6967-6977	containing	_	_	
28-41	6978-6981	the	_	_	
28-42	6982-6989	weights	_	_	
28-43	6990-6992	is	_	_	
28-44	6993-7003	compatible	_	_	
28-45	7004-7008	with	_	_	
28-46	7009-7012	the	_	_	
28-47	7013-7023	definition	_	_	
28-48	7024-7026	of	_	_	
28-49	7027-7030	the	_	_	
28-50	7031-7032	`	_	_	
28-51	7032-7041	multitask	_	_	
28-52	7041-7042	`	_	_	
28-53	7043-7046	job	_	_	
28-54	7046-7047	.	_	_	

#Text=The multi-task model was fine-tuned as described in the paper.
29-1	7049-7052	The	_	_	
29-2	7053-7063	multi-task	_	_	
29-3	7064-7069	model	_	_	
29-4	7070-7073	was	_	_	
29-5	7074-7084	fine-tuned	_	_	
29-6	7085-7087	as	_	_	
29-7	7088-7097	described	_	_	
29-8	7098-7100	in	_	_	
29-9	7101-7104	the	_	_	
29-10	7105-7110	paper	_	_	
29-11	7110-7111	.	_	_	

#Text=The results differ slightly from what is reported in the paper due to small code changes.
#Text=
#Text=
#Text=## Licenses
#Text=
#Text=The code of this repository is released under the [Apache 2.0 license](LICENSE).
30-1	7112-7115	The	_	_	
30-2	7116-7123	results	_	_	
30-3	7124-7130	differ	_	_	
30-4	7131-7139	slightly	_	_	
30-5	7140-7144	from	_	_	
30-6	7145-7149	what	_	_	
30-7	7150-7152	is	_	_	
30-8	7153-7161	reported	_	_	
30-9	7162-7164	in	_	_	
30-10	7165-7168	the	_	_	
30-11	7169-7174	paper	_	_	
30-12	7175-7178	due	_	_	
30-13	7179-7181	to	_	_	
30-14	7182-7187	small	_	_	
30-15	7188-7192	code	_	_	
30-16	7193-7200	changes	_	_	
30-17	7200-7201	.	_	_	
30-18	7204-7205	#	_	_	
30-19	7205-7206	#	_	_	
30-20	7207-7215	Licenses	_	_	
30-21	7217-7220	The	_	_	
30-22	7221-7225	code	_	_	
30-23	7226-7228	of	_	_	
30-24	7229-7233	this	_	_	
30-25	7234-7244	repository	_	_	
30-26	7245-7247	is	_	_	
30-27	7248-7256	released	_	_	
30-28	7257-7262	under	_	_	
30-29	7263-7266	the	_	_	
30-30	7267-7268	[	_	_	
30-31	7268-7274	Apache	*[13]	LICENSE[13]	
30-32	7275-7278	2.0	*[13]	LICENSE[13]	
30-33	7279-7286	license	_	_	
30-34	7286-7287	]	_	_	
30-35	7287-7288	(	_	_	
30-36	7288-7295	LICENSE	_	_	
30-37	7295-7296	)	_	_	
30-38	7296-7297	.	_	_	

#Text=The weights of the [fine-tuned multi-task model](#fine-tuned-multi-task-model) are released under the [CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/).
31-1	7298-7301	The	_	_	
31-2	7302-7309	weights	_	_	
31-3	7310-7312	of	_	_	
31-4	7313-7316	the	_	_	
31-5	7317-7318	[	_	_	
31-6	7318-7328	fine-tuned	_	_	
31-7	7329-7339	multi-task	_	_	
31-8	7340-7345	model	_	_	
31-9	7345-7346	]	_	_	
31-10	7346-7347	(	_	_	
31-11	7347-7348	#	_	_	
31-12	7348-7375	fine-tuned-multi-task-model	_	_	
31-13	7375-7376	)	_	_	
31-14	7377-7380	are	_	_	
31-15	7381-7389	released	_	_	
31-16	7390-7395	under	_	_	
31-17	7396-7399	the	_	_	
31-18	7400-7401	[	_	_	
31-19	7401-7403	CC	*[14]	LICENSE[14]	
31-20	7404-7406	BY	*[14]	LICENSE[14]	
31-21	7407-7410	4.0	*[14]	LICENSE[14]	
31-22	7411-7418	license	_	_	
31-23	7418-7419	]	_	_	
31-24	7419-7420	(	_	_	
31-25	7420-7425	https	_	_	
31-26	7425-7426	:	_	_	
31-27	7426-7427	/	_	_	
31-28	7427-7428	/	_	_	
31-29	7428-7447	creativecommons.org	_	_	
31-30	7447-7448	/	_	_	
31-31	7448-7456	licenses	_	_	
31-32	7456-7457	/	_	_	
31-33	7457-7459	by	_	_	
31-34	7459-7460	/	_	_	
31-35	7460-7463	4.0	_	_	
31-36	7463-7464	/	_	_	
31-37	7464-7465	)	_	_	
31-38	7465-7466	.	_	_	
