#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# ActionFormer: Localizing Moments of Actions with Transformers  ## Introduction This code repo implements Actionformer, one of the first Transformer-based model for temporal action localization --- detecting the onsets and offsets of action instances and recognizing their action categories.
1-1	0-1	#	_	_
1-2	2-14	ActionFormer	_	_
1-3	14-15	:	_	_
1-4	16-26	Localizing	_	_
1-5	27-34	Moments	_	_
1-6	35-37	of	_	_
1-7	38-45	Actions	_	_
1-8	46-50	with	_	_
1-9	51-63	Transformers	_	_
1-10	65-66	#	_	_
1-11	66-67	#	_	_
1-12	68-80	Introduction	_	_
1-13	81-85	This	_	_
1-14	86-90	code	_	_
1-15	91-95	repo	_	_
1-16	96-106	implements	_	_
1-17	107-119	Actionformer	_	_
1-18	119-120	,	_	_
1-19	121-124	one	_	_
1-20	125-127	of	_	_
1-21	128-131	the	_	_
1-22	132-137	first	_	_
1-23	138-155	Transformer-based	_	_
1-24	156-161	model	_	_
1-25	162-165	for	_	_
1-26	166-174	temporal	_	_
1-27	175-181	action	_	_
1-28	182-194	localization	_	_
1-29	195-196	-	_	_
1-30	196-197	-	_	_
1-31	197-198	-	_	_
1-32	199-208	detecting	_	_
1-33	209-212	the	_	_
1-34	213-219	onsets	_	_
1-35	220-223	and	_	_
1-36	224-231	offsets	_	_
1-37	232-234	of	_	_
1-38	235-241	action	_	_
1-39	242-251	instances	_	_
1-40	252-255	and	_	_
1-41	256-267	recognizing	_	_
1-42	268-273	their	_	_
1-43	274-280	action	_	_
1-44	281-291	categories	_	_
1-45	291-292	.	_	_

#Text=Without bells and whistles, ActionFormer achieves 71.0% mAP at tIoU=0.5 on THUMOS14, outperforming the best prior model by 14.1 absolute percentage points and crossing the 60% mAP for the first time.
2-1	293-300	Without	_	_
2-2	301-306	bells	_	_
2-3	307-310	and	_	_
2-4	311-319	whistles	_	_
2-5	319-320	,	_	_
2-6	321-333	ActionFormer	_	_
2-7	334-342	achieves	_	_
2-8	343-348	71.0%	_	_
2-9	349-352	mAP	_	_
2-10	353-355	at	_	_
2-11	356-360	tIoU	_	_
2-12	360-361	=	_	_
2-13	361-364	0.5	_	_
2-14	365-367	on	_	_
2-15	368-376	THUMOS14	_	_
2-16	376-377	,	_	_
2-17	378-391	outperforming	_	_
2-18	392-395	the	_	_
2-19	396-400	best	_	_
2-20	401-406	prior	_	_
2-21	407-412	model	_	_
2-22	413-415	by	_	_
2-23	416-420	14.1	_	_
2-24	421-429	absolute	_	_
2-25	430-440	percentage	_	_
2-26	441-447	points	_	_
2-27	448-451	and	_	_
2-28	452-460	crossing	_	_
2-29	461-464	the	_	_
2-30	465-468	60%	_	_
2-31	469-472	mAP	_	_
2-32	473-476	for	_	_
2-33	477-480	the	_	_
2-34	481-486	first	_	_
2-35	487-491	time	_	_
2-36	491-492	.	_	_

#Text=Further, ActionFormer demonstrates strong results on ActivityNet 1.3 (36.56% average mAP) and the more challenging EPIC-Kitchens 100 (+13.5% average mAP over prior works).
3-1	493-500	Further	_	_
3-2	500-501	,	_	_
3-3	502-514	ActionFormer	_	_
3-4	515-527	demonstrates	_	_
3-5	528-534	strong	_	_
3-6	535-542	results	_	_
3-7	543-545	on	_	_
3-8	546-557	ActivityNet	_	_
3-9	558-561	1.3	_	_
3-10	562-563	(	_	_
3-11	563-569	36.56%	_	_
3-12	570-577	average	_	_
3-13	578-581	mAP	_	_
3-14	581-582	)	_	_
3-15	583-586	and	_	_
3-16	587-590	the	_	_
3-17	591-595	more	_	_
3-18	596-607	challenging	_	_
3-19	608-621	EPIC-Kitchens	_	_
3-20	622-625	100	_	_
3-21	626-627	(	_	_
3-22	627-628	+	_	_
3-23	628-633	13.5%	_	_
3-24	634-641	average	_	_
3-25	642-645	mAP	_	_
3-26	646-650	over	_	_
3-27	651-656	prior	_	_
3-28	657-662	works	_	_
3-29	662-663	)	_	_
3-30	663-664	.	_	_

#Text=Our paper is accepted to ECCV 2022 and an arXiv version can be found at \[this link\](https://arxiv.org/abs/2202.07925).
4-1	665-668	Our	_	_
4-2	669-674	paper	_	_
4-3	675-677	is	_	_
4-4	678-686	accepted	_	_
4-5	687-689	to	_	_
4-6	690-694	ECCV	_	_
4-7	695-699	2022	_	_
4-8	700-703	and	_	_
4-9	704-706	an	_	_
4-10	707-712	arXiv	_	_
4-11	713-720	version	_	_
4-12	721-724	can	_	_
4-13	725-727	be	_	_
4-14	728-733	found	_	_
4-15	734-736	at	_	_
4-16	737-738	\[	_	_
4-17	738-742	this	_	_
4-18	743-747	link	_	_
4-19	747-748	\]	_	_
4-20	748-749	(	_	_
4-21	749-754	https	_	_
4-22	754-755	:	_	_
4-23	755-756	/	_	_
4-24	756-757	/	_	_
4-25	757-766	arxiv.org	_	_
4-26	766-767	/	_	_
4-27	767-770	abs	_	_
4-28	770-771	/	_	_
4-29	771-781	2202.07925	_	_
4-30	781-782	)	_	_
4-31	782-783	.	_	_

#Text=In addition, ActionFormer is the backbone for many winning solutions in the Ego4D Moment Queries Challenge 2022.
5-1	785-787	In	_	_
5-2	788-796	addition	_	_
5-3	796-797	,	_	_
5-4	798-810	ActionFormer	_	_
5-5	811-813	is	_	_
5-6	814-817	the	_	_
5-7	818-826	backbone	_	_
5-8	827-830	for	_	_
5-9	831-835	many	_	_
5-10	836-843	winning	_	_
5-11	844-853	solutions	_	_
5-12	854-856	in	_	_
5-13	857-860	the	_	_
5-14	861-866	Ego4D	_	_
5-15	867-873	Moment	_	_
5-16	874-881	Queries	_	_
5-17	882-891	Challenge	_	_
5-18	892-896	2022	_	_
5-19	896-897	.	_	_

#Text=Our submission in particular is ranked 2nd with a record 21.76% average mAP and 42.54% Recall@1x, tIoU=0.5, nearly three times higher than the official baseline.
6-1	898-901	Our	_	_
6-2	902-912	submission	_	_
6-3	913-915	in	_	_
6-4	916-926	particular	_	_
6-5	927-929	is	_	_
6-6	930-936	ranked	_	_
6-7	937-940	2nd	_	_
6-8	941-945	with	_	_
6-9	946-947	a	_	_
6-10	948-954	record	_	_
6-11	955-961	21.76%	_	_
6-12	962-969	average	_	_
6-13	970-973	mAP	_	_
6-14	974-977	and	_	_
6-15	978-984	42.54%	_	_
6-16	985-991	Recall	_	_
6-17	991-992	@	_	_
6-18	992-994	1x	_	_
6-19	994-995	,	_	_
6-20	996-1000	tIoU	_	_
6-21	1000-1001	=	_	_
6-22	1001-1004	0.5	_	_
6-23	1004-1005	,	_	_
6-24	1006-1012	nearly	_	_
6-25	1013-1018	three	_	_
6-26	1019-1024	times	_	_
6-27	1025-1031	higher	_	_
6-28	1032-1036	than	_	_
6-29	1037-1040	the	_	_
6-30	1041-1049	official	_	_
6-31	1050-1058	baseline	_	_
6-32	1058-1059	.	_	_

#Text=An arXiv version of our tech report can be found at \[this link\](https://arxiv.org/abs/2211.09074).
7-1	1060-1062	An	_	_
7-2	1063-1068	arXiv	_	_
7-3	1069-1076	version	_	_
7-4	1077-1079	of	_	_
7-5	1080-1083	our	_	_
7-6	1084-1088	tech	_	_
7-7	1089-1095	report	_	_
7-8	1096-1099	can	_	_
7-9	1100-1102	be	_	_
7-10	1103-1108	found	_	_
7-11	1109-1111	at	_	_
7-12	1112-1113	\[	_	_
7-13	1113-1117	this	_	_
7-14	1118-1122	link	_	_
7-15	1122-1123	\]	_	_
7-16	1123-1124	(	_	_
7-17	1124-1129	https	_	_
7-18	1129-1130	:	_	_
7-19	1130-1131	/	_	_
7-20	1131-1132	/	_	_
7-21	1132-1141	arxiv.org	_	_
7-22	1141-1142	/	_	_
7-23	1142-1145	abs	_	_
7-24	1145-1146	/	_	_
7-25	1146-1156	2211.09074	_	_
7-26	1156-1157	)	_	_
7-27	1157-1158	.	_	_

#Text=We invite our audience to try out the code.
8-1	1159-1161	We	_	_
8-2	1162-1168	invite	_	_
8-3	1169-1172	our	_	_
8-4	1173-1181	audience	_	_
8-5	1182-1184	to	_	_
8-6	1185-1188	try	_	_
8-7	1189-1192	out	_	_
8-8	1193-1196	the	_	_
8-9	1197-1201	code	_	_
8-10	1201-1202	.	_	_

#Text=<div align="center">   <img src="teaser.jpg" width="600px"/> </div>  Specifically, we adopt a minimalist design and develop a Transformer based model for temporal action localization, inspired by the recent success of Transformers in NLP and vision.
9-1	1204-1205	<	_	_
9-2	1205-1208	div	_	_
9-3	1209-1214	align	_	_
9-4	1214-1215	=	_	_
9-5	1215-1216	"	_	_
9-6	1216-1222	center	_	_
9-7	1222-1223	"	_	_
9-8	1223-1224	>	_	_
9-9	1227-1228	<	_	_
9-10	1228-1231	img	_	_
9-11	1232-1235	src	_	_
9-12	1235-1236	=	_	_
9-13	1236-1237	"	_	_
9-14	1237-1247	teaser.jpg	_	_
9-15	1247-1248	"	_	_
9-16	1249-1254	width	_	_
9-17	1254-1255	=	_	_
9-18	1255-1256	"	_	_
9-19	1256-1261	600px	_	_
9-20	1261-1262	"	_	_
9-21	1262-1263	/	_	_
9-22	1263-1264	>	_	_
9-23	1265-1266	<	_	_
9-24	1266-1267	/	_	_
9-25	1267-1270	div	_	_
9-26	1270-1271	>	_	_
9-27	1273-1285	Specifically	_	_
9-28	1285-1286	,	_	_
9-29	1287-1289	we	_	_
9-30	1290-1295	adopt	_	_
9-31	1296-1297	a	_	_
9-32	1298-1308	minimalist	_	_
9-33	1309-1315	design	_	_
9-34	1316-1319	and	_	_
9-35	1320-1327	develop	_	_
9-36	1328-1329	a	_	_
9-37	1330-1341	Transformer	_	_
9-38	1342-1347	based	_	_
9-39	1348-1353	model	_	_
9-40	1354-1357	for	_	_
9-41	1358-1366	temporal	_	_
9-42	1367-1373	action	_	_
9-43	1374-1386	localization	_	_
9-44	1386-1387	,	_	_
9-45	1388-1396	inspired	_	_
9-46	1397-1399	by	_	_
9-47	1400-1403	the	_	_
9-48	1404-1410	recent	_	_
9-49	1411-1418	success	_	_
9-50	1419-1421	of	_	_
9-51	1422-1434	Transformers	_	_
9-52	1435-1437	in	_	_
9-53	1438-1441	NLP	_	_
9-54	1442-1445	and	_	_
9-55	1446-1452	vision	_	_
9-56	1452-1453	.	_	_

#Text=Our method, illustrated in the figure, adapts local self-attention to model temporal context in untrimmed videos, classifies every moment in an input video, and regresses their corresponding action boundaries.
10-1	1454-1457	Our	_	_
10-2	1458-1464	method	_	_
10-3	1464-1465	,	_	_
10-4	1466-1477	illustrated	_	_
10-5	1478-1480	in	_	_
10-6	1481-1484	the	_	_
10-7	1485-1491	figure	_	_
10-8	1491-1492	,	_	_
10-9	1493-1499	adapts	_	_
10-10	1500-1505	local	_	_
10-11	1506-1520	self-attention	_	_
10-12	1521-1523	to	_	_
10-13	1524-1529	model	_	_
10-14	1530-1538	temporal	_	_
10-15	1539-1546	context	_	_
10-16	1547-1549	in	_	_
10-17	1550-1559	untrimmed	_	_
10-18	1560-1566	videos	_	_
10-19	1566-1567	,	_	_
10-20	1568-1578	classifies	_	_
10-21	1579-1584	every	_	_
10-22	1585-1591	moment	_	_
10-23	1592-1594	in	_	_
10-24	1595-1597	an	_	_
10-25	1598-1603	input	_	_
10-26	1604-1609	video	_	_
10-27	1609-1610	,	_	_
10-28	1611-1614	and	_	_
10-29	1615-1624	regresses	_	_
10-30	1625-1630	their	_	_
10-31	1631-1644	corresponding	_	_
10-32	1645-1651	action	_	_
10-33	1652-1662	boundaries	_	_
10-34	1662-1663	.	_	_

#Text=The result is a deep model that is trained using standard classification and regression loss, and can localize moments of actions in a single shot, without using action proposals or pre-defined anchor windows.
11-1	1664-1667	The	_	_
11-2	1668-1674	result	_	_
11-3	1675-1677	is	_	_
11-4	1678-1679	a	_	_
11-5	1680-1684	deep	_	_
11-6	1685-1690	model	_	_
11-7	1691-1695	that	_	_
11-8	1696-1698	is	_	_
11-9	1699-1706	trained	_	_
11-10	1707-1712	using	_	_
11-11	1713-1721	standard	_	_
11-12	1722-1736	classification	_	_
11-13	1737-1740	and	_	_
11-14	1741-1751	regression	_	_
11-15	1752-1756	loss	_	_
11-16	1756-1757	,	_	_
11-17	1758-1761	and	_	_
11-18	1762-1765	can	_	_
11-19	1766-1774	localize	_	_
11-20	1775-1782	moments	_	_
11-21	1783-1785	of	_	_
11-22	1786-1793	actions	_	_
11-23	1794-1796	in	_	_
11-24	1797-1798	a	_	_
11-25	1799-1805	single	_	_
11-26	1806-1810	shot	_	_
11-27	1810-1811	,	_	_
11-28	1812-1819	without	_	_
11-29	1820-1825	using	_	_
11-30	1826-1832	action	_	_
11-31	1833-1842	proposals	_	_
11-32	1843-1845	or	_	_
11-33	1846-1857	pre-defined	_	_
11-34	1858-1864	anchor	_	_
11-35	1865-1872	windows	_	_
11-36	1872-1873	.	_	_

#Text=\*\*Related projects\*\*: > \[\*\*SnAG: Scalable and Accurate Video Grounding\*\*\](https://arxiv.org/abs/2404.02257) <br> > Fangzhou Mu\\\*, Sicheng Mo\\\*, Yin Li <br> > \*CVPR 2024\* <br> \[!
12-1	1875-1876	\*	_	_
12-2	1876-1877	\*	_	_
12-3	1877-1884	Related	_	_
12-4	1885-1893	projects	_	_
12-5	1893-1894	\*	_	_
12-6	1894-1895	\*	_	_
12-7	1895-1896	:	_	_
12-8	1897-1898	>	_	_
12-9	1899-1900	\[	_	_
12-10	1900-1901	\*	_	_
12-11	1901-1902	\*	_	_
12-12	1902-1906	SnAG	_	_
12-13	1906-1907	:	_	_
12-14	1908-1916	Scalable	_	_
12-15	1917-1920	and	_	_
12-16	1921-1929	Accurate	_	_
12-17	1930-1935	Video	_	_
12-18	1936-1945	Grounding	_	_
12-19	1945-1946	\*	_	_
12-20	1946-1947	\*	_	_
12-21	1947-1948	\]	_	_
12-22	1948-1949	(	_	_
12-23	1949-1954	https	_	_
12-24	1954-1955	:	_	_
12-25	1955-1956	/	_	_
12-26	1956-1957	/	_	_
12-27	1957-1966	arxiv.org	_	_
12-28	1966-1967	/	_	_
12-29	1967-1970	abs	_	_
12-30	1970-1971	/	_	_
12-31	1971-1981	2404.02257	_	_
12-32	1981-1982	)	_	_
12-33	1983-1984	<	_	_
12-34	1984-1986	br	_	_
12-35	1986-1987	>	_	_
12-36	1988-1989	>	_	_
12-37	1990-1998	Fangzhou	_	_
12-38	1999-2001	Mu	_	_
12-39	2001-2002	\\	_	_
12-40	2002-2003	\*	_	_
12-41	2003-2004	,	_	_
12-42	2005-2012	Sicheng	_	_
12-43	2013-2015	Mo	_	_
12-44	2015-2016	\\	_	_
12-45	2016-2017	\*	_	_
12-46	2017-2018	,	_	_
12-47	2019-2022	Yin	_	_
12-48	2023-2025	Li	_	_
12-49	2026-2027	<	_	_
12-50	2027-2029	br	_	_
12-51	2029-2030	>	_	_
12-52	2031-2032	>	_	_
12-53	2033-2034	\*	_	_
12-54	2034-2038	CVPR	_	_
12-55	2039-2043	2024	_	_
12-56	2043-2044	\*	_	_
12-57	2045-2046	<	_	_
12-58	2046-2048	br	_	_
12-59	2048-2049	>	_	_
12-60	2050-2051	\[	_	_
12-61	2051-2052	!	_	_

#Text=\[github\](https://img.shields.io/badge/-Github-black?
13-1	2052-2053	\[	_	_
13-2	2053-2059	github	_	_
13-3	2059-2060	\]	_	_
13-4	2060-2061	(	_	_
13-5	2061-2066	https	_	_
13-6	2066-2067	:	_	_
13-7	2067-2068	/	_	_
13-8	2068-2069	/	_	_
13-9	2069-2083	img.shields.io	_	_
13-10	2083-2084	/	_	_
13-11	2084-2089	badge	_	_
13-12	2089-2090	/	_	_
13-13	2090-2091	-	_	_
13-14	2091-2103	Github-black	_	_
13-15	2103-2104	?	_	_

#Text=logo=github)\](https://github.com/fmu2/snag\_release)  \[!
14-1	2104-2108	logo	_	_
14-2	2108-2109	=	_	_
14-3	2109-2115	github	_	_
14-4	2115-2116	)	_	_
14-5	2116-2117	\]	_	_
14-6	2117-2118	(	_	_
14-7	2118-2123	https	_	_
14-8	2123-2124	:	_	_
14-9	2124-2125	/	_	_
14-10	2125-2126	/	_	_
14-11	2126-2136	github.com	_	_
14-12	2136-2137	/	_	_
14-13	2137-2141	fmu2	_	_
14-14	2141-2142	/	_	_
14-15	2142-2154	snag\_release	_	_
14-16	2154-2155	)	_	_
14-17	2157-2158	\[	_	_
14-18	2158-2159	!	_	_

#Text=\[github\](https://img.shields.io/github/stars/fmu2/snag\_release.svg?
15-1	2159-2160	\[	_	_
15-2	2160-2166	github	_	_
15-3	2166-2167	\]	_	_
15-4	2167-2168	(	_	_
15-5	2168-2173	https	_	_
15-6	2173-2174	:	_	_
15-7	2174-2175	/	_	_
15-8	2175-2176	/	_	_
15-9	2176-2190	img.shields.io	_	_
15-10	2190-2191	/	_	_
15-11	2191-2197	github	_	_
15-12	2197-2198	/	_	_
15-13	2198-2203	stars	_	_
15-14	2203-2204	/	_	_
15-15	2204-2208	fmu2	_	_
15-16	2208-2209	/	_	_
15-17	2209-2225	snag\_release.svg	_	_
15-18	2225-2226	?	_	_

#Text=style=social)\](https://github.com/fmu2/snag\_release)  \[!
16-1	2226-2231	style	_	_
16-2	2231-2232	=	_	_
16-3	2232-2238	social	_	_
16-4	2238-2239	)	_	_
16-5	2239-2240	\]	_	_
16-6	2240-2241	(	_	_
16-7	2241-2246	https	_	_
16-8	2246-2247	:	_	_
16-9	2247-2248	/	_	_
16-10	2248-2249	/	_	_
16-11	2249-2259	github.com	_	_
16-12	2259-2260	/	_	_
16-13	2260-2264	fmu2	_	_
16-14	2264-2265	/	_	_
16-15	2265-2277	snag\_release	_	_
16-16	2277-2278	)	_	_
16-17	2280-2281	\[	_	_
16-18	2281-2282	!	_	_

#Text=\[arXiv\](https://img.shields.io/badge/Arxiv-2404.02257-b31b1b.svg?
17-1	2282-2283	\[	_	_
17-2	2283-2288	arXiv	_	_
17-3	2288-2289	\]	_	_
17-4	2289-2290	(	_	_
17-5	2290-2295	https	_	_
17-6	2295-2296	:	_	_
17-7	2296-2297	/	_	_
17-8	2297-2298	/	_	_
17-9	2298-2312	img.shields.io	_	_
17-10	2312-2313	/	_	_
17-11	2313-2318	badge	_	_
17-12	2318-2319	/	_	_
17-13	2319-2324	Arxiv	_	_
17-14	2324-2325	-	_	_
17-15	2325-2335	2404.02257	_	_
17-16	2335-2336	-	_	_
17-17	2336-2346	b31b1b.svg	_	_
17-18	2346-2347	?	_	_

#Text=logo=arXiv)\](https://arxiv.org/abs/2404.02257) <br>  ## Changelog \* 11/18/2022: We have released the \[tech report\](https://arxiv.org/abs/2211.09074) for our submission to the \[Ego4D Moment Queries (MQ) Challenge\](https://eval.ai/web/challenges/challenge-page/1626/overview).
18-1	2347-2351	logo	_	_
18-2	2351-2352	=	_	_
18-3	2352-2357	arXiv	_	_
18-4	2357-2358	)	_	_
18-5	2358-2359	\]	_	_
18-6	2359-2360	(	_	_
18-7	2360-2365	https	_	_
18-8	2365-2366	:	_	_
18-9	2366-2367	/	_	_
18-10	2367-2368	/	_	_
18-11	2368-2377	arxiv.org	_	_
18-12	2377-2378	/	_	_
18-13	2378-2381	abs	_	_
18-14	2381-2382	/	_	_
18-15	2382-2392	2404.02257	_	_
18-16	2392-2393	)	_	_
18-17	2394-2395	<	_	_
18-18	2395-2397	br	_	_
18-19	2397-2398	>	_	_
18-20	2400-2401	#	_	_
18-21	2401-2402	#	_	_
18-22	2403-2412	Changelog	_	_
18-23	2413-2414	\*	_	_
18-24	2415-2417	11	_	_
18-25	2417-2418	/	_	_
18-26	2418-2420	18	_	_
18-27	2420-2421	/	_	_
18-28	2421-2425	2022	_	_
18-29	2425-2426	:	_	_
18-30	2427-2429	We	_	_
18-31	2430-2434	have	_	_
18-32	2435-2443	released	_	_
18-33	2444-2447	the	_	_
18-34	2448-2449	\[	_	_
18-35	2449-2453	tech	_	_
18-36	2454-2460	report	_	_
18-37	2460-2461	\]	_	_
18-38	2461-2462	(	_	_
18-39	2462-2467	https	_	_
18-40	2467-2468	:	_	_
18-41	2468-2469	/	_	_
18-42	2469-2470	/	_	_
18-43	2470-2479	arxiv.org	_	_
18-44	2479-2480	/	_	_
18-45	2480-2483	abs	_	_
18-46	2483-2484	/	_	_
18-47	2484-2494	2211.09074	_	_
18-48	2494-2495	)	_	_
18-49	2496-2499	for	_	_
18-50	2500-2503	our	_	_
18-51	2504-2514	submission	_	_
18-52	2515-2517	to	_	_
18-53	2518-2521	the	_	_
18-54	2522-2523	\[	_	_
18-55	2523-2528	Ego4D	_	_
18-56	2529-2535	Moment	_	_
18-57	2536-2543	Queries	_	_
18-58	2544-2545	(	_	_
18-59	2545-2547	MQ	_	_
18-60	2547-2548	)	_	_
18-61	2549-2558	Challenge	_	_
18-62	2558-2559	\]	_	_
18-63	2559-2560	(	_	_
18-64	2560-2565	https	_	_
18-65	2565-2566	:	_	_
18-66	2566-2567	/	_	_
18-67	2567-2568	/	_	_
18-68	2568-2575	eval.ai	_	_
18-69	2575-2576	/	_	_
18-70	2576-2579	web	_	_
18-71	2579-2580	/	_	_
18-72	2580-2590	challenges	_	_
18-73	2590-2591	/	_	_
18-74	2591-2605	challenge-page	_	_
18-75	2605-2606	/	_	_
18-76	2606-2610	1626	_	_
18-77	2610-2611	/	_	_
18-78	2611-2619	overview	_	_
18-79	2619-2620	)	_	_
18-80	2620-2621	.	_	_

#Text=The code repo now includes config files, pre-trained models and results on the Ego4D MQ benchmark
19-1	2622-2625	The	_	_
19-2	2626-2630	code	_	_
19-3	2631-2635	repo	_	_
19-4	2636-2639	now	_	_
19-5	2640-2648	includes	_	_
19-6	2649-2655	config	_	_
19-7	2656-2661	files	_	_
19-8	2661-2662	,	_	_
19-9	2663-2674	pre-trained	_	_
19-10	2675-2681	models	_	_
19-11	2682-2685	and	_	_
19-12	2686-2693	results	_	_
19-13	2694-2696	on	_	_
19-14	2697-2700	the	_	_
19-15	2701-2706	Ego4D	_	_
19-16	2707-2709	MQ	_	_
19-17	2710-2719	benchmark	_	_

#Text=.
20-1	2719-2720	.	_	_

#Text=\* 08/29/2022: Updated arXiv version
21-1	2722-2723	\*	_	_
21-2	2724-2726	08	_	_
21-3	2726-2727	/	_	_
21-4	2727-2729	29	_	_
21-5	2729-2730	/	_	_
21-6	2730-2734	2022	_	_
21-7	2734-2735	:	_	_
21-8	2736-2743	Updated	_	_
21-9	2744-2749	arXiv	_	_
21-10	2750-2757	version	_	_

#Text=.
22-1	2757-2758	.	_	_

#Text=\* 08/01/2022: Updated code repo with latest results on ActivityNet
23-1	2760-2761	\*	_	_
23-2	2762-2764	08	_	_
23-3	2764-2765	/	_	_
23-4	2765-2767	01	_	_
23-5	2767-2768	/	_	_
23-6	2768-2772	2022	_	_
23-7	2772-2773	:	_	_
23-8	2774-2781	Updated	_	_
23-9	2782-2786	code	_	_
23-10	2787-2791	repo	_	_
23-11	2792-2796	with	_	_
23-12	2797-2803	latest	_	_
23-13	2804-2811	results	_	_
23-14	2812-2814	on	_	_
23-15	2815-2826	ActivityNet	_	_

#Text=.
24-1	2826-2827	.	_	_

#Text=\* 07/08/2022: The paper is accepted to ECCV 2022
25-1	2829-2830	\*	_	_
25-2	2831-2833	07	_	_
25-3	2833-2834	/	_	_
25-4	2834-2836	08	_	_
25-5	2836-2837	/	_	_
25-6	2837-2841	2022	_	_
25-7	2841-2842	:	_	_
25-8	2843-2846	The	_	_
25-9	2847-2852	paper	_	_
25-10	2853-2855	is	_	_
25-11	2856-2864	accepted	_	_
25-12	2865-2867	to	_	_
25-13	2868-2872	ECCV	_	_
25-14	2873-2877	2022	_	_

#Text=.
26-1	2877-2878	.	_	_

#Text=\* 05/09/2022: Pre-trained models have been updated
27-1	2880-2881	\*	_	_
27-2	2882-2884	05	_	_
27-3	2884-2885	/	_	_
27-4	2885-2887	09	_	_
27-5	2887-2888	/	_	_
27-6	2888-2892	2022	_	_
27-7	2892-2893	:	_	_
27-8	2894-2905	Pre-trained	_	_
27-9	2906-2912	models	_	_
27-10	2913-2917	have	_	_
27-11	2918-2922	been	_	_
27-12	2923-2930	updated	_	_

#Text=.
28-1	2930-2931	.	_	_

#Text=\* 05/08/2022: We have updated the code repo based on the community feedback and our code review, leading to significantly better average mAP on THUMOS14 (>66.0%) and slightly improved results on ActivityNet and EPIC-Kitchens 100.   ## Code Overview The structure of this code repo is heavily inspired by Detectron2.
29-1	2933-2934	\*	_	_
29-2	2935-2937	05	_	_
29-3	2937-2938	/	_	_
29-4	2938-2940	08	_	_
29-5	2940-2941	/	_	_
29-6	2941-2945	2022	_	_
29-7	2945-2946	:	_	_
29-8	2947-2949	We	_	_
29-9	2950-2954	have	_	_
29-10	2955-2962	updated	_	_
29-11	2963-2966	the	_	_
29-12	2967-2971	code	_	_
29-13	2972-2976	repo	_	_
29-14	2977-2982	based	_	_
29-15	2983-2985	on	_	_
29-16	2986-2989	the	_	_
29-17	2990-2999	community	_	_
29-18	3000-3008	feedback	_	_
29-19	3009-3012	and	_	_
29-20	3013-3016	our	_	_
29-21	3017-3021	code	_	_
29-22	3022-3028	review	_	_
29-23	3028-3029	,	_	_
29-24	3030-3037	leading	_	_
29-25	3038-3040	to	_	_
29-26	3041-3054	significantly	_	_
29-27	3055-3061	better	_	_
29-28	3062-3069	average	_	_
29-29	3070-3073	mAP	_	_
29-30	3074-3076	on	_	_
29-31	3077-3085	THUMOS14	_	_
29-32	3086-3087	(	_	_
29-33	3087-3088	>	_	_
29-34	3088-3093	66.0%	_	_
29-35	3093-3094	)	_	_
29-36	3095-3098	and	_	_
29-37	3099-3107	slightly	_	_
29-38	3108-3116	improved	_	_
29-39	3117-3124	results	_	_
29-40	3125-3127	on	_	_
29-41	3128-3139	ActivityNet	_	_
29-42	3140-3143	and	_	_
29-43	3144-3157	EPIC-Kitchens	_	_
29-44	3158-3161	100	_	_
29-45	3161-3162	.	_	_
29-46	3165-3166	#	_	_
29-47	3166-3167	#	_	_
29-48	3168-3172	Code	_	_
29-49	3173-3181	Overview	_	_
29-50	3182-3185	The	_	_
29-51	3186-3195	structure	_	_
29-52	3196-3198	of	_	_
29-53	3199-3203	this	_	_
29-54	3204-3208	code	_	_
29-55	3209-3213	repo	_	_
29-56	3214-3216	is	_	_
29-57	3217-3224	heavily	_	_
29-58	3225-3233	inspired	_	_
29-59	3234-3236	by	_	_
29-60	3237-3247	Detectron2	_	_
29-61	3247-3248	.	_	_

#Text=Some of the main components are \* .
30-1	3249-3253	Some	_	_
30-2	3254-3256	of	_	_
30-3	3257-3260	the	_	_
30-4	3261-3265	main	_	_
30-5	3266-3276	components	_	_
30-6	3277-3280	are	_	_
30-7	3281-3282	\*	_	_
30-8	3283-3284	.	_	_

#Text=/libs/core: Parameter configuration module. \* .
31-1	3284-3285	/	_	_
31-2	3285-3289	libs	_	_
31-3	3289-3290	/	_	_
31-4	3290-3294	core	_	_
31-5	3294-3295	:	_	_
31-6	3296-3305	Parameter	_	_
31-7	3306-3319	configuration	_	_
31-8	3320-3326	module	_	_
31-9	3326-3327	.	_	_
31-10	3328-3329	\*	_	_
31-11	3330-3331	.	_	_

#Text=/libs/datasets: Data loader and IO module. \* .
32-1	3331-3332	/	_	_
32-2	3332-3336	libs	_	_
32-3	3336-3337	/	_	_
32-4	3337-3345	datasets	_	_
32-5	3345-3346	:	_	_
32-6	3347-3351	Data	_	_
32-7	3352-3358	loader	_	_
32-8	3359-3362	and	_	_
32-9	3363-3365	IO	_	_
32-10	3366-3372	module	_	_
32-11	3372-3373	.	_	_
32-12	3374-3375	\*	_	_
32-13	3376-3377	.	_	_

#Text=/libs/modeling: Our main model with all its building blocks. \* .
33-1	3377-3378	/	_	_
33-2	3378-3382	libs	_	_
33-3	3382-3383	/	_	_
33-4	3383-3391	modeling	_	_
33-5	3391-3392	:	_	_
33-6	3393-3396	Our	_	_
33-7	3397-3401	main	_	_
33-8	3402-3407	model	_	_
33-9	3408-3412	with	_	_
33-10	3413-3416	all	_	_
33-11	3417-3420	its	_	_
33-12	3421-3429	building	_	_
33-13	3430-3436	blocks	_	_
33-14	3436-3437	.	_	_
33-15	3438-3439	\*	_	_
33-16	3440-3441	.	_	_

#Text=/libs/utils: Utility functions for training, inference, and postprocessing.  ## Installation \* Follow INSTALL.md for installing necessary dependencies and compiling the code.  ## Frequently Asked Questions \* See FAQ.md.   ## To Reproduce Our Results on THUMOS14 \*\*Download Features and Annotations\*\* \* Download \*thumos.tar.gz\* (`md5sum 375f76ffbf7447af1035e694971ec9b2`) from \[this Box link\](https://uwmadison.box.com/s/glpuxadymf3gd01m1cj6g5c3bn39qbgr) or \[this Google Drive link\](https://drive.google.com/file/d/1zt2eoldshf99vJMDuu8jqxda55dCyhZP/view?
34-1	3441-3442	/	_	_
34-2	3442-3446	libs	_	_
34-3	3446-3447	/	_	_
34-4	3447-3452	utils	_	_
34-5	3452-3453	:	_	_
34-6	3454-3461	Utility	_	_
34-7	3462-3471	functions	_	_
34-8	3472-3475	for	_	_
34-9	3476-3484	training	_	_
34-10	3484-3485	,	_	_
34-11	3486-3495	inference	_	_
34-12	3495-3496	,	_	_
34-13	3497-3500	and	_	_
34-14	3501-3515	postprocessing	_	_
34-15	3515-3516	.	_	_
34-16	3518-3519	#	_	_
34-17	3519-3520	#	_	_
34-18	3521-3533	Installation	_	_
34-19	3534-3535	\*	_	_
34-20	3536-3542	Follow	_	_
34-21	3543-3553	INSTALL.md	_	_
34-22	3554-3557	for	_	_
34-23	3558-3568	installing	_	_
34-24	3569-3578	necessary	_	_
34-25	3579-3591	dependencies	_	_
34-26	3592-3595	and	_	_
34-27	3596-3605	compiling	_	_
34-28	3606-3609	the	_	_
34-29	3610-3614	code	_	_
34-30	3614-3615	.	_	_
34-31	3617-3618	#	_	_
34-32	3618-3619	#	_	_
34-33	3620-3630	Frequently	_	_
34-34	3631-3636	Asked	_	_
34-35	3637-3646	Questions	_	_
34-36	3647-3648	\*	_	_
34-37	3649-3652	See	_	_
34-38	3653-3659	FAQ.md	_	_
34-39	3659-3660	.	_	_
34-40	3663-3664	#	_	_
34-41	3664-3665	#	_	_
34-42	3666-3668	To	_	_
34-43	3669-3678	Reproduce	_	_
34-44	3679-3682	Our	_	_
34-45	3683-3690	Results	_	_
34-46	3691-3693	on	_	_
34-47	3694-3702	THUMOS14	_	_
34-48	3703-3704	\*	_	_
34-49	3704-3705	\*	_	_
34-50	3705-3713	Download	_	_
34-51	3714-3722	Features	_	_
34-52	3723-3726	and	_	_
34-53	3727-3738	Annotations	_	_
34-54	3738-3739	\*	_	_
34-55	3739-3740	\*	_	_
34-56	3741-3742	\*	_	_
34-57	3743-3751	Download	_	_
34-58	3752-3753	\*	_	_
34-59	3753-3766	thumos.tar.gz	_	_
34-59	3753-3759	thumos	_	_
34-60	3766-3767	\*	_	_
34-61	3768-3769	(	_	_
34-62	3769-3770	`	_	_
34-63	3770-3776	md5sum	_	_
34-64	3777-3809	375f76ffbf7447af1035e694971ec9b2	_	_
34-65	3809-3810	`	_	_
34-66	3810-3811	)	_	_
34-67	3812-3816	from	_	_
34-68	3817-3818	\[	_	_
34-69	3818-3822	this	_	_
34-70	3823-3826	Box	_	_
34-71	3827-3831	link	_	_
34-72	3831-3832	\]	_	_
34-73	3832-3833	(	_	_
34-74	3833-3838	https	_	_
34-75	3838-3839	:	_	_
34-76	3839-3840	/	_	_
34-77	3840-3841	/	_	_
34-78	3841-3858	uwmadison.box.com	_	_
34-79	3858-3859	/	_	_
34-80	3859-3860	s	_	_
34-81	3860-3861	/	_	_
34-82	3861-3893	glpuxadymf3gd01m1cj6g5c3bn39qbgr	_	_
34-83	3893-3894	)	_	_
34-84	3895-3897	or	_	_
34-85	3898-3899	\[	_	_
34-86	3899-3903	this	_	_
34-87	3904-3910	Google	_	_
34-88	3911-3916	Drive	_	_
34-89	3917-3921	link	_	_
34-90	3921-3922	\]	_	_
34-91	3922-3923	(	_	_
34-92	3923-3928	https	_	_
34-93	3928-3929	:	_	_
34-94	3929-3930	/	_	_
34-95	3930-3931	/	_	_
34-96	3931-3947	drive.google.com	_	_
34-97	3947-3948	/	_	_
34-98	3948-3952	file	_	_
34-99	3952-3953	/	_	_
34-100	3953-3954	d	_	_
34-101	3954-3955	/	_	_
34-102	3955-3988	1zt2eoldshf99vJMDuu8jqxda55dCyhZP	_	_
34-103	3988-3989	/	_	_
34-104	3989-3993	view	_	_
34-105	3993-3994	?	_	_

#Text=usp=sharing) or \[this BaiduYun link\](https://pan.baidu.com/s/1TgS91LVV-vzFTgIHl1AEGA?
35-1	3994-3997	usp	_	_
35-2	3997-3998	=	_	_
35-3	3998-4005	sharing	_	_
35-4	4005-4006	)	_	_
35-5	4007-4009	or	_	_
35-6	4010-4011	\[	_	_
35-7	4011-4015	this	_	_
35-8	4016-4024	BaiduYun	_	_
35-9	4025-4029	link	_	_
35-10	4029-4030	\]	_	_
35-11	4030-4031	(	_	_
35-12	4031-4036	https	_	_
35-13	4036-4037	:	_	_
35-14	4037-4038	/	_	_
35-15	4038-4039	/	_	_
35-16	4039-4052	pan.baidu.com	_	_
35-17	4052-4053	/	_	_
35-18	4053-4054	s	_	_
35-19	4054-4055	/	_	_
35-20	4055-4078	1TgS91LVV-vzFTgIHl1AEGA	_	_
35-21	4078-4079	?	_	_

#Text=pwd=74eh). \* The file includes I3D features, action annotations in json format (similar to ActivityNet annotation format), and external classification scores.
36-1	4079-4082	pwd	_	_
36-2	4082-4083	=	_	_
36-3	4083-4087	74eh	_	_
36-4	4087-4088	)	_	_
36-5	4088-4089	.	_	_
36-6	4090-4091	\*	_	_
36-7	4092-4095	The	_	_
36-8	4096-4100	file	_	_
36-9	4101-4109	includes	_	_
36-10	4110-4113	I3D	_	_
36-11	4114-4122	features	_	_
36-12	4122-4123	,	_	_
36-13	4124-4130	action	_	_
36-14	4131-4142	annotations	_	_
36-15	4143-4145	in	_	_
36-16	4146-4150	json	_	_
36-17	4151-4157	format	_	_
36-18	4158-4159	(	_	_
36-19	4159-4166	similar	_	_
36-20	4167-4169	to	_	_
36-21	4170-4181	ActivityNet	_	_
36-22	4182-4192	annotation	_	_
36-23	4193-4199	format	_	_
36-24	4199-4200	)	_	_
36-25	4200-4201	,	_	_
36-26	4202-4205	and	_	_
36-27	4206-4214	external	_	_
36-28	4215-4229	classification	_	_
36-29	4230-4236	scores	_	_
36-30	4236-4237	.	_	_

#Text=\*\*Details\*\*: The features are extracted from two-stream I3D models pretrained on Kinetics using clips of `16 frames` at the video frame rate (`~30 fps`) and a stride of `4 frames`.
37-1	4239-4240	\*	_	_
37-2	4240-4241	\*	_	_
37-3	4241-4248	Details	_	_
37-4	4248-4249	\*	_	_
37-5	4249-4250	\*	_	_
37-6	4250-4251	:	_	_
37-7	4252-4255	The	_	_
37-8	4256-4264	features	_	_
37-9	4265-4268	are	_	_
37-10	4269-4278	extracted	_	_
37-11	4279-4283	from	_	_
37-12	4284-4294	two-stream	_	_
37-13	4295-4298	I3D	_	_
37-14	4299-4305	models	_	_
37-15	4306-4316	pretrained	_	_
37-16	4317-4319	on	_	_
37-17	4320-4328	Kinetics	_	_
37-18	4329-4334	using	_	_
37-19	4335-4340	clips	_	_
37-20	4341-4343	of	_	_
37-21	4344-4345	`	_	_
37-22	4345-4347	16	_	_
37-23	4348-4354	frames	_	_
37-24	4354-4355	`	_	_
37-25	4356-4358	at	_	_
37-26	4359-4362	the	_	_
37-27	4363-4368	video	_	_
37-28	4369-4374	frame	_	_
37-29	4375-4379	rate	_	_
37-30	4380-4381	(	_	_
37-31	4381-4382	`	_	_
37-32	4382-4383	~	_	_
37-33	4383-4385	30	_	_
37-34	4386-4389	fps	_	_
37-35	4389-4390	`	_	_
37-36	4390-4391	)	_	_
37-37	4392-4395	and	_	_
37-38	4396-4397	a	_	_
37-39	4398-4404	stride	_	_
37-40	4405-4407	of	_	_
37-41	4408-4409	`	_	_
37-42	4409-4410	4	_	_
37-43	4411-4417	frames	_	_
37-44	4417-4418	`	_	_
37-45	4418-4419	.	_	_

#Text=This gives one feature vector per `4/30 ~= 0.1333` seconds.
38-1	4420-4424	This	_	_
38-2	4425-4430	gives	_	_
38-3	4431-4434	one	_	_
38-4	4435-4442	feature	_	_
38-5	4443-4449	vector	_	_
38-6	4450-4453	per	_	_
38-7	4454-4455	`	_	_
38-8	4455-4456	4	_	_
38-9	4456-4457	/	_	_
38-10	4457-4459	30	_	_
38-11	4460-4461	~	_	_
38-12	4461-4462	=	_	_
38-13	4463-4469	0.1333	_	_
38-14	4469-4470	`	_	_
38-15	4471-4478	seconds	_	_
38-16	4478-4479	.	_	_

#Text=\*\*Unpack Features and Annotations\*\* \* Unpack the file under \*.
39-1	4481-4482	\*	_	_
39-2	4482-4483	\*	_	_
39-3	4483-4489	Unpack	_	_
39-4	4490-4498	Features	_	_
39-5	4499-4502	and	_	_
39-6	4503-4514	Annotations	_	_
39-7	4514-4515	\*	_	_
39-8	4515-4516	\*	_	_
39-9	4517-4518	\*	_	_
39-10	4519-4525	Unpack	_	_
39-11	4526-4529	the	_	_
39-12	4530-4534	file	_	_
39-13	4535-4540	under	_	_
39-14	4541-4542	\*	_	_
39-15	4542-4543	.	_	_

#Text=/data\* (or elsewhere and link to \*.
40-1	4543-4544	/	_	_
40-2	4544-4548	data	_	_
40-3	4548-4549	\*	_	_
40-4	4550-4551	(	_	_
40-5	4551-4553	or	_	_
40-6	4554-4563	elsewhere	_	_
40-7	4564-4567	and	_	_
40-8	4568-4572	link	_	_
40-9	4573-4575	to	_	_
40-10	4576-4577	\*	_	_
40-11	4577-4578	.	_	_

#Text=/data\*). \* The folder structure should look like ``` This folder │   README.md │
41-1	4578-4579	/	_	_
41-2	4579-4583	data	_	_
41-3	4583-4584	\*	_	_
41-4	4584-4585	)	_	_
41-5	4585-4586	.	_	_
41-6	4587-4588	\*	_	_
41-7	4589-4592	The	_	_
41-8	4593-4599	folder	_	_
41-9	4600-4609	structure	_	_
41-10	4610-4616	should	_	_
41-11	4617-4621	look	_	_
41-12	4622-4626	like	_	_
41-13	4627-4628	`	_	_
41-14	4628-4629	`	_	_
41-15	4629-4630	`	_	_
41-16	4631-4635	This	_	_
41-17	4636-4642	folder	_	_
41-18	4643-4644	│	_	_
41-19	4647-4656	README.md	_	_
41-20	4657-4658	│	_	_

#Text=.
42-1	4661-4662	.	_	_

#Text=.
43-1	4662-4663	.	_	_

#Text=.
44-1	4663-4664	.	_	_

#Text=│ └───data/ │    └───thumos/ │    │  └───annotations │    │  └───i3d\_features    │    └───... \| └───libs │ │   ... ```  \*\*Training and Evaluation\*\* \* Train our ActionFormer with I3D features.
45-1	4667-4668	│	_	_
45-2	4669-4670	└	_	_
45-3	4670-4671	─	_	_
45-4	4671-4672	─	_	_
45-5	4672-4673	─	_	_
45-6	4673-4677	data	_	_
45-7	4677-4678	/	_	_
45-8	4679-4680	│	_	_
45-9	4684-4685	└	_	_
45-10	4685-4686	─	_	_
45-11	4686-4687	─	_	_
45-12	4687-4688	─	_	_
45-13	4688-4694	thumos	_	_
45-14	4694-4695	/	_	_
45-15	4696-4697	│	_	_
45-16	4701-4702	│	_	_
45-17	4704-4705	└	_	_
45-18	4705-4706	─	_	_
45-19	4706-4707	─	_	_
45-20	4707-4708	─	_	_
45-21	4708-4719	annotations	_	_
45-22	4720-4721	│	_	_
45-23	4725-4726	│	_	_
45-24	4728-4729	└	_	_
45-25	4729-4730	─	_	_
45-26	4730-4731	─	_	_
45-27	4731-4732	─	_	_
45-28	4732-4744	i3d\_features	_	_
45-29	4748-4749	│	_	_
45-30	4753-4754	└	_	_
45-31	4754-4755	─	_	_
45-32	4755-4756	─	_	_
45-33	4756-4757	─	_	_
45-34	4757-4758	.	_	_
45-35	4758-4759	.	_	_
45-36	4759-4760	.	_	_
45-37	4761-4762	\|	_	_
45-38	4763-4764	└	_	_
45-39	4764-4765	─	_	_
45-40	4765-4766	─	_	_
45-41	4766-4767	─	_	_
45-42	4767-4771	libs	_	_
45-43	4772-4773	│	_	_
45-44	4774-4775	│	_	_
45-45	4778-4779	.	_	_
45-46	4779-4780	.	_	_
45-47	4780-4781	.	_	_
45-48	4782-4783	`	_	_
45-49	4783-4784	`	_	_
45-50	4784-4785	`	_	_
45-51	4787-4788	\*	_	_
45-52	4788-4789	\*	_	_
45-53	4789-4797	Training	_	_
45-54	4798-4801	and	_	_
45-55	4802-4812	Evaluation	_	_
45-56	4812-4813	\*	_	_
45-57	4813-4814	\*	_	_
45-58	4815-4816	\*	_	_
45-59	4817-4822	Train	_	_
45-60	4823-4826	our	_	_
45-61	4827-4839	ActionFormer	_	_
45-62	4840-4844	with	_	_
45-63	4845-4848	I3D	_	_
45-64	4849-4857	features	_	_
45-65	4857-4858	.	_	_

#Text=This will create an experiment folder under \*.
46-1	4859-4863	This	_	_
46-2	4864-4868	will	_	_
46-3	4869-4875	create	_	_
46-4	4876-4878	an	_	_
46-5	4879-4889	experiment	_	_
46-6	4890-4896	folder	_	_
46-7	4897-4902	under	_	_
46-8	4903-4904	\*	_	_
46-9	4904-4905	.	_	_

#Text=/ckpt\* that stores training config, logs, and checkpoints.
47-1	4905-4906	/	_	_
47-2	4906-4910	ckpt	_	_
47-3	4910-4911	\*	_	_
47-4	4912-4916	that	_	_
47-5	4917-4923	stores	_	_
47-6	4924-4932	training	_	_
47-7	4933-4939	config	_	_
47-8	4939-4940	,	_	_
47-9	4941-4945	logs	_	_
47-10	4945-4946	,	_	_
47-11	4947-4950	and	_	_
47-12	4951-4962	checkpoints	_	_
47-13	4962-4963	.	_	_

#Text=```shell python .
48-1	4964-4965	`	_	_
48-2	4965-4966	`	_	_
48-3	4966-4967	`	_	_
48-4	4967-4972	shell	_	_
48-5	4973-4979	python	_	_
48-6	4980-4981	.	_	_

#Text=/train.py .
49-1	4981-4982	/	_	_
49-2	4982-4990	train.py	_	_
49-3	4991-4992	.	_	_

#Text=/configs/thumos\_i3d.yaml --output reproduce ``` \* \[Optional\] Monitor the training using TensorBoard ```shell tensorboard --logdir=.
50-1	4992-4993	/	_	_
50-2	4993-5000	configs	_	_
50-3	5000-5001	/	_	_
50-4	5001-5016	thumos\_i3d.yaml	_	_
50-4	5001-5007	thumos	_	_
50-5	5017-5018	-	_	_
50-6	5018-5019	-	_	_
50-7	5019-5025	output	_	_
50-8	5026-5035	reproduce	_	_
50-9	5036-5037	`	_	_
50-10	5037-5038	`	_	_
50-11	5038-5039	`	_	_
50-12	5040-5041	\*	_	_
50-13	5042-5043	\[	_	_
50-14	5043-5051	Optional	_	_
50-15	5051-5052	\]	_	_
50-16	5053-5060	Monitor	_	_
50-17	5061-5064	the	_	_
50-18	5065-5073	training	_	_
50-19	5074-5079	using	_	_
50-20	5080-5091	TensorBoard	_	_
50-21	5092-5093	`	_	_
50-22	5093-5094	`	_	_
50-23	5094-5095	`	_	_
50-24	5095-5100	shell	_	_
50-25	5101-5112	tensorboard	_	_
50-26	5113-5114	-	_	_
50-27	5114-5115	-	_	_
50-28	5115-5121	logdir	_	_
50-29	5121-5122	=	_	_
50-30	5122-5123	.	_	_

#Text=/ckpt/thumos\_i3d\_reproduce/logs ``` \* Evaluate the trained model.
51-1	5123-5124	/	_	_
51-2	5124-5128	ckpt	_	_
51-3	5128-5129	/	_	_
51-4	5129-5149	thumos\_i3d\_reproduce	_	_
51-4	5129-5135	thumos	_	_
51-5	5149-5150	/	_	_
51-6	5150-5154	logs	_	_
51-7	5155-5156	`	_	_
51-8	5156-5157	`	_	_
51-9	5157-5158	`	_	_
51-10	5159-5160	\*	_	_
51-11	5161-5169	Evaluate	_	_
51-12	5170-5173	the	_	_
51-13	5174-5181	trained	_	_
51-14	5182-5187	model	_	_
51-15	5187-5188	.	_	_

#Text=The expected average mAP should be around 62.6(%) as in Table 1 of our main paper.
52-1	5189-5192	The	_	_
52-2	5193-5201	expected	_	_
52-3	5202-5209	average	_	_
52-4	5210-5213	mAP	_	_
52-5	5214-5220	should	_	_
52-6	5221-5223	be	_	_
52-7	5224-5230	around	_	_
52-8	5231-5235	62.6	_	_
52-9	5235-5236	(	_	_
52-10	5236-5237	%	_	_
52-11	5237-5238	)	_	_
52-12	5239-5241	as	_	_
52-13	5242-5244	in	_	_
52-14	5245-5250	Table	_	_
52-15	5251-5252	1	_	_
52-16	5253-5255	of	_	_
52-17	5256-5259	our	_	_
52-18	5260-5264	main	_	_
52-19	5265-5270	paper	_	_
52-20	5270-5271	.	_	_

#Text=\*\*With recent commits, the expected average mAP should be higher than 66.0(%)\*\*.
53-1	5272-5273	\*	_	_
53-2	5273-5274	\*	_	_
53-3	5274-5278	With	_	_
53-4	5279-5285	recent	_	_
53-5	5286-5293	commits	_	_
53-6	5293-5294	,	_	_
53-7	5295-5298	the	_	_
53-8	5299-5307	expected	_	_
53-9	5308-5315	average	_	_
53-10	5316-5319	mAP	_	_
53-11	5320-5326	should	_	_
53-12	5327-5329	be	_	_
53-13	5330-5336	higher	_	_
53-14	5337-5341	than	_	_
53-15	5342-5346	66.0	_	_
53-16	5346-5347	(	_	_
53-17	5347-5348	%	_	_
53-18	5348-5349	)	_	_
53-19	5349-5350	\*	_	_
53-20	5350-5351	\*	_	_
53-21	5351-5352	.	_	_

#Text=```shell python .
54-1	5353-5354	`	_	_
54-2	5354-5355	`	_	_
54-3	5355-5356	`	_	_
54-4	5356-5361	shell	_	_
54-5	5362-5368	python	_	_
54-6	5369-5370	.	_	_

#Text=/eval.py .
55-1	5370-5371	/	_	_
55-2	5371-5378	eval.py	_	_
55-3	5379-5380	.	_	_

#Text=/configs/thumos\_i3d.yaml .
56-1	5380-5381	/	_	_
56-2	5381-5388	configs	_	_
56-3	5388-5389	/	_	_
56-4	5389-5404	thumos\_i3d.yaml	_	_
56-4	5389-5395	thumos	_	_
56-5	5405-5406	.	_	_

#Text=/ckpt/thumos\_i3d\_reproduce ``` \* Training our model on THUMOS requires ~4.5GB GPU memory, yet the inference might require over 10GB GPU memory.
57-1	5406-5407	/	_	_
57-2	5407-5411	ckpt	_	_
57-3	5411-5412	/	_	_
57-4	5412-5432	thumos\_i3d\_reproduce	_	_
57-4	5412-5418	thumos	_	_
57-5	5433-5434	`	_	_
57-6	5434-5435	`	_	_
57-7	5435-5436	`	_	_
57-8	5437-5438	\*	_	_
57-9	5439-5447	Training	_	_
57-10	5448-5451	our	_	_
57-11	5452-5457	model	_	_
57-12	5458-5460	on	_	_
57-13	5461-5467	THUMOS	_	_
57-14	5468-5476	requires	_	_
57-15	5477-5478	~	_	_
57-16	5478-5483	4.5GB	_	_
57-17	5484-5487	GPU	_	_
57-18	5488-5494	memory	_	_
57-19	5494-5495	,	_	_
57-20	5496-5499	yet	_	_
57-21	5500-5503	the	_	_
57-22	5504-5513	inference	_	_
57-23	5514-5519	might	_	_
57-24	5520-5527	require	_	_
57-25	5528-5532	over	_	_
57-26	5533-5537	10GB	_	_
57-27	5538-5541	GPU	_	_
57-28	5542-5548	memory	_	_
57-29	5548-5549	.	_	_

#Text=We recommend using a GPU with at least 12 GB of memory.
58-1	5550-5552	We	_	_
58-2	5553-5562	recommend	_	_
58-3	5563-5568	using	_	_
58-4	5569-5570	a	_	_
58-5	5571-5574	GPU	_	_
58-6	5575-5579	with	_	_
58-7	5580-5582	at	_	_
58-8	5583-5588	least	_	_
58-9	5589-5591	12	_	_
58-10	5592-5594	GB	_	_
58-11	5595-5597	of	_	_
58-12	5598-5604	memory	_	_
58-13	5604-5605	.	_	_

#Text=\*\*\[Optional\] Evaluating Our Pre-trained Model\*\*  We also provide a pre-trained model for THUMOS 14.
59-1	5607-5608	\*	_	_
59-2	5608-5609	\*	_	_
59-3	5609-5610	\[	_	_
59-4	5610-5618	Optional	_	_
59-5	5618-5619	\]	_	_
59-6	5620-5630	Evaluating	_	_
59-7	5631-5634	Our	_	_
59-8	5635-5646	Pre-trained	_	_
59-9	5647-5652	Model	_	_
59-10	5652-5653	\*	_	_
59-11	5653-5654	\*	_	_
59-12	5656-5658	We	_	_
59-13	5659-5663	also	_	_
59-14	5664-5671	provide	_	_
59-15	5672-5673	a	_	_
59-16	5674-5685	pre-trained	_	_
59-17	5686-5691	model	_	_
59-18	5692-5695	for	_	_
59-19	5696-5702	THUMOS	_	_
59-20	5703-5705	14	_	_
59-21	5705-5706	.	_	_

#Text=The model with all training logs can be downloaded from \[this Google Drive link\](https://drive.google.com/file/d/1isG3bc1dG5-llBRFCivJwz\_7c\_b0XDcY/view?
60-1	5707-5710	The	_	_
60-2	5711-5716	model	_	_
60-3	5717-5721	with	_	_
60-4	5722-5725	all	_	_
60-5	5726-5734	training	_	_
60-6	5735-5739	logs	_	_
60-7	5740-5743	can	_	_
60-8	5744-5746	be	_	_
60-9	5747-5757	downloaded	_	_
60-10	5758-5762	from	_	_
60-11	5763-5764	\[	_	_
60-12	5764-5768	this	_	_
60-13	5769-5775	Google	_	_
60-14	5776-5781	Drive	_	_
60-15	5782-5786	link	_	_
60-16	5786-5787	\]	_	_
60-17	5787-5788	(	_	_
60-18	5788-5793	https	_	_
60-19	5793-5794	:	_	_
60-20	5794-5795	/	_	_
60-21	5795-5796	/	_	_
60-22	5796-5812	drive.google.com	_	_
60-23	5812-5813	/	_	_
60-24	5813-5817	file	_	_
60-25	5817-5818	/	_	_
60-26	5818-5819	d	_	_
60-27	5819-5820	/	_	_
60-28	5820-5831	1isG3bc1dG5	_	_
60-29	5831-5832	-	_	_
60-30	5832-5843	llBRFCivJwz	_	_
60-31	5843-5844	\_	_	_
60-32	5844-5853	7c\_b0XDcY	_	_
60-33	5853-5854	/	_	_
60-34	5854-5858	view	_	_
60-35	5858-5859	?	_	_

#Text=usp=sharing).
61-1	5859-5862	usp	_	_
61-2	5862-5863	=	_	_
61-3	5863-5870	sharing	_	_
61-4	5870-5871	)	_	_
61-5	5871-5872	.	_	_

#Text=To evaluate the pre-trained model, please follow the steps listed below
62-1	5873-5875	To	_	_
62-2	5876-5884	evaluate	_	_
62-3	5885-5888	the	_	_
62-4	5889-5900	pre-trained	_	_
62-5	5901-5906	model	_	_
62-6	5906-5907	,	_	_
62-7	5908-5914	please	_	_
62-8	5915-5921	follow	_	_
62-9	5922-5925	the	_	_
62-10	5926-5931	steps	_	_
62-11	5932-5938	listed	_	_
62-12	5939-5944	below	_	_

#Text=.
63-1	5944-5945	.	_	_

#Text=\* Create a folder \*.
64-1	5947-5948	\*	_	_
64-2	5949-5955	Create	_	_
64-3	5956-5957	a	_	_
64-4	5958-5964	folder	_	_
64-5	5965-5966	\*	_	_
64-6	5966-5967	.	_	_

#Text=/pretrained\* and unpack the file under \*.
65-1	5967-5968	/	_	_
65-2	5968-5978	pretrained	_	_
65-3	5978-5979	\*	_	_
65-4	5980-5983	and	_	_
65-5	5984-5990	unpack	_	_
65-6	5991-5994	the	_	_
65-7	5995-5999	file	_	_
65-8	6000-6005	under	_	_
65-9	6006-6007	\*	_	_
65-10	6007-6008	.	_	_

#Text=/pretrained\* (or elsewhere and link to \*.
66-1	6008-6009	/	_	_
66-2	6009-6019	pretrained	_	_
66-3	6019-6020	\*	_	_
66-4	6021-6022	(	_	_
66-5	6022-6024	or	_	_
66-6	6025-6034	elsewhere	_	_
66-7	6035-6038	and	_	_
66-8	6039-6043	link	_	_
66-9	6044-6046	to	_	_
66-10	6047-6048	\*	_	_
66-11	6048-6049	.	_	_

#Text=/pretrained\*). \* The folder structure should look like ``` This folder │   README.md │
67-1	6049-6050	/	_	_
67-2	6050-6060	pretrained	_	_
67-3	6060-6061	\*	_	_
67-4	6061-6062	)	_	_
67-5	6062-6063	.	_	_
67-6	6064-6065	\*	_	_
67-7	6066-6069	The	_	_
67-8	6070-6076	folder	_	_
67-9	6077-6086	structure	_	_
67-10	6087-6093	should	_	_
67-11	6094-6098	look	_	_
67-12	6099-6103	like	_	_
67-13	6104-6105	`	_	_
67-14	6105-6106	`	_	_
67-15	6106-6107	`	_	_
67-16	6108-6112	This	_	_
67-17	6113-6119	folder	_	_
67-18	6120-6121	│	_	_
67-19	6124-6133	README.md	_	_
67-20	6134-6135	│	_	_

#Text=.
68-1	6138-6139	.	_	_

#Text=.
69-1	6139-6140	.	_	_

#Text=.
70-1	6140-6141	.	_	_

#Text=│ └───pretrained/ │    └───thumos\_i3d\_reproduce/ │    │  └───thumos\_reproduce\_log.txt │    │  └───thumos\_reproduce\_results.txt │    │   └───
71-1	6144-6145	│	_	_
71-2	6146-6147	└	_	_
71-3	6147-6148	─	_	_
71-4	6148-6149	─	_	_
71-5	6149-6150	─	_	_
71-6	6150-6160	pretrained	_	_
71-7	6160-6161	/	_	_
71-8	6162-6163	│	_	_
71-9	6167-6168	└	_	_
71-10	6168-6169	─	_	_
71-11	6169-6170	─	_	_
71-12	6170-6171	─	_	_
71-13	6171-6191	thumos\_i3d\_reproduce	_	_
71-13	6171-6177	thumos	_	_
71-14	6191-6192	/	_	_
71-15	6193-6194	│	_	_
71-16	6198-6199	│	_	_
71-17	6201-6202	└	_	_
71-18	6202-6203	─	_	_
71-19	6203-6204	─	_	_
71-20	6204-6205	─	_	_
71-21	6205-6229	thumos\_reproduce\_log.txt	_	_
71-21	6205-6211	thumos	_	_
71-22	6230-6231	│	_	_
71-23	6235-6236	│	_	_
71-24	6238-6239	└	_	_
71-25	6239-6240	─	_	_
71-26	6240-6241	─	_	_
71-27	6241-6242	─	_	_
71-28	6242-6270	thumos\_reproduce\_results.txt	_	_
71-28	6242-6248	thumos	_	_
71-29	6271-6272	│	_	_
71-30	6276-6277	│	_	_
71-31	6280-6281	└	_	_
71-32	6281-6282	─	_	_
71-33	6282-6283	─	_	_
71-34	6283-6284	─	_	_

#Text=.
72-1	6284-6285	.	_	_

#Text=.
73-1	6285-6286	.	_	_

#Text=.
74-1	6286-6287	.	_	_

#Text=│    └───... \| └───libs │ │   ... ``` \* The training config is recorded in \*.
75-1	6292-6293	│	_	_
75-2	6297-6298	└	_	_
75-3	6298-6299	─	_	_
75-4	6299-6300	─	_	_
75-5	6300-6301	─	_	_
75-6	6301-6302	.	_	_
75-7	6302-6303	.	_	_
75-8	6303-6304	.	_	_
75-9	6305-6306	\|	_	_
75-10	6307-6308	└	_	_
75-11	6308-6309	─	_	_
75-12	6309-6310	─	_	_
75-13	6310-6311	─	_	_
75-14	6311-6315	libs	_	_
75-15	6316-6317	│	_	_
75-16	6318-6319	│	_	_
75-17	6322-6323	.	_	_
75-18	6323-6324	.	_	_
75-19	6324-6325	.	_	_
75-20	6326-6327	`	_	_
75-21	6327-6328	`	_	_
75-22	6328-6329	`	_	_
75-23	6330-6331	\*	_	_
75-24	6332-6335	The	_	_
75-25	6336-6344	training	_	_
75-26	6345-6351	config	_	_
75-27	6352-6354	is	_	_
75-28	6355-6363	recorded	_	_
75-29	6364-6366	in	_	_
75-30	6367-6368	\*	_	_
75-31	6368-6369	.	_	_

#Text=/pretrained/thumos\_i3d\_reproduce/config.txt\*. \* The training log is located at \*.
76-1	6369-6370	/	_	_
76-2	6370-6380	pretrained	_	_
76-3	6380-6381	/	_	_
76-4	6381-6401	thumos\_i3d\_reproduce	_	_
76-4	6381-6387	thumos	_	_
76-5	6401-6402	/	_	_
76-6	6402-6412	config.txt	_	_
76-7	6412-6413	\*	_	_
76-8	6413-6414	.	_	_
76-9	6415-6416	\*	_	_
76-10	6417-6420	The	_	_
76-11	6421-6429	training	_	_
76-12	6430-6433	log	_	_
76-13	6434-6436	is	_	_
76-14	6437-6444	located	_	_
76-15	6445-6447	at	_	_
76-16	6448-6449	\*	_	_
76-17	6449-6450	.	_	_

#Text=/pretrained/thumos\_i3d\_reproduce/thumos\_reproduce\_log.txt\* and also \*.
77-1	6450-6451	/	_	_
77-2	6451-6461	pretrained	_	_
77-3	6461-6462	/	_	_
77-4	6462-6482	thumos\_i3d\_reproduce	_	_
77-4	6462-6468	thumos	_	_
77-5	6482-6483	/	_	_
77-6	6483-6507	thumos\_reproduce\_log.txt	_	_
77-7	6507-6508	\*	_	_
77-8	6509-6512	and	_	_
77-9	6513-6517	also	_	_
77-10	6518-6519	\*	_	_
77-11	6519-6520	.	_	_

#Text=/pretrained/thumos\_i3d\_reproduce/logs\*. \* The pre-trained model is \*.
78-1	6520-6521	/	_	_
78-2	6521-6531	pretrained	_	_
78-3	6531-6532	/	_	_
78-4	6532-6552	thumos\_i3d\_reproduce	_	_
78-4	6532-6538	thumos	_	_
78-5	6552-6553	/	_	_
78-6	6553-6557	logs	_	_
78-7	6557-6558	\*	_	_
78-8	6558-6559	.	_	_
78-9	6560-6561	\*	_	_
78-10	6562-6565	The	_	_
78-11	6566-6577	pre-trained	_	_
78-12	6578-6583	model	_	_
78-13	6584-6586	is	_	_
78-14	6587-6588	\*	_	_
78-15	6588-6589	.	_	_

#Text=/pretrained/thumos\_i3d\_reproduce/epoch\_034.pth.tar\*. \* Evaluate the pre-trained model.
79-1	6589-6590	/	_	_
79-2	6590-6600	pretrained	_	_
79-3	6600-6601	/	_	_
79-4	6601-6621	thumos\_i3d\_reproduce	_	_
79-4	6601-6607	thumos	_	_
79-5	6621-6622	/	_	_
79-6	6622-6627	epoch	_	_
79-7	6627-6628	\_	_	_
79-8	6628-6631	034	_	_
79-9	6631-6632	.	_	_
79-10	6632-6639	pth.tar	_	_
79-11	6639-6640	\*	_	_
79-12	6640-6641	.	_	_
79-13	6642-6643	\*	_	_
79-14	6644-6652	Evaluate	_	_
79-15	6653-6656	the	_	_
79-16	6657-6668	pre-trained	_	_
79-17	6669-6674	model	_	_
79-18	6674-6675	.	_	_

#Text=```shell python .
80-1	6676-6677	`	_	_
80-2	6677-6678	`	_	_
80-3	6678-6679	`	_	_
80-4	6679-6684	shell	_	_
80-5	6685-6691	python	_	_
80-6	6692-6693	.	_	_

#Text=/eval.py .
81-1	6693-6694	/	_	_
81-2	6694-6701	eval.py	_	_
81-3	6702-6703	.	_	_

#Text=/configs/thumos\_i3d.yaml .
82-1	6703-6704	/	_	_
82-2	6704-6711	configs	_	_
82-3	6711-6712	/	_	_
82-4	6712-6727	thumos\_i3d.yaml	_	_
82-4	6712-6718	thumos	_	_
82-5	6728-6729	.	_	_

#Text=/pretrained/thumos\_i3d\_reproduce/ ``` \* The results (mAP at tIoUs) should be  \| Method            \|  0.3  \|  0.4  \|  0.5  \|  0.6  \|  0.7  \|  Avg  \| \|-------------------\|-------\|-------\|-------\|-------\|-------\|-------\| \| ActionFormer      \| 82.13 \| 77.80 \| 70.95 \| 59.40 \| 43.87 \| 66.83 \|   ## To Reproduce Our Results on ActivityNet 1.3 \*\*Download Features and Annotations\*\* \* Download \*anet\_1.3.tar.gz\* (`md5sum c415f50120b9425ee1ede9ac3ce11203`) from \[this Box link\](https://uwmadison.box.com/s/aisdoymowukc99zoc7gpqegxbb4whikx) or \[this Google Drive Link\](https://drive.google.com/file/d/1VW8px1Nz9A17i0wMVUfxh6YsPCLVqL-S/view?
83-1	6729-6730	/	_	_
83-2	6730-6740	pretrained	_	_
83-3	6740-6741	/	_	_
83-4	6741-6761	thumos\_i3d\_reproduce	_	_
83-4	6741-6747	thumos	_	_
83-5	6761-6762	/	_	_
83-6	6763-6764	`	_	_
83-7	6764-6765	`	_	_
83-8	6765-6766	`	_	_
83-9	6767-6768	\*	_	_
83-10	6769-6772	The	_	_
83-11	6773-6780	results	_	_
83-12	6781-6782	(	_	_
83-13	6782-6785	mAP	_	_
83-14	6786-6788	at	_	_
83-15	6789-6794	tIoUs	_	_
83-16	6794-6795	)	_	_
83-17	6796-6802	should	_	_
83-18	6803-6805	be	_	_
83-19	6807-6808	\|	_	_
83-20	6809-6815	Method	_	_
83-21	6827-6828	\|	_	_
83-22	6830-6833	0.3	_	_
83-23	6835-6836	\|	_	_
83-24	6838-6841	0.4	_	_
83-25	6843-6844	\|	_	_
83-26	6846-6849	0.5	_	_
83-27	6851-6852	\|	_	_
83-28	6854-6857	0.6	_	_
83-29	6859-6860	\|	_	_
83-30	6862-6865	0.7	_	_
83-31	6867-6868	\|	_	_
83-32	6870-6873	Avg	_	_
83-33	6875-6876	\|	_	_
83-34	6877-6878	\|	_	_
83-35	6878-6879	-	_	_
83-36	6879-6880	-	_	_
83-37	6880-6881	-	_	_
83-38	6881-6882	-	_	_
83-39	6882-6883	-	_	_
83-40	6883-6884	-	_	_
83-41	6884-6885	-	_	_
83-42	6885-6886	-	_	_
83-43	6886-6887	-	_	_
83-44	6887-6888	-	_	_
83-45	6888-6889	-	_	_
83-46	6889-6890	-	_	_
83-47	6890-6891	-	_	_
83-48	6891-6892	-	_	_
83-49	6892-6893	-	_	_
83-50	6893-6894	-	_	_
83-51	6894-6895	-	_	_
83-52	6895-6896	-	_	_
83-53	6896-6897	-	_	_
83-54	6897-6898	\|	_	_
83-55	6898-6899	-	_	_
83-56	6899-6900	-	_	_
83-57	6900-6901	-	_	_
83-58	6901-6902	-	_	_
83-59	6902-6903	-	_	_
83-60	6903-6904	-	_	_
83-61	6904-6905	-	_	_
83-62	6905-6906	\|	_	_
83-63	6906-6907	-	_	_
83-64	6907-6908	-	_	_
83-65	6908-6909	-	_	_
83-66	6909-6910	-	_	_
83-67	6910-6911	-	_	_
83-68	6911-6912	-	_	_
83-69	6912-6913	-	_	_
83-70	6913-6914	\|	_	_
83-71	6914-6915	-	_	_
83-72	6915-6916	-	_	_
83-73	6916-6917	-	_	_
83-74	6917-6918	-	_	_
83-75	6918-6919	-	_	_
83-76	6919-6920	-	_	_
83-77	6920-6921	-	_	_
83-78	6921-6922	\|	_	_
83-79	6922-6923	-	_	_
83-80	6923-6924	-	_	_
83-81	6924-6925	-	_	_
83-82	6925-6926	-	_	_
83-83	6926-6927	-	_	_
83-84	6927-6928	-	_	_
83-85	6928-6929	-	_	_
83-86	6929-6930	\|	_	_
83-87	6930-6931	-	_	_
83-88	6931-6932	-	_	_
83-89	6932-6933	-	_	_
83-90	6933-6934	-	_	_
83-91	6934-6935	-	_	_
83-92	6935-6936	-	_	_
83-93	6936-6937	-	_	_
83-94	6937-6938	\|	_	_
83-95	6938-6939	-	_	_
83-96	6939-6940	-	_	_
83-97	6940-6941	-	_	_
83-98	6941-6942	-	_	_
83-99	6942-6943	-	_	_
83-100	6943-6944	-	_	_
83-101	6944-6945	-	_	_
83-102	6945-6946	\|	_	_
83-103	6947-6948	\|	_	_
83-104	6949-6961	ActionFormer	_	_
83-105	6967-6968	\|	_	_
83-106	6969-6974	82.13	_	_
83-107	6975-6976	\|	_	_
83-108	6977-6982	77.80	_	_
83-109	6983-6984	\|	_	_
83-110	6985-6990	70.95	_	_
83-111	6991-6992	\|	_	_
83-112	6993-6998	59.40	_	_
83-113	6999-7000	\|	_	_
83-114	7001-7006	43.87	_	_
83-115	7007-7008	\|	_	_
83-116	7009-7014	66.83	_	_
83-117	7015-7016	\|	_	_
83-118	7019-7020	#	_	_
83-119	7020-7021	#	_	_
83-120	7022-7024	To	_	_
83-121	7025-7034	Reproduce	_	_
83-122	7035-7038	Our	_	_
83-123	7039-7046	Results	_	_
83-124	7047-7049	on	_	_
83-125	7050-7061	ActivityNet	_	_
83-126	7062-7065	1.3	_	_
83-127	7066-7067	\*	_	_
83-128	7067-7068	\*	_	_
83-129	7068-7076	Download	_	_
83-130	7077-7085	Features	_	_
83-131	7086-7089	and	_	_
83-132	7090-7101	Annotations	_	_
83-133	7101-7102	\*	_	_
83-134	7102-7103	\*	_	_
83-135	7104-7105	\*	_	_
83-136	7106-7114	Download	_	_
83-137	7115-7116	\*	_	_
83-138	7116-7120	anet	_	_
83-139	7120-7121	\_	_	_
83-140	7121-7124	1.3	_	_
83-141	7124-7125	.	_	_
83-142	7125-7131	tar.gz	_	_
83-143	7131-7132	\*	_	_
83-144	7133-7134	(	_	_
83-145	7134-7135	`	_	_
83-146	7135-7141	md5sum	_	_
83-147	7142-7174	c415f50120b9425ee1ede9ac3ce11203	_	_
83-148	7174-7175	`	_	_
83-149	7175-7176	)	_	_
83-150	7177-7181	from	_	_
83-151	7182-7183	\[	_	_
83-152	7183-7187	this	_	_
83-153	7188-7191	Box	_	_
83-154	7192-7196	link	_	_
83-155	7196-7197	\]	_	_
83-156	7197-7198	(	_	_
83-157	7198-7203	https	_	_
83-158	7203-7204	:	_	_
83-159	7204-7205	/	_	_
83-160	7205-7206	/	_	_
83-161	7206-7223	uwmadison.box.com	_	_
83-162	7223-7224	/	_	_
83-163	7224-7225	s	_	_
83-164	7225-7226	/	_	_
83-165	7226-7258	aisdoymowukc99zoc7gpqegxbb4whikx	_	_
83-166	7258-7259	)	_	_
83-167	7260-7262	or	_	_
83-168	7263-7264	\[	_	_
83-169	7264-7268	this	_	_
83-170	7269-7275	Google	_	_
83-171	7276-7281	Drive	_	_
83-172	7282-7286	Link	_	_
83-173	7286-7287	\]	_	_
83-174	7287-7288	(	_	_
83-175	7288-7293	https	_	_
83-176	7293-7294	:	_	_
83-177	7294-7295	/	_	_
83-178	7295-7296	/	_	_
83-179	7296-7312	drive.google.com	_	_
83-180	7312-7313	/	_	_
83-181	7313-7317	file	_	_
83-182	7317-7318	/	_	_
83-183	7318-7319	d	_	_
83-184	7319-7320	/	_	_
83-185	7320-7353	1VW8px1Nz9A17i0wMVUfxh6YsPCLVqL-S	_	_
83-186	7353-7354	/	_	_
83-187	7354-7358	view	_	_
83-188	7358-7359	?	_	_

#Text=usp=sharing) or \[this BaiduYun Link\](https://pan.baidu.com/s/1tw5W8B5YqDvfl-mrlWQvnQ?
84-1	7359-7362	usp	_	_
84-2	7362-7363	=	_	_
84-3	7363-7370	sharing	_	_
84-4	7370-7371	)	_	_
84-5	7372-7374	or	_	_
84-6	7375-7376	\[	_	_
84-7	7376-7380	this	_	_
84-8	7381-7389	BaiduYun	_	_
84-9	7390-7394	Link	_	_
84-10	7394-7395	\]	_	_
84-11	7395-7396	(	_	_
84-12	7396-7401	https	_	_
84-13	7401-7402	:	_	_
84-14	7402-7403	/	_	_
84-15	7403-7404	/	_	_
84-16	7404-7417	pan.baidu.com	_	_
84-17	7417-7418	/	_	_
84-18	7418-7419	s	_	_
84-19	7419-7420	/	_	_
84-20	7420-7443	1tw5W8B5YqDvfl-mrlWQvnQ	_	_
84-21	7443-7444	?	_	_

#Text=pwd=xuit). \* The file includes TSP features, action annotations in json format (similar to ActivityNet annotation format), and external classification scores.
85-1	7444-7447	pwd	_	_
85-2	7447-7448	=	_	_
85-3	7448-7452	xuit	_	_
85-4	7452-7453	)	_	_
85-5	7453-7454	.	_	_
85-6	7455-7456	\*	_	_
85-7	7457-7460	The	_	_
85-8	7461-7465	file	_	_
85-9	7466-7474	includes	_	_
85-10	7475-7478	TSP	_	_
85-11	7479-7487	features	_	_
85-12	7487-7488	,	_	_
85-13	7489-7495	action	_	_
85-14	7496-7507	annotations	_	_
85-15	7508-7510	in	_	_
85-16	7511-7515	json	_	_
85-17	7516-7522	format	_	_
85-18	7523-7524	(	_	_
85-19	7524-7531	similar	_	_
85-20	7532-7534	to	_	_
85-21	7535-7546	ActivityNet	_	_
85-22	7547-7557	annotation	_	_
85-23	7558-7564	format	_	_
85-24	7564-7565	)	_	_
85-25	7565-7566	,	_	_
85-26	7567-7570	and	_	_
85-27	7571-7579	external	_	_
85-28	7580-7594	classification	_	_
85-29	7595-7601	scores	_	_
85-30	7601-7602	.	_	_

#Text=\*\*Details\*\*: The features are extracted from the R(2+1)D-34 model pretrained with TSP on ActivityNet using clips of `16 frames` at a frame rate of `15 fps` and a stride of `16 frames` (\*i.e.,\* \*\*non-overlapping\*\* clips).
86-1	7604-7605	\*	_	_
86-2	7605-7606	\*	_	_
86-3	7606-7613	Details	_	_
86-4	7613-7614	\*	_	_
86-5	7614-7615	\*	_	_
86-6	7615-7616	:	_	_
86-7	7617-7620	The	_	_
86-8	7621-7629	features	_	_
86-9	7630-7633	are	_	_
86-10	7634-7643	extracted	_	_
86-11	7644-7648	from	_	_
86-12	7649-7652	the	_	_
86-13	7653-7654	R	_	_
86-14	7654-7655	(	_	_
86-15	7655-7656	2	_	_
86-16	7656-7657	+	_	_
86-17	7657-7658	1	_	_
86-18	7658-7659	)	_	_
86-19	7659-7660	D	_	_
86-20	7660-7661	-	_	_
86-21	7661-7663	34	_	_
86-22	7664-7669	model	_	_
86-23	7670-7680	pretrained	_	_
86-24	7681-7685	with	_	_
86-25	7686-7689	TSP	_	_
86-26	7690-7692	on	_	_
86-27	7693-7704	ActivityNet	_	_
86-28	7705-7710	using	_	_
86-29	7711-7716	clips	_	_
86-30	7717-7719	of	_	_
86-31	7720-7721	`	_	_
86-32	7721-7723	16	_	_
86-33	7724-7730	frames	_	_
86-34	7730-7731	`	_	_
86-35	7732-7734	at	_	_
86-36	7735-7736	a	_	_
86-37	7737-7742	frame	_	_
86-38	7743-7747	rate	_	_
86-39	7748-7750	of	_	_
86-40	7751-7752	`	_	_
86-41	7752-7754	15	_	_
86-42	7755-7758	fps	_	_
86-43	7758-7759	`	_	_
86-44	7760-7763	and	_	_
86-45	7764-7765	a	_	_
86-46	7766-7772	stride	_	_
86-47	7773-7775	of	_	_
86-48	7776-7777	`	_	_
86-49	7777-7779	16	_	_
86-50	7780-7786	frames	_	_
86-51	7786-7787	`	_	_
86-52	7788-7789	(	_	_
86-53	7789-7790	\*	_	_
86-54	7790-7793	i.e	_	_
86-55	7793-7794	.	_	_
86-56	7794-7795	,	_	_
86-57	7795-7796	\*	_	_
86-58	7797-7798	\*	_	_
86-59	7798-7799	\*	_	_
86-60	7799-7814	non-overlapping	_	_
86-61	7814-7815	\*	_	_
86-62	7815-7816	\*	_	_
86-63	7817-7822	clips	_	_
86-64	7822-7823	)	_	_
86-65	7823-7824	.	_	_

#Text=This gives one feature vector per `16/15 ~= 1.067` seconds.
87-1	7825-7829	This	_	_
87-2	7830-7835	gives	_	_
87-3	7836-7839	one	_	_
87-4	7840-7847	feature	_	_
87-5	7848-7854	vector	_	_
87-6	7855-7858	per	_	_
87-7	7859-7860	`	_	_
87-8	7860-7862	16	_	_
87-9	7862-7863	/	_	_
87-10	7863-7865	15	_	_
87-11	7866-7867	~	_	_
87-12	7867-7868	=	_	_
87-13	7869-7874	1.067	_	_
87-14	7874-7875	`	_	_
87-15	7876-7883	seconds	_	_
87-16	7883-7884	.	_	_

#Text=The features are converted into numpy files for our code.
88-1	7885-7888	The	_	_
88-2	7889-7897	features	_	_
88-3	7898-7901	are	_	_
88-4	7902-7911	converted	_	_
88-5	7912-7916	into	_	_
88-6	7917-7922	numpy	_	_
88-7	7923-7928	files	_	_
88-8	7929-7932	for	_	_
88-9	7933-7936	our	_	_
88-10	7937-7941	code	_	_
88-11	7941-7942	.	_	_

#Text=\*\*Unpack Features and Annotations\*\* \* Unpack the file under \*.
89-1	7944-7945	\*	_	_
89-2	7945-7946	\*	_	_
89-3	7946-7952	Unpack	_	_
89-4	7953-7961	Features	_	_
89-5	7962-7965	and	_	_
89-6	7966-7977	Annotations	_	_
89-7	7977-7978	\*	_	_
89-8	7978-7979	\*	_	_
89-9	7980-7981	\*	_	_
89-10	7982-7988	Unpack	_	_
89-11	7989-7992	the	_	_
89-12	7993-7997	file	_	_
89-13	7998-8003	under	_	_
89-14	8004-8005	\*	_	_
89-15	8005-8006	.	_	_

#Text=/data\* (or elsewhere and link to \*.
90-1	8006-8007	/	_	_
90-2	8007-8011	data	_	_
90-3	8011-8012	\*	_	_
90-4	8013-8014	(	_	_
90-5	8014-8016	or	_	_
90-6	8017-8026	elsewhere	_	_
90-7	8027-8030	and	_	_
90-8	8031-8035	link	_	_
90-9	8036-8038	to	_	_
90-10	8039-8040	\*	_	_
90-11	8040-8041	.	_	_

#Text=/data\*). \* The folder structure should look like ``` This folder │   README.md │
91-1	8041-8042	/	_	_
91-2	8042-8046	data	_	_
91-3	8046-8047	\*	_	_
91-4	8047-8048	)	_	_
91-5	8048-8049	.	_	_
91-6	8050-8051	\*	_	_
91-7	8052-8055	The	_	_
91-8	8056-8062	folder	_	_
91-9	8063-8072	structure	_	_
91-10	8073-8079	should	_	_
91-11	8080-8084	look	_	_
91-12	8085-8089	like	_	_
91-13	8090-8091	`	_	_
91-14	8091-8092	`	_	_
91-15	8092-8093	`	_	_
91-16	8094-8098	This	_	_
91-17	8099-8105	folder	_	_
91-18	8106-8107	│	_	_
91-19	8110-8119	README.md	_	_
91-20	8120-8121	│	_	_

#Text=.
92-1	8124-8125	.	_	_

#Text=.
93-1	8125-8126	.	_	_

#Text=.
94-1	8126-8127	.	_	_

#Text=│ └───data/ │    └───anet\_1.3/ │    │  └───annotations │    │  └───tsp\_features    │    └───... \| └───libs │ │   ... ```  \*\*Training and Evaluation\*\* \* Train our ActionFormer with TSP features.
95-1	8130-8131	│	_	_
95-2	8132-8133	└	_	_
95-3	8133-8134	─	_	_
95-4	8134-8135	─	_	_
95-5	8135-8136	─	_	_
95-6	8136-8140	data	_	_
95-7	8140-8141	/	_	_
95-8	8142-8143	│	_	_
95-9	8147-8148	└	_	_
95-10	8148-8149	─	_	_
95-11	8149-8150	─	_	_
95-12	8150-8151	─	_	_
95-13	8151-8155	anet	_	_
95-14	8155-8156	\_	_	_
95-15	8156-8159	1.3	_	_
95-16	8159-8160	/	_	_
95-17	8161-8162	│	_	_
95-18	8166-8167	│	_	_
95-19	8169-8170	└	_	_
95-20	8170-8171	─	_	_
95-21	8171-8172	─	_	_
95-22	8172-8173	─	_	_
95-23	8173-8184	annotations	_	_
95-24	8185-8186	│	_	_
95-25	8190-8191	│	_	_
95-26	8193-8194	└	_	_
95-27	8194-8195	─	_	_
95-28	8195-8196	─	_	_
95-29	8196-8197	─	_	_
95-30	8197-8209	tsp\_features	_	_
95-31	8213-8214	│	_	_
95-32	8218-8219	└	_	_
95-33	8219-8220	─	_	_
95-34	8220-8221	─	_	_
95-35	8221-8222	─	_	_
95-36	8222-8223	.	_	_
95-37	8223-8224	.	_	_
95-38	8224-8225	.	_	_
95-39	8226-8227	\|	_	_
95-40	8228-8229	└	_	_
95-41	8229-8230	─	_	_
95-42	8230-8231	─	_	_
95-43	8231-8232	─	_	_
95-44	8232-8236	libs	_	_
95-45	8237-8238	│	_	_
95-46	8239-8240	│	_	_
95-47	8243-8244	.	_	_
95-48	8244-8245	.	_	_
95-49	8245-8246	.	_	_
95-50	8247-8248	`	_	_
95-51	8248-8249	`	_	_
95-52	8249-8250	`	_	_
95-53	8252-8253	\*	_	_
95-54	8253-8254	\*	_	_
95-55	8254-8262	Training	_	_
95-56	8263-8266	and	_	_
95-57	8267-8277	Evaluation	_	_
95-58	8277-8278	\*	_	_
95-59	8278-8279	\*	_	_
95-60	8280-8281	\*	_	_
95-61	8282-8287	Train	_	_
95-62	8288-8291	our	_	_
95-63	8292-8304	ActionFormer	_	_
95-64	8305-8309	with	_	_
95-65	8310-8313	TSP	_	_
95-66	8314-8322	features	_	_
95-67	8322-8323	.	_	_

#Text=This will create an experiment folder under \*.
96-1	8324-8328	This	_	_
96-2	8329-8333	will	_	_
96-3	8334-8340	create	_	_
96-4	8341-8343	an	_	_
96-5	8344-8354	experiment	_	_
96-6	8355-8361	folder	_	_
96-7	8362-8367	under	_	_
96-8	8368-8369	\*	_	_
96-9	8369-8370	.	_	_

#Text=/ckpt\* that stores training config, logs, and checkpoints.
97-1	8370-8371	/	_	_
97-2	8371-8375	ckpt	_	_
97-3	8375-8376	\*	_	_
97-4	8377-8381	that	_	_
97-5	8382-8388	stores	_	_
97-6	8389-8397	training	_	_
97-7	8398-8404	config	_	_
97-8	8404-8405	,	_	_
97-9	8406-8410	logs	_	_
97-10	8410-8411	,	_	_
97-11	8412-8415	and	_	_
97-12	8416-8427	checkpoints	_	_
97-13	8427-8428	.	_	_

#Text=```shell python .
98-1	8429-8430	`	_	_
98-2	8430-8431	`	_	_
98-3	8431-8432	`	_	_
98-4	8432-8437	shell	_	_
98-5	8438-8444	python	_	_
98-6	8445-8446	.	_	_

#Text=/train.py .
99-1	8446-8447	/	_	_
99-2	8447-8455	train.py	_	_
99-3	8456-8457	.	_	_

#Text=/configs/anet\_tsp.yaml --output reproduce ``` \* \[Optional\] Monitor the training using TensorBoard ```shell tensorboard --logdir=.
100-1	8457-8458	/	_	_
100-2	8458-8465	configs	_	_
100-3	8465-8466	/	_	_
100-4	8466-8479	anet\_tsp.yaml	_	_
100-5	8480-8481	-	_	_
100-6	8481-8482	-	_	_
100-7	8482-8488	output	_	_
100-8	8489-8498	reproduce	_	_
100-9	8499-8500	`	_	_
100-10	8500-8501	`	_	_
100-11	8501-8502	`	_	_
100-12	8503-8504	\*	_	_
100-13	8505-8506	\[	_	_
100-14	8506-8514	Optional	_	_
100-15	8514-8515	\]	_	_
100-16	8516-8523	Monitor	_	_
100-17	8524-8527	the	_	_
100-18	8528-8536	training	_	_
100-19	8537-8542	using	_	_
100-20	8543-8554	TensorBoard	_	_
100-21	8555-8556	`	_	_
100-22	8556-8557	`	_	_
100-23	8557-8558	`	_	_
100-24	8558-8563	shell	_	_
100-25	8564-8575	tensorboard	_	_
100-26	8576-8577	-	_	_
100-27	8577-8578	-	_	_
100-28	8578-8584	logdir	_	_
100-29	8584-8585	=	_	_
100-30	8585-8586	.	_	_

#Text=/ckpt/anet\_tsp\_reproduce/logs ``` \* Evaluate the trained model.
101-1	8586-8587	/	_	_
101-2	8587-8591	ckpt	_	_
101-3	8591-8592	/	_	_
101-4	8592-8610	anet\_tsp\_reproduce	_	_
101-5	8610-8611	/	_	_
101-6	8611-8615	logs	_	_
101-7	8616-8617	`	_	_
101-8	8617-8618	`	_	_
101-9	8618-8619	`	_	_
101-10	8620-8621	\*	_	_
101-11	8622-8630	Evaluate	_	_
101-12	8631-8634	the	_	_
101-13	8635-8642	trained	_	_
101-14	8643-8648	model	_	_
101-15	8648-8649	.	_	_

#Text=The expected average mAP should be around 36.5(%) as in Table 1 of our main paper.
102-1	8650-8653	The	_	_
102-2	8654-8662	expected	_	_
102-3	8663-8670	average	_	_
102-4	8671-8674	mAP	_	_
102-5	8675-8681	should	_	_
102-6	8682-8684	be	_	_
102-7	8685-8691	around	_	_
102-8	8692-8696	36.5	_	_
102-9	8696-8697	(	_	_
102-10	8697-8698	%	_	_
102-11	8698-8699	)	_	_
102-12	8700-8702	as	_	_
102-13	8703-8705	in	_	_
102-14	8706-8711	Table	_	_
102-15	8712-8713	1	_	_
102-16	8714-8716	of	_	_
102-17	8717-8720	our	_	_
102-18	8721-8725	main	_	_
102-19	8726-8731	paper	_	_
102-20	8731-8732	.	_	_

#Text=```shell python .
103-1	8733-8734	`	_	_
103-2	8734-8735	`	_	_
103-3	8735-8736	`	_	_
103-4	8736-8741	shell	_	_
103-5	8742-8748	python	_	_
103-6	8749-8750	.	_	_

#Text=/eval.py .
104-1	8750-8751	/	_	_
104-2	8751-8758	eval.py	_	_
104-3	8759-8760	.	_	_

#Text=/configs/anet\_tsp.yaml .
105-1	8760-8761	/	_	_
105-2	8761-8768	configs	_	_
105-3	8768-8769	/	_	_
105-4	8769-8782	anet\_tsp.yaml	_	_
105-5	8783-8784	.	_	_

#Text=/ckpt/anet\_tsp\_reproduce ``` \* Training our model on ActivityNet requires ~4.6GB GPU memory, yet the inference might require over 10GB GPU memory.
106-1	8784-8785	/	_	_
106-2	8785-8789	ckpt	_	_
106-3	8789-8790	/	_	_
106-4	8790-8808	anet\_tsp\_reproduce	_	_
106-5	8809-8810	`	_	_
106-6	8810-8811	`	_	_
106-7	8811-8812	`	_	_
106-8	8813-8814	\*	_	_
106-9	8815-8823	Training	_	_
106-10	8824-8827	our	_	_
106-11	8828-8833	model	_	_
106-12	8834-8836	on	_	_
106-13	8837-8848	ActivityNet	_	_
106-14	8849-8857	requires	_	_
106-15	8858-8859	~	_	_
106-16	8859-8864	4.6GB	_	_
106-17	8865-8868	GPU	_	_
106-18	8869-8875	memory	_	_
106-19	8875-8876	,	_	_
106-20	8877-8880	yet	_	_
106-21	8881-8884	the	_	_
106-22	8885-8894	inference	_	_
106-23	8895-8900	might	_	_
106-24	8901-8908	require	_	_
106-25	8909-8913	over	_	_
106-26	8914-8918	10GB	_	_
106-27	8919-8922	GPU	_	_
106-28	8923-8929	memory	_	_
106-29	8929-8930	.	_	_

#Text=We recommend using a GPU with at least 12 GB of memory.
107-1	8931-8933	We	_	_
107-2	8934-8943	recommend	_	_
107-3	8944-8949	using	_	_
107-4	8950-8951	a	_	_
107-5	8952-8955	GPU	_	_
107-6	8956-8960	with	_	_
107-7	8961-8963	at	_	_
107-8	8964-8969	least	_	_
107-9	8970-8972	12	_	_
107-10	8973-8975	GB	_	_
107-11	8976-8978	of	_	_
107-12	8979-8985	memory	_	_
107-13	8985-8986	.	_	_

#Text=\*\*\[Optional\] Evaluating Our Pre-trained Model\*\*  We also provide a pre-trained model for ActivityNet 1.3.
108-1	8988-8989	\*	_	_
108-2	8989-8990	\*	_	_
108-3	8990-8991	\[	_	_
108-4	8991-8999	Optional	_	_
108-5	8999-9000	\]	_	_
108-6	9001-9011	Evaluating	_	_
108-7	9012-9015	Our	_	_
108-8	9016-9027	Pre-trained	_	_
108-9	9028-9033	Model	_	_
108-10	9033-9034	\*	_	_
108-11	9034-9035	\*	_	_
108-12	9037-9039	We	_	_
108-13	9040-9044	also	_	_
108-14	9045-9052	provide	_	_
108-15	9053-9054	a	_	_
108-16	9055-9066	pre-trained	_	_
108-17	9067-9072	model	_	_
108-18	9073-9076	for	_	_
108-19	9077-9088	ActivityNet	_	_
108-20	9089-9092	1.3	_	_
108-21	9092-9093	.	_	_

#Text=The model with all training logs can be downloaded from \[this Google Drive link\](https://drive.google.com/file/d/1JKh3w14ngAjgzuuP22BnjhkhIcBSqteJ/view?
109-1	9094-9097	The	_	_
109-2	9098-9103	model	_	_
109-3	9104-9108	with	_	_
109-4	9109-9112	all	_	_
109-5	9113-9121	training	_	_
109-6	9122-9126	logs	_	_
109-7	9127-9130	can	_	_
109-8	9131-9133	be	_	_
109-9	9134-9144	downloaded	_	_
109-10	9145-9149	from	_	_
109-11	9150-9151	\[	_	_
109-12	9151-9155	this	_	_
109-13	9156-9162	Google	_	_
109-14	9163-9168	Drive	_	_
109-15	9169-9173	link	_	_
109-16	9173-9174	\]	_	_
109-17	9174-9175	(	_	_
109-18	9175-9180	https	_	_
109-19	9180-9181	:	_	_
109-20	9181-9182	/	_	_
109-21	9182-9183	/	_	_
109-22	9183-9199	drive.google.com	_	_
109-23	9199-9200	/	_	_
109-24	9200-9204	file	_	_
109-25	9204-9205	/	_	_
109-26	9205-9206	d	_	_
109-27	9206-9207	/	_	_
109-28	9207-9240	1JKh3w14ngAjgzuuP22BnjhkhIcBSqteJ	_	_
109-29	9240-9241	/	_	_
109-30	9241-9245	view	_	_
109-31	9245-9246	?	_	_

#Text=usp=sharing).
110-1	9246-9249	usp	_	_
110-2	9249-9250	=	_	_
110-3	9250-9257	sharing	_	_
110-4	9257-9258	)	_	_
110-5	9258-9259	.	_	_

#Text=To evaluate the pre-trained model, please follow the steps listed below
111-1	9260-9262	To	_	_
111-2	9263-9271	evaluate	_	_
111-3	9272-9275	the	_	_
111-4	9276-9287	pre-trained	_	_
111-5	9288-9293	model	_	_
111-6	9293-9294	,	_	_
111-7	9295-9301	please	_	_
111-8	9302-9308	follow	_	_
111-9	9309-9312	the	_	_
111-10	9313-9318	steps	_	_
111-11	9319-9325	listed	_	_
111-12	9326-9331	below	_	_

#Text=.
112-1	9331-9332	.	_	_

#Text=\* Create a folder \*.
113-1	9334-9335	\*	_	_
113-2	9336-9342	Create	_	_
113-3	9343-9344	a	_	_
113-4	9345-9351	folder	_	_
113-5	9352-9353	\*	_	_
113-6	9353-9354	.	_	_

#Text=/pretrained\* and unpack the file under \*.
114-1	9354-9355	/	_	_
114-2	9355-9365	pretrained	_	_
114-3	9365-9366	\*	_	_
114-4	9367-9370	and	_	_
114-5	9371-9377	unpack	_	_
114-6	9378-9381	the	_	_
114-7	9382-9386	file	_	_
114-8	9387-9392	under	_	_
114-9	9393-9394	\*	_	_
114-10	9394-9395	.	_	_

#Text=/pretrained\* (or elsewhere and link to \*.
115-1	9395-9396	/	_	_
115-2	9396-9406	pretrained	_	_
115-3	9406-9407	\*	_	_
115-4	9408-9409	(	_	_
115-5	9409-9411	or	_	_
115-6	9412-9421	elsewhere	_	_
115-7	9422-9425	and	_	_
115-8	9426-9430	link	_	_
115-9	9431-9433	to	_	_
115-10	9434-9435	\*	_	_
115-11	9435-9436	.	_	_

#Text=/pretrained\*). \* The folder structure should look like ``` This folder │   README.md │
116-1	9436-9437	/	_	_
116-2	9437-9447	pretrained	_	_
116-3	9447-9448	\*	_	_
116-4	9448-9449	)	_	_
116-5	9449-9450	.	_	_
116-6	9451-9452	\*	_	_
116-7	9453-9456	The	_	_
116-8	9457-9463	folder	_	_
116-9	9464-9473	structure	_	_
116-10	9474-9480	should	_	_
116-11	9481-9485	look	_	_
116-12	9486-9490	like	_	_
116-13	9491-9492	`	_	_
116-14	9492-9493	`	_	_
116-15	9493-9494	`	_	_
116-16	9495-9499	This	_	_
116-17	9500-9506	folder	_	_
116-18	9507-9508	│	_	_
116-19	9511-9520	README.md	_	_
116-20	9521-9522	│	_	_

#Text=.
117-1	9525-9526	.	_	_

#Text=.
118-1	9526-9527	.	_	_

#Text=.
119-1	9527-9528	.	_	_

#Text=│ └───pretrained/ │    └───anet\_tsp\_reproduce/ │    │  └───anet\_tsp\_reproduce\_log.txt │    │  └───anet\_tsp\_reproduce\_results.txt │    │   └───
120-1	9531-9532	│	_	_
120-2	9533-9534	└	_	_
120-3	9534-9535	─	_	_
120-4	9535-9536	─	_	_
120-5	9536-9537	─	_	_
120-6	9537-9547	pretrained	_	_
120-7	9547-9548	/	_	_
120-8	9549-9550	│	_	_
120-9	9554-9555	└	_	_
120-10	9555-9556	─	_	_
120-11	9556-9557	─	_	_
120-12	9557-9558	─	_	_
120-13	9558-9576	anet\_tsp\_reproduce	_	_
120-14	9576-9577	/	_	_
120-15	9578-9579	│	_	_
120-16	9583-9584	│	_	_
120-17	9586-9587	└	_	_
120-18	9587-9588	─	_	_
120-19	9588-9589	─	_	_
120-20	9589-9590	─	_	_
120-21	9590-9616	anet\_tsp\_reproduce\_log.txt	_	_
120-22	9617-9618	│	_	_
120-23	9622-9623	│	_	_
120-24	9625-9626	└	_	_
120-25	9626-9627	─	_	_
120-26	9627-9628	─	_	_
120-27	9628-9629	─	_	_
120-28	9629-9659	anet\_tsp\_reproduce\_results.txt	_	_
120-29	9660-9661	│	_	_
120-30	9665-9666	│	_	_
120-31	9669-9670	└	_	_
120-32	9670-9671	─	_	_
120-33	9671-9672	─	_	_
120-34	9672-9673	─	_	_

#Text=.
121-1	9673-9674	.	_	_

#Text=.
122-1	9674-9675	.	_	_

#Text=.
123-1	9675-9676	.	_	_

#Text=│    └───... \| └───libs │ │   ... ``` \* The training config is recorded in \*.
124-1	9681-9682	│	_	_
124-2	9686-9687	└	_	_
124-3	9687-9688	─	_	_
124-4	9688-9689	─	_	_
124-5	9689-9690	─	_	_
124-6	9690-9691	.	_	_
124-7	9691-9692	.	_	_
124-8	9692-9693	.	_	_
124-9	9694-9695	\|	_	_
124-10	9696-9697	└	_	_
124-11	9697-9698	─	_	_
124-12	9698-9699	─	_	_
124-13	9699-9700	─	_	_
124-14	9700-9704	libs	_	_
124-15	9705-9706	│	_	_
124-16	9707-9708	│	_	_
124-17	9711-9712	.	_	_
124-18	9712-9713	.	_	_
124-19	9713-9714	.	_	_
124-20	9715-9716	`	_	_
124-21	9716-9717	`	_	_
124-22	9717-9718	`	_	_
124-23	9719-9720	\*	_	_
124-24	9721-9724	The	_	_
124-25	9725-9733	training	_	_
124-26	9734-9740	config	_	_
124-27	9741-9743	is	_	_
124-28	9744-9752	recorded	_	_
124-29	9753-9755	in	_	_
124-30	9756-9757	\*	_	_
124-31	9757-9758	.	_	_

#Text=/pretrained/anet\_tsp\_reproduce/config.txt\*. \* The training log is located at \*.
125-1	9758-9759	/	_	_
125-2	9759-9769	pretrained	_	_
125-3	9769-9770	/	_	_
125-4	9770-9788	anet\_tsp\_reproduce	_	_
125-5	9788-9789	/	_	_
125-6	9789-9799	config.txt	_	_
125-7	9799-9800	\*	_	_
125-8	9800-9801	.	_	_
125-9	9802-9803	\*	_	_
125-10	9804-9807	The	_	_
125-11	9808-9816	training	_	_
125-12	9817-9820	log	_	_
125-13	9821-9823	is	_	_
125-14	9824-9831	located	_	_
125-15	9832-9834	at	_	_
125-16	9835-9836	\*	_	_
125-17	9836-9837	.	_	_

#Text=/pretrained/anet\_tsp\_reproduce/anet\_tsp\_reproduce\_log.txt\* and also \*.
126-1	9837-9838	/	_	_
126-2	9838-9848	pretrained	_	_
126-3	9848-9849	/	_	_
126-4	9849-9867	anet\_tsp\_reproduce	_	_
126-5	9867-9868	/	_	_
126-6	9868-9894	anet\_tsp\_reproduce\_log.txt	_	_
126-7	9894-9895	\*	_	_
126-8	9896-9899	and	_	_
126-9	9900-9904	also	_	_
126-10	9905-9906	\*	_	_
126-11	9906-9907	.	_	_

#Text=/pretrained/anet\_tsp\_reproduce/logs\*. \* The pre-trained model is \*.
127-1	9907-9908	/	_	_
127-2	9908-9918	pretrained	_	_
127-3	9918-9919	/	_	_
127-4	9919-9937	anet\_tsp\_reproduce	_	_
127-5	9937-9938	/	_	_
127-6	9938-9942	logs	_	_
127-7	9942-9943	\*	_	_
127-8	9943-9944	.	_	_
127-9	9945-9946	\*	_	_
127-10	9947-9950	The	_	_
127-11	9951-9962	pre-trained	_	_
127-12	9963-9968	model	_	_
127-13	9969-9971	is	_	_
127-14	9972-9973	\*	_	_
127-15	9973-9974	.	_	_

#Text=/pretrained/anet\_tsp\_reproduce/epoch\_014.pth.tar\*. \* Evaluate the pre-trained model.
128-1	9974-9975	/	_	_
128-2	9975-9985	pretrained	_	_
128-3	9985-9986	/	_	_
128-4	9986-10004	anet\_tsp\_reproduce	_	_
128-5	10004-10005	/	_	_
128-6	10005-10010	epoch	_	_
128-7	10010-10011	\_	_	_
128-8	10011-10014	014	_	_
128-9	10014-10015	.	_	_
128-10	10015-10022	pth.tar	_	_
128-11	10022-10023	\*	_	_
128-12	10023-10024	.	_	_
128-13	10025-10026	\*	_	_
128-14	10027-10035	Evaluate	_	_
128-15	10036-10039	the	_	_
128-16	10040-10051	pre-trained	_	_
128-17	10052-10057	model	_	_
128-18	10057-10058	.	_	_

#Text=```shell python .
129-1	10059-10060	`	_	_
129-2	10060-10061	`	_	_
129-3	10061-10062	`	_	_
129-4	10062-10067	shell	_	_
129-5	10068-10074	python	_	_
129-6	10075-10076	.	_	_

#Text=/eval.py .
130-1	10076-10077	/	_	_
130-2	10077-10084	eval.py	_	_
130-3	10085-10086	.	_	_

#Text=/configs/anet\_tsp.yaml .
131-1	10086-10087	/	_	_
131-2	10087-10094	configs	_	_
131-3	10094-10095	/	_	_
131-4	10095-10108	anet\_tsp.yaml	_	_
131-5	10109-10110	.	_	_

#Text=/pretrained/anet\_tsp\_reproduce/ ``` \* The results (mAP at tIoUs) should be  \| Method            \|  0.5  \|  0.75 \|  0.95 \|  Avg  \| \|-------------------\|-------\|-------\|-------\|-------\| \| ActionFormer      \| 54.67 \| 37.81 \|  8.36 \| 36.56 \|   \*\*\[Optional\] Reproducing Our Results with I3D Features\*\*  \* Download \*anet\_1.3\_i3d.tar.gz\* (`md5sum e649425954e0123401650312dd0d56a7`) from \[this Google Drive Link\](https://drive.google.com/file/d/16239kUT2Z-j6S6PXIT1b\_31OJi35QW\_o/view?
132-1	10110-10111	/	_	_
132-2	10111-10121	pretrained	_	_
132-3	10121-10122	/	_	_
132-4	10122-10140	anet\_tsp\_reproduce	_	_
132-5	10140-10141	/	_	_
132-6	10142-10143	`	_	_
132-7	10143-10144	`	_	_
132-8	10144-10145	`	_	_
132-9	10146-10147	\*	_	_
132-10	10148-10151	The	_	_
132-11	10152-10159	results	_	_
132-12	10160-10161	(	_	_
132-13	10161-10164	mAP	_	_
132-14	10165-10167	at	_	_
132-15	10168-10173	tIoUs	_	_
132-15	10168-10172	tIoU	_	_
132-16	10173-10174	)	_	_
132-17	10175-10181	should	_	_
132-18	10182-10184	be	_	_
132-19	10186-10187	\|	_	_
132-20	10188-10194	Method	_	_
132-21	10206-10207	\|	_	_
132-22	10209-10212	0.5	_	_
132-23	10214-10215	\|	_	_
132-24	10217-10221	0.75	_	_
132-25	10222-10223	\|	_	_
132-26	10225-10229	0.95	_	_
132-27	10230-10231	\|	_	_
132-28	10233-10236	Avg	_	_
132-29	10238-10239	\|	_	_
132-30	10240-10241	\|	_	_
132-31	10241-10242	-	_	_
132-32	10242-10243	-	_	_
132-33	10243-10244	-	_	_
132-34	10244-10245	-	_	_
132-35	10245-10246	-	_	_
132-36	10246-10247	-	_	_
132-37	10247-10248	-	_	_
132-38	10248-10249	-	_	_
132-39	10249-10250	-	_	_
132-40	10250-10251	-	_	_
132-41	10251-10252	-	_	_
132-42	10252-10253	-	_	_
132-43	10253-10254	-	_	_
132-44	10254-10255	-	_	_
132-45	10255-10256	-	_	_
132-46	10256-10257	-	_	_
132-47	10257-10258	-	_	_
132-48	10258-10259	-	_	_
132-49	10259-10260	-	_	_
132-50	10260-10261	\|	_	_
132-51	10261-10262	-	_	_
132-52	10262-10263	-	_	_
132-53	10263-10264	-	_	_
132-54	10264-10265	-	_	_
132-55	10265-10266	-	_	_
132-56	10266-10267	-	_	_
132-57	10267-10268	-	_	_
132-58	10268-10269	\|	_	_
132-59	10269-10270	-	_	_
132-60	10270-10271	-	_	_
132-61	10271-10272	-	_	_
132-62	10272-10273	-	_	_
132-63	10273-10274	-	_	_
132-64	10274-10275	-	_	_
132-65	10275-10276	-	_	_
132-66	10276-10277	\|	_	_
132-67	10277-10278	-	_	_
132-68	10278-10279	-	_	_
132-69	10279-10280	-	_	_
132-70	10280-10281	-	_	_
132-71	10281-10282	-	_	_
132-72	10282-10283	-	_	_
132-73	10283-10284	-	_	_
132-74	10284-10285	\|	_	_
132-75	10285-10286	-	_	_
132-76	10286-10287	-	_	_
132-77	10287-10288	-	_	_
132-78	10288-10289	-	_	_
132-79	10289-10290	-	_	_
132-80	10290-10291	-	_	_
132-81	10291-10292	-	_	_
132-82	10292-10293	\|	_	_
132-83	10294-10295	\|	_	_
132-84	10296-10308	ActionFormer	_	_
132-85	10314-10315	\|	_	_
132-86	10316-10321	54.67	_	_
132-87	10322-10323	\|	_	_
132-88	10324-10329	37.81	_	_
132-89	10330-10331	\|	_	_
132-90	10333-10337	8.36	_	_
132-91	10338-10339	\|	_	_
132-92	10340-10345	36.56	_	_
132-93	10346-10347	\|	_	_
132-94	10350-10351	\*	_	_
132-95	10351-10352	\*	_	_
132-96	10352-10353	\[	_	_
132-97	10353-10361	Optional	_	_
132-98	10361-10362	\]	_	_
132-99	10363-10374	Reproducing	_	_
132-100	10375-10378	Our	_	_
132-101	10379-10386	Results	_	_
132-102	10387-10391	with	_	_
132-103	10392-10395	I3D	_	_
132-104	10396-10404	Features	_	_
132-105	10404-10405	\*	_	_
132-106	10405-10406	\*	_	_
132-107	10408-10409	\*	_	_
132-108	10410-10418	Download	_	_
132-109	10419-10420	\*	_	_
132-110	10420-10424	anet	_	_
132-111	10424-10425	\_	_	_
132-112	10425-10428	1.3	_	_
132-113	10428-10429	\_	_	_
132-114	10429-10439	i3d.tar.gz	_	_
132-115	10439-10440	\*	_	_
132-116	10441-10442	(	_	_
132-117	10442-10443	`	_	_
132-118	10443-10449	md5sum	_	_
132-119	10450-10482	e649425954e0123401650312dd0d56a7	_	_
132-120	10482-10483	`	_	_
132-121	10483-10484	)	_	_
132-122	10485-10489	from	_	_
132-123	10490-10491	\[	_	_
132-124	10491-10495	this	_	_
132-125	10496-10502	Google	_	_
132-126	10503-10508	Drive	_	_
132-127	10509-10513	Link	_	_
132-128	10513-10514	\]	_	_
132-129	10514-10515	(	_	_
132-130	10515-10520	https	_	_
132-131	10520-10521	:	_	_
132-132	10521-10522	/	_	_
132-133	10522-10523	/	_	_
132-134	10523-10539	drive.google.com	_	_
132-135	10539-10540	/	_	_
132-136	10540-10544	file	_	_
132-137	10544-10545	/	_	_
132-138	10545-10546	d	_	_
132-139	10546-10547	/	_	_
132-140	10547-10568	16239kUT2Z-j6S6PXIT1b	_	_
132-141	10568-10569	\_	_	_
132-142	10569-10580	31OJi35QW\_o	_	_
132-143	10580-10581	/	_	_
132-144	10581-10585	view	_	_
132-145	10585-10586	?	_	_

#Text=usp=sharing).
133-1	10586-10589	usp	_	_
133-2	10589-10590	=	_	_
133-3	10590-10597	sharing	_	_
133-4	10597-10598	)	_	_
133-5	10598-10599	.	_	_

#Text=\*\*Details\*\*: The features are extracted from the I3D model pretrained on Kinetics using clips of `16 frames` at a frame rate of `25 fps` and a stride of `16 frames`.
134-1	10601-10602	\*	_	_
134-2	10602-10603	\*	_	_
134-3	10603-10610	Details	_	_
134-4	10610-10611	\*	_	_
134-5	10611-10612	\*	_	_
134-6	10612-10613	:	_	_
134-7	10614-10617	The	_	_
134-8	10618-10626	features	_	_
134-9	10627-10630	are	_	_
134-10	10631-10640	extracted	_	_
134-11	10641-10645	from	_	_
134-12	10646-10649	the	_	_
134-13	10650-10653	I3D	_	_
134-14	10654-10659	model	_	_
134-15	10660-10670	pretrained	_	_
134-16	10671-10673	on	_	_
134-17	10674-10682	Kinetics	_	_
134-18	10683-10688	using	_	_
134-19	10689-10694	clips	_	_
134-20	10695-10697	of	_	_
134-21	10698-10699	`	_	_
134-22	10699-10701	16	_	_
134-23	10702-10708	frames	_	_
134-24	10708-10709	`	_	_
134-25	10710-10712	at	_	_
134-26	10713-10714	a	_	_
134-27	10715-10720	frame	_	_
134-28	10721-10725	rate	_	_
134-29	10726-10728	of	_	_
134-30	10729-10730	`	_	_
134-31	10730-10732	25	_	_
134-32	10733-10736	fps	_	_
134-33	10736-10737	`	_	_
134-34	10738-10741	and	_	_
134-35	10742-10743	a	_	_
134-36	10744-10750	stride	_	_
134-37	10751-10753	of	_	_
134-38	10754-10755	`	_	_
134-39	10755-10757	16	_	_
134-40	10758-10764	frames	_	_
134-41	10764-10765	`	_	_
134-42	10765-10766	.	_	_

#Text=This gives one feature vector per `16/25 = 0.64` seconds.
135-1	10767-10771	This	_	_
135-2	10772-10777	gives	_	_
135-3	10778-10781	one	_	_
135-4	10782-10789	feature	_	_
135-5	10790-10796	vector	_	_
135-6	10797-10800	per	_	_
135-7	10801-10802	`	_	_
135-8	10802-10804	16	_	_
135-9	10804-10805	/	_	_
135-10	10805-10807	25	_	_
135-11	10808-10809	=	_	_
135-12	10810-10814	0.64	_	_
135-13	10814-10815	`	_	_
135-14	10816-10823	seconds	_	_
135-15	10823-10824	.	_	_

#Text=The features are converted into numpy files for our code
136-1	10825-10828	The	_	_
136-2	10829-10837	features	_	_
136-3	10838-10841	are	_	_
136-4	10842-10851	converted	_	_
136-5	10852-10856	into	_	_
136-6	10857-10862	numpy	_	_
136-7	10863-10868	files	_	_
136-8	10869-10872	for	_	_
136-9	10873-10876	our	_	_
136-10	10877-10881	code	_	_

#Text=.
137-1	10881-10882	.	_	_

#Text=\* Unpack the file under \*.
138-1	10884-10885	\*	_	_
138-2	10886-10892	Unpack	_	_
138-3	10893-10896	the	_	_
138-4	10897-10901	file	_	_
138-5	10902-10907	under	_	_
138-6	10908-10909	\*	_	_
138-7	10909-10910	.	_	_

#Text=/data\* (or elsewhere and link to \*.
139-1	10910-10911	/	_	_
139-2	10911-10915	data	_	_
139-3	10915-10916	\*	_	_
139-4	10917-10918	(	_	_
139-5	10918-10920	or	_	_
139-6	10921-10930	elsewhere	_	_
139-7	10931-10934	and	_	_
139-8	10935-10939	link	_	_
139-9	10940-10942	to	_	_
139-10	10943-10944	\*	_	_
139-11	10944-10945	.	_	_

#Text=/data\*), similar to TSP features
140-1	10945-10946	/	_	_
140-2	10946-10950	data	_	_
140-3	10950-10951	\*	_	_
140-4	10951-10952	)	_	_
140-5	10952-10953	,	_	_
140-6	10954-10961	similar	_	_
140-7	10962-10964	to	_	_
140-8	10965-10968	TSP	_	_
140-9	10969-10977	features	_	_

#Text=.
141-1	10977-10978	.	_	_

#Text=\* Train our ActionFormer with I3D features.
142-1	10980-10981	\*	_	_
142-2	10982-10987	Train	_	_
142-3	10988-10991	our	_	_
142-4	10992-11004	ActionFormer	_	_
142-5	11005-11009	with	_	_
142-6	11010-11013	I3D	_	_
142-7	11014-11022	features	_	_
142-8	11022-11023	.	_	_

#Text=This will create an experiment folder under \*.
143-1	11024-11028	This	_	_
143-2	11029-11033	will	_	_
143-3	11034-11040	create	_	_
143-4	11041-11043	an	_	_
143-5	11044-11054	experiment	_	_
143-6	11055-11061	folder	_	_
143-7	11062-11067	under	_	_
143-8	11068-11069	\*	_	_
143-9	11069-11070	.	_	_

#Text=/ckpt\* that stores training config, logs, and checkpoints.
144-1	11070-11071	/	_	_
144-2	11071-11075	ckpt	_	_
144-3	11075-11076	\*	_	_
144-4	11077-11081	that	_	_
144-5	11082-11088	stores	_	_
144-6	11089-11097	training	_	_
144-7	11098-11104	config	_	_
144-8	11104-11105	,	_	_
144-9	11106-11110	logs	_	_
144-10	11110-11111	,	_	_
144-11	11112-11115	and	_	_
144-12	11116-11127	checkpoints	_	_
144-13	11127-11128	.	_	_

#Text=```shell python .
145-1	11129-11130	`	_	_
145-2	11130-11131	`	_	_
145-3	11131-11132	`	_	_
145-4	11132-11137	shell	_	_
145-5	11138-11144	python	_	_
145-6	11145-11146	.	_	_

#Text=/train.py .
146-1	11146-11147	/	_	_
146-2	11147-11155	train.py	_	_
146-3	11156-11157	.	_	_

#Text=/configs/anet\_i3d.yaml --output reproduce ```  \* Evaluate the trained model.
147-1	11157-11158	/	_	_
147-2	11158-11165	configs	_	_
147-3	11165-11166	/	_	_
147-4	11166-11179	anet\_i3d.yaml	_	_
147-5	11180-11181	-	_	_
147-6	11181-11182	-	_	_
147-7	11182-11188	output	_	_
147-8	11189-11198	reproduce	_	_
147-9	11199-11200	`	_	_
147-10	11200-11201	`	_	_
147-11	11201-11202	`	_	_
147-12	11204-11205	\*	_	_
147-13	11206-11214	Evaluate	_	_
147-14	11215-11218	the	_	_
147-15	11219-11226	trained	_	_
147-16	11227-11232	model	_	_
147-17	11232-11233	.	_	_

#Text=The expected average mAP should be around 36.0(%).
148-1	11234-11237	The	_	_
148-2	11238-11246	expected	_	_
148-3	11247-11254	average	_	_
148-4	11255-11258	mAP	_	_
148-5	11259-11265	should	_	_
148-6	11266-11268	be	_	_
148-7	11269-11275	around	_	_
148-8	11276-11280	36.0	_	_
148-9	11280-11281	(	_	_
148-10	11281-11282	%	_	_
148-11	11282-11283	)	_	_
148-12	11283-11284	.	_	_

#Text=This is slightly improved from our paper.
149-1	11285-11289	This	_	_
149-2	11290-11292	is	_	_
149-3	11293-11301	slightly	_	_
149-4	11302-11310	improved	_	_
149-5	11311-11315	from	_	_
149-6	11316-11319	our	_	_
149-7	11320-11325	paper	_	_
149-8	11325-11326	.	_	_

#Text=The improvement is produced by better training scheme / hyperparameters (see comments in the config file).
150-1	11327-11330	The	_	_
150-2	11331-11342	improvement	_	_
150-3	11343-11345	is	_	_
150-4	11346-11354	produced	_	_
150-5	11355-11357	by	_	_
150-6	11358-11364	better	_	_
150-7	11365-11373	training	_	_
150-8	11374-11380	scheme	_	_
150-9	11381-11382	/	_	_
150-10	11383-11398	hyperparameters	_	_
150-11	11399-11400	(	_	_
150-12	11400-11403	see	_	_
150-13	11404-11412	comments	_	_
150-14	11413-11415	in	_	_
150-15	11416-11419	the	_	_
150-16	11420-11426	config	_	_
150-17	11427-11431	file	_	_
150-18	11431-11432	)	_	_
150-19	11432-11433	.	_	_

#Text=```shell python .
151-1	11434-11435	`	_	_
151-2	11435-11436	`	_	_
151-3	11436-11437	`	_	_
151-4	11437-11442	shell	_	_
151-5	11443-11449	python	_	_
151-6	11450-11451	.	_	_

#Text=/eval.py .
152-1	11451-11452	/	_	_
152-2	11452-11459	eval.py	_	_
152-3	11460-11461	.	_	_

#Text=/configs/anet\_i3d.yaml .
153-1	11461-11462	/	_	_
153-2	11462-11469	configs	_	_
153-3	11469-11470	/	_	_
153-4	11470-11483	anet\_i3d.yaml	_	_
153-5	11484-11485	.	_	_

#Text=/ckpt/anet\_i3d\_reproduce ```  \* The pre-trained model with all training logs can be downloaded from \[this Google Drive link\](https://drive.google.com/file/d/152dw2JDoNPssSnaQDaNolQUSFgcHlxe3/view?
154-1	11485-11486	/	_	_
154-2	11486-11490	ckpt	_	_
154-3	11490-11491	/	_	_
154-4	11491-11509	anet\_i3d\_reproduce	_	_
154-5	11510-11511	`	_	_
154-6	11511-11512	`	_	_
154-7	11512-11513	`	_	_
154-8	11515-11516	\*	_	_
154-9	11517-11520	The	_	_
154-10	11521-11532	pre-trained	_	_
154-11	11533-11538	model	_	_
154-12	11539-11543	with	_	_
154-13	11544-11547	all	_	_
154-14	11548-11556	training	_	_
154-15	11557-11561	logs	_	_
154-16	11562-11565	can	_	_
154-17	11566-11568	be	_	_
154-18	11569-11579	downloaded	_	_
154-19	11580-11584	from	_	_
154-20	11585-11586	\[	_	_
154-21	11586-11590	this	_	_
154-22	11591-11597	Google	_	_
154-23	11598-11603	Drive	_	_
154-24	11604-11608	link	_	_
154-25	11608-11609	\]	_	_
154-26	11609-11610	(	_	_
154-27	11610-11615	https	_	_
154-28	11615-11616	:	_	_
154-29	11616-11617	/	_	_
154-30	11617-11618	/	_	_
154-31	11618-11634	drive.google.com	_	_
154-32	11634-11635	/	_	_
154-33	11635-11639	file	_	_
154-34	11639-11640	/	_	_
154-35	11640-11641	d	_	_
154-36	11641-11642	/	_	_
154-37	11642-11675	152dw2JDoNPssSnaQDaNolQUSFgcHlxe3	_	_
154-38	11675-11676	/	_	_
154-39	11676-11680	view	_	_
154-40	11680-11681	?	_	_

#Text=usp=sharing).
155-1	11681-11684	usp	_	_
155-2	11684-11685	=	_	_
155-3	11685-11692	sharing	_	_
155-4	11692-11693	)	_	_
155-5	11693-11694	.	_	_

#Text=To produce the results, create a folder \*.
156-1	11695-11697	To	_	_
156-2	11698-11705	produce	_	_
156-3	11706-11709	the	_	_
156-4	11710-11717	results	_	_
156-5	11717-11718	,	_	_
156-6	11719-11725	create	_	_
156-7	11726-11727	a	_	_
156-8	11728-11734	folder	_	_
156-9	11735-11736	\*	_	_
156-10	11736-11737	.	_	_

#Text=/pretrained\*, unpack the file under \*.
157-1	11737-11738	/	_	_
157-2	11738-11748	pretrained	_	_
157-3	11748-11749	\*	_	_
157-4	11749-11750	,	_	_
157-5	11751-11757	unpack	_	_
157-6	11758-11761	the	_	_
157-7	11762-11766	file	_	_
157-8	11767-11772	under	_	_
157-9	11773-11774	\*	_	_
157-10	11774-11775	.	_	_

#Text=/pretrained\* (or elsewhere and link to \*.
158-1	11775-11776	/	_	_
158-2	11776-11786	pretrained	_	_
158-3	11786-11787	\*	_	_
158-4	11788-11789	(	_	_
158-5	11789-11791	or	_	_
158-6	11792-11801	elsewhere	_	_
158-7	11802-11805	and	_	_
158-8	11806-11810	link	_	_
158-9	11811-11813	to	_	_
158-10	11814-11815	\*	_	_
158-11	11815-11816	.	_	_

#Text=/pretrained\*), and run ```shell python .
159-1	11816-11817	/	_	_
159-2	11817-11827	pretrained	_	_
159-3	11827-11828	\*	_	_
159-4	11828-11829	)	_	_
159-5	11829-11830	,	_	_
159-6	11831-11834	and	_	_
159-7	11835-11838	run	_	_
159-8	11839-11840	`	_	_
159-9	11840-11841	`	_	_
159-10	11841-11842	`	_	_
159-11	11842-11847	shell	_	_
159-12	11848-11854	python	_	_
159-13	11855-11856	.	_	_

#Text=/eval.py .
160-1	11856-11857	/	_	_
160-2	11857-11864	eval.py	_	_
160-3	11865-11866	.	_	_

#Text=/configs/anet\_i3d.yaml .
161-1	11866-11867	/	_	_
161-2	11867-11874	configs	_	_
161-3	11874-11875	/	_	_
161-4	11875-11888	anet\_i3d.yaml	_	_
161-5	11889-11890	.	_	_

#Text=/pretrained/anet\_i3d\_reproduce/ ```  \* The results (mAP at tIoUs) with I3D features should be  \| Method            \|  0.5  \|  0.75 \|  0.95 \|  Avg  \| \|-------------------\|-------\|-------\|-------\|-------\| \| ActionFormer      \| 54.29 \| 36.71 \|  8.24 \| 36.03 \|  ## To Reproduce Our Results on EPIC Kitchens 100 \*\*Download Features and Annotations\*\* \* Download \*epic\_kitchens.tar.gz\* (`md5sum add9803756afd9a023bc9a9c547e0229`) from \[this Box link\](https://uwmadison.box.com/s/vdha47qnce6jhqktz9g4mq1gc40w82yj) or \[this Google Drive Link\](https://drive.google.com/file/d/1Z4U\_dLuu6\_cV5NBIrSzsSDOOj2Uar85X/view?
162-1	11890-11891	/	_	_
162-2	11891-11901	pretrained	_	_
162-3	11901-11902	/	_	_
162-4	11902-11920	anet\_i3d\_reproduce	_	_
162-5	11920-11921	/	_	_
162-6	11922-11923	`	_	_
162-7	11923-11924	`	_	_
162-8	11924-11925	`	_	_
162-9	11927-11928	\*	_	_
162-10	11929-11932	The	_	_
162-11	11933-11940	results	_	_
162-12	11941-11942	(	_	_
162-13	11942-11945	mAP	_	_
162-14	11946-11948	at	_	_
162-15	11949-11954	tIoUs	_	_
162-16	11954-11955	)	_	_
162-17	11956-11960	with	_	_
162-18	11961-11964	I3D	_	_
162-19	11965-11973	features	_	_
162-20	11974-11980	should	_	_
162-21	11981-11983	be	_	_
162-22	11985-11986	\|	_	_
162-23	11987-11993	Method	_	_
162-24	12005-12006	\|	_	_
162-25	12008-12011	0.5	_	_
162-26	12013-12014	\|	_	_
162-27	12016-12020	0.75	_	_
162-28	12021-12022	\|	_	_
162-29	12024-12028	0.95	_	_
162-30	12029-12030	\|	_	_
162-31	12032-12035	Avg	_	_
162-32	12037-12038	\|	_	_
162-33	12039-12040	\|	_	_
162-34	12040-12041	-	_	_
162-35	12041-12042	-	_	_
162-36	12042-12043	-	_	_
162-37	12043-12044	-	_	_
162-38	12044-12045	-	_	_
162-39	12045-12046	-	_	_
162-40	12046-12047	-	_	_
162-41	12047-12048	-	_	_
162-42	12048-12049	-	_	_
162-43	12049-12050	-	_	_
162-44	12050-12051	-	_	_
162-45	12051-12052	-	_	_
162-46	12052-12053	-	_	_
162-47	12053-12054	-	_	_
162-48	12054-12055	-	_	_
162-49	12055-12056	-	_	_
162-50	12056-12057	-	_	_
162-51	12057-12058	-	_	_
162-52	12058-12059	-	_	_
162-53	12059-12060	\|	_	_
162-54	12060-12061	-	_	_
162-55	12061-12062	-	_	_
162-56	12062-12063	-	_	_
162-57	12063-12064	-	_	_
162-58	12064-12065	-	_	_
162-59	12065-12066	-	_	_
162-60	12066-12067	-	_	_
162-61	12067-12068	\|	_	_
162-62	12068-12069	-	_	_
162-63	12069-12070	-	_	_
162-64	12070-12071	-	_	_
162-65	12071-12072	-	_	_
162-66	12072-12073	-	_	_
162-67	12073-12074	-	_	_
162-68	12074-12075	-	_	_
162-69	12075-12076	\|	_	_
162-70	12076-12077	-	_	_
162-71	12077-12078	-	_	_
162-72	12078-12079	-	_	_
162-73	12079-12080	-	_	_
162-74	12080-12081	-	_	_
162-75	12081-12082	-	_	_
162-76	12082-12083	-	_	_
162-77	12083-12084	\|	_	_
162-78	12084-12085	-	_	_
162-79	12085-12086	-	_	_
162-80	12086-12087	-	_	_
162-81	12087-12088	-	_	_
162-82	12088-12089	-	_	_
162-83	12089-12090	-	_	_
162-84	12090-12091	-	_	_
162-85	12091-12092	\|	_	_
162-86	12093-12094	\|	_	_
162-87	12095-12107	ActionFormer	_	_
162-88	12113-12114	\|	_	_
162-89	12115-12120	54.29	_	_
162-90	12121-12122	\|	_	_
162-91	12123-12128	36.71	_	_
162-92	12129-12130	\|	_	_
162-93	12132-12136	8.24	_	_
162-94	12137-12138	\|	_	_
162-95	12139-12144	36.03	_	_
162-96	12145-12146	\|	_	_
162-97	12148-12149	#	_	_
162-98	12149-12150	#	_	_
162-99	12151-12153	To	_	_
162-100	12154-12163	Reproduce	_	_
162-101	12164-12167	Our	_	_
162-102	12168-12175	Results	_	_
162-103	12176-12178	on	_	_
162-104	12179-12183	EPIC	_	_
162-105	12184-12192	Kitchens	_	_
162-106	12193-12196	100	_	_
162-107	12197-12198	\*	_	_
162-108	12198-12199	\*	_	_
162-109	12199-12207	Download	_	_
162-110	12208-12216	Features	_	_
162-111	12217-12220	and	_	_
162-112	12221-12232	Annotations	_	_
162-113	12232-12233	\*	_	_
162-114	12233-12234	\*	_	_
162-115	12235-12236	\*	_	_
162-116	12237-12245	Download	_	_
162-117	12246-12247	\*	_	_
162-118	12247-12267	epic\_kitchens.tar.gz	_	_
162-118	12247-12260	epic\_kitchens	_	_
162-119	12267-12268	\*	_	_
162-120	12269-12270	(	_	_
162-121	12270-12271	`	_	_
162-122	12271-12277	md5sum	_	_
162-123	12278-12310	add9803756afd9a023bc9a9c547e0229	_	_
162-124	12310-12311	`	_	_
162-125	12311-12312	)	_	_
162-126	12313-12317	from	_	_
162-127	12318-12319	\[	_	_
162-128	12319-12323	this	_	_
162-129	12324-12327	Box	_	_
162-130	12328-12332	link	_	_
162-131	12332-12333	\]	_	_
162-132	12333-12334	(	_	_
162-133	12334-12339	https	_	_
162-134	12339-12340	:	_	_
162-135	12340-12341	/	_	_
162-136	12341-12342	/	_	_
162-137	12342-12359	uwmadison.box.com	_	_
162-138	12359-12360	/	_	_
162-139	12360-12361	s	_	_
162-140	12361-12362	/	_	_
162-141	12362-12394	vdha47qnce6jhqktz9g4mq1gc40w82yj	_	_
162-142	12394-12395	)	_	_
162-143	12396-12398	or	_	_
162-144	12399-12400	\[	_	_
162-145	12400-12404	this	_	_
162-146	12405-12411	Google	_	_
162-147	12412-12417	Drive	_	_
162-148	12418-12422	Link	_	_
162-149	12422-12423	\]	_	_
162-150	12423-12424	(	_	_
162-151	12424-12429	https	_	_
162-152	12429-12430	:	_	_
162-153	12430-12431	/	_	_
162-154	12431-12432	/	_	_
162-155	12432-12448	drive.google.com	_	_
162-156	12448-12449	/	_	_
162-157	12449-12453	file	_	_
162-158	12453-12454	/	_	_
162-159	12454-12455	d	_	_
162-160	12455-12456	/	_	_
162-161	12456-12466	1Z4U\_dLuu6	_	_
162-162	12466-12467	\_	_	_
162-163	12467-12489	cV5NBIrSzsSDOOj2Uar85X	_	_
162-164	12489-12490	/	_	_
162-165	12490-12494	view	_	_
162-166	12494-12495	?	_	_

#Text=usp=sharing) or \[this BaiduYun Link\](https://pan.baidu.com/s/15tOdX6Yp4AJ9lFGjbQ8dgg?
163-1	12495-12498	usp	_	_
163-2	12498-12499	=	_	_
163-3	12499-12506	sharing	_	_
163-4	12506-12507	)	_	_
163-5	12508-12510	or	_	_
163-6	12511-12512	\[	_	_
163-7	12512-12516	this	_	_
163-8	12517-12525	BaiduYun	_	_
163-9	12526-12530	Link	_	_
163-10	12530-12531	\]	_	_
163-11	12531-12532	(	_	_
163-12	12532-12537	https	_	_
163-13	12537-12538	:	_	_
163-14	12538-12539	/	_	_
163-15	12539-12540	/	_	_
163-16	12540-12553	pan.baidu.com	_	_
163-17	12553-12554	/	_	_
163-18	12554-12555	s	_	_
163-19	12555-12556	/	_	_
163-20	12556-12579	15tOdX6Yp4AJ9lFGjbQ8dgg	_	_
163-21	12579-12580	?	_	_

#Text=pwd=f3tx). \* The file includes SlowFast features as well as action annotations in json format (similar to ActivityNet annotation format).
164-1	12580-12583	pwd	_	_
164-2	12583-12584	=	_	_
164-3	12584-12588	f3tx	_	_
164-4	12588-12589	)	_	_
164-5	12589-12590	.	_	_
164-6	12591-12592	\*	_	_
164-7	12593-12596	The	_	_
164-8	12597-12601	file	_	_
164-9	12602-12610	includes	_	_
164-10	12611-12619	SlowFast	_	_
164-11	12620-12628	features	_	_
164-12	12629-12631	as	_	_
164-13	12632-12636	well	_	_
164-14	12637-12639	as	_	_
164-15	12640-12646	action	_	_
164-16	12647-12658	annotations	_	_
164-17	12659-12661	in	_	_
164-18	12662-12666	json	_	_
164-19	12667-12673	format	_	_
164-20	12674-12675	(	_	_
164-21	12675-12682	similar	_	_
164-22	12683-12685	to	_	_
164-23	12686-12697	ActivityNet	_	_
164-24	12698-12708	annotation	_	_
164-25	12709-12715	format	_	_
164-26	12715-12716	)	_	_
164-27	12716-12717	.	_	_

#Text=\*\*Details\*\*: The features are extracted from the SlowFast model pretrained on the training set of EPIC Kitchens 100 (action classification) using clips of `32 frames` at a frame rate of `30 fps` and a stride of `16 frames`.
165-1	12719-12720	\*	_	_
165-2	12720-12721	\*	_	_
165-3	12721-12728	Details	_	_
165-4	12728-12729	\*	_	_
165-5	12729-12730	\*	_	_
165-6	12730-12731	:	_	_
165-7	12732-12735	The	_	_
165-8	12736-12744	features	_	_
165-9	12745-12748	are	_	_
165-10	12749-12758	extracted	_	_
165-11	12759-12763	from	_	_
165-12	12764-12767	the	_	_
165-13	12768-12776	SlowFast	_	_
165-14	12777-12782	model	_	_
165-15	12783-12793	pretrained	_	_
165-16	12794-12796	on	_	_
165-17	12797-12800	the	_	_
165-18	12801-12809	training	_	_
165-19	12810-12813	set	_	_
165-20	12814-12816	of	_	_
165-21	12817-12821	EPIC	_	_
165-22	12822-12830	Kitchens	_	_
165-23	12831-12834	100	_	_
165-24	12835-12836	(	_	_
165-25	12836-12842	action	_	_
165-26	12843-12857	classification	_	_
165-27	12857-12858	)	_	_
165-28	12859-12864	using	_	_
165-29	12865-12870	clips	_	_
165-30	12871-12873	of	_	_
165-31	12874-12875	`	_	_
165-32	12875-12877	32	_	_
165-33	12878-12884	frames	_	_
165-34	12884-12885	`	_	_
165-35	12886-12888	at	_	_
165-36	12889-12890	a	_	_
165-37	12891-12896	frame	_	_
165-38	12897-12901	rate	_	_
165-39	12902-12904	of	_	_
165-40	12905-12906	`	_	_
165-41	12906-12908	30	_	_
165-42	12909-12912	fps	_	_
165-43	12912-12913	`	_	_
165-44	12914-12917	and	_	_
165-45	12918-12919	a	_	_
165-46	12920-12926	stride	_	_
165-47	12927-12929	of	_	_
165-48	12930-12931	`	_	_
165-49	12931-12933	16	_	_
165-50	12934-12940	frames	_	_
165-51	12940-12941	`	_	_
165-52	12941-12942	.	_	_

#Text=This gives one feature vector per `16/30 ~= 0.5333` seconds.
166-1	12943-12947	This	_	_
166-2	12948-12953	gives	_	_
166-3	12954-12957	one	_	_
166-4	12958-12965	feature	_	_
166-5	12966-12972	vector	_	_
166-6	12973-12976	per	_	_
166-7	12977-12978	`	_	_
166-8	12978-12980	16	_	_
166-9	12980-12981	/	_	_
166-10	12981-12983	30	_	_
166-11	12984-12985	~	_	_
166-12	12985-12986	=	_	_
166-13	12987-12993	0.5333	_	_
166-14	12993-12994	`	_	_
166-15	12995-13002	seconds	_	_
166-16	13002-13003	.	_	_

#Text=\*\*Unpack Features and Annotations\*\* \* Unpack the file under \*.
167-1	13005-13006	\*	_	_
167-2	13006-13007	\*	_	_
167-3	13007-13013	Unpack	_	_
167-4	13014-13022	Features	_	_
167-5	13023-13026	and	_	_
167-6	13027-13038	Annotations	_	_
167-7	13038-13039	\*	_	_
167-8	13039-13040	\*	_	_
167-9	13041-13042	\*	_	_
167-10	13043-13049	Unpack	_	_
167-11	13050-13053	the	_	_
167-12	13054-13058	file	_	_
167-13	13059-13064	under	_	_
167-14	13065-13066	\*	_	_
167-15	13066-13067	.	_	_

#Text=/data\* (or elsewhere and link to \*.
168-1	13067-13068	/	_	_
168-2	13068-13072	data	_	_
168-3	13072-13073	\*	_	_
168-4	13074-13075	(	_	_
168-5	13075-13077	or	_	_
168-6	13078-13087	elsewhere	_	_
168-7	13088-13091	and	_	_
168-8	13092-13096	link	_	_
168-9	13097-13099	to	_	_
168-10	13100-13101	\*	_	_
168-11	13101-13102	.	_	_

#Text=/data\*). \* The folder structure should look like ``` This folder │   README.md │
169-1	13102-13103	/	_	_
169-2	13103-13107	data	_	_
169-3	13107-13108	\*	_	_
169-4	13108-13109	)	_	_
169-5	13109-13110	.	_	_
169-6	13111-13112	\*	_	_
169-7	13113-13116	The	_	_
169-8	13117-13123	folder	_	_
169-9	13124-13133	structure	_	_
169-10	13134-13140	should	_	_
169-11	13141-13145	look	_	_
169-12	13146-13150	like	_	_
169-13	13151-13152	`	_	_
169-14	13152-13153	`	_	_
169-15	13153-13154	`	_	_
169-16	13155-13159	This	_	_
169-17	13160-13166	folder	_	_
169-18	13167-13168	│	_	_
169-19	13171-13180	README.md	_	_
169-20	13181-13182	│	_	_

#Text=.
170-1	13185-13186	.	_	_

#Text=.
171-1	13186-13187	.	_	_

#Text=.
172-1	13187-13188	.	_	_

#Text=│ └───data/ │    └───epic\_kitchens/ │    │  └───annotations │    │  └───features    │    └───... \| └───libs │ │   ... ```  \*\*Training and Evaluation\*\* \* On EPIC Kitchens, we train separate models for nouns and verbs. \* To train our ActionFormer on verbs with SlowFast features, use ```shell python .
173-1	13191-13192	│	_	_
173-2	13193-13194	└	_	_
173-3	13194-13195	─	_	_
173-4	13195-13196	─	_	_
173-5	13196-13197	─	_	_
173-6	13197-13201	data	_	_
173-7	13201-13202	/	_	_
173-8	13203-13204	│	_	_
173-9	13208-13209	└	_	_
173-10	13209-13210	─	_	_
173-11	13210-13211	─	_	_
173-12	13211-13212	─	_	_
173-13	13212-13225	epic\_kitchens	_	_
173-14	13225-13226	/	_	_
173-15	13227-13228	│	_	_
173-16	13232-13233	│	_	_
173-17	13235-13236	└	_	_
173-18	13236-13237	─	_	_
173-19	13237-13238	─	_	_
173-20	13238-13239	─	_	_
173-21	13239-13250	annotations	_	_
173-22	13251-13252	│	_	_
173-23	13256-13257	│	_	_
173-24	13259-13260	└	_	_
173-25	13260-13261	─	_	_
173-26	13261-13262	─	_	_
173-27	13262-13263	─	_	_
173-28	13263-13271	features	_	_
173-29	13275-13276	│	_	_
173-30	13280-13281	└	_	_
173-31	13281-13282	─	_	_
173-32	13282-13283	─	_	_
173-33	13283-13284	─	_	_
173-34	13284-13285	.	_	_
173-35	13285-13286	.	_	_
173-36	13286-13287	.	_	_
173-37	13288-13289	\|	_	_
173-38	13290-13291	└	_	_
173-39	13291-13292	─	_	_
173-40	13292-13293	─	_	_
173-41	13293-13294	─	_	_
173-42	13294-13298	libs	_	_
173-43	13299-13300	│	_	_
173-44	13301-13302	│	_	_
173-45	13305-13306	.	_	_
173-46	13306-13307	.	_	_
173-47	13307-13308	.	_	_
173-48	13309-13310	`	_	_
173-49	13310-13311	`	_	_
173-50	13311-13312	`	_	_
173-51	13314-13315	\*	_	_
173-52	13315-13316	\*	_	_
173-53	13316-13324	Training	_	_
173-54	13325-13328	and	_	_
173-55	13329-13339	Evaluation	_	_
173-56	13339-13340	\*	_	_
173-57	13340-13341	\*	_	_
173-58	13342-13343	\*	_	_
173-59	13344-13346	On	_	_
173-60	13347-13351	EPIC	_	_
173-61	13352-13360	Kitchens	_	_
173-62	13360-13361	,	_	_
173-63	13362-13364	we	_	_
173-64	13365-13370	train	_	_
173-65	13371-13379	separate	_	_
173-66	13380-13386	models	_	_
173-67	13387-13390	for	_	_
173-68	13391-13396	nouns	_	_
173-69	13397-13400	and	_	_
173-70	13401-13406	verbs	_	_
173-71	13406-13407	.	_	_
173-72	13408-13409	\*	_	_
173-73	13410-13412	To	_	_
173-74	13413-13418	train	_	_
173-75	13419-13422	our	_	_
173-76	13423-13435	ActionFormer	_	_
173-77	13436-13438	on	_	_
173-78	13439-13444	verbs	_	_
173-79	13445-13449	with	_	_
173-80	13450-13458	SlowFast	_	_
173-81	13459-13467	features	_	_
173-82	13467-13468	,	_	_
173-83	13469-13472	use	_	_
173-84	13473-13474	`	_	_
173-85	13474-13475	`	_	_
173-86	13475-13476	`	_	_
173-87	13476-13481	shell	_	_
173-88	13482-13488	python	_	_
173-89	13489-13490	.	_	_

#Text=/train.py .
174-1	13490-13491	/	_	_
174-2	13491-13499	train.py	_	_
174-3	13500-13501	.	_	_

#Text=/configs/epic\_slowfast\_verb.yaml --output reproduce ``` \* To train our ActionFormer on nouns with SlowFast features, use ```shell python .
175-1	13501-13502	/	_	_
175-2	13502-13509	configs	_	_
175-3	13509-13510	/	_	_
175-4	13510-13533	epic\_slowfast\_verb.yaml	_	_
175-5	13534-13535	-	_	_
175-6	13535-13536	-	_	_
175-7	13536-13542	output	_	_
175-8	13543-13552	reproduce	_	_
175-9	13553-13554	`	_	_
175-10	13554-13555	`	_	_
175-11	13555-13556	`	_	_
175-12	13557-13558	\*	_	_
175-13	13559-13561	To	_	_
175-14	13562-13567	train	_	_
175-15	13568-13571	our	_	_
175-16	13572-13584	ActionFormer	_	_
175-17	13585-13587	on	_	_
175-18	13588-13593	nouns	_	_
175-19	13594-13598	with	_	_
175-20	13599-13607	SlowFast	_	_
175-21	13608-13616	features	_	_
175-22	13616-13617	,	_	_
175-23	13618-13621	use	_	_
175-24	13622-13623	`	_	_
175-25	13623-13624	`	_	_
175-26	13624-13625	`	_	_
175-27	13625-13630	shell	_	_
175-28	13631-13637	python	_	_
175-29	13638-13639	.	_	_

#Text=/train.py .
176-1	13639-13640	/	_	_
176-2	13640-13648	train.py	_	_
176-3	13649-13650	.	_	_

#Text=/configs/epic\_slowfast\_noun.yaml --output reproduce ``` \* Evaluate the trained model for verbs.
177-1	13650-13651	/	_	_
177-2	13651-13658	configs	_	_
177-3	13658-13659	/	_	_
177-4	13659-13682	epic\_slowfast\_noun.yaml	_	_
177-5	13683-13684	-	_	_
177-6	13684-13685	-	_	_
177-7	13685-13691	output	_	_
177-8	13692-13701	reproduce	_	_
177-9	13702-13703	`	_	_
177-10	13703-13704	`	_	_
177-11	13704-13705	`	_	_
177-12	13706-13707	\*	_	_
177-13	13708-13716	Evaluate	_	_
177-14	13717-13720	the	_	_
177-15	13721-13728	trained	_	_
177-16	13729-13734	model	_	_
177-17	13735-13738	for	_	_
177-18	13739-13744	verbs	_	_
177-19	13744-13745	.	_	_

#Text=The expected average mAP should be around 23.4(%) as in Table 2 of our main paper.
178-1	13746-13749	The	_	_
178-2	13750-13758	expected	_	_
178-3	13759-13766	average	_	_
178-4	13767-13770	mAP	_	_
178-5	13771-13777	should	_	_
178-6	13778-13780	be	_	_
178-7	13781-13787	around	_	_
178-8	13788-13792	23.4	_	_
178-9	13792-13793	(	_	_
178-10	13793-13794	%	_	_
178-11	13794-13795	)	_	_
178-12	13796-13798	as	_	_
178-13	13799-13801	in	_	_
178-14	13802-13807	Table	_	_
178-15	13808-13809	2	_	_
178-16	13810-13812	of	_	_
178-17	13813-13816	our	_	_
178-18	13817-13821	main	_	_
178-19	13822-13827	paper	_	_
178-20	13827-13828	.	_	_

#Text=```shell python .
179-1	13829-13830	`	_	_
179-2	13830-13831	`	_	_
179-3	13831-13832	`	_	_
179-4	13832-13837	shell	_	_
179-5	13838-13844	python	_	_
179-6	13845-13846	.	_	_

#Text=/eval.py .
180-1	13846-13847	/	_	_
180-2	13847-13854	eval.py	_	_
180-3	13855-13856	.	_	_

#Text=/configs/epic\_slowfast\_verb.yaml .
181-1	13856-13857	/	_	_
181-2	13857-13864	configs	_	_
181-3	13864-13865	/	_	_
181-4	13865-13888	epic\_slowfast\_verb.yaml	_	_
181-5	13889-13890	.	_	_

#Text=/ckpt/epic\_slowfast\_verb\_reproduce ``` \* Evaluate the trained model for nouns.
182-1	13890-13891	/	_	_
182-2	13891-13895	ckpt	_	_
182-3	13895-13896	/	_	_
182-4	13896-13924	epic\_slowfast\_verb\_reproduce	_	_
182-5	13925-13926	`	_	_
182-6	13926-13927	`	_	_
182-7	13927-13928	`	_	_
182-8	13929-13930	\*	_	_
182-9	13931-13939	Evaluate	_	_
182-10	13940-13943	the	_	_
182-11	13944-13951	trained	_	_
182-12	13952-13957	model	_	_
182-13	13958-13961	for	_	_
182-14	13962-13967	nouns	_	_
182-15	13967-13968	.	_	_

#Text=The expected average mAP should be around 21.9(%) as in Table 2 of our main paper.
183-1	13969-13972	The	_	_
183-2	13973-13981	expected	_	_
183-3	13982-13989	average	_	_
183-4	13990-13993	mAP	_	_
183-5	13994-14000	should	_	_
183-6	14001-14003	be	_	_
183-7	14004-14010	around	_	_
183-8	14011-14015	21.9	_	_
183-9	14015-14016	(	_	_
183-10	14016-14017	%	_	_
183-11	14017-14018	)	_	_
183-12	14019-14021	as	_	_
183-13	14022-14024	in	_	_
183-14	14025-14030	Table	_	_
183-15	14031-14032	2	_	_
183-16	14033-14035	of	_	_
183-17	14036-14039	our	_	_
183-18	14040-14044	main	_	_
183-19	14045-14050	paper	_	_
183-20	14050-14051	.	_	_

#Text=```shell python .
184-1	14052-14053	`	_	_
184-2	14053-14054	`	_	_
184-3	14054-14055	`	_	_
184-4	14055-14060	shell	_	_
184-5	14061-14067	python	_	_
184-6	14068-14069	.	_	_

#Text=/eval.py .
185-1	14069-14070	/	_	_
185-2	14070-14077	eval.py	_	_
185-3	14078-14079	.	_	_

#Text=/configs/epic\_slowfast\_noun.yaml .
186-1	14079-14080	/	_	_
186-2	14080-14087	configs	_	_
186-3	14087-14088	/	_	_
186-4	14088-14111	epic\_slowfast\_noun.yaml	_	_
186-5	14112-14113	.	_	_

#Text=/ckpt/epic\_slowfast\_noun\_reproduce ``` \* Training our model on EPIC Kitchens requires ~4.5GB GPU memory, yet the inference might require over 10GB GPU memory.
187-1	14113-14114	/	_	_
187-2	14114-14118	ckpt	_	_
187-3	14118-14119	/	_	_
187-4	14119-14147	epic\_slowfast\_noun\_reproduce	_	_
187-5	14148-14149	`	_	_
187-6	14149-14150	`	_	_
187-7	14150-14151	`	_	_
187-8	14152-14153	\*	_	_
187-9	14154-14162	Training	_	_
187-10	14163-14166	our	_	_
187-11	14167-14172	model	_	_
187-12	14173-14175	on	_	_
187-13	14176-14180	EPIC	_	_
187-14	14181-14189	Kitchens	_	_
187-15	14190-14198	requires	_	_
187-16	14199-14200	~	_	_
187-17	14200-14205	4.5GB	_	_
187-18	14206-14209	GPU	_	_
187-19	14210-14216	memory	_	_
187-20	14216-14217	,	_	_
187-21	14218-14221	yet	_	_
187-22	14222-14225	the	_	_
187-23	14226-14235	inference	_	_
187-24	14236-14241	might	_	_
187-25	14242-14249	require	_	_
187-26	14250-14254	over	_	_
187-27	14255-14259	10GB	_	_
187-28	14260-14263	GPU	_	_
187-29	14264-14270	memory	_	_
187-30	14270-14271	.	_	_

#Text=We recommend using a GPU with at least 12 GB of memory.
188-1	14272-14274	We	_	_
188-2	14275-14284	recommend	_	_
188-3	14285-14290	using	_	_
188-4	14291-14292	a	_	_
188-5	14293-14296	GPU	_	_
188-6	14297-14301	with	_	_
188-7	14302-14304	at	_	_
188-8	14305-14310	least	_	_
188-9	14311-14313	12	_	_
188-10	14314-14316	GB	_	_
188-11	14317-14319	of	_	_
188-12	14320-14326	memory	_	_
188-13	14326-14327	.	_	_

#Text=\*\*\[Optional\] Evaluating Our Pre-trained Model\*\*  We also provide a pre-trained model for EPIC-Kitchens 100.
189-1	14329-14330	\*	_	_
189-2	14330-14331	\*	_	_
189-3	14331-14332	\[	_	_
189-4	14332-14340	Optional	_	_
189-5	14340-14341	\]	_	_
189-6	14342-14352	Evaluating	_	_
189-7	14353-14356	Our	_	_
189-8	14357-14368	Pre-trained	_	_
189-9	14369-14374	Model	_	_
189-10	14374-14375	\*	_	_
189-11	14375-14376	\*	_	_
189-12	14378-14380	We	_	_
189-13	14381-14385	also	_	_
189-14	14386-14393	provide	_	_
189-15	14394-14395	a	_	_
189-16	14396-14407	pre-trained	_	_
189-17	14408-14413	model	_	_
189-18	14414-14417	for	_	_
189-19	14418-14431	EPIC-Kitchens	_	_
189-20	14432-14435	100	_	_
189-21	14435-14436	.	_	_

#Text=The model with all training logs can be downloaded from \[this Google Drive link\](https://drive.google.com/file/d/1Ta4ggKSj2YcszSrDbePlHe1ECF1CFKK4/view?
190-1	14437-14440	The	_	_
190-2	14441-14446	model	_	_
190-3	14447-14451	with	_	_
190-4	14452-14455	all	_	_
190-5	14456-14464	training	_	_
190-6	14465-14469	logs	_	_
190-7	14470-14473	can	_	_
190-8	14474-14476	be	_	_
190-9	14477-14487	downloaded	_	_
190-10	14488-14492	from	_	_
190-11	14493-14494	\[	_	_
190-12	14494-14498	this	_	_
190-13	14499-14505	Google	_	_
190-14	14506-14511	Drive	_	_
190-15	14512-14516	link	_	_
190-16	14516-14517	\]	_	_
190-17	14517-14518	(	_	_
190-18	14518-14523	https	_	_
190-19	14523-14524	:	_	_
190-20	14524-14525	/	_	_
190-21	14525-14526	/	_	_
190-22	14526-14542	drive.google.com	_	_
190-23	14542-14543	/	_	_
190-24	14543-14547	file	_	_
190-25	14547-14548	/	_	_
190-26	14548-14549	d	_	_
190-27	14549-14550	/	_	_
190-28	14550-14583	1Ta4ggKSj2YcszSrDbePlHe1ECF1CFKK4	_	_
190-29	14583-14584	/	_	_
190-30	14584-14588	view	_	_
190-31	14588-14589	?	_	_

#Text=usp=sharing) (verb), and from this \[Google Drive link\](https://drive.google.com/file/d/1OTlxeiWj8JE9n1-LsRYogHmqgUdsE5PR/view?
191-1	14589-14592	usp	_	_
191-2	14592-14593	=	_	_
191-3	14593-14600	sharing	_	_
191-4	14600-14601	)	_	_
191-5	14602-14603	(	_	_
191-6	14603-14607	verb	_	_
191-7	14607-14608	)	_	_
191-8	14608-14609	,	_	_
191-9	14610-14613	and	_	_
191-10	14614-14618	from	_	_
191-11	14619-14623	this	_	_
191-12	14624-14625	\[	_	_
191-13	14625-14631	Google	_	_
191-14	14632-14637	Drive	_	_
191-15	14638-14642	link	_	_
191-16	14642-14643	\]	_	_
191-17	14643-14644	(	_	_
191-18	14644-14649	https	_	_
191-19	14649-14650	:	_	_
191-20	14650-14651	/	_	_
191-21	14651-14652	/	_	_
191-22	14652-14668	drive.google.com	_	_
191-23	14668-14669	/	_	_
191-24	14669-14673	file	_	_
191-25	14673-14674	/	_	_
191-26	14674-14675	d	_	_
191-27	14675-14676	/	_	_
191-28	14676-14691	1OTlxeiWj8JE9n1	_	_
191-29	14691-14692	-	_	_
191-30	14692-14709	LsRYogHmqgUdsE5PR	_	_
191-31	14709-14710	/	_	_
191-32	14710-14714	view	_	_
191-33	14714-14715	?	_	_

#Text=usp=sharing) (noun).
192-1	14715-14718	usp	_	_
192-2	14718-14719	=	_	_
192-3	14719-14726	sharing	_	_
192-4	14726-14727	)	_	_
192-5	14728-14729	(	_	_
192-6	14729-14733	noun	_	_
192-7	14733-14734	)	_	_
192-8	14734-14735	.	_	_

#Text=To evaluate the pre-trained model, please follow the steps listed below
193-1	14736-14738	To	_	_
193-2	14739-14747	evaluate	_	_
193-3	14748-14751	the	_	_
193-4	14752-14763	pre-trained	_	_
193-5	14764-14769	model	_	_
193-6	14769-14770	,	_	_
193-7	14771-14777	please	_	_
193-8	14778-14784	follow	_	_
193-9	14785-14788	the	_	_
193-10	14789-14794	steps	_	_
193-11	14795-14801	listed	_	_
193-12	14802-14807	below	_	_

#Text=.
194-1	14807-14808	.	_	_

#Text=\* Create a folder \*.
195-1	14810-14811	\*	_	_
195-2	14812-14818	Create	_	_
195-3	14819-14820	a	_	_
195-4	14821-14827	folder	_	_
195-5	14828-14829	\*	_	_
195-6	14829-14830	.	_	_

#Text=/pretrained\* and unpack the file under \*.
196-1	14830-14831	/	_	_
196-2	14831-14841	pretrained	_	_
196-3	14841-14842	\*	_	_
196-4	14843-14846	and	_	_
196-5	14847-14853	unpack	_	_
196-6	14854-14857	the	_	_
196-7	14858-14862	file	_	_
196-8	14863-14868	under	_	_
196-9	14869-14870	\*	_	_
196-10	14870-14871	.	_	_

#Text=/pretrained\* (or elsewhere and link to \*.
197-1	14871-14872	/	_	_
197-2	14872-14882	pretrained	_	_
197-3	14882-14883	\*	_	_
197-4	14884-14885	(	_	_
197-5	14885-14887	or	_	_
197-6	14888-14897	elsewhere	_	_
197-7	14898-14901	and	_	_
197-8	14902-14906	link	_	_
197-9	14907-14909	to	_	_
197-10	14910-14911	\*	_	_
197-11	14911-14912	.	_	_

#Text=/pretrained\*). \* The folder structure should look like ``` This folder │   README.md │
198-1	14912-14913	/	_	_
198-2	14913-14923	pretrained	_	_
198-3	14923-14924	\*	_	_
198-4	14924-14925	)	_	_
198-5	14925-14926	.	_	_
198-6	14927-14928	\*	_	_
198-7	14929-14932	The	_	_
198-8	14933-14939	folder	_	_
198-9	14940-14949	structure	_	_
198-10	14950-14956	should	_	_
198-11	14957-14961	look	_	_
198-12	14962-14966	like	_	_
198-13	14967-14968	`	_	_
198-14	14968-14969	`	_	_
198-15	14969-14970	`	_	_
198-16	14971-14975	This	_	_
198-17	14976-14982	folder	_	_
198-18	14983-14984	│	_	_
198-19	14987-14996	README.md	_	_
198-20	14997-14998	│	_	_

#Text=.
199-1	15001-15002	.	_	_

#Text=.
200-1	15002-15003	.	_	_

#Text=.
201-1	15003-15004	.	_	_

#Text=│ └───pretrained/ │    └───epic\_slowfast\_verb\_reproduce/ │    │  └───epic\_slowfast\_verb\_reproduce\_log.txt │    │  └───epic\_slowfast\_verb\_reproduce\_results.txt │    │   └───
202-1	15007-15008	│	_	_
202-2	15009-15010	└	_	_
202-3	15010-15011	─	_	_
202-4	15011-15012	─	_	_
202-5	15012-15013	─	_	_
202-6	15013-15023	pretrained	_	_
202-7	15023-15024	/	_	_
202-8	15025-15026	│	_	_
202-9	15030-15031	└	_	_
202-10	15031-15032	─	_	_
202-11	15032-15033	─	_	_
202-12	15033-15034	─	_	_
202-13	15034-15062	epic\_slowfast\_verb\_reproduce	_	_
202-14	15062-15063	/	_	_
202-15	15064-15065	│	_	_
202-16	15069-15070	│	_	_
202-17	15072-15073	└	_	_
202-18	15073-15074	─	_	_
202-19	15074-15075	─	_	_
202-20	15075-15076	─	_	_
202-21	15076-15112	epic\_slowfast\_verb\_reproduce\_log.txt	_	_
202-22	15113-15114	│	_	_
202-23	15118-15119	│	_	_
202-24	15121-15122	└	_	_
202-25	15122-15123	─	_	_
202-26	15123-15124	─	_	_
202-27	15124-15125	─	_	_
202-28	15125-15165	epic\_slowfast\_verb\_reproduce\_results.txt	_	_
202-29	15166-15167	│	_	_
202-30	15171-15172	│	_	_
202-31	15175-15176	└	_	_
202-32	15176-15177	─	_	_
202-33	15177-15178	─	_	_
202-34	15178-15179	─	_	_

#Text=.
203-1	15179-15180	.	_	_

#Text=.
204-1	15180-15181	.	_	_

#Text=.
205-1	15181-15182	.	_	_

#Text=│    └───epic\_slowfast\_noun\_reproduce/ │    │  └───epic\_slowfast\_noun\_reproduce\_log.txt │    │  └───epic\_slowfast\_noun\_reproduce\_results.txt │    │   └───
206-1	15186-15187	│	_	_
206-2	15191-15192	└	_	_
206-3	15192-15193	─	_	_
206-4	15193-15194	─	_	_
206-5	15194-15195	─	_	_
206-6	15195-15223	epic\_slowfast\_noun\_reproduce	_	_
206-7	15223-15224	/	_	_
206-8	15225-15226	│	_	_
206-9	15230-15231	│	_	_
206-10	15233-15234	└	_	_
206-11	15234-15235	─	_	_
206-12	15235-15236	─	_	_
206-13	15236-15237	─	_	_
206-14	15237-15273	epic\_slowfast\_noun\_reproduce\_log.txt	_	_
206-15	15274-15275	│	_	_
206-16	15279-15280	│	_	_
206-17	15282-15283	└	_	_
206-18	15283-15284	─	_	_
206-19	15284-15285	─	_	_
206-20	15285-15286	─	_	_
206-21	15286-15326	epic\_slowfast\_noun\_reproduce\_results.txt	_	_
206-22	15327-15328	│	_	_
206-23	15332-15333	│	_	_
206-24	15336-15337	└	_	_
206-25	15337-15338	─	_	_
206-26	15338-15339	─	_	_
206-27	15339-15340	─	_	_

#Text=.
207-1	15340-15341	.	_	_

#Text=.
208-1	15341-15342	.	_	_

#Text=.
209-1	15342-15343	.	_	_

#Text=│    └───... \| └───libs │ │   ... ``` \* The training config is recorded in \*.
210-1	15346-15347	│	_	_
210-2	15351-15352	└	_	_
210-3	15352-15353	─	_	_
210-4	15353-15354	─	_	_
210-5	15354-15355	─	_	_
210-6	15355-15356	.	_	_
210-7	15356-15357	.	_	_
210-8	15357-15358	.	_	_
210-9	15359-15360	\|	_	_
210-10	15361-15362	└	_	_
210-11	15362-15363	─	_	_
210-12	15363-15364	─	_	_
210-13	15364-15365	─	_	_
210-14	15365-15369	libs	_	_
210-15	15370-15371	│	_	_
210-16	15372-15373	│	_	_
210-17	15376-15377	.	_	_
210-18	15377-15378	.	_	_
210-19	15378-15379	.	_	_
210-20	15380-15381	`	_	_
210-21	15381-15382	`	_	_
210-22	15382-15383	`	_	_
210-23	15384-15385	\*	_	_
210-24	15386-15389	The	_	_
210-25	15390-15398	training	_	_
210-26	15399-15405	config	_	_
210-27	15406-15408	is	_	_
210-28	15409-15417	recorded	_	_
210-29	15418-15420	in	_	_
210-30	15421-15422	\*	_	_
210-31	15422-15423	.	_	_

#Text=/pretrained/epic\_slowfast\_(verb\|noun)\_reproduce/config.txt\*. \* The training log is located at \*.
211-1	15423-15424	/	_	_
211-2	15424-15434	pretrained	_	_
211-3	15434-15435	/	_	_
211-4	15435-15448	epic\_slowfast	_	_
211-5	15448-15449	\_	_	_
211-6	15449-15450	(	_	_
211-7	15450-15454	verb	_	_
211-8	15454-15455	\|	_	_
211-9	15455-15459	noun	_	_
211-10	15459-15460	)	_	_
211-11	15460-15461	\_	_	_
211-12	15461-15470	reproduce	_	_
211-13	15470-15471	/	_	_
211-14	15471-15481	config.txt	_	_
211-15	15481-15482	\*	_	_
211-16	15482-15483	.	_	_
211-17	15484-15485	\*	_	_
211-18	15486-15489	The	_	_
211-19	15490-15498	training	_	_
211-20	15499-15502	log	_	_
211-21	15503-15505	is	_	_
211-22	15506-15513	located	_	_
211-23	15514-15516	at	_	_
211-24	15517-15518	\*	_	_
211-25	15518-15519	.	_	_

#Text=/pretrained/epic\_slowfast\_(verb\|noun)\_reproduce/epic\_slowfast\_(verb\|noun)\_reproduce\_log.txt\* and also \*.
212-1	15519-15520	/	_	_
212-2	15520-15530	pretrained	_	_
212-3	15530-15531	/	_	_
212-4	15531-15544	epic\_slowfast	_	_
212-5	15544-15545	\_	_	_
212-6	15545-15546	(	_	_
212-7	15546-15550	verb	_	_
212-8	15550-15551	\|	_	_
212-9	15551-15555	noun	_	_
212-10	15555-15556	)	_	_
212-11	15556-15557	\_	_	_
212-12	15557-15566	reproduce	_	_
212-13	15566-15567	/	_	_
212-14	15567-15580	epic\_slowfast	_	_
212-15	15580-15581	\_	_	_
212-16	15581-15582	(	_	_
212-17	15582-15586	verb	_	_
212-18	15586-15587	\|	_	_
212-19	15587-15591	noun	_	_
212-20	15591-15592	)	_	_
212-21	15592-15593	\_	_	_
212-22	15593-15610	reproduce\_log.txt	_	_
212-23	15610-15611	\*	_	_
212-24	15612-15615	and	_	_
212-25	15616-15620	also	_	_
212-26	15621-15622	\*	_	_
212-27	15622-15623	.	_	_

#Text=/pretrained/epic\_slowfast\_(verb\|noun)\_reproduce/logs\*. \* The pre-trained model is \*.
213-1	15623-15624	/	_	_
213-2	15624-15634	pretrained	_	_
213-3	15634-15635	/	_	_
213-4	15635-15648	epic\_slowfast	_	_
213-5	15648-15649	\_	_	_
213-6	15649-15650	(	_	_
213-7	15650-15654	verb	_	_
213-8	15654-15655	\|	_	_
213-9	15655-15659	noun	_	_
213-10	15659-15660	)	_	_
213-11	15660-15661	\_	_	_
213-12	15661-15670	reproduce	_	_
213-13	15670-15671	/	_	_
213-14	15671-15675	logs	_	_
213-15	15675-15676	\*	_	_
213-16	15676-15677	.	_	_
213-17	15678-15679	\*	_	_
213-18	15680-15683	The	_	_
213-19	15684-15695	pre-trained	_	_
213-20	15696-15701	model	_	_
213-21	15702-15704	is	_	_
213-22	15705-15706	\*	_	_
213-23	15706-15707	.	_	_

#Text=/pretrained/epic\_slowfast\_(verb\|noun)\_reproduce/epoch\_(020\|020).pth.tar\*. \* Evaluate the pre-trained model for verbs.
214-1	15707-15708	/	_	_
214-2	15708-15718	pretrained	_	_
214-3	15718-15719	/	_	_
214-4	15719-15732	epic\_slowfast	_	_
214-5	15732-15733	\_	_	_
214-6	15733-15734	(	_	_
214-7	15734-15738	verb	_	_
214-8	15738-15739	\|	_	_
214-9	15739-15743	noun	_	_
214-10	15743-15744	)	_	_
214-11	15744-15745	\_	_	_
214-12	15745-15754	reproduce	_	_
214-13	15754-15755	/	_	_
214-14	15755-15760	epoch	_	_
214-15	15760-15761	\_	_	_
214-16	15761-15762	(	_	_
214-17	15762-15765	020	_	_
214-18	15765-15766	\|	_	_
214-19	15766-15769	020	_	_
214-20	15769-15770	)	_	_
214-21	15770-15771	.	_	_
214-22	15771-15778	pth.tar	_	_
214-23	15778-15779	\*	_	_
214-24	15779-15780	.	_	_
214-25	15781-15782	\*	_	_
214-26	15783-15791	Evaluate	_	_
214-27	15792-15795	the	_	_
214-28	15796-15807	pre-trained	_	_
214-29	15808-15813	model	_	_
214-30	15814-15817	for	_	_
214-31	15818-15823	verbs	_	_
214-32	15823-15824	.	_	_

#Text=```shell python .
215-1	15825-15826	`	_	_
215-2	15826-15827	`	_	_
215-3	15827-15828	`	_	_
215-4	15828-15833	shell	_	_
215-5	15834-15840	python	_	_
215-6	15841-15842	.	_	_

#Text=/eval.py .
216-1	15842-15843	/	_	_
216-2	15843-15850	eval.py	_	_
216-3	15851-15852	.	_	_

#Text=/configs/epic\_slowfast\_verb.yaml .
217-1	15852-15853	/	_	_
217-2	15853-15860	configs	_	_
217-3	15860-15861	/	_	_
217-4	15861-15884	epic\_slowfast\_verb.yaml	_	_
217-5	15885-15886	.	_	_

#Text=/pretrained/epic\_slowfast\_verb\_reproduce/ ``` \* Evaluate the pre-trained model for nouns.
218-1	15886-15887	/	_	_
218-2	15887-15897	pretrained	_	_
218-3	15897-15898	/	_	_
218-4	15898-15926	epic\_slowfast\_verb\_reproduce	_	_
218-5	15926-15927	/	_	_
218-6	15928-15929	`	_	_
218-7	15929-15930	`	_	_
218-8	15930-15931	`	_	_
218-9	15932-15933	\*	_	_
218-10	15934-15942	Evaluate	_	_
218-11	15943-15946	the	_	_
218-12	15947-15958	pre-trained	_	_
218-13	15959-15964	model	_	_
218-14	15965-15968	for	_	_
218-15	15969-15974	nouns	_	_
218-16	15974-15975	.	_	_

#Text=```shell python .
219-1	15976-15977	`	_	_
219-2	15977-15978	`	_	_
219-3	15978-15979	`	_	_
219-4	15979-15984	shell	_	_
219-5	15985-15991	python	_	_
219-6	15992-15993	.	_	_

#Text=/eval.py .
220-1	15993-15994	/	_	_
220-2	15994-16001	eval.py	_	_
220-3	16002-16003	.	_	_

#Text=/configs/epic\_slowfast\_noun.yaml .
221-1	16003-16004	/	_	_
221-2	16004-16011	configs	_	_
221-3	16011-16012	/	_	_
221-4	16012-16035	epic\_slowfast\_noun.yaml	_	_
221-5	16036-16037	.	_	_

#Text=/pretrained/epic\_slowfast\_noun\_reproduce/ ``` \* The results (mAP at tIoUs) should be  \| Method              \|  0.1  \|  0.2  \|  0.3  \|  0.4  \|  0.5  \|  Avg  \| \|---------------------\|-------\|-------\|-------\|-------\|-------\|-------\| \| ActionFormer (verb) \| 26.58 \| 25.42 \| 24.15 \| 22.29 \| 19.09 \| 23.51 \| \| ActionFormer (noun) \| 25.21 \| 24.11 \| 22.66 \| 20.47 \| 16.97 \| 21.88 \|  ## To Reproduce Our Results on Ego4D Moment Queries Benchmark \*\*Download Features and Annotations\*\* \* Download the official SlowFast and Omnivore features from \[the Ego4D website\](https://ego4d-data.org/#download) and the official EgoVLP features from \[this link\](https://github.com/showlab/EgoVLP/issues/1#issuecomment-1219076014).
222-1	16037-16038	/	_	_
222-2	16038-16048	pretrained	_	_
222-3	16048-16049	/	_	_
222-4	16049-16077	epic\_slowfast\_noun\_reproduce	_	_
222-5	16077-16078	/	_	_
222-6	16079-16080	`	_	_
222-7	16080-16081	`	_	_
222-8	16081-16082	`	_	_
222-9	16083-16084	\*	_	_
222-10	16085-16088	The	_	_
222-11	16089-16096	results	_	_
222-12	16097-16098	(	_	_
222-13	16098-16101	mAP	_	_
222-14	16102-16104	at	_	_
222-15	16105-16110	tIoUs	_	_
222-16	16110-16111	)	_	_
222-17	16112-16118	should	_	_
222-18	16119-16121	be	_	_
222-19	16123-16124	\|	_	_
222-20	16125-16131	Method	_	_
222-21	16145-16146	\|	_	_
222-22	16148-16151	0.1	_	_
222-23	16153-16154	\|	_	_
222-24	16156-16159	0.2	_	_
222-25	16161-16162	\|	_	_
222-26	16164-16167	0.3	_	_
222-27	16169-16170	\|	_	_
222-28	16172-16175	0.4	_	_
222-29	16177-16178	\|	_	_
222-30	16180-16183	0.5	_	_
222-31	16185-16186	\|	_	_
222-32	16188-16191	Avg	_	_
222-33	16193-16194	\|	_	_
222-34	16195-16196	\|	_	_
222-35	16196-16197	-	_	_
222-36	16197-16198	-	_	_
222-37	16198-16199	-	_	_
222-38	16199-16200	-	_	_
222-39	16200-16201	-	_	_
222-40	16201-16202	-	_	_
222-41	16202-16203	-	_	_
222-42	16203-16204	-	_	_
222-43	16204-16205	-	_	_
222-44	16205-16206	-	_	_
222-45	16206-16207	-	_	_
222-46	16207-16208	-	_	_
222-47	16208-16209	-	_	_
222-48	16209-16210	-	_	_
222-49	16210-16211	-	_	_
222-50	16211-16212	-	_	_
222-51	16212-16213	-	_	_
222-52	16213-16214	-	_	_
222-53	16214-16215	-	_	_
222-54	16215-16216	-	_	_
222-55	16216-16217	-	_	_
222-56	16217-16218	\|	_	_
222-57	16218-16219	-	_	_
222-58	16219-16220	-	_	_
222-59	16220-16221	-	_	_
222-60	16221-16222	-	_	_
222-61	16222-16223	-	_	_
222-62	16223-16224	-	_	_
222-63	16224-16225	-	_	_
222-64	16225-16226	\|	_	_
222-65	16226-16227	-	_	_
222-66	16227-16228	-	_	_
222-67	16228-16229	-	_	_
222-68	16229-16230	-	_	_
222-69	16230-16231	-	_	_
222-70	16231-16232	-	_	_
222-71	16232-16233	-	_	_
222-72	16233-16234	\|	_	_
222-73	16234-16235	-	_	_
222-74	16235-16236	-	_	_
222-75	16236-16237	-	_	_
222-76	16237-16238	-	_	_
222-77	16238-16239	-	_	_
222-78	16239-16240	-	_	_
222-79	16240-16241	-	_	_
222-80	16241-16242	\|	_	_
222-81	16242-16243	-	_	_
222-82	16243-16244	-	_	_
222-83	16244-16245	-	_	_
222-84	16245-16246	-	_	_
222-85	16246-16247	-	_	_
222-86	16247-16248	-	_	_
222-87	16248-16249	-	_	_
222-88	16249-16250	\|	_	_
222-89	16250-16251	-	_	_
222-90	16251-16252	-	_	_
222-91	16252-16253	-	_	_
222-92	16253-16254	-	_	_
222-93	16254-16255	-	_	_
222-94	16255-16256	-	_	_
222-95	16256-16257	-	_	_
222-96	16257-16258	\|	_	_
222-97	16258-16259	-	_	_
222-98	16259-16260	-	_	_
222-99	16260-16261	-	_	_
222-100	16261-16262	-	_	_
222-101	16262-16263	-	_	_
222-102	16263-16264	-	_	_
222-103	16264-16265	-	_	_
222-104	16265-16266	\|	_	_
222-105	16267-16268	\|	_	_
222-106	16269-16281	ActionFormer	_	_
222-107	16282-16283	(	_	_
222-108	16283-16287	verb	_	_
222-109	16287-16288	)	_	_
222-110	16289-16290	\|	_	_
222-111	16291-16296	26.58	_	_
222-112	16297-16298	\|	_	_
222-113	16299-16304	25.42	_	_
222-114	16305-16306	\|	_	_
222-115	16307-16312	24.15	_	_
222-116	16313-16314	\|	_	_
222-117	16315-16320	22.29	_	_
222-118	16321-16322	\|	_	_
222-119	16323-16328	19.09	_	_
222-120	16329-16330	\|	_	_
222-121	16331-16336	23.51	_	_
222-122	16337-16338	\|	_	_
222-123	16339-16340	\|	_	_
222-124	16341-16353	ActionFormer	_	_
222-125	16354-16355	(	_	_
222-126	16355-16359	noun	_	_
222-127	16359-16360	)	_	_
222-128	16361-16362	\|	_	_
222-129	16363-16368	25.21	_	_
222-130	16369-16370	\|	_	_
222-131	16371-16376	24.11	_	_
222-132	16377-16378	\|	_	_
222-133	16379-16384	22.66	_	_
222-134	16385-16386	\|	_	_
222-135	16387-16392	20.47	_	_
222-136	16393-16394	\|	_	_
222-137	16395-16400	16.97	_	_
222-138	16401-16402	\|	_	_
222-139	16403-16408	21.88	_	_
222-140	16409-16410	\|	_	_
222-141	16412-16413	#	_	_
222-142	16413-16414	#	_	_
222-143	16415-16417	To	_	_
222-144	16418-16427	Reproduce	_	_
222-145	16428-16431	Our	_	_
222-146	16432-16439	Results	_	_
222-147	16440-16442	on	_	_
222-148	16443-16448	Ego4D	_	_
222-149	16449-16455	Moment	_	_
222-150	16456-16463	Queries	_	_
222-151	16464-16473	Benchmark	_	_
222-152	16474-16475	\*	_	_
222-153	16475-16476	\*	_	_
222-154	16476-16484	Download	_	_
222-155	16485-16493	Features	_	_
222-156	16494-16497	and	_	_
222-157	16498-16509	Annotations	_	_
222-158	16509-16510	\*	_	_
222-159	16510-16511	\*	_	_
222-160	16512-16513	\*	_	_
222-161	16514-16522	Download	_	_
222-162	16523-16526	the	_	_
222-163	16527-16535	official	_	_
222-164	16536-16544	SlowFast	_	_
222-165	16545-16548	and	_	_
222-166	16549-16557	Omnivore	_	_
222-167	16558-16566	features	_	_
222-168	16567-16571	from	_	_
222-169	16572-16573	\[	_	_
222-170	16573-16576	the	_	_
222-171	16577-16582	Ego4D	_	_
222-172	16583-16590	website	_	_
222-173	16590-16591	\]	_	_
222-174	16591-16592	(	_	_
222-175	16592-16597	https	_	_
222-176	16597-16598	:	_	_
222-177	16598-16599	/	_	_
222-178	16599-16600	/	_	_
222-179	16600-16614	ego4d-data.org	_	_
222-180	16614-16615	/	_	_
222-181	16615-16616	#	_	_
222-182	16616-16624	download	_	_
222-183	16624-16625	)	_	_
222-184	16626-16629	and	_	_
222-185	16630-16633	the	_	_
222-186	16634-16642	official	_	_
222-187	16643-16649	EgoVLP	_	_
222-188	16650-16658	features	_	_
222-189	16659-16663	from	_	_
222-190	16664-16665	\[	_	_
222-191	16665-16669	this	_	_
222-192	16670-16674	link	_	_
222-193	16674-16675	\]	_	_
222-194	16675-16676	(	_	_
222-195	16676-16681	https	_	_
222-196	16681-16682	:	_	_
222-197	16682-16683	/	_	_
222-198	16683-16684	/	_	_
222-199	16684-16694	github.com	_	_
222-200	16694-16695	/	_	_
222-201	16695-16702	showlab	_	_
222-202	16702-16703	/	_	_
222-203	16703-16709	EgoVLP	_	_
222-204	16709-16710	/	_	_
222-205	16710-16716	issues	_	_
222-206	16716-16717	/	_	_
222-207	16717-16718	1	_	_
222-208	16718-16719	#	_	_
222-209	16719-16731	issuecomment	_	_
222-210	16731-16732	-	_	_
222-211	16732-16742	1219076014	_	_
222-212	16742-16743	)	_	_
222-213	16743-16744	.	_	_

#Text=Please note that we are not authorized to release the features and annotations.
223-1	16745-16751	Please	_	_
223-2	16752-16756	note	_	_
223-3	16757-16761	that	_	_
223-4	16762-16764	we	_	_
223-5	16765-16768	are	_	_
223-6	16769-16772	not	_	_
223-7	16773-16783	authorized	_	_
223-8	16784-16786	to	_	_
223-9	16787-16794	release	_	_
223-10	16795-16798	the	_	_
223-11	16799-16807	features	_	_
223-12	16808-16811	and	_	_
223-13	16812-16823	annotations	_	_
223-14	16823-16824	.	_	_

#Text=Instead, we provide our script for feature and annotation conversion at `.
224-1	16825-16832	Instead	_	_
224-2	16832-16833	,	_	_
224-3	16834-16836	we	_	_
224-4	16837-16844	provide	_	_
224-5	16845-16848	our	_	_
224-6	16849-16855	script	_	_
224-7	16856-16859	for	_	_
224-8	16860-16867	feature	_	_
224-9	16868-16871	and	_	_
224-10	16872-16882	annotation	_	_
224-11	16883-16893	conversion	_	_
224-12	16894-16896	at	_	_
224-13	16897-16898	`	_	_
224-14	16898-16899	.	_	_

#Text=/tools/convert\_ego4d\_trainval.py`.
225-1	16899-16900	/	_	_
225-2	16900-16905	tools	_	_
225-3	16905-16906	/	_	_
225-4	16906-16931	convert\_ego4d\_trainval.py	_	_
225-5	16931-16932	`	_	_
225-6	16932-16933	.	_	_

#Text=\*\*Details\*\*: All features are extracted at `1.875 fps` from videos at `30 fps`.
226-1	16935-16936	\*	_	_
226-2	16936-16937	\*	_	_
226-3	16937-16944	Details	_	_
226-4	16944-16945	\*	_	_
226-5	16945-16946	\*	_	_
226-6	16946-16947	:	_	_
226-7	16948-16951	All	_	_
226-8	16952-16960	features	_	_
226-9	16961-16964	are	_	_
226-10	16965-16974	extracted	_	_
226-11	16975-16977	at	_	_
226-12	16978-16979	`	_	_
226-13	16979-16984	1.875	_	_
226-14	16985-16988	fps	_	_
226-15	16988-16989	`	_	_
226-16	16990-16994	from	_	_
226-17	16995-17001	videos	_	_
226-18	17002-17004	at	_	_
226-19	17005-17006	`	_	_
226-20	17006-17008	30	_	_
226-21	17009-17012	fps	_	_
226-22	17012-17013	`	_	_
226-23	17013-17014	.	_	_

#Text=This gives one feature vector per `~0.5333` seconds.
227-1	17015-17019	This	_	_
227-2	17020-17025	gives	_	_
227-3	17026-17029	one	_	_
227-4	17030-17037	feature	_	_
227-5	17038-17044	vector	_	_
227-6	17045-17048	per	_	_
227-7	17049-17050	`	_	_
227-8	17050-17051	~	_	_
227-9	17051-17057	0.5333	_	_
227-10	17057-17058	`	_	_
227-11	17059-17066	seconds	_	_
227-12	17066-17067	.	_	_

#Text=Please refer to Ego4D and EgoVLP's documentation for more details on feature extraction.
228-1	17068-17074	Please	_	_
228-2	17075-17080	refer	_	_
228-3	17081-17083	to	_	_
228-4	17084-17089	Ego4D	_	_
228-5	17090-17093	and	_	_
228-6	17094-17102	EgoVLP's	_	_
228-6	17094-17100	EgoVLP	_	_
228-7	17103-17116	documentation	_	_
228-8	17117-17120	for	_	_
228-9	17121-17125	more	_	_
228-10	17126-17133	details	_	_
228-11	17134-17136	on	_	_
228-12	17137-17144	feature	_	_
228-13	17145-17155	extraction	_	_
228-14	17155-17156	.	_	_

#Text=\*\*Unpack Features and Annotations\*\* \* Unpack the file under \*.
229-1	17158-17159	\*	_	_
229-2	17159-17160	\*	_	_
229-3	17160-17166	Unpack	_	_
229-4	17167-17175	Features	_	_
229-5	17176-17179	and	_	_
229-6	17180-17191	Annotations	_	_
229-7	17191-17192	\*	_	_
229-8	17192-17193	\*	_	_
229-9	17194-17195	\*	_	_
229-10	17196-17202	Unpack	_	_
229-11	17203-17206	the	_	_
229-12	17207-17211	file	_	_
229-13	17212-17217	under	_	_
229-14	17218-17219	\*	_	_
229-15	17219-17220	.	_	_

#Text=/data\* (or elsewhere and link to \*.
230-1	17220-17221	/	_	_
230-2	17221-17225	data	_	_
230-3	17225-17226	\*	_	_
230-4	17227-17228	(	_	_
230-5	17228-17230	or	_	_
230-6	17231-17240	elsewhere	_	_
230-7	17241-17244	and	_	_
230-8	17245-17249	link	_	_
230-9	17250-17252	to	_	_
230-10	17253-17254	\*	_	_
230-11	17254-17255	.	_	_

#Text=/data\*). \* The folder structure should look like ``` This folder │   README.md │
231-1	17255-17256	/	_	_
231-2	17256-17260	data	_	_
231-3	17260-17261	\*	_	_
231-4	17261-17262	)	_	_
231-5	17262-17263	.	_	_
231-6	17264-17265	\*	_	_
231-7	17266-17269	The	_	_
231-8	17270-17276	folder	_	_
231-9	17277-17286	structure	_	_
231-10	17287-17293	should	_	_
231-11	17294-17298	look	_	_
231-12	17299-17303	like	_	_
231-13	17304-17305	`	_	_
231-14	17305-17306	`	_	_
231-15	17306-17307	`	_	_
231-16	17308-17312	This	_	_
231-17	17313-17319	folder	_	_
231-18	17320-17321	│	_	_
231-19	17324-17333	README.md	_	_
231-20	17334-17335	│	_	_

#Text=.
232-1	17338-17339	.	_	_

#Text=.
233-1	17339-17340	.	_	_

#Text=.
234-1	17340-17341	.	_	_

#Text=│ └───data/ │    └───ego4d/ │    │   └───annotations │    │   └───slowfast\_features │    │   └───omnivore\_features │    │   └───egovlp\_features   │    └───... \| └───libs │ │   ... ```  \*\*Training and Evaluation\*\* \* We provide config files for training ActionFormer with different feature combinations.
235-1	17344-17345	│	_	_
235-2	17346-17347	└	_	_
235-3	17347-17348	─	_	_
235-4	17348-17349	─	_	_
235-5	17349-17350	─	_	_
235-6	17350-17354	data	_	_
235-7	17354-17355	/	_	_
235-8	17356-17357	│	_	_
235-9	17361-17362	└	_	_
235-10	17362-17363	─	_	_
235-11	17363-17364	─	_	_
235-12	17364-17365	─	_	_
235-13	17365-17370	ego4d	_	_
235-14	17370-17371	/	_	_
235-15	17372-17373	│	_	_
235-16	17377-17378	│	_	_
235-17	17381-17382	└	_	_
235-18	17382-17383	─	_	_
235-19	17383-17384	─	_	_
235-20	17384-17385	─	_	_
235-21	17385-17396	annotations	_	_
235-22	17397-17398	│	_	_
235-23	17402-17403	│	_	_
235-24	17406-17407	└	_	_
235-25	17407-17408	─	_	_
235-26	17408-17409	─	_	_
235-27	17409-17410	─	_	_
235-28	17410-17427	slowfast\_features	_	_
235-29	17428-17429	│	_	_
235-30	17433-17434	│	_	_
235-31	17437-17438	└	_	_
235-32	17438-17439	─	_	_
235-33	17439-17440	─	_	_
235-34	17440-17441	─	_	_
235-35	17441-17458	omnivore\_features	_	_
235-36	17459-17460	│	_	_
235-37	17464-17465	│	_	_
235-38	17468-17469	└	_	_
235-39	17469-17470	─	_	_
235-40	17470-17471	─	_	_
235-41	17471-17472	─	_	_
235-42	17472-17487	egovlp\_features	_	_
235-43	17490-17491	│	_	_
235-44	17495-17496	└	_	_
235-45	17496-17497	─	_	_
235-46	17497-17498	─	_	_
235-47	17498-17499	─	_	_
235-48	17499-17500	.	_	_
235-49	17500-17501	.	_	_
235-50	17501-17502	.	_	_
235-51	17503-17504	\|	_	_
235-52	17505-17506	└	_	_
235-53	17506-17507	─	_	_
235-54	17507-17508	─	_	_
235-55	17508-17509	─	_	_
235-56	17509-17513	libs	_	_
235-57	17514-17515	│	_	_
235-58	17516-17517	│	_	_
235-59	17520-17521	.	_	_
235-60	17521-17522	.	_	_
235-61	17522-17523	.	_	_
235-62	17524-17525	`	_	_
235-63	17525-17526	`	_	_
235-64	17526-17527	`	_	_
235-65	17529-17530	\*	_	_
235-66	17530-17531	\*	_	_
235-67	17531-17539	Training	_	_
235-68	17540-17543	and	_	_
235-69	17544-17554	Evaluation	_	_
235-70	17554-17555	\*	_	_
235-71	17555-17556	\*	_	_
235-72	17557-17558	\*	_	_
235-73	17559-17561	We	_	_
235-74	17562-17569	provide	_	_
235-75	17570-17576	config	_	_
235-76	17577-17582	files	_	_
235-77	17583-17586	for	_	_
235-78	17587-17595	training	_	_
235-79	17596-17608	ActionFormer	_	_
235-80	17609-17613	with	_	_
235-81	17614-17623	different	_	_
235-82	17624-17631	feature	_	_
235-83	17632-17644	combinations	_	_
235-84	17644-17645	.	_	_

#Text=For example, training on Omnivore and EgoVLP features will create an experiment folder under \*.
236-1	17646-17649	For	_	_
236-2	17650-17657	example	_	_
236-3	17657-17658	,	_	_
236-4	17659-17667	training	_	_
236-5	17668-17670	on	_	_
236-6	17671-17679	Omnivore	_	_
236-7	17680-17683	and	_	_
236-8	17684-17690	EgoVLP	_	_
236-9	17691-17699	features	_	_
236-10	17700-17704	will	_	_
236-11	17705-17711	create	_	_
236-12	17712-17714	an	_	_
236-13	17715-17725	experiment	_	_
236-14	17726-17732	folder	_	_
236-15	17733-17738	under	_	_
236-16	17739-17740	\*	_	_
236-17	17740-17741	.	_	_

#Text=/ckpt\* that stores training config, logs, and checkpoints.
237-1	17741-17742	/	_	_
237-2	17742-17746	ckpt	_	_
237-3	17746-17747	\*	_	_
237-4	17748-17752	that	_	_
237-5	17753-17759	stores	_	_
237-6	17760-17768	training	_	_
237-7	17769-17775	config	_	_
237-8	17775-17776	,	_	_
237-9	17777-17781	logs	_	_
237-10	17781-17782	,	_	_
237-11	17783-17786	and	_	_
237-12	17787-17798	checkpoints	_	_
237-13	17798-17799	.	_	_

#Text=```shell python .
238-1	17800-17801	`	_	_
238-2	17801-17802	`	_	_
238-3	17802-17803	`	_	_
238-4	17803-17808	shell	_	_
238-5	17809-17815	python	_	_
238-6	17816-17817	.	_	_

#Text=/train.py .
239-1	17817-17818	/	_	_
239-2	17818-17826	train.py	_	_
239-3	17827-17828	.	_	_

#Text=/configs/ego4d\_omnivore\_egovlp.yaml --output reproduce ``` \* \[Optional\] Monitor the training using TensorBoard ```shell tensorboard --logdir=.
240-1	17828-17829	/	_	_
240-2	17829-17836	configs	_	_
240-3	17836-17837	/	_	_
240-4	17837-17863	ego4d\_omnivore\_egovlp.yaml	_	_
240-5	17864-17865	-	_	_
240-6	17865-17866	-	_	_
240-7	17866-17872	output	_	_
240-8	17873-17882	reproduce	_	_
240-9	17883-17884	`	_	_
240-10	17884-17885	`	_	_
240-11	17885-17886	`	_	_
240-12	17887-17888	\*	_	_
240-13	17889-17890	\[	_	_
240-14	17890-17898	Optional	_	_
240-15	17898-17899	\]	_	_
240-16	17900-17907	Monitor	_	_
240-17	17908-17911	the	_	_
240-18	17912-17920	training	_	_
240-19	17921-17926	using	_	_
240-20	17927-17938	TensorBoard	_	_
240-21	17939-17940	`	_	_
240-22	17940-17941	`	_	_
240-23	17941-17942	`	_	_
240-24	17942-17947	shell	_	_
240-25	17948-17959	tensorboard	_	_
240-26	17960-17961	-	_	_
240-27	17961-17962	-	_	_
240-28	17962-17968	logdir	_	_
240-29	17968-17969	=	_	_
240-30	17969-17970	.	_	_

#Text=/ckpt/ego4d\_omnivore\_egovlp\_reproduce/logs ``` \* Evaluate the trained model.
241-1	17970-17971	/	_	_
241-2	17971-17975	ckpt	_	_
241-3	17975-17976	/	_	_
241-4	17976-18007	ego4d\_omnivore\_egovlp\_reproduce	_	_
241-5	18007-18008	/	_	_
241-6	18008-18012	logs	_	_
241-7	18013-18014	`	_	_
241-8	18014-18015	`	_	_
241-9	18015-18016	`	_	_
241-10	18017-18018	\*	_	_
241-11	18019-18027	Evaluate	_	_
241-12	18028-18031	the	_	_
241-13	18032-18039	trained	_	_
241-14	18040-18045	model	_	_
241-15	18045-18046	.	_	_

#Text=The expected average mAP and Recall@1x, tIoU=0.5 should be around 22.0(%) and 40.0(%) respectively.
242-1	18047-18050	The	_	_
242-2	18051-18059	expected	_	_
242-3	18060-18067	average	_	_
242-4	18068-18071	mAP	_	_
242-5	18072-18075	and	_	_
242-6	18076-18082	Recall	_	_
242-7	18082-18083	@	_	_
242-8	18083-18085	1x	_	_
242-9	18085-18086	,	_	_
242-10	18087-18091	tIoU	_	_
242-11	18091-18092	=	_	_
242-12	18092-18095	0.5	_	_
242-13	18096-18102	should	_	_
242-14	18103-18105	be	_	_
242-15	18106-18112	around	_	_
242-16	18113-18117	22.0	_	_
242-17	18117-18118	(	_	_
242-18	18118-18119	%	_	_
242-19	18119-18120	)	_	_
242-20	18121-18124	and	_	_
242-21	18125-18129	40.0	_	_
242-22	18129-18130	(	_	_
242-23	18130-18131	%	_	_
242-24	18131-18132	)	_	_
242-25	18133-18145	respectively	_	_
242-26	18145-18146	.	_	_

#Text=```shell python .
243-1	18147-18148	`	_	_
243-2	18148-18149	`	_	_
243-3	18149-18150	`	_	_
243-4	18150-18155	shell	_	_
243-5	18156-18162	python	_	_
243-6	18163-18164	.	_	_

#Text=/eval.py .
244-1	18164-18165	/	_	_
244-2	18165-18172	eval.py	_	_
244-3	18173-18174	.	_	_

#Text=/configs/ego4d\_omnivore\_egovlp.yaml .
245-1	18174-18175	/	_	_
245-2	18175-18182	configs	_	_
245-3	18182-18183	/	_	_
245-4	18183-18209	ego4d\_omnivore\_egovlp.yaml	_	_
245-5	18210-18211	.	_	_

#Text=/ckpt/ego4d\_omnivore\_egovlp\_reproduce ``` \* Training our model on Ego4D with all three features requires ~4.5GB GPU memory, yet the inference might require over 10GB GPU memory.
246-1	18211-18212	/	_	_
246-2	18212-18216	ckpt	_	_
246-3	18216-18217	/	_	_
246-4	18217-18248	ego4d\_omnivore\_egovlp\_reproduce	_	_
246-5	18249-18250	`	_	_
246-6	18250-18251	`	_	_
246-7	18251-18252	`	_	_
246-8	18253-18254	\*	_	_
246-9	18255-18263	Training	_	_
246-10	18264-18267	our	_	_
246-11	18268-18273	model	_	_
246-12	18274-18276	on	_	_
246-13	18277-18282	Ego4D	_	_
246-14	18283-18287	with	_	_
246-15	18288-18291	all	_	_
246-16	18292-18297	three	_	_
246-17	18298-18306	features	_	_
246-18	18307-18315	requires	_	_
246-19	18316-18317	~	_	_
246-20	18317-18322	4.5GB	_	_
246-21	18323-18326	GPU	_	_
246-22	18327-18333	memory	_	_
246-23	18333-18334	,	_	_
246-24	18335-18338	yet	_	_
246-25	18339-18342	the	_	_
246-26	18343-18352	inference	_	_
246-27	18353-18358	might	_	_
246-28	18359-18366	require	_	_
246-29	18367-18371	over	_	_
246-30	18372-18376	10GB	_	_
246-31	18377-18380	GPU	_	_
246-32	18381-18387	memory	_	_
246-33	18387-18388	.	_	_

#Text=We recommend using a GPU with at least 12 GB of memory.
247-1	18389-18391	We	_	_
247-2	18392-18401	recommend	_	_
247-3	18402-18407	using	_	_
247-4	18408-18409	a	_	_
247-5	18410-18413	GPU	_	_
247-6	18414-18418	with	_	_
247-7	18419-18421	at	_	_
247-8	18422-18427	least	_	_
247-9	18428-18430	12	_	_
247-10	18431-18433	GB	_	_
247-11	18434-18436	of	_	_
247-12	18437-18443	memory	_	_
247-13	18443-18444	.	_	_

#Text=\*\*\[Optional\] Evaluating Our Pre-trained Model\*\*  We also provide pre-trained models for Ego4D trained with all feature combinations.
248-1	18446-18447	\*	_	_
248-2	18447-18448	\*	_	_
248-3	18448-18449	\[	_	_
248-4	18449-18457	Optional	_	_
248-5	18457-18458	\]	_	_
248-6	18459-18469	Evaluating	_	_
248-7	18470-18473	Our	_	_
248-8	18474-18485	Pre-trained	_	_
248-9	18486-18491	Model	_	_
248-10	18491-18492	\*	_	_
248-11	18492-18493	\*	_	_
248-12	18495-18497	We	_	_
248-13	18498-18502	also	_	_
248-14	18503-18510	provide	_	_
248-15	18511-18522	pre-trained	_	_
248-16	18523-18529	models	_	_
248-17	18530-18533	for	_	_
248-18	18534-18539	Ego4D	_	_
248-19	18540-18547	trained	_	_
248-20	18548-18552	with	_	_
248-21	18553-18556	all	_	_
248-22	18557-18564	feature	_	_
248-23	18565-18577	combinations	_	_
248-24	18577-18578	.	_	_

#Text=The models with all training logs can be downloaded from \[this Google Drive link\](https://drive.google.com/drive/folders/1NpAECS0ZhcCuehXkF9OhLQDPFrNdStJb?
249-1	18579-18582	The	_	_
249-2	18583-18589	models	_	_
249-3	18590-18594	with	_	_
249-4	18595-18598	all	_	_
249-5	18599-18607	training	_	_
249-6	18608-18612	logs	_	_
249-7	18613-18616	can	_	_
249-8	18617-18619	be	_	_
249-9	18620-18630	downloaded	_	_
249-10	18631-18635	from	_	_
249-11	18636-18637	\[	_	_
249-12	18637-18641	this	_	_
249-13	18642-18648	Google	_	_
249-14	18649-18654	Drive	_	_
249-15	18655-18659	link	_	_
249-16	18659-18660	\]	_	_
249-17	18660-18661	(	_	_
249-18	18661-18666	https	_	_
249-19	18666-18667	:	_	_
249-20	18667-18668	/	_	_
249-21	18668-18669	/	_	_
249-22	18669-18685	drive.google.com	_	_
249-23	18685-18686	/	_	_
249-24	18686-18691	drive	_	_
249-25	18691-18692	/	_	_
249-26	18692-18699	folders	_	_
249-27	18699-18700	/	_	_
249-28	18700-18733	1NpAECS0ZhcCuehXkF9OhLQDPFrNdStJb	_	_
249-29	18733-18734	?	_	_

#Text=usp=sharing).
250-1	18734-18737	usp	_	_
250-2	18737-18738	=	_	_
250-3	18738-18745	sharing	_	_
250-4	18745-18746	)	_	_
250-5	18746-18747	.	_	_

#Text=To evaluate the pre-trained model, please follow the steps listed below
251-1	18748-18750	To	_	_
251-2	18751-18759	evaluate	_	_
251-3	18760-18763	the	_	_
251-4	18764-18775	pre-trained	_	_
251-5	18776-18781	model	_	_
251-6	18781-18782	,	_	_
251-7	18783-18789	please	_	_
251-8	18790-18796	follow	_	_
251-9	18797-18800	the	_	_
251-10	18801-18806	steps	_	_
251-11	18807-18813	listed	_	_
251-12	18814-18819	below	_	_

#Text=.
252-1	18819-18820	.	_	_

#Text=\* Create a folder \*.
253-1	18822-18823	\*	_	_
253-2	18824-18830	Create	_	_
253-3	18831-18832	a	_	_
253-4	18833-18839	folder	_	_
253-5	18840-18841	\*	_	_
253-6	18841-18842	.	_	_

#Text=/pretrained\* and unpack the file under \*.
254-1	18842-18843	/	_	_
254-2	18843-18853	pretrained	_	_
254-3	18853-18854	\*	_	_
254-4	18855-18858	and	_	_
254-5	18859-18865	unpack	_	_
254-6	18866-18869	the	_	_
254-7	18870-18874	file	_	_
254-8	18875-18880	under	_	_
254-9	18881-18882	\*	_	_
254-10	18882-18883	.	_	_

#Text=/pretrained\* (or elsewhere and link to \*.
255-1	18883-18884	/	_	_
255-2	18884-18894	pretrained	_	_
255-3	18894-18895	\*	_	_
255-4	18896-18897	(	_	_
255-5	18897-18899	or	_	_
255-6	18900-18909	elsewhere	_	_
255-7	18910-18913	and	_	_
255-8	18914-18918	link	_	_
255-9	18919-18921	to	_	_
255-10	18922-18923	\*	_	_
255-11	18923-18924	.	_	_

#Text=/pretrained\*). \* An example of the folder structure should look like ``` This folder │   README.md │
256-1	18924-18925	/	_	_
256-2	18925-18935	pretrained	_	_
256-3	18935-18936	\*	_	_
256-4	18936-18937	)	_	_
256-5	18937-18938	.	_	_
256-6	18939-18940	\*	_	_
256-7	18941-18943	An	_	_
256-8	18944-18951	example	_	_
256-9	18952-18954	of	_	_
256-10	18955-18958	the	_	_
256-11	18959-18965	folder	_	_
256-12	18966-18975	structure	_	_
256-13	18976-18982	should	_	_
256-14	18983-18987	look	_	_
256-15	18988-18992	like	_	_
256-16	18993-18994	`	_	_
256-17	18994-18995	`	_	_
256-18	18995-18996	`	_	_
256-19	18997-19001	This	_	_
256-20	19002-19008	folder	_	_
256-21	19009-19010	│	_	_
256-22	19013-19022	README.md	_	_
256-23	19023-19024	│	_	_

#Text=.
257-1	19027-19028	.	_	_

#Text=.
258-1	19028-19029	.	_	_

#Text=.
259-1	19029-19030	.	_	_

#Text=│ └───pretrained/ │    └───ego4d\_omnivore\_egovlp\_reproduce/ │    │   └───ego4d\_omnivore\_egovlp\_reproduce\_log.txt │    │   └───ego4d\_omnivore\_egovlp\_reproduce\_results.txt │    │   └───
260-1	19033-19034	│	_	_
260-2	19035-19036	└	_	_
260-3	19036-19037	─	_	_
260-4	19037-19038	─	_	_
260-5	19038-19039	─	_	_
260-6	19039-19049	pretrained	_	_
260-7	19049-19050	/	_	_
260-8	19051-19052	│	_	_
260-9	19056-19057	└	_	_
260-10	19057-19058	─	_	_
260-11	19058-19059	─	_	_
260-12	19059-19060	─	_	_
260-13	19060-19091	ego4d\_omnivore\_egovlp\_reproduce	_	_
260-13	19060-19081	ego4d\_omnivore\_egovlp	_	_
260-14	19091-19092	/	_	_
260-15	19093-19094	│	_	_
260-16	19098-19099	│	_	_
260-17	19102-19103	└	_	_
260-18	19103-19104	─	_	_
260-19	19104-19105	─	_	_
260-20	19105-19106	─	_	_
260-21	19106-19145	ego4d\_omnivore\_egovlp\_reproduce\_log.txt	_	_
260-21	19106-19127	ego4d\_omnivore\_egovlp	_	_
260-22	19146-19147	│	_	_
260-23	19151-19152	│	_	_
260-24	19155-19156	└	_	_
260-25	19156-19157	─	_	_
260-26	19157-19158	─	_	_
260-27	19158-19159	─	_	_
260-28	19159-19202	ego4d\_omnivore\_egovlp\_reproduce\_results.txt	_	_
260-28	19159-19180	ego4d\_omnivore\_egovlp	_	_
260-29	19203-19204	│	_	_
260-30	19208-19209	│	_	_
260-31	19212-19213	└	_	_
260-32	19213-19214	─	_	_
260-33	19214-19215	─	_	_
260-34	19215-19216	─	_	_

#Text=.
261-1	19216-19217	.	_	_

#Text=.
262-1	19217-19218	.	_	_

#Text=.
263-1	19218-19219	.	_	_

#Text=│    └───... \| └───libs │ │   ... ``` \* The training config is recorded in \*.
264-1	19223-19224	│	_	_
264-2	19228-19229	└	_	_
264-3	19229-19230	─	_	_
264-4	19230-19231	─	_	_
264-5	19231-19232	─	_	_
264-6	19232-19233	.	_	_
264-7	19233-19234	.	_	_
264-8	19234-19235	.	_	_
264-9	19236-19237	\|	_	_
264-10	19238-19239	└	_	_
264-11	19239-19240	─	_	_
264-12	19240-19241	─	_	_
264-13	19241-19242	─	_	_
264-14	19242-19246	libs	_	_
264-15	19247-19248	│	_	_
264-16	19249-19250	│	_	_
264-17	19253-19254	.	_	_
264-18	19254-19255	.	_	_
264-19	19255-19256	.	_	_
264-20	19257-19258	`	_	_
264-21	19258-19259	`	_	_
264-22	19259-19260	`	_	_
264-23	19261-19262	\*	_	_
264-24	19263-19266	The	_	_
264-25	19267-19275	training	_	_
264-26	19276-19282	config	_	_
264-27	19283-19285	is	_	_
264-28	19286-19294	recorded	_	_
264-29	19295-19297	in	_	_
264-30	19298-19299	\*	_	_
264-31	19299-19300	.	_	_

#Text=/pretrained/ego4d\_omnivore\_egovlp\_reproduce/config.txt\*. \* The training log is located at \*.
265-1	19300-19301	/	_	_
265-2	19301-19311	pretrained	_	_
265-3	19311-19312	/	_	_
265-4	19312-19343	ego4d\_omnivore\_egovlp\_reproduce	_	_
265-4	19312-19333	ego4d\_omnivore\_egovlp	_	_
265-5	19343-19344	/	_	_
265-6	19344-19354	config.txt	_	_
265-7	19354-19355	\*	_	_
265-8	19355-19356	.	_	_
265-9	19357-19358	\*	_	_
265-10	19359-19362	The	_	_
265-11	19363-19371	training	_	_
265-12	19372-19375	log	_	_
265-13	19376-19378	is	_	_
265-14	19379-19386	located	_	_
265-15	19387-19389	at	_	_
265-16	19390-19391	\*	_	_
265-17	19391-19392	.	_	_

#Text=/pretrained/ego4d\_omnivore\_egovlp\_reproduce/ego4d\_omnivore\_egovlp\_reproduce\_log.txt\* and also \*.
266-1	19392-19393	/	_	_
266-2	19393-19403	pretrained	_	_
266-3	19403-19404	/	_	_
266-4	19404-19435	ego4d\_omnivore\_egovlp\_reproduce	_	_
266-4	19404-19425	ego4d\_omnivore\_egovlp	_	_
266-5	19435-19436	/	_	_
266-6	19436-19475	ego4d\_omnivore\_egovlp\_reproduce\_log.txt	_	_
266-7	19475-19476	\*	_	_
266-8	19477-19480	and	_	_
266-9	19481-19485	also	_	_
266-10	19486-19487	\*	_	_
266-11	19487-19488	.	_	_

#Text=/pretrained/ego4d\_omnivore\_egovlp\_reproduce/logs\*. \* The pre-trained model is \*.
267-1	19488-19489	/	_	_
267-2	19489-19499	pretrained	_	_
267-3	19499-19500	/	_	_
267-4	19500-19531	ego4d\_omnivore\_egovlp\_reproduce	_	_
267-4	19500-19521	ego4d\_omnivore\_egovlp	_	_
267-5	19531-19532	/	_	_
267-6	19532-19536	logs	_	_
267-7	19536-19537	\*	_	_
267-8	19537-19538	.	_	_
267-9	19539-19540	\*	_	_
267-10	19541-19544	The	_	_
267-11	19545-19556	pre-trained	_	_
267-12	19557-19562	model	_	_
267-13	19563-19565	is	_	_
267-14	19566-19567	\*	_	_
267-15	19567-19568	.	_	_

#Text=/pretrained/ego4d\_omnivore\_egovlp\_reproduce/epoch\_010.pth.tar\*. \* Evaluate the pre-trained model.
268-1	19568-19569	/	_	_
268-2	19569-19579	pretrained	_	_
268-3	19579-19580	/	_	_
268-4	19580-19611	ego4d\_omnivore\_egovlp\_reproduce	_	_
268-4	19580-19601	ego4d\_omnivore\_egovlp	_	_
268-5	19611-19612	/	_	_
268-6	19612-19617	epoch	_	_
268-7	19617-19618	\_	_	_
268-8	19618-19621	010	_	_
268-9	19621-19622	.	_	_
268-10	19622-19629	pth.tar	_	_
268-11	19629-19630	\*	_	_
268-12	19630-19631	.	_	_
268-13	19632-19633	\*	_	_
268-14	19634-19642	Evaluate	_	_
268-15	19643-19646	the	_	_
268-16	19647-19658	pre-trained	_	_
268-17	19659-19664	model	_	_
268-18	19664-19665	.	_	_

#Text=```shell python .
269-1	19666-19667	`	_	_
269-2	19667-19668	`	_	_
269-3	19668-19669	`	_	_
269-4	19669-19674	shell	_	_
269-5	19675-19681	python	_	_
269-6	19682-19683	.	_	_

#Text=/eval.py .
270-1	19683-19684	/	_	_
270-2	19684-19691	eval.py	_	_
270-3	19692-19693	.	_	_

#Text=/configs/ego4d\_omnivore\_egovlp.yaml .
271-1	19693-19694	/	_	_
271-2	19694-19701	configs	_	_
271-3	19701-19702	/	_	_
271-4	19702-19728	ego4d\_omnivore\_egovlp.yaml	_	_
271-5	19729-19730	.	_	_

#Text=/pretrained/ego4d\_omnivore\_egovlp\_reproduce/ ``` \* The results (mAP at tIoUs) should be  \| Method                \|  0.1  \|  0.2  \|  0.3  \|  0.4  \|  0.5  \|  Avg  \| \|-----------------------\|-------\|-------\|-------\|-------\|-------\|-------\| \| ActionFormer (S)      \| 20.09 \| 17.45 \| 14.44 \| 12.46 \| 10.00 \| 14.89 \| \| ActionFormer (O)      \| 23.87 \| 20.78 \| 18.39 \| 15.33 \| 12.65 \| 18.20 \| \| ActionFormer (E)      \| 26.84 \| 23.86 \| 20.57 \| 17.19 \| 14.54 \| 20.60 \| \| ActionFormer (S+E)    \| 27.98 \| 24.46 \| 21.21 \| 18.56 \| 15.60 \| 21.56 \| \| ActionFormer (O+E)    \| 27.99 \| 24.94 \| 21.94 \| 19.05 \| 15.98 \| 21.98 \| \| ActionFormer (S+O+E)  \| 28.26 \| 24.69 \| 21.88 \| 19.35 \| 16.28 \| 22.09 \|  \* The results (Recall@1x at tIoUs) should be  \| Method                \|  0.1  \|  0.2  \|  0.3  \|  0.4  \|  0.5  \|  Avg  \| \|-----------------------\|-------\|-------\|-------\|-------\|-------\|-------\| \| ActionFormer (S)      \| 52.25 \| 45.84 \| 40.60 \| 36.58 \| 31.33 \| 41.32 \| \| ActionFormer (O)      \| 54.63 \| 48.72 \| 43.03 \| 37.76 \| 33.57 \| 43.54 \| \| ActionFormer (E)      \| 59.53 \| 54.39 \| 48.97 \| 42.75 \| 37.12 \| 48.55 \| \| ActionFormer (S+E)    \| 59.96 \| 53.75 \| 48.76 \| 44.00 \| 38.96 \| 49.09 \| \| ActionFormer (O+E)    \| 61.03 \| 54.15 \| 49.79 \| 45.17 \| 39.88 \| 49.99 \| \| ActionFormer (S+O+E)  \| 60.85 \| 54.16 \| 49.60 \| 45.12 \| 39.87 \| 49.92 \|  ## Training and Evaluating Your Own Dataset Work in progress.
272-1	19730-19731	/	_	_
272-2	19731-19741	pretrained	_	_
272-3	19741-19742	/	_	_
272-4	19742-19773	ego4d\_omnivore\_egovlp\_reproduce	_	_
272-5	19773-19774	/	_	_
272-6	19775-19776	`	_	_
272-7	19776-19777	`	_	_
272-8	19777-19778	`	_	_
272-9	19779-19780	\*	_	_
272-10	19781-19784	The	_	_
272-11	19785-19792	results	_	_
272-12	19793-19794	(	_	_
272-13	19794-19797	mAP	_	_
272-14	19798-19800	at	_	_
272-15	19801-19806	tIoUs	_	_
272-16	19806-19807	)	_	_
272-17	19808-19814	should	_	_
272-18	19815-19817	be	_	_
272-19	19819-19820	\|	_	_
272-20	19821-19827	Method	_	_
272-21	19843-19844	\|	_	_
272-22	19846-19849	0.1	_	_
272-23	19851-19852	\|	_	_
272-24	19854-19857	0.2	_	_
272-25	19859-19860	\|	_	_
272-26	19862-19865	0.3	_	_
272-27	19867-19868	\|	_	_
272-28	19870-19873	0.4	_	_
272-29	19875-19876	\|	_	_
272-30	19878-19881	0.5	_	_
272-31	19883-19884	\|	_	_
272-32	19886-19889	Avg	_	_
272-33	19891-19892	\|	_	_
272-34	19893-19894	\|	_	_
272-35	19894-19895	-	_	_
272-36	19895-19896	-	_	_
272-37	19896-19897	-	_	_
272-38	19897-19898	-	_	_
272-39	19898-19899	-	_	_
272-40	19899-19900	-	_	_
272-41	19900-19901	-	_	_
272-42	19901-19902	-	_	_
272-43	19902-19903	-	_	_
272-44	19903-19904	-	_	_
272-45	19904-19905	-	_	_
272-46	19905-19906	-	_	_
272-47	19906-19907	-	_	_
272-48	19907-19908	-	_	_
272-49	19908-19909	-	_	_
272-50	19909-19910	-	_	_
272-51	19910-19911	-	_	_
272-52	19911-19912	-	_	_
272-53	19912-19913	-	_	_
272-54	19913-19914	-	_	_
272-55	19914-19915	-	_	_
272-56	19915-19916	-	_	_
272-57	19916-19917	-	_	_
272-58	19917-19918	\|	_	_
272-59	19918-19919	-	_	_
272-60	19919-19920	-	_	_
272-61	19920-19921	-	_	_
272-62	19921-19922	-	_	_
272-63	19922-19923	-	_	_
272-64	19923-19924	-	_	_
272-65	19924-19925	-	_	_
272-66	19925-19926	\|	_	_
272-67	19926-19927	-	_	_
272-68	19927-19928	-	_	_
272-69	19928-19929	-	_	_
272-70	19929-19930	-	_	_
272-71	19930-19931	-	_	_
272-72	19931-19932	-	_	_
272-73	19932-19933	-	_	_
272-74	19933-19934	\|	_	_
272-75	19934-19935	-	_	_
272-76	19935-19936	-	_	_
272-77	19936-19937	-	_	_
272-78	19937-19938	-	_	_
272-79	19938-19939	-	_	_
272-80	19939-19940	-	_	_
272-81	19940-19941	-	_	_
272-82	19941-19942	\|	_	_
272-83	19942-19943	-	_	_
272-84	19943-19944	-	_	_
272-85	19944-19945	-	_	_
272-86	19945-19946	-	_	_
272-87	19946-19947	-	_	_
272-88	19947-19948	-	_	_
272-89	19948-19949	-	_	_
272-90	19949-19950	\|	_	_
272-91	19950-19951	-	_	_
272-92	19951-19952	-	_	_
272-93	19952-19953	-	_	_
272-94	19953-19954	-	_	_
272-95	19954-19955	-	_	_
272-96	19955-19956	-	_	_
272-97	19956-19957	-	_	_
272-98	19957-19958	\|	_	_
272-99	19958-19959	-	_	_
272-100	19959-19960	-	_	_
272-101	19960-19961	-	_	_
272-102	19961-19962	-	_	_
272-103	19962-19963	-	_	_
272-104	19963-19964	-	_	_
272-105	19964-19965	-	_	_
272-106	19965-19966	\|	_	_
272-107	19967-19968	\|	_	_
272-108	19969-19981	ActionFormer	_	_
272-109	19982-19983	(	_	_
272-110	19983-19984	S	_	_
272-111	19984-19985	)	_	_
272-112	19991-19992	\|	_	_
272-113	19993-19998	20.09	_	_
272-114	19999-20000	\|	_	_
272-115	20001-20006	17.45	_	_
272-116	20007-20008	\|	_	_
272-117	20009-20014	14.44	_	_
272-118	20015-20016	\|	_	_
272-119	20017-20022	12.46	_	_
272-120	20023-20024	\|	_	_
272-121	20025-20030	10.00	_	_
272-122	20031-20032	\|	_	_
272-123	20033-20038	14.89	_	_
272-124	20039-20040	\|	_	_
272-125	20041-20042	\|	_	_
272-126	20043-20055	ActionFormer	_	_
272-127	20056-20057	(	_	_
272-128	20057-20058	O	_	_
272-129	20058-20059	)	_	_
272-130	20065-20066	\|	_	_
272-131	20067-20072	23.87	_	_
272-132	20073-20074	\|	_	_
272-133	20075-20080	20.78	_	_
272-134	20081-20082	\|	_	_
272-135	20083-20088	18.39	_	_
272-136	20089-20090	\|	_	_
272-137	20091-20096	15.33	_	_
272-138	20097-20098	\|	_	_
272-139	20099-20104	12.65	_	_
272-140	20105-20106	\|	_	_
272-141	20107-20112	18.20	_	_
272-142	20113-20114	\|	_	_
272-143	20115-20116	\|	_	_
272-144	20117-20129	ActionFormer	_	_
272-145	20130-20131	(	_	_
272-146	20131-20132	E	_	_
272-147	20132-20133	)	_	_
272-148	20139-20140	\|	_	_
272-149	20141-20146	26.84	_	_
272-150	20147-20148	\|	_	_
272-151	20149-20154	23.86	_	_
272-152	20155-20156	\|	_	_
272-153	20157-20162	20.57	_	_
272-154	20163-20164	\|	_	_
272-155	20165-20170	17.19	_	_
272-156	20171-20172	\|	_	_
272-157	20173-20178	14.54	_	_
272-158	20179-20180	\|	_	_
272-159	20181-20186	20.60	_	_
272-160	20187-20188	\|	_	_
272-161	20189-20190	\|	_	_
272-162	20191-20203	ActionFormer	_	_
272-163	20204-20205	(	_	_
272-164	20205-20206	S	_	_
272-165	20206-20207	+	_	_
272-166	20207-20208	E	_	_
272-167	20208-20209	)	_	_
272-168	20213-20214	\|	_	_
272-169	20215-20220	27.98	_	_
272-170	20221-20222	\|	_	_
272-171	20223-20228	24.46	_	_
272-172	20229-20230	\|	_	_
272-173	20231-20236	21.21	_	_
272-174	20237-20238	\|	_	_
272-175	20239-20244	18.56	_	_
272-176	20245-20246	\|	_	_
272-177	20247-20252	15.60	_	_
272-178	20253-20254	\|	_	_
272-179	20255-20260	21.56	_	_
272-180	20261-20262	\|	_	_
272-181	20263-20264	\|	_	_
272-182	20265-20277	ActionFormer	_	_
272-183	20278-20279	(	_	_
272-184	20279-20280	O	_	_
272-185	20280-20281	+	_	_
272-186	20281-20282	E	_	_
272-187	20282-20283	)	_	_
272-188	20287-20288	\|	_	_
272-189	20289-20294	27.99	_	_
272-190	20295-20296	\|	_	_
272-191	20297-20302	24.94	_	_
272-192	20303-20304	\|	_	_
272-193	20305-20310	21.94	_	_
272-194	20311-20312	\|	_	_
272-195	20313-20318	19.05	_	_
272-196	20319-20320	\|	_	_
272-197	20321-20326	15.98	_	_
272-198	20327-20328	\|	_	_
272-199	20329-20334	21.98	_	_
272-200	20335-20336	\|	_	_
272-201	20337-20338	\|	_	_
272-202	20339-20351	ActionFormer	_	_
272-203	20352-20353	(	_	_
272-204	20353-20354	S	_	_
272-205	20354-20355	+	_	_
272-206	20355-20356	O	_	_
272-207	20356-20357	+	_	_
272-208	20357-20358	E	_	_
272-209	20358-20359	)	_	_
272-210	20361-20362	\|	_	_
272-211	20363-20368	28.26	_	_
272-212	20369-20370	\|	_	_
272-213	20371-20376	24.69	_	_
272-214	20377-20378	\|	_	_
272-215	20379-20384	21.88	_	_
272-216	20385-20386	\|	_	_
272-217	20387-20392	19.35	_	_
272-218	20393-20394	\|	_	_
272-219	20395-20400	16.28	_	_
272-220	20401-20402	\|	_	_
272-221	20403-20408	22.09	_	_
272-222	20409-20410	\|	_	_
272-223	20412-20413	\*	_	_
272-224	20414-20417	The	_	_
272-225	20418-20425	results	_	_
272-226	20426-20427	(	_	_
272-227	20427-20433	Recall	_	_
272-228	20433-20434	@	_	_
272-229	20434-20436	1x	_	_
272-230	20437-20439	at	_	_
272-231	20440-20445	tIoUs	_	_
272-232	20445-20446	)	_	_
272-233	20447-20453	should	_	_
272-234	20454-20456	be	_	_
272-235	20458-20459	\|	_	_
272-236	20460-20466	Method	_	_
272-237	20482-20483	\|	_	_
272-238	20485-20488	0.1	_	_
272-239	20490-20491	\|	_	_
272-240	20493-20496	0.2	_	_
272-241	20498-20499	\|	_	_
272-242	20501-20504	0.3	_	_
272-243	20506-20507	\|	_	_
272-244	20509-20512	0.4	_	_
272-245	20514-20515	\|	_	_
272-246	20517-20520	0.5	_	_
272-247	20522-20523	\|	_	_
272-248	20525-20528	Avg	_	_
272-249	20530-20531	\|	_	_
272-250	20532-20533	\|	_	_
272-251	20533-20534	-	_	_
272-252	20534-20535	-	_	_
272-253	20535-20536	-	_	_
272-254	20536-20537	-	_	_
272-255	20537-20538	-	_	_
272-256	20538-20539	-	_	_
272-257	20539-20540	-	_	_
272-258	20540-20541	-	_	_
272-259	20541-20542	-	_	_
272-260	20542-20543	-	_	_
272-261	20543-20544	-	_	_
272-262	20544-20545	-	_	_
272-263	20545-20546	-	_	_
272-264	20546-20547	-	_	_
272-265	20547-20548	-	_	_
272-266	20548-20549	-	_	_
272-267	20549-20550	-	_	_
272-268	20550-20551	-	_	_
272-269	20551-20552	-	_	_
272-270	20552-20553	-	_	_
272-271	20553-20554	-	_	_
272-272	20554-20555	-	_	_
272-273	20555-20556	-	_	_
272-274	20556-20557	\|	_	_
272-275	20557-20558	-	_	_
272-276	20558-20559	-	_	_
272-277	20559-20560	-	_	_
272-278	20560-20561	-	_	_
272-279	20561-20562	-	_	_
272-280	20562-20563	-	_	_
272-281	20563-20564	-	_	_
272-282	20564-20565	\|	_	_
272-283	20565-20566	-	_	_
272-284	20566-20567	-	_	_
272-285	20567-20568	-	_	_
272-286	20568-20569	-	_	_
272-287	20569-20570	-	_	_
272-288	20570-20571	-	_	_
272-289	20571-20572	-	_	_
272-290	20572-20573	\|	_	_
272-291	20573-20574	-	_	_
272-292	20574-20575	-	_	_
272-293	20575-20576	-	_	_
272-294	20576-20577	-	_	_
272-295	20577-20578	-	_	_
272-296	20578-20579	-	_	_
272-297	20579-20580	-	_	_
272-298	20580-20581	\|	_	_
272-299	20581-20582	-	_	_
272-300	20582-20583	-	_	_
272-301	20583-20584	-	_	_
272-302	20584-20585	-	_	_
272-303	20585-20586	-	_	_
272-304	20586-20587	-	_	_
272-305	20587-20588	-	_	_
272-306	20588-20589	\|	_	_
272-307	20589-20590	-	_	_
272-308	20590-20591	-	_	_
272-309	20591-20592	-	_	_
272-310	20592-20593	-	_	_
272-311	20593-20594	-	_	_
272-312	20594-20595	-	_	_
272-313	20595-20596	-	_	_
272-314	20596-20597	\|	_	_
272-315	20597-20598	-	_	_
272-316	20598-20599	-	_	_
272-317	20599-20600	-	_	_
272-318	20600-20601	-	_	_
272-319	20601-20602	-	_	_
272-320	20602-20603	-	_	_
272-321	20603-20604	-	_	_
272-322	20604-20605	\|	_	_
272-323	20606-20607	\|	_	_
272-324	20608-20620	ActionFormer	_	_
272-325	20621-20622	(	_	_
272-326	20622-20623	S	_	_
272-327	20623-20624	)	_	_
272-328	20630-20631	\|	_	_
272-329	20632-20637	52.25	_	_
272-330	20638-20639	\|	_	_
272-331	20640-20645	45.84	_	_
272-332	20646-20647	\|	_	_
272-333	20648-20653	40.60	_	_
272-334	20654-20655	\|	_	_
272-335	20656-20661	36.58	_	_
272-336	20662-20663	\|	_	_
272-337	20664-20669	31.33	_	_
272-338	20670-20671	\|	_	_
272-339	20672-20677	41.32	_	_
272-340	20678-20679	\|	_	_
272-341	20680-20681	\|	_	_
272-342	20682-20694	ActionFormer	_	_
272-343	20695-20696	(	_	_
272-344	20696-20697	O	_	_
272-345	20697-20698	)	_	_
272-346	20704-20705	\|	_	_
272-347	20706-20711	54.63	_	_
272-348	20712-20713	\|	_	_
272-349	20714-20719	48.72	_	_
272-350	20720-20721	\|	_	_
272-351	20722-20727	43.03	_	_
272-352	20728-20729	\|	_	_
272-353	20730-20735	37.76	_	_
272-354	20736-20737	\|	_	_
272-355	20738-20743	33.57	_	_
272-356	20744-20745	\|	_	_
272-357	20746-20751	43.54	_	_
272-358	20752-20753	\|	_	_
272-359	20754-20755	\|	_	_
272-360	20756-20768	ActionFormer	_	_
272-361	20769-20770	(	_	_
272-362	20770-20771	E	_	_
272-363	20771-20772	)	_	_
272-364	20778-20779	\|	_	_
272-365	20780-20785	59.53	_	_
272-366	20786-20787	\|	_	_
272-367	20788-20793	54.39	_	_
272-368	20794-20795	\|	_	_
272-369	20796-20801	48.97	_	_
272-370	20802-20803	\|	_	_
272-371	20804-20809	42.75	_	_
272-372	20810-20811	\|	_	_
272-373	20812-20817	37.12	_	_
272-374	20818-20819	\|	_	_
272-375	20820-20825	48.55	_	_
272-376	20826-20827	\|	_	_
272-377	20828-20829	\|	_	_
272-378	20830-20842	ActionFormer	_	_
272-379	20843-20844	(	_	_
272-380	20844-20845	S	_	_
272-381	20845-20846	+	_	_
272-382	20846-20847	E	_	_
272-383	20847-20848	)	_	_
272-384	20852-20853	\|	_	_
272-385	20854-20859	59.96	_	_
272-386	20860-20861	\|	_	_
272-387	20862-20867	53.75	_	_
272-388	20868-20869	\|	_	_
272-389	20870-20875	48.76	_	_
272-390	20876-20877	\|	_	_
272-391	20878-20883	44.00	_	_
272-392	20884-20885	\|	_	_
272-393	20886-20891	38.96	_	_
272-394	20892-20893	\|	_	_
272-395	20894-20899	49.09	_	_
272-396	20900-20901	\|	_	_
272-397	20902-20903	\|	_	_
272-398	20904-20916	ActionFormer	_	_
272-399	20917-20918	(	_	_
272-400	20918-20919	O	_	_
272-401	20919-20920	+	_	_
272-402	20920-20921	E	_	_
272-403	20921-20922	)	_	_
272-404	20926-20927	\|	_	_
272-405	20928-20933	61.03	_	_
272-406	20934-20935	\|	_	_
272-407	20936-20941	54.15	_	_
272-408	20942-20943	\|	_	_
272-409	20944-20949	49.79	_	_
272-410	20950-20951	\|	_	_
272-411	20952-20957	45.17	_	_
272-412	20958-20959	\|	_	_
272-413	20960-20965	39.88	_	_
272-414	20966-20967	\|	_	_
272-415	20968-20973	49.99	_	_
272-416	20974-20975	\|	_	_
272-417	20976-20977	\|	_	_
272-418	20978-20990	ActionFormer	_	_
272-419	20991-20992	(	_	_
272-420	20992-20993	S	_	_
272-421	20993-20994	+	_	_
272-422	20994-20995	O	_	_
272-423	20995-20996	+	_	_
272-424	20996-20997	E	_	_
272-425	20997-20998	)	_	_
272-426	21000-21001	\|	_	_
272-427	21002-21007	60.85	_	_
272-428	21008-21009	\|	_	_
272-429	21010-21015	54.16	_	_
272-430	21016-21017	\|	_	_
272-431	21018-21023	49.60	_	_
272-432	21024-21025	\|	_	_
272-433	21026-21031	45.12	_	_
272-434	21032-21033	\|	_	_
272-435	21034-21039	39.87	_	_
272-436	21040-21041	\|	_	_
272-437	21042-21047	49.92	_	_
272-438	21048-21049	\|	_	_
272-439	21051-21052	#	_	_
272-440	21052-21053	#	_	_
272-441	21054-21062	Training	_	_
272-442	21063-21066	and	_	_
272-443	21067-21077	Evaluating	_	_
272-444	21078-21082	Your	_	_
272-445	21083-21086	Own	_	_
272-446	21087-21094	Dataset	_	_
272-447	21095-21099	Work	_	_
272-448	21100-21102	in	_	_
272-449	21103-21111	progress	_	_
272-450	21111-21112	.	_	_

#Text=Stay tuned.  ## Contact Yin Li (yin.li@wisc.edu)  ## References If you are using our code, please consider citing our paper. ``` @inproceedings{zhang2022actionformer,   title={ActionFormer: Localizing Moments of Actions with Transformers},   author={Zhang, Chen-Lin and Wu, Jianxin and Li, Yin},   booktitle={European Conference on Computer Vision},   series={LNCS},   volume={13664},   pages={492-510},   year={2022} } ```  If you cite our results on Ego4D, please consider citing our tech report in addition to the main paper. ``` @article{mu2022actionformerego4d,   title={Where a Strong Backbone Meets Strong Features -- ActionFormer for Ego4D Moment Queries Challenge},   author={Mu, Fangzhou and Mo, Sicheng and Wang, Gillian, and Li, Yin},   journal={arXiv e-prints},   year={2022} } ```  If you are using TSP features, please cite ``` @inproceedings{alwassel2021tsp,   title={{TSP}: Temporally-sensitive pretraining of video encoders for localization tasks},   author={Alwassel, Humam and Giancola, Silvio and Ghanem, Bernard},   booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},   pages={3173--3183},   year={2021} } ```
273-1	21113-21117	Stay	_	_
273-2	21118-21123	tuned	_	_
273-3	21123-21124	.	_	_
273-4	21126-21127	#	_	_
273-5	21127-21128	#	_	_
273-6	21129-21136	Contact	_	_
273-7	21137-21140	Yin	_	_
273-8	21141-21143	Li	_	_
273-9	21144-21145	(	_	_
273-10	21145-21151	yin.li	_	_
273-11	21151-21152	@	_	_
273-12	21152-21160	wisc.edu	_	_
273-13	21160-21161	)	_	_
273-14	21163-21164	#	_	_
273-15	21164-21165	#	_	_
273-16	21166-21176	References	_	_
273-17	21177-21179	If	_	_
273-18	21180-21183	you	_	_
273-19	21184-21187	are	_	_
273-20	21188-21193	using	_	_
273-21	21194-21197	our	_	_
273-22	21198-21202	code	_	_
273-23	21202-21203	,	_	_
273-24	21204-21210	please	_	_
273-25	21211-21219	consider	_	_
273-26	21220-21226	citing	_	_
273-27	21227-21230	our	_	_
273-28	21231-21236	paper	_	_
273-29	21236-21237	.	_	_
273-30	21238-21239	`	_	_
273-31	21239-21240	`	_	_
273-32	21240-21241	`	_	_
273-33	21242-21243	@	_	_
273-34	21243-21256	inproceedings	_	_
273-35	21256-21257	{	_	_
273-36	21257-21278	zhang2022actionformer	_	_
273-37	21278-21279	,	_	_
273-38	21282-21287	title	_	_
273-39	21287-21288	=	_	_
273-40	21288-21289	{	_	_
273-41	21289-21301	ActionFormer	_	_
273-42	21301-21302	:	_	_
273-43	21303-21313	Localizing	_	_
273-44	21314-21321	Moments	_	_
273-45	21322-21324	of	_	_
273-46	21325-21332	Actions	_	_
273-47	21333-21337	with	_	_
273-48	21338-21350	Transformers	_	_
273-49	21350-21351	}	_	_
273-50	21351-21352	,	_	_
273-51	21355-21361	author	_	_
273-52	21361-21362	=	_	_
273-53	21362-21363	{	_	_
273-54	21363-21368	Zhang	_	_
273-55	21368-21369	,	_	_
273-56	21370-21378	Chen-Lin	_	_
273-57	21379-21382	and	_	_
273-58	21383-21385	Wu	_	_
273-59	21385-21386	,	_	_
273-60	21387-21394	Jianxin	_	_
273-61	21395-21398	and	_	_
273-62	21399-21401	Li	_	_
273-63	21401-21402	,	_	_
273-64	21403-21406	Yin	_	_
273-65	21406-21407	}	_	_
273-66	21407-21408	,	_	_
273-67	21411-21420	booktitle	_	_
273-68	21420-21421	=	_	_
273-69	21421-21422	{	_	_
273-70	21422-21430	European	_	_
273-71	21431-21441	Conference	_	_
273-72	21442-21444	on	_	_
273-73	21445-21453	Computer	_	_
273-74	21454-21460	Vision	_	_
273-75	21460-21461	}	_	_
273-76	21461-21462	,	_	_
273-77	21465-21471	series	_	_
273-78	21471-21472	=	_	_
273-79	21472-21473	{	_	_
273-80	21473-21477	LNCS	_	_
273-81	21477-21478	}	_	_
273-82	21478-21479	,	_	_
273-83	21482-21488	volume	_	_
273-84	21488-21489	=	_	_
273-85	21489-21490	{	_	_
273-86	21490-21495	13664	_	_
273-87	21495-21496	}	_	_
273-88	21496-21497	,	_	_
273-89	21500-21505	pages	_	_
273-90	21505-21506	=	_	_
273-91	21506-21507	{	_	_
273-92	21507-21510	492	_	_
273-93	21510-21511	-	_	_
273-94	21511-21514	510	_	_
273-95	21514-21515	}	_	_
273-96	21515-21516	,	_	_
273-97	21519-21523	year	_	_
273-98	21523-21524	=	_	_
273-99	21524-21525	{	_	_
273-100	21525-21529	2022	_	_
273-101	21529-21530	}	_	_
273-102	21531-21532	}	_	_
273-103	21533-21534	`	_	_
273-104	21534-21535	`	_	_
273-105	21535-21536	`	_	_
273-106	21538-21540	If	_	_
273-107	21541-21544	you	_	_
273-108	21545-21549	cite	_	_
273-109	21550-21553	our	_	_
273-110	21554-21561	results	_	_
273-111	21562-21564	on	_	_
273-112	21565-21570	Ego4D	_	_
273-113	21570-21571	,	_	_
273-114	21572-21578	please	_	_
273-115	21579-21587	consider	_	_
273-116	21588-21594	citing	_	_
273-117	21595-21598	our	_	_
273-118	21599-21603	tech	_	_
273-119	21604-21610	report	_	_
273-120	21611-21613	in	_	_
273-121	21614-21622	addition	_	_
273-122	21623-21625	to	_	_
273-123	21626-21629	the	_	_
273-124	21630-21634	main	_	_
273-125	21635-21640	paper	_	_
273-126	21640-21641	.	_	_
273-127	21642-21643	`	_	_
273-128	21643-21644	`	_	_
273-129	21644-21645	`	_	_
273-130	21646-21647	@	_	_
273-131	21647-21654	article	_	_
273-132	21654-21655	{	_	_
273-133	21655-21678	mu2022actionformerego4d	_	_
273-134	21678-21679	,	_	_
273-135	21682-21687	title	_	_
273-136	21687-21688	=	_	_
273-137	21688-21689	{	_	_
273-138	21689-21694	Where	_	_
273-139	21695-21696	a	_	_
273-140	21697-21703	Strong	_	_
273-141	21704-21712	Backbone	_	_
273-142	21713-21718	Meets	_	_
273-143	21719-21725	Strong	_	_
273-144	21726-21734	Features	_	_
273-145	21735-21736	-	_	_
273-146	21736-21737	-	_	_
273-147	21738-21750	ActionFormer	_	_
273-148	21751-21754	for	_	_
273-149	21755-21760	Ego4D	_	_
273-150	21761-21767	Moment	_	_
273-151	21768-21775	Queries	_	_
273-152	21776-21785	Challenge	_	_
273-153	21785-21786	}	_	_
273-154	21786-21787	,	_	_
273-155	21790-21796	author	_	_
273-156	21796-21797	=	_	_
273-157	21797-21798	{	_	_
273-158	21798-21800	Mu	_	_
273-159	21800-21801	,	_	_
273-160	21802-21810	Fangzhou	_	_
273-161	21811-21814	and	_	_
273-162	21815-21817	Mo	_	_
273-163	21817-21818	,	_	_
273-164	21819-21826	Sicheng	_	_
273-165	21827-21830	and	_	_
273-166	21831-21835	Wang	_	_
273-167	21835-21836	,	_	_
273-168	21837-21844	Gillian	_	_
273-169	21844-21845	,	_	_
273-170	21846-21849	and	_	_
273-171	21850-21852	Li	_	_
273-172	21852-21853	,	_	_
273-173	21854-21857	Yin	_	_
273-174	21857-21858	}	_	_
273-175	21858-21859	,	_	_
273-176	21862-21869	journal	_	_
273-177	21869-21870	=	_	_
273-178	21870-21871	{	_	_
273-179	21871-21876	arXiv	_	_
273-180	21877-21885	e-prints	_	_
273-181	21885-21886	}	_	_
273-182	21886-21887	,	_	_
273-183	21890-21894	year	_	_
273-184	21894-21895	=	_	_
273-185	21895-21896	{	_	_
273-186	21896-21900	2022	_	_
273-187	21900-21901	}	_	_
273-188	21902-21903	}	_	_
273-189	21904-21905	`	_	_
273-190	21905-21906	`	_	_
273-191	21906-21907	`	_	_
273-192	21909-21911	If	_	_
273-193	21912-21915	you	_	_
273-194	21916-21919	are	_	_
273-195	21920-21925	using	_	_
273-196	21926-21929	TSP	_	_
273-197	21930-21938	features	_	_
273-198	21938-21939	,	_	_
273-199	21940-21946	please	_	_
273-200	21947-21951	cite	_	_
273-201	21952-21953	`	_	_
273-202	21953-21954	`	_	_
273-203	21954-21955	`	_	_
273-204	21956-21957	@	_	_
273-205	21957-21970	inproceedings	_	_
273-206	21970-21971	{	_	_
273-207	21971-21986	alwassel2021tsp	_	_
273-208	21986-21987	,	_	_
273-209	21990-21995	title	_	_
273-210	21995-21996	=	_	_
273-211	21996-21997	{	_	_
273-212	21997-21998	{	_	_
273-213	21998-22001	TSP	_	_
273-214	22001-22002	}	_	_
273-215	22002-22003	:	_	_
273-216	22004-22024	Temporally-sensitive	_	_
273-217	22025-22036	pretraining	_	_
273-218	22037-22039	of	_	_
273-219	22040-22045	video	_	_
273-220	22046-22054	encoders	_	_
273-221	22055-22058	for	_	_
273-222	22059-22071	localization	_	_
273-223	22072-22077	tasks	_	_
273-224	22077-22078	}	_	_
273-225	22078-22079	,	_	_
273-226	22082-22088	author	_	_
273-227	22088-22089	=	_	_
273-228	22089-22090	{	_	_
273-229	22090-22098	Alwassel	_	_
273-230	22098-22099	,	_	_
273-231	22100-22105	Humam	_	_
273-232	22106-22109	and	_	_
273-233	22110-22118	Giancola	_	_
273-234	22118-22119	,	_	_
273-235	22120-22126	Silvio	_	_
273-236	22127-22130	and	_	_
273-237	22131-22137	Ghanem	_	_
273-238	22137-22138	,	_	_
273-239	22139-22146	Bernard	_	_
273-240	22146-22147	}	_	_
273-241	22147-22148	,	_	_
273-242	22151-22160	booktitle	_	_
273-243	22160-22161	=	_	_
273-244	22161-22162	{	_	_
273-245	22162-22173	Proceedings	_	_
273-246	22174-22176	of	_	_
273-247	22177-22180	the	_	_
273-248	22181-22185	IEEE	_	_
273-249	22185-22186	/	_	_
273-250	22186-22189	CVF	_	_
273-251	22190-22203	International	_	_
273-252	22204-22214	Conference	_	_
273-253	22215-22217	on	_	_
273-254	22218-22226	Computer	_	_
273-255	22227-22233	Vision	_	_
273-256	22234-22243	Workshops	_	_
273-257	22243-22244	}	_	_
273-258	22244-22245	,	_	_
273-259	22248-22253	pages	_	_
273-260	22253-22254	=	_	_
273-261	22254-22255	{	_	_
273-262	22255-22259	3173	_	_
273-263	22259-22260	-	_	_
273-264	22260-22261	-	_	_
273-265	22261-22265	3183	_	_
273-266	22265-22266	}	_	_
273-267	22266-22267	,	_	_
273-268	22270-22274	year	_	_
273-269	22274-22275	=	_	_
273-270	22275-22276	{	_	_
273-271	22276-22280	2021	_	_
273-272	22280-22281	}	_	_
273-273	22282-22283	}	_	_
273-274	22284-22285	`	_	_
273-275	22285-22286	`	_	_
273-276	22286-22287	`	_	_