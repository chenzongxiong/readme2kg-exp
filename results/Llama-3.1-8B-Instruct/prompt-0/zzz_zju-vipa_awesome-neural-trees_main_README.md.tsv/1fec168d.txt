Therefore, this survey comprises approaches that extract <PUBLICATION>partial knowledge</PUBLICATION> contained in the hidden layers and do not demand their approximation target is the input-output relationship  - ***<SOFTWARE>Extended C-Net algorithm</SOFTWARE>***   - **"<PUBLICATION>Towards Interpretable ANNs: An Exact Transformation to Multi-Class Multivariate Decision Trees</PUBLICATION>**", arXiv, 2020     - Duy T Nguyen, Kathryn E Kasmarik, Hussein A Abbass *(a typical eclectic technique)*     - [[Paper]](http://arxiv-export-lb.library.cornell.edu/abs/<PUBLICATION>2003.04675</PUBLICATION>)  - ***<SOFTWARE>Generalized eclectic techniques</SOFTWARE>***   - **"<PUBLICATION>Global Model Interpretation Via Recursive Partitioning</PUBLICATION>**", HPCC/SmartCity/DSS, 2018     - Chengliang Yang, Anand Rangarajan, Sanjay Ranka *(<SOFTWARE>CART tree learned from the contribution matrix and applied to scene understanding tasks</SOFTWARE>)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/<PUBLICATION>8622994</PUBLICATION>) [[Code]](https://github.com/west-gates/<SOFTWARE>GIRP</SOFTWARE>)   - **"<PUBLICATION>Interpreting CNNs via Decision Trees</PUBLICATION>**", <CONFERENCE>CVPR</CONFERENCE>, 2019     - Quanshi Zhang *et al.* *(encodes all potential decision modes of the CNN in a coarse-to-fine manner)*     - [[Paper]](https://openaccess.thecvf.com/content_<CONFERENCE>CVPR</CONFERENCE>_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html)  ##### *1.2.4 Optional: DTs for Regularizing NNs.* These approaches train NNs that resemble compact DTs through crafted regularization terms, so that they can be well-approximated by small DTs