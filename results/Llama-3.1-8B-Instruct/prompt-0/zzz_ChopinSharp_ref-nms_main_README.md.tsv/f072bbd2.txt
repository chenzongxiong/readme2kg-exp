Then, run the following commands to evaluate on REC and RES task: 
``` 
# Evaluate REC performance
python tools/extract_mrcn_ref_feats.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type>
python tools/eval_ref.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type>
# Evaluate RES performance
python tools/run_propose_to_mask.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type>
python tools/eval_ref_masks.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save
```
## Pretrained Models 
We provide pre-trained model weights as long as the corresponding **<SOFTWARE>MAttNet</SOFTWARE>-style detection file** (note the <SOFTWARE>MAttNet</SOFTWARE>-style detection files can be directly used to evaluate downstream <CONFERENCE>REG</CONFERENCE> task performance).