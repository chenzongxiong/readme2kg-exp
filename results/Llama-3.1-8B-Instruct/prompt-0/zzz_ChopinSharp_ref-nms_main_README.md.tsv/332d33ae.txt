Run following script to setup `<SOFTWARE>cache</SOFTWARE>` directory: ``` sh scripts/prepare_data.sh ``` This should generate following files under `<SOFTWARE>cache</SOFTWARE>` directory: - vocabulary file: `<DATASET>std_vocab_<dataset>_<split_by>.txt</DATASET>` - selected GloVe feature: `<DATASET>std_glove_<dataset>_<split_by>.npy</DATASET>` - referring expression database: `<DATASET>std_refdb_<dataset>_<split_by>.json</DATASET>` - critical objects database: `<DATASET>std_ctxdb_<dataset>_<split_by>.json</DATASET>`   ## Train **<PUBLICATION>Train with binary XE loss:</PUBLICATION>** ``` <PROGLANG>PYTHONPATH=$PWD</PROGLANG> python <SOFTWARE>tools/train_att_vanilla.py</SOFTWARE> --<DATASET>dataset</DATASET> refcoco --<DATASET>split-by</DATASET> unc ```  **<PUBLICATION>Train with ranking loss:</PUBLICATION>** ``` <PROGLANG>PYTHONPATH=$PWD</PROGLANG> python <SOFTWARE>tools/train_att_rank.py</SOFTWARE> --<DATASET>dataset</DATASET> refcoco --<DATASET>split-by</DATASET> unc ```  We use <SOFTWARE>tensorboard</SOFTWARE> to monitor the training process.