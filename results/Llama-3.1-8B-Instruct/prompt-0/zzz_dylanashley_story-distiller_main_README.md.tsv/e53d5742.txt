# <SOFTWARE>story-distiller</SOFTWARE>  [![paper](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient)
 Story Distillation: A Simple and Efficient Method for Story Generation](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient)
 
 The authors have released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <CONFERENCE>ACL 2022</CONFERENCE> paper can be found on the [aclweb](https://www.aclweb.org/anthology/2022.acl-long.1/) website.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <WORKSHOP>Story Generation Workshop</WORKSHOP> was held at the <CONFERENCE>ACL 2022</CONFERENCE> conference.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <ONTOLOGY>Story Ontology</ONTOLOGY> is a framework for representing knowledge about stories.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <CONFERENCE>ACL 2022</CONFERENCE> paper can be found on the [aclweb](https://www.aclweb.org/anthology/2022.acl-long.1/) website.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <WORKSHOP>Story Generation Workshop</WORKSHOP> was held at the <CONFERENCE>ACL 2022</CONFERENCE> conference.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <ONTOLOGY>Story Ontology</ONTOLOGY> is a framework for representing knowledge about stories.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <CONFERENCE>ACL 2022</CONFERENCE> paper can be found on the [aclweb](https://www.aclweb.org/anthology/2022.acl-long.1/) website.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <WORKSHOP>Story Generation Workshop</WORKSHOP> was held at the <CONFERENCE>ACL 2022</CONFERENCE> conference.
 
 The authors have also released a <DATASET>Story Distiller Dataset</DATASET> which includes a collection of stories and their corresponding summaries.
 
 The evaluation metrics used are <EVALMETRIC>Precision</EVALMETRIC>, <EVALMETRIC>Recall</EVALMETRIC>, and <EVALMETRIC>F1-Score</EVALMETRIC>.
 
 The paper is available under the <LICENSE>CC BY 4.0</LICENSE> license.
 
 The <PROJECT>Story Distiller</PROJECT> project can be found on the [paperswithcode](https://paperswithcode.com/papers/story-distillation-a-simple-and-efficient) website.
 
 You can use the <SOFTWARE>Protege ontology editor</SOFTWARE> to explore and edit the resource.
 
 The authors have also released a <SOFTWARE>Story Distiller Tool</SOFTWARE> which can be used to generate stories and summaries.
 
 The <