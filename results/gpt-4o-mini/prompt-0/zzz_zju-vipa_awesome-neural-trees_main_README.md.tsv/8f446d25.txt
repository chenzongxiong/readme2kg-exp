A comparison between NDTs according to whether it implements a class hierarchy and whether it is data-driven: <p align='center'>     </br>     <img src='NDT_hierarchy.png' width='1000'> </p>  - ***Informativeness-related splitting functions with NN-based routers***   - **"Neural trees-using neural nets in a tree classifier structure"**, <CONFERENCE>ICASSP</CONFERENCE>, 1991     - J-E Stromberg, Jalel Zrida, Alf Isaksson *(train a small NN at each internal node, which singles out one unique class that gains the most class purity)*     - [[Paper]](https://www.computer.org/csdl/proceedings-article/icassp/1991/0003137/12OmNzdoMSH)   - **"Evolutionary design of neural network tree-integration of decision tree, neural network and GA"**, <CONFERENCE>CEC</CONFERENCE>, 2001     - Qiangfu Zhao *(use genetic algorithms to maximize the information gain ratio at each internal node)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/934395)   - **"Hybrid decision tree"**, <PUBLICATION>Knowledge-Based Systems</PUBLICATION>, 2002     - Zhi-Hua Zhou, Zhao-Qian Chen *(Divide the instance space into ordered attributes and unordered attributes)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0950705102000382)   - **"Classification trees with neural network feature extraction"**, <CONFERENCE>CVPR</CONFERENCE>, 1992     - Heng Guo, Saul B Gelfand *(find two clusters that minimizes a Gini impurity criterion, then find a good split through back-propagation)*     - [[Paper]](https://www.computer.org/csdl/proceedings-article/cvpr/1992/00223275/12OmNzBOilt)  - ***Decrease the classification error at each node to be extended***   - **"Growing and pruning neural tree networks"**, <PUBLICATION>IEEE Transactions on Computers</PUBLICATION>, 1993     - A Sakar *et al.* *(Divide the instance space into ordered attributes and unordered attributes)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/210172)  - ***Grows during competitive learning***   - **"Competitive neural trees for pattern classification"**,  <PUBLICATION>IEEE Transactions on Neural Networks</PUBLICATION>, 1998     - Sven Behnke, Nicolaos B Karayiannis     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/728387)  - ***Map examples into the label embedding space and predicts using a NDT***   - **"Label Embedding Trees for Large Multi-Class Tasks"**, <CONFERENCE>NIPS</CONFERENCE>, 2010     - Samy Bengio, Jason Weston, David Grangier     - [[Paper]](https://proceedings.neurips.cc/paper/2010/hash/06138bc5af6023646ede0e1f7c1eac75-Abstract.html)   - **"Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition"**, <CONFERENCE>NIPS</CONFERENCE>, 2011     - Jia Deng, Sanjeev Satheesh, Alexander Berg, Fei Li     - [[Paper]](https://proceedings.neurips.cc/paper/2011/hash/5a4b25aaed25c2ee1b74de72dc03c14e-Abstract.html)  - ***Apply data-driven architectures to fuzzy NDTs***   - **"Globally optimal fuzzy decision trees for classification and regression"**, <PUBLICATION>IEEE Transactions on Pattern Analysis and Machine Intelligence</PUBLICATION>, 1999     - Alberto Suárez, James F Lutsko *(superimpose a fuzzy structure over the skeleton of a CART tree and introduce a global optimization algorithm)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/817409)   - **"Budding Trees"**, <CONFERENCE>ICPR</CONFERENCE>, 2014     - Ozan Irsoy, Olcay Taner Yildiz, Ethem Alpaydin *(a FDT model that can be dynamically adjusted)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6977328) [[Code]](https://github.com/oir/budding-tree)   - **"Convolutional Decision Trees for Feature Learning and Segmentation"**, <CONFERENCE>GCPR</CONFERENCE>, 2014    - Dmitry Laptev, Joachim M Buhmann *(applies fuzzy NDTs to image segmentation by extracting the most informative and interpretable features)*     - [[Paper]](https://link.springer.com/chapter/10.1007/978-3-319-11752-2_8)   - **"Neural Decision Trees"**, <PUBLICATION>arXiv</PUBLICATION>, 2017     - Randall Balestriero *(map similar inputs to the same hash value)*     - [[Paper]](https://arxiv.org/abs/1702.07360)   - **"Neuro-fuzzy decision trees"**, <PUBLICATION>Neural Systems</PUBLICATION>, 2006     - Rajen B Bhatt, M Gopal *(employs fuzzy ID3 algorithm for DT-renovation)*     - [[Paper]](https://www.worldscientific.com/doi/abs/10.1142/s0129065706000470)  - ***Incremental learning***   - **"Hybrid decision tree"**, <PUBLICATION>Knowledge-Based Systems</PUBLICATION>, 2022     - Zhi-Hua Zhou, Zhao-Qian Chen *(two example-incremental tasks, one hypothesis-driven constructive induction mechanism)*     - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0950705102000382)   - **"Soft decision trees"**, <CONFERENCE>ICPR</CONFERENCE>, 2012     - Ozan Irsoy, Olcay Taner Yıldız, Ethem Alpaydın *(sigmoid-based FDT whose splits are made by checking if there is an improvement over the validation set)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/6460506)   - **"A Neural Tree with Partial Incremental Learning Capability"**, <CONFERENCE>ICMLC</CONFERENCE>, 2007     - Mu-Chun Su, Hsu-Hsun Lo *(choose a target class at each internal node and train a small NN to separate the positive patterns from negative ones)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/4370106)  ##### *3.1.2 Bigot NDTs.* A bigot NDT tends to have a pre-defined structure and determine leaves (pure classes or fixed class distributions) by priors or algorithms such that induce the class hierarchy