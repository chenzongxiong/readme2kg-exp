For info on how to run this file see src/pre_process/README_NER     <div style="margin-left: auto;             margin-right: auto;             width: 95%">  | Model name in paper         | Config under `config/models_config/{<domain>}`  | Model class in code   | |-----------------------------|:-------------------------:|:-----------:| | cosentbert              |        `cosentbert`        |  `facetid_models.sentsim_models.SentBERTWrapper` | | ICTSentBert              |        `ictsentbert`        |  `facetid_models.sentsim_models.ICTBERTWrapper` | | SPECTER-CoCite              |        `hparam_opt/cospecter-best`/`hparam_opt/cospecter-specinit-best`        |  `facetid_models.disent_models.MySPECTER`  | | tsAspire                    |        `hparam_opt/sbalisentbienc-sup-best`        |        `facetid_models.disent_models.WordSentAbsSupAlignBiEnc`   | | otAspire                    |        `hparam_opt/miswordbienc-otstuni-best`        |      `facetid_models.disent_models.WordSentAlignBiEnc`   | | ts+otAspire                 |        `hparam_opt/sbalisentbienc-otuni-best`        |        `facetid_models.disent_models.WordSentAbsSupAlignBiEnc`   | | maxAspire                 |          `hparam_opt/miswordbienc-l2max-best`      |        `facetid_models.disent_models.WordSentAlignBiEnc` | | absAspire                 |          `hparam_opt/sbalisentbienc-sup-absali-best`      |        `facetid_models.disent_models.WordSentAbsSupAlignBiEnc`   | | attAspire                 |          `hparam_opt/miswordbienc-cdatt-best`      |        `facetid_models.disent_models.WordSentAlignBiEnc`   |  </div>   ### Acknowledgements <a name="acks"></a>  This work relies on: (1) Data from the <DATASET>Semantic Scholar Open Research Corpus</DATASET> (<https://github.com/allenai/s2orc>) (S2ORC) and the evaluation datasets <DATASET>RELISH</DATASET> (kindly shared by <PUBLICATION>Mariana Neves</PUBLICATION> (<https://mariananeves.github.io/>)), <DATASET>TRECCOVID</DATASET>, <DATASET>SciDocs</DATASET>, and <DATASET>CSFCube</DATASET> linked above. (2) The pre-trained models of <SOFTWARE>SPECTER</SOFTWARE> (<https://github.com/allenai/specter>). (3) The software packages: <SOFTWARE>GeomLoss</SOFTWARE> (<https://www.kernel-operations.io/geomloss/index.html>) and <SOFTWARE>sentence-transformers</SOFTWARE> (<https://www.sbert.net/>).   ### Citation <a name="citation"></a>  Please cite the <PUBLICATION>Aspire paper</PUBLICATION> (<https://arxiv.org/pdf/2004.07180.pdf>) as:    ```bibtex @misc{mysore2021aspire,       title={Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity},        author={Sheshera Mysore and Arman Cohan and Tom Hope},       year={2021},       eprint={2111.08366},       archivePrefix={arXiv},       primaryClass={cs.CL} } ```   ### TODOs <a name="todos"></a>  1.