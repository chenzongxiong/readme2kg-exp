Use the above training scripts and set `--epochs` to be 0 for evaluation. ### Retrieval Results | val Recall@100 | test Recall@100 | val LRAP | test LRAP | val passage-level Recall@100 | test passage-level Recall@100| |:----------------:|:-----------------:|:----------:|:-----------:|:---------------------:|:---------------------:| |     98.17%     |     96.62%      |  83.98%  |  82.65%   |      97.03%         |        94.59%       |   **Recall@k** is the percentage of total number of positive entities retrieved by the topk candidates with respect to the total number of gold entities for all the query passages. \ **passage-level Recall@k** is the percentage of the number of passages with all the gold entities retrieved in the topk candidates with respect to the number of passages. \ **LRAP** is [Label ranking average precision ](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.label_ranking_average_precision_score.html) which measures the multi-label ranking performance.    ## Train Reader   Train reader by  ``` <PROGLANG>python</PROGLANG> run_reader.py  \ --model /model_reader/reader.pt   --data_dir /reader_input/  \ --C 64  --B 2  --L 180  --C_val 100  --gpus 0,1   --val_bsz 32 \ --gradient_accumulation_steps 2  --warmup_proportion 0.06  \ --epochs 4  --lr 1e-5 --thresd  0.05  --logging_steps 100  \ --k 3  --stride 16 --max_passage_len 32  --filter_span  \ --type_encoder <PROGLANG>squad2_electra_large</PROGLANG>  \ --type_span_loss sum_log  --type_rank_loss sum_log  \ --do_rerank  --add_topic  --results_dir /reader_results/  --kb_dir /kb/  ``` It takes about 6 hours on 2 <SOFTWARE>A100</SOFTWARE> GPUs to finish the reader training experiment.