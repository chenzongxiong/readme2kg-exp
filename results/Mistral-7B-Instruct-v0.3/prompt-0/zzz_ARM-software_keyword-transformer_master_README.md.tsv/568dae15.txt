`There are three variants of the Keyword-Transformer model: \
* **Time-domain attention**: each time-window is treated as a patch, self-attention is computed between time-windows \
* **Frequency-domain attention**: each frequency is treated as a patch, self-attention is computed between frequencies \
* **Combination of both**: The signal is fed into both a time- and a frequency-domain transformer and the outputs are combined \
* **Patch-wise attention**: Similar to the vision transformer, it extracts rectangular patches from the spectrogram, so attention happens both in the time and frequency domain simultaneously. \
## Training a model from scratch To train KWT-3 from scratch on Speech Commands V2, run \
```shell sh train.sh ``` \
Please note that the train directory (given by the argument `--train_dir`) cannot exist prior to start script.`

In this example, the following entities have been annotated:

- `Keyword-Transformer` (PROJECT)
- `Time-domain attention` (CONFERENCE)
- `Frequency-domain attention` (CON