#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# XTR: Rethinking the Role of Token Retrieval in Multi-Vector Retrieval  In this repository, we provide how you can run XTR (conteXtualized Token Retriever) for document retrieval.
1-1	0-1	#	_	_
1-2	2-5	XTR	_	_
1-3	5-6	:	_	_
1-4	7-17	Rethinking	_	_
1-5	18-21	the	_	_
1-6	22-26	Role	_	_
1-7	27-29	of	_	_
1-8	30-35	Token	_	_
1-9	36-45	Retrieval	_	_
1-10	46-48	in	_	_
1-11	49-61	Multi-Vector	_	_
1-12	62-71	Retrieval	_	_
1-13	73-75	In	_	_
1-14	76-80	this	_	_
1-15	81-91	repository	_	_
1-16	91-92	,	_	_
1-17	93-95	we	_	_
1-18	96-103	provide	_	_
1-19	104-107	how	_	_
1-20	108-111	you	_	_
1-21	112-115	can	_	_
1-22	116-119	run	_	_
1-23	120-123	XTR	_	_
1-24	124-125	(	_	_
1-25	125-139	conteXtualized	_	_
1-26	140-145	Token	_	_
1-27	146-155	Retriever	_	_
1-28	155-156	)	_	_
1-29	157-160	for	_	_
1-30	161-169	document	_	_
1-31	170-179	retrieval	_	_
1-32	179-180	.	_	_

#Text=Please refer to our NeurIPS 2023 paper (\[Lee et al., 2023\](https://arxiv.org/abs/2304.01982)) for technical details.  ## Usage  XTR is available through \[Kaggle Models\](https://www.kaggle.com/models/deepmind/xtr/).
2-1	181-187	Please	_	_
2-2	188-193	refer	_	_
2-3	194-196	to	_	_
2-4	197-200	our	_	_
2-5	201-208	NeurIPS	_	_
2-6	209-213	2023	_	_
2-7	214-219	paper	_	_
2-8	220-221	(	_	_
2-9	221-222	\[	_	_
2-10	222-225	Lee	_	_
2-11	226-228	et	_	_
2-12	229-231	al	_	_
2-13	231-232	.	_	_
2-14	232-233	,	_	_
2-15	234-238	2023	_	_
2-16	238-239	\]	_	_
2-17	239-240	(	_	_
2-18	240-245	https	_	_
2-19	245-246	:	_	_
2-20	246-247	/	_	_
2-21	247-248	/	_	_
2-22	248-257	arxiv.org	_	_
2-23	257-258	/	_	_
2-24	258-261	abs	_	_
2-25	261-262	/	_	_
2-26	262-272	2304.01982	_	_
2-27	272-273	)	_	_
2-28	273-274	)	_	_
2-29	275-278	for	_	_
2-30	279-288	technical	_	_
2-31	289-296	details	_	_
2-32	296-297	.	_	_
2-33	299-300	#	_	_
2-34	300-301	#	_	_
2-35	302-307	Usage	_	_
2-36	309-312	XTR	_	_
2-37	313-315	is	_	_
2-38	316-325	available	_	_
2-39	326-333	through	*[124]	PUBLICATION[124]
2-40	334-335	\[	*[124]	PUBLICATION[124]
2-41	335-341	Kaggle	*[124]	PUBLICATION[124]
2-42	342-348	Models	*[124]	PUBLICATION[124]
2-43	348-349	\]	*[124]	PUBLICATION[124]
2-44	349-350	(	*[124]	PUBLICATION[124]
2-45	350-355	https	*[124]	PUBLICATION[124]
2-46	355-356	:	*[124]	PUBLICATION[124]
2-47	356-357	/	_	_
2-48	357-358	/	_	_
2-49	358-372	www.kaggle.com	_	_
2-49	362-368	kaggle	_	_
2-50	372-373	/	_	_
2-51	373-379	models	_	_
2-52	379-380	/	_	_
2-53	380-388	deepmind	_	_
2-54	388-389	/	_	_
2-55	389-392	xtr	_	_
2-56	392-393	/	_	_
2-57	393-394	)	_	_
2-58	394-395	.	_	_

#Text=For instance, you can load XTR checkpoints as follows:  ```python ## Model Usage import tensorflow\_hub as hub import tensorflow as tf import tensorflow\_text as text  # Registers the ops.
3-1	396-399	For	_	_
3-2	400-408	instance	_	_
3-3	408-409	,	_	_
3-4	410-413	you	_	_
3-5	414-417	can	_	_
3-6	418-422	load	_	_
3-7	423-426	XTR	_	_
3-8	427-438	checkpoints	_	_
3-9	439-441	as	_	_
3-10	442-449	follows	_	_
3-11	449-450	:	_	_
3-12	452-453	`	_	_
3-13	453-454	`	_	_
3-14	454-455	`	_	_
3-15	455-461	python	_	_
3-16	462-463	#	_	_
3-17	463-464	#	_	_
3-18	465-470	Model	_	_
3-19	471-476	Usage	_	_
3-20	477-483	import	*[144]	PROJECT[144]
3-21	484-498	tensorflow\_hub	*[144]	PROJECT[144]
3-21	484-494	tensorflow	*[144]	PROJECT[144]
3-22	499-501	as	*[144]	PROJECT[144]
3-23	502-505	hub	*[144]	PROJECT[144]
3-24	506-512	import	*[144]	PROJECT[144]
3-25	513-523	tensorflow	*[144]	PROJECT[144]
3-26	524-526	as	*[144]	PROJECT[144]
3-27	527-529	tf	*[144]	PROJECT[144]
3-28	530-536	import	*[144]	PROJECT[144]
3-29	537-552	tensorflow\_text	*[144]	PROJECT[144]
3-29	537-547	tensorflow	*[144]	PROJECT[144]
3-30	553-555	as	*[144]	PROJECT[144]
3-31	556-560	text	_	_
3-32	562-563	#	_	_
3-33	564-573	Registers	_	_
3-34	574-577	the	_	_
3-35	578-581	ops	_	_
3-36	581-582	.	_	_

#Text=hub\_url = "/kaggle/input/xtr/tensorflow2/base-en/2/" # if using Kaggle Notebooks, otherwise: hub\_url = "https://www.kaggle.com/models/deepmind/xtr/frameworks/tensorFlow2/variations/base-en/versions/2" encoder = hub.KerasLayer(hub\_url, signature="serving\_default", signature\_outputs\_as\_dict=True)  # Sample texts to encode. sample\_texts = tf.constant(\["dog", "Puppies are nice.", "I enjoy taking long walks along the beach with my dog."\]) sample\_embeds = encoder(sample\_texts)  # This returns token-level representations from XTR. encodings = sample\_embeds\["encodings"\].numpy() mask = sample\_embeds\["mask"\].numpy() print(f"encodings: {encodings.shape}, mask: {mask.shape}") ```  \[!
4-1	584-591	hub\_url	_	_
4-2	592-593	=	_	_
4-3	594-595	"	_	_
4-4	595-596	/	_	_
4-5	596-602	kaggle	_	_
4-6	602-603	/	_	_
4-7	603-608	input	_	_
4-8	608-609	/	_	_
4-9	609-612	xtr	_	_
4-10	612-613	/	_	_
4-11	613-624	tensorflow2	_	_
4-12	624-625	/	_	_
4-13	625-632	base-en	_	_
4-14	632-633	/	_	_
4-15	633-634	2	_	_
4-16	634-635	/	_	_
4-17	635-636	"	_	_
4-18	637-638	#	_	_
4-19	639-641	if	_	_
4-20	642-647	using	_	_
4-21	648-654	Kaggle	_	_
4-22	655-664	Notebooks	_	_
4-23	664-665	,	_	_
4-24	666-675	otherwise	_	_
4-25	675-676	:	_	_
4-26	677-684	hub\_url	_	_
4-27	685-686	=	_	_
4-28	687-688	"	_	_
4-29	688-693	https	_	_
4-30	693-694	:	_	_
4-31	694-695	/	_	_
4-32	695-696	/	_	_
4-33	696-710	www.kaggle.com	_	_
4-33	700-706	kaggle	_	_
4-34	710-711	/	_	_
4-35	711-717	models	_	_
4-36	717-718	/	_	_
4-37	718-726	deepmind	_	_
4-38	726-727	/	_	_
4-39	727-730	xtr	_	_
4-40	730-731	/	_	_
4-41	731-741	frameworks	_	_
4-42	741-742	/	_	_
4-43	742-753	tensorFlow2	_	_
4-44	753-754	/	_	_
4-45	754-764	variations	_	_
4-46	764-765	/	_	_
4-47	765-772	base-en	_	_
4-48	772-773	/	_	_
4-49	773-781	versions	_	_
4-50	781-782	/	_	_
4-51	782-783	2	_	_
4-52	783-784	"	_	_
4-53	785-792	encoder	_	_
4-54	793-794	=	_	_
4-55	795-809	hub.KerasLayer	_	_
4-55	799-804	Keras	_	_
4-56	809-810	(	_	_
4-57	810-817	hub\_url	_	_
4-58	817-818	,	_	_
4-59	819-828	signature	_	_
4-60	828-829	=	_	_
4-61	829-830	"	_	_
4-62	830-845	serving\_default	_	_
4-63	845-846	"	_	_
4-64	846-847	,	_	_
4-65	848-873	signature\_outputs\_as\_dict	_	_
4-66	873-874	=	_	_
4-67	874-878	True	_	_
4-68	878-879	)	_	_
4-69	881-882	#	_	_
4-70	883-889	Sample	_	_
4-71	890-895	texts	_	_
4-72	896-898	to	_	_
4-73	899-905	encode	_	_
4-74	905-906	.	_	_
4-75	907-919	sample\_texts	_	_
4-76	920-921	=	_	_
4-77	922-933	tf.constant	_	_
4-78	933-934	(	_	_
4-79	934-935	\[	_	_
4-80	935-936	"	_	_
4-81	936-939	dog	_	_
4-82	939-940	"	_	_
4-83	940-941	,	_	_
4-84	942-943	"	_	_
4-85	943-950	Puppies	_	_
4-86	951-954	are	_	_
4-87	955-959	nice	_	_
4-88	959-960	.	_	_
4-89	960-961	"	_	_
4-90	961-962	,	_	_
4-91	963-964	"	_	_
4-92	964-965	I	_	_
4-93	966-971	enjoy	_	_
4-94	972-978	taking	_	_
4-95	979-983	long	_	_
4-96	984-989	walks	_	_
4-97	990-995	along	_	_
4-98	996-999	the	_	_
4-99	1000-1005	beach	_	_
4-100	1006-1010	with	_	_
4-101	1011-1013	my	_	_
4-102	1014-1017	dog	_	_
4-103	1017-1018	.	_	_
4-104	1018-1019	"	_	_
4-105	1019-1020	\]	_	_
4-106	1020-1021	)	_	_
4-107	1022-1035	sample\_embeds	_	_
4-108	1036-1037	=	_	_
4-109	1038-1045	encoder	_	_
4-110	1045-1046	(	_	_
4-111	1046-1058	sample\_texts	_	_
4-112	1058-1059	)	_	_
4-113	1061-1062	#	_	_
4-114	1063-1067	This	_	_
4-115	1068-1075	returns	_	_
4-116	1076-1087	token-level	_	_
4-117	1088-1103	representations	_	_
4-118	1104-1108	from	_	_
4-119	1109-1112	XTR	_	_
4-120	1112-1113	.	_	_
4-121	1114-1123	encodings	_	_
4-122	1124-1125	=	*[148]	PROGLANG[148]
4-123	1126-1139	sample\_embeds	*[148]	PROGLANG[148]
4-124	1139-1140	\[	*[148]	PROGLANG[148]
4-125	1140-1141	"	*[148]	PROGLANG[148]
4-126	1141-1150	encodings	*[148]	PROGLANG[148]
4-127	1150-1151	"	*[148]	PROGLANG[148]
4-128	1151-1152	\]	*[148]	PROGLANG[148]
4-129	1152-1153	.	*[148]	PROGLANG[148]
4-130	1153-1158	numpy	*[148]	PROGLANG[148]
4-131	1158-1159	(	*[148]	PROGLANG[148]
4-132	1159-1160	)	*[148]	PROGLANG[148]
4-133	1161-1165	mask	*[148]	PROGLANG[148]
4-134	1166-1167	=	*[148]	PROGLANG[148]
4-135	1168-1181	sample\_embeds	_	_
4-136	1181-1182	\[	_	_
4-137	1182-1183	"	_	_
4-138	1183-1187	mask	_	_
4-139	1187-1188	"	_	_
4-140	1188-1189	\]	_	_
4-141	1189-1190	.	_	_
4-142	1190-1195	numpy	_	_
4-143	1195-1196	(	_	_
4-144	1196-1197	)	_	_
4-145	1198-1203	print	_	_
4-146	1203-1204	(	_	_
4-147	1204-1215	f"encodings	_	_
4-148	1215-1216	:	_	_
4-149	1217-1218	{	_	_
4-150	1218-1233	encodings.shape	_	_
4-151	1233-1234	}	_	_
4-152	1234-1235	,	_	_
4-153	1236-1240	mask	_	_
4-154	1240-1241	:	_	_
4-155	1242-1243	{	_	_
4-156	1243-1253	mask.shape	_	_
4-157	1253-1254	}	_	_
4-158	1254-1255	"	_	_
4-159	1255-1256	)	_	_
4-160	1257-1258	`	_	_
4-161	1258-1259	`	_	_
4-162	1259-1260	`	_	_
4-163	1262-1263	\[	_	_
4-164	1263-1264	!	_	_

#Text=\[Open In Colab\](https://colab.research.google.com/assets/colab-badge.svg)\](https://colab.research.google.com/github/google-deepmind/xtr/blob/main/xtr\_evaluation\_on\_beir\_miracl.ipynb)  Please check out our Notebook above, which contains the full inference for running document retrieval with XTR.
5-1	1264-1265	\[	_	_
5-2	1265-1269	Open	_	_
5-3	1270-1272	In	_	_
5-4	1273-1278	Colab	_	_
5-5	1278-1279	\]	_	_
5-6	1279-1280	(	_	_
5-7	1280-1285	https	_	_
5-8	1285-1286	:	_	_
5-9	1286-1287	/	_	_
5-10	1287-1288	/	_	_
5-11	1288-1313	colab.research.google.com	_	_
5-11	1288-1293	colab	*[142]	LICENSE[142]
5-12	1313-1314	/	*[142]	LICENSE[142]
5-13	1314-1320	assets	*[142]	LICENSE[142]
5-14	1320-1321	/	*[142]	LICENSE[142]
5-15	1321-1336	colab-badge.svg	*[142]	LICENSE[142]
5-15	1321-1326	colab	*[142]	LICENSE[142]
5-16	1336-1337	)	*[142]	LICENSE[142]
5-17	1337-1338	\]	*[142]	LICENSE[142]
5-18	1338-1339	(	*[142]	LICENSE[142]
5-19	1339-1344	https	*[142]	LICENSE[142]
5-20	1344-1345	:	*[142]	LICENSE[142]
5-21	1345-1346	/	*[142]	LICENSE[142]
5-22	1346-1347	/	*[142]	LICENSE[142]
5-23	1347-1372	colab.research.google.com	*[142]	LICENSE[142]
5-23	1347-1352	colab	*[142]	LICENSE[142]
5-24	1372-1373	/	*[142]	LICENSE[142]
5-25	1373-1379	github	*[142]	LICENSE[142]
5-26	1379-1380	/	*[142]	LICENSE[142]
5-27	1380-1395	google-deepmind	*[142]	LICENSE[142]
5-28	1395-1396	/	*[142]	LICENSE[142]
5-29	1396-1399	xtr	*[142]	LICENSE[142]
5-30	1399-1400	/	*[142]	LICENSE[142]
5-31	1400-1404	blob	*[142]	LICENSE[142]
5-32	1404-1405	/	*[142]	LICENSE[142]
5-33	1405-1409	main	*[142]	LICENSE[142]
5-34	1409-1410	/	*[142]	LICENSE[142]
5-35	1410-1445	xtr\_evaluation\_on\_beir\_miracl.ipynb	*[142]	LICENSE[142]
5-35	1410-1413	xtr	*[142]	LICENSE[142]
5-36	1445-1446	)	*[142]	LICENSE[142]
5-37	1448-1454	Please	*[142]	LICENSE[142]
5-38	1455-1460	check	*[142]	LICENSE[142]
5-39	1461-1464	out	*[142]	LICENSE[142]
5-40	1465-1468	our	*[142]	LICENSE[142]
5-41	1469-1477	Notebook	*[142]	LICENSE[142]
5-42	1478-1483	above	*[142]	LICENSE[142]
5-43	1483-1484	,	*[142]	LICENSE[142]
5-44	1485-1490	which	*[142]	LICENSE[142]
5-45	1491-1499	contains	*[142]	LICENSE[142]
5-46	1500-1503	the	*[142]	LICENSE[142]
5-47	1504-1508	full	*[142]	LICENSE[142]
5-48	1509-1518	inference	*[142]	LICENSE[142]
5-49	1519-1522	for	*[142]	LICENSE[142]
5-50	1523-1530	running	*[142]	LICENSE[142]
5-51	1531-1539	document	*[142]	LICENSE[142]
5-52	1540-1549	retrieval	*[142]	LICENSE[142]
5-53	1550-1554	with	*[142]	LICENSE[142]
5-54	1555-1558	XTR	*[142]	LICENSE[142]
5-55	1558-1559	.	_	_

#Text=XTR is also available in \[Huggingface\](https://huggingface.co/google/xtr-base-en) thanks to \[Mujeen Sung\](https://github.com/mjeensung).  ## Citing this work  ```bibtex @article{lee2024rethinking,   title={Rethinking the role of token retrieval in multi-vector retrieval},   author={Lee, Jinhyuk and Dai, Zhuyun and Duddu, Sai Meher Karthik and Lei, Tao and Naim, Iftekhar and Chang, Ming-Wei and Zhao, Vincent},   journal={Advances in Neural Information Processing Systems},   volume={36},   year={2024} } ```  ## License and disclaimer  Copyright 2024 DeepMind Technologies Limited  All software is licensed under the Apache License, Version 2.0 (Apache 2.0)\; you may not use this file except in compliance with the Apache 2.0 license.
6-1	1561-1564	XTR	_	_
6-2	1565-1567	is	_	_
6-3	1568-1572	also	_	_
6-4	1573-1582	available	_	_
6-5	1583-1585	in	_	_
6-6	1586-1587	\[	_	_
6-7	1587-1598	Huggingface	_	_
6-8	1598-1599	\]	_	_
6-9	1599-1600	(	_	_
6-10	1600-1605	https	_	_
6-11	1605-1606	:	_	_
6-12	1606-1607	/	_	_
6-13	1607-1608	/	_	_
6-14	1608-1622	huggingface.co	_	_
6-14	1608-1619	huggingface	_	_
6-15	1622-1623	/	_	_
6-16	1623-1629	google	_	_
6-17	1629-1630	/	_	_
6-18	1630-1641	xtr-base-en	_	_
6-18	1630-1633	xtr	_	_
6-19	1641-1642	)	_	_
6-20	1643-1649	thanks	_	_
6-21	1650-1652	to	_	_
6-22	1653-1654	\[	_	_
6-23	1654-1660	Mujeen	_	_
6-24	1661-1665	Sung	_	_
6-25	1665-1666	\]	_	_
6-26	1666-1667	(	_	_
6-27	1667-1672	https	_	_
6-28	1672-1673	:	_	_
6-29	1673-1674	/	_	_
6-30	1674-1675	/	_	_
6-31	1675-1685	github.com	_	_
6-32	1685-1686	/	_	_
6-33	1686-1695	mjeensung	_	_
6-34	1695-1696	)	_	_
6-35	1696-1697	.	_	_
6-36	1699-1700	#	_	_
6-37	1700-1701	#	_	_
6-38	1702-1708	Citing	_	_
6-39	1709-1713	this	_	_
6-40	1714-1718	work	_	_
6-41	1720-1721	`	_	_
6-42	1721-1722	`	*[125]	PUBLICATION[125]
6-43	1722-1723	`	*[125]	PUBLICATION[125]
6-44	1723-1729	bibtex	*[125]	PUBLICATION[125]
6-45	1730-1731	@	*[125]	PUBLICATION[125]
6-46	1731-1738	article	*[125]	PUBLICATION[125]
6-47	1738-1739	{	*[125]	PUBLICATION[125]
6-48	1739-1756	lee2024rethinking	*[125]	PUBLICATION[125]
6-49	1756-1757	,	*[125]	PUBLICATION[125]
6-50	1760-1765	title	*[125]	PUBLICATION[125]
6-51	1765-1766	=	*[125]	PUBLICATION[125]
6-52	1766-1767	{	*[125]	PUBLICATION[125]
6-53	1767-1777	Rethinking	*[125]	PUBLICATION[125]
6-54	1778-1781	the	*[125]	PUBLICATION[125]
6-55	1782-1786	role	*[125]	PUBLICATION[125]
6-56	1787-1789	of	*[125]	PUBLICATION[125]
6-57	1790-1795	token	*[125]	PUBLICATION[125]
6-58	1796-1805	retrieval	*[125]	PUBLICATION[125]
6-59	1806-1808	in	*[125]	PUBLICATION[125]
6-60	1809-1821	multi-vector	*[125]	PUBLICATION[125]
6-61	1822-1831	retrieval	*[125]	PUBLICATION[125]
6-62	1831-1832	}	*[125]	PUBLICATION[125]
6-63	1832-1833	,	*[125]	PUBLICATION[125]
6-64	1836-1842	author	*[125]	PUBLICATION[125]
6-65	1842-1843	=	*[125]	PUBLICATION[125]
6-66	1843-1844	{	*[125]	PUBLICATION[125]
6-67	1844-1847	Lee	*[125]	PUBLICATION[125]
6-68	1847-1848	,	*[125]	PUBLICATION[125]
6-69	1849-1856	Jinhyuk	*[125]	PUBLICATION[125]
6-70	1857-1860	and	*[125]	PUBLICATION[125]
6-71	1861-1864	Dai	*[125]	PUBLICATION[125]
6-72	1864-1865	,	*[125]	PUBLICATION[125]
6-73	1866-1872	Zhuyun	*[125]	PUBLICATION[125]
6-74	1873-1876	and	*[125]	PUBLICATION[125]
6-75	1877-1882	Duddu	*[125]	PUBLICATION[125]
6-76	1882-1883	,	*[125]	PUBLICATION[125]
6-77	1884-1887	Sai	*[125]	PUBLICATION[125]
6-78	1888-1893	Meher	*[125]	PUBLICATION[125]
6-79	1894-1901	Karthik	*[125]	PUBLICATION[125]
6-80	1902-1905	and	*[125]	PUBLICATION[125]
6-81	1906-1909	Lei	*[125]	PUBLICATION[125]
6-82	1909-1910	,	*[125]	PUBLICATION[125]
6-83	1911-1914	Tao	*[125]	PUBLICATION[125]
6-84	1915-1918	and	*[125]	PUBLICATION[125]
6-85	1919-1923	Naim	*[125]	PUBLICATION[125]
6-86	1923-1924	,	*[125]	PUBLICATION[125]
6-87	1925-1933	Iftekhar	*[125]	PUBLICATION[125]
6-88	1934-1937	and	*[125]	PUBLICATION[125]
6-89	1938-1943	Chang	*[125]	PUBLICATION[125]
6-90	1943-1944	,	*[125]	PUBLICATION[125]
6-91	1945-1953	Ming-Wei	*[125]	PUBLICATION[125]
6-92	1954-1957	and	*[125]	PUBLICATION[125]
6-93	1958-1962	Zhao	*[125]	PUBLICATION[125]
6-94	1962-1963	,	*[125]	PUBLICATION[125]
6-95	1964-1971	Vincent	*[125]	PUBLICATION[125]
6-96	1971-1972	}	*[125]	PUBLICATION[125]
6-97	1972-1973	,	*[125]	PUBLICATION[125]
6-98	1976-1983	journal	*[125]	PUBLICATION[125]
6-99	1983-1984	=	*[125]	PUBLICATION[125]
6-100	1984-1985	{	*[125]	PUBLICATION[125]
6-101	1985-1993	Advances	*[125]	PUBLICATION[125]
6-102	1994-1996	in	*[125]	PUBLICATION[125]
6-103	1997-2003	Neural	*[125]	PUBLICATION[125]
6-104	2004-2015	Information	*[125]	PUBLICATION[125]
6-105	2016-2026	Processing	*[125]	PUBLICATION[125]
6-106	2027-2034	Systems	*[125]	PUBLICATION[125]
6-107	2034-2035	}	*[125]	PUBLICATION[125]
6-108	2035-2036	,	*[125]	PUBLICATION[125]
6-109	2039-2045	volume	*[125]	PUBLICATION[125]
6-110	2045-2046	=	*[125]	PUBLICATION[125]
6-111	2046-2047	{	*[125]	PUBLICATION[125]
6-112	2047-2049	36	*[125]	PUBLICATION[125]
6-113	2049-2050	}	*[125]	PUBLICATION[125]
6-114	2050-2051	,	*[125]	PUBLICATION[125]
6-115	2054-2058	year	*[125]	PUBLICATION[125]
6-116	2058-2059	=	*[125]	PUBLICATION[125]
6-117	2059-2060	{	*[125]	PUBLICATION[125]
6-118	2060-2064	2024	*[125]	PUBLICATION[125]
6-119	2064-2065	}	*[125]	PUBLICATION[125]
6-120	2066-2067	}	*[125]	PUBLICATION[125]
6-121	2068-2069	`	*[125]	PUBLICATION[125]
6-122	2069-2070	`	*[125]	PUBLICATION[125]
6-123	2070-2071	`	*[125]	PUBLICATION[125]
6-124	2073-2074	#	*[125]	PUBLICATION[125]
6-125	2074-2075	#	*[125]	PUBLICATION[125]
6-126	2076-2083	License	*[125]	PUBLICATION[125]
6-127	2084-2087	and	*[125]	PUBLICATION[125]
6-128	2088-2098	disclaimer	*[125]	PUBLICATION[125]
6-129	2100-2109	Copyright	*[125]	PUBLICATION[125]
6-130	2110-2114	2024	*[125]	PUBLICATION[125]
6-131	2115-2123	DeepMind	*[125]	PUBLICATION[125]
6-132	2124-2136	Technologies	*[125]	PUBLICATION[125]
6-133	2137-2144	Limited	*[125]	PUBLICATION[125]
6-134	2146-2149	All	*[125]	PUBLICATION[125]
6-135	2150-2158	software	*[125]	PUBLICATION[125]
6-136	2159-2161	is	*[125]	PUBLICATION[125]
6-137	2162-2170	licensed	*[125]	PUBLICATION[125]
6-138	2171-2176	under	*[125]	PUBLICATION[125]
6-139	2177-2180	the	*[125]	PUBLICATION[125]
6-140	2181-2187	Apache	_	_
6-141	2188-2195	License	_	_
6-142	2195-2196	,	_	_
6-143	2197-2204	Version	_	_
6-144	2205-2208	2.0	_	_
6-145	2209-2210	(	_	_
6-146	2210-2216	Apache	_	_
6-147	2217-2220	2.0	_	_
6-148	2220-2221	)	_	_
6-149	2221-2222	\;	_	_
6-150	2223-2226	you	_	_
6-151	2227-2230	may	_	_
6-152	2231-2234	not	_	_
6-153	2235-2238	use	_	_
6-154	2239-2243	this	_	_
6-155	2244-2248	file	_	_
6-156	2249-2255	except	_	_
6-157	2256-2258	in	_	_
6-158	2259-2269	compliance	_	_
6-159	2270-2274	with	_	_
6-160	2275-2278	the	_	_
6-161	2279-2285	Apache	_	_
6-162	2286-2289	2.0	_	_
6-163	2290-2297	license	_	_
6-164	2297-2298	.	_	_

#Text=You may obtain a copy of the Apache 2.0 license at: https://www.apache.org/licenses/LICENSE-2.0  All other materials are licensed under the Creative Commons Attribution 4.0 International License (CC-BY).
7-1	2299-2302	You	_	_
7-2	2303-2306	may	_	_
7-3	2307-2313	obtain	_	_
7-4	2314-2315	a	_	_
7-5	2316-2320	copy	_	_
7-6	2321-2323	of	_	_
7-7	2324-2327	the	_	_
7-8	2328-2334	Apache	_	_
7-9	2335-2338	2.0	_	_
7-10	2339-2346	license	_	_
7-11	2347-2349	at	_	_
7-12	2349-2350	:	_	_
7-13	2351-2356	https	_	_
7-14	2356-2357	:	*[136]	WORKSHOP[136]
7-15	2357-2358	/	*[136]	WORKSHOP[136]
7-16	2358-2359	/	*[136]	WORKSHOP[136]
7-17	2359-2373	www.apache.org	*[136]	WORKSHOP[136]
7-18	2373-2374	/	*[136]	WORKSHOP[136]
7-19	2374-2382	licenses	*[136]	WORKSHOP[136]
7-20	2382-2383	/	*[136]	WORKSHOP[136]
7-21	2383-2390	LICENSE	*[136]	WORKSHOP[136]
7-22	2390-2391	-	*[136]	WORKSHOP[136]
7-23	2391-2394	2.0	*[136]	WORKSHOP[136]
7-24	2396-2399	All	*[136]	WORKSHOP[136]
7-25	2400-2405	other	*[136]	WORKSHOP[136]
7-26	2406-2415	materials	*[136]	WORKSHOP[136]
7-27	2416-2419	are	*[136]	WORKSHOP[136]
7-28	2420-2428	licensed	*[136]	WORKSHOP[136]
7-29	2429-2434	under	*[136]	WORKSHOP[136]
7-30	2435-2438	the	*[136]	WORKSHOP[136]
7-31	2439-2447	Creative	*[136]	WORKSHOP[136]
7-32	2448-2455	Commons	_	_
7-33	2456-2467	Attribution	_	_
7-34	2468-2471	4.0	_	_
7-35	2472-2485	International	_	_
7-36	2486-2493	License	_	_
7-37	2494-2495	(	_	_
7-38	2495-2500	CC-BY	_	_
7-39	2500-2501	)	_	_
7-40	2501-2502	.	_	_

#Text=You may obtain a copy of the CC-BY license at: https://creativecommons.org/licenses/by/4.0/legalcode  Unless required by applicable law or agreed to in writing, all software and materials distributed here under the Apache 2.0 or CC-BY licenses are distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
8-1	2503-2506	You	_	_
8-2	2507-2510	may	_	_
8-3	2511-2517	obtain	_	_
8-4	2518-2519	a	_	_
8-5	2520-2524	copy	_	_
8-6	2525-2527	of	_	_
8-7	2528-2531	the	_	_
8-8	2532-2537	CC-BY	_	_
8-9	2538-2545	license	_	_
8-10	2546-2548	at	_	_
8-11	2548-2549	:	_	_
8-12	2550-2555	https	_	_
8-13	2555-2556	:	_	_
8-14	2556-2557	/	_	_
8-15	2557-2558	/	_	_
8-16	2558-2577	creativecommons.org	_	_
8-17	2577-2578	/	_	_
8-18	2578-2586	licenses	_	_
8-19	2586-2587	/	_	_
8-20	2587-2589	by	_	_
8-21	2589-2590	/	_	_
8-22	2590-2593	4.0	_	_
8-23	2593-2594	/	_	_
8-24	2594-2603	legalcode	_	_
8-25	2605-2611	Unless	_	_
8-26	2612-2620	required	_	_
8-27	2621-2623	by	_	_
8-28	2624-2634	applicable	_	_
8-29	2635-2638	law	_	_
8-30	2639-2641	or	_	_
8-31	2642-2648	agreed	_	_
8-32	2649-2651	to	_	_
8-33	2652-2654	in	_	_
8-34	2655-2662	writing	_	_
8-35	2662-2663	,	_	_
8-36	2664-2667	all	_	_
8-37	2668-2676	software	_	_
8-38	2677-2680	and	_	_
8-39	2681-2690	materials	_	_
8-40	2691-2702	distributed	_	_
8-41	2703-2707	here	_	_
8-42	2708-2713	under	_	_
8-43	2714-2717	the	_	_
8-44	2718-2724	Apache	_	_
8-45	2725-2728	2.0	_	_
8-46	2729-2731	or	_	_
8-47	2732-2737	CC-BY	*[145]	PROJECT[145]
8-48	2738-2746	licenses	*[145]	PROJECT[145]
8-49	2747-2750	are	*[145]	PROJECT[145]
8-50	2751-2762	distributed	*[145]	PROJECT[145]
8-51	2763-2765	on	*[145]	PROJECT[145]
8-52	2766-2768	an	*[145]	PROJECT[145]
8-53	2769-2770	"	*[145]	PROJECT[145]
8-54	2770-2772	AS	*[145]	PROJECT[145]
8-55	2773-2775	IS	*[145]	PROJECT[145]
8-56	2775-2776	"	*[145]	PROJECT[145]
8-57	2777-2782	BASIS	*[145]	PROJECT[145]
8-58	2782-2783	,	*[145]	PROJECT[145]
8-59	2784-2791	WITHOUT	*[145]	PROJECT[145]
8-60	2792-2802	WARRANTIES	*[145]	PROJECT[145]
8-61	2803-2805	OR	*[145]	PROJECT[145]
8-62	2806-2816	CONDITIONS	*[145]	PROJECT[145]
8-63	2817-2819	OF	*[145]	PROJECT[145]
8-64	2820-2823	ANY	*[145]	PROJECT[145]
8-65	2824-2828	KIND	*[145]	PROJECT[145]
8-66	2828-2829	,	*[145]	PROJECT[145]
8-67	2830-2836	either	*[145]	PROJECT[145]
8-68	2837-2844	express	_	_
8-69	2845-2847	or	_	_
8-70	2848-2855	implied	_	_
8-71	2855-2856	.	_	_

#Text=See the licenses for the specific language governing permissions and limitations under those licenses.
9-1	2857-2860	See	_	_
9-2	2861-2864	the	_	_
9-3	2865-2873	licenses	_	_
9-4	2874-2877	for	_	_
9-5	2878-2881	the	_	_
9-6	2882-2890	specific	_	_
9-7	2891-2899	language	*[149]	PROGLANG[149]
9-8	2900-2909	governing	*[149]	PROGLANG[149]
9-9	2910-2921	permissions	*[149]	PROGLANG[149]
9-10	2922-2925	and	_	_
9-11	2926-2937	limitations	_	_
9-12	2938-2943	under	_	_
9-13	2944-2949	those	_	_
9-14	2950-2958	licenses	_	_
9-15	2958-2959	.	_	_

#Text=This is not an official Google product.
10-1	2961-2965	This	_	_
10-2	2966-2968	is	_	_
10-3	2969-2972	not	_	_
10-4	2973-2975	an	_	_
10-5	2976-2984	official	_	_
10-6	2985-2991	Google	*[137]	WORKSHOP[137]
10-7	2992-2999	product	_	_
10-8	2999-3000	.	_	_