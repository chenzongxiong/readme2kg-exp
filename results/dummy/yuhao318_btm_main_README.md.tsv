#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# BTM \*\*Reviving Undersampling for Long-Tailed Learning\*\*  \*\*Authors\*\*: Hao Yu, Yingxiao Du, Jianxin Wu  \[\[`arXiv`\](https://arxiv.org/pdf/2401.16811.pdf)\] \[\[`bibtex`\](#Citation)\]   \*\*Introduction\*\*: This repository provides an implementation for the paper: "\[Reviving Undersampling for Long-Tailed Learning\](https://arxiv.org/pdf/2401.16811.pdf)" based on \[MiSLAS\](https://github.com/dvlab-research/MiSLAS).
1-1	0-1	#	_	_
1-2	2-5	BTM	_	_
1-3	6-7	\*	_	_
1-4	7-8	\*	_	_
1-5	8-16	Reviving	_	_
1-6	17-30	Undersampling	_	_
1-7	31-34	for	_	_
1-8	35-46	Long-Tailed	_	_
1-9	47-55	Learning	_	_
1-10	55-56	\*	_	_
1-11	56-57	\*	_	_
1-12	59-60	\*	_	_
1-13	60-61	\*	_	_
1-14	61-68	Authors	_	_
1-15	68-69	\*	_	_
1-16	69-70	\*	_	_
1-17	70-71	:	_	_
1-18	72-75	Hao	_	_
1-19	76-78	Yu	_	_
1-20	78-79	,	_	_
1-21	80-88	Yingxiao	_	_
1-22	89-91	Du	_	_
1-23	91-92	,	_	_
1-24	93-100	Jianxin	_	_
1-25	101-103	Wu	_	_
1-26	105-106	\[	_	_
1-27	106-107	\[	_	_
1-28	107-108	`	_	_
1-29	108-113	arXiv	_	_
1-30	113-114	`	_	_
1-31	114-115	\]	_	_
1-32	115-116	(	_	_
1-33	116-121	https	_	_
1-34	121-122	:	_	_
1-35	122-123	/	_	_
1-36	123-124	/	_	_
1-37	124-133	arxiv.org	_	_
1-38	133-134	/	_	_
1-39	134-137	pdf	_	_
1-40	137-138	/	_	_
1-41	138-148	2401.16811	_	_
1-42	148-149	.	_	_
1-43	149-152	pdf	_	_
1-44	152-153	)	_	_
1-45	153-154	\]	_	_
1-46	155-156	\[	_	_
1-47	156-157	\[	_	_
1-48	157-158	`	_	_
1-49	158-164	bibtex	_	_
1-50	164-165	`	_	_
1-51	165-166	\]	_	_
1-52	166-167	(	_	_
1-53	167-168	#	_	_
1-54	168-176	Citation	_	_
1-55	176-177	)	_	_
1-56	177-178	\]	_	_
1-57	181-182	\*	_	_
1-58	182-183	\*	_	_
1-59	183-195	Introduction	_	_
1-60	195-196	\*	_	_
1-61	196-197	\*	_	_
1-62	197-198	:	_	_
1-63	199-203	This	_	_
1-64	204-214	repository	_	_
1-65	215-223	provides	_	_
1-66	224-226	an	_	_
1-67	227-241	implementation	_	_
1-68	242-245	for	_	_
1-69	246-249	the	_	_
1-70	250-255	paper	_	_
1-71	255-256	:	_	_
1-72	257-258	"	_	_
1-73	258-259	\[	_	_
1-74	259-267	Reviving	_	_
1-75	268-281	Undersampling	_	_
1-76	282-285	for	_	_
1-77	286-297	Long-Tailed	_	_
1-78	298-306	Learning	_	_
1-79	306-307	\]	*[354]	EVALMETRIC[354]
1-80	307-308	(	*[354]	EVALMETRIC[354]
1-81	308-313	https	*[354]	EVALMETRIC[354]
1-82	313-314	:	*[354]	EVALMETRIC[354]
1-83	314-315	/	*[354]	EVALMETRIC[354]
1-84	315-316	/	*[354]	EVALMETRIC[354]
1-85	316-325	arxiv.org	_	_
1-86	325-326	/	_	_
1-87	326-329	pdf	_	_
1-88	329-330	/	_	_
1-89	330-340	2401.16811	_	_
1-90	340-341	.	_	_
1-91	341-344	pdf	_	_
1-92	344-345	)	_	_
1-93	345-346	"	_	_
1-94	347-352	based	_	_
1-95	353-355	on	_	_
1-96	356-357	\[	_	_
1-97	357-363	MiSLAS	_	_
1-98	363-364	\]	_	_
1-99	364-365	(	_	_
1-100	365-370	https	_	_
1-101	370-371	:	_	_
1-102	371-372	/	_	_
1-103	372-373	/	_	_
1-104	373-383	github.com	_	_
1-105	383-384	/	_	_
1-106	384-398	dvlab-research	_	_
1-107	398-399	/	_	_
1-108	399-405	MiSLAS	_	_
1-109	405-406	)	_	_
1-110	406-407	.	_	_

#Text=\*We aim to enhance the accuracy of the worst-performing categories and utilize the harmonic mean and geometric mean to assess the model's performance.
2-1	408-409	\*	_	_
2-2	409-411	We	_	_
2-3	412-415	aim	_	_
2-4	416-418	to	_	_
2-5	419-426	enhance	_	_
2-6	427-430	the	_	_
2-7	431-439	accuracy	_	_
2-8	440-442	of	_	_
2-9	443-446	the	_	_
2-10	447-463	worst-performing	_	_
2-11	464-474	categories	_	_
2-12	475-478	and	_	_
2-13	479-486	utilize	_	_
2-14	487-490	the	_	_
2-15	491-499	harmonic	_	_
2-16	500-504	mean	_	_
2-17	505-508	and	_	_
2-18	509-518	geometric	_	_
2-19	519-523	mean	_	_
2-20	524-526	to	_	_
2-21	527-533	assess	_	_
2-22	534-537	the	_	_
2-23	538-545	model's	_	_
2-24	546-557	performance	_	_
2-25	557-558	.	_	_

#Text=We revive the balanced undersampling produces a more equitable distribution of accuracy across categories, and devise a straightforward model ensemble strategy, which does not result in any additional overhead and achieves improved harmonic and geometric mean while keeping the average accuracy.\* BTM is a simple, and efficient framework for long-tailed recognition.  ## Installation  \*\*Requirements\*\*  \* Python 3.8 \* torchvision 0.13.0 \* Pytorch 1.12.0  \*\*Dataset Preparation\*\* \* \[ImageNet-LT\](http://image-net.org/index) \* \[iNaturalist 2018\](https://github.com/visipedia/inat\_comp/tree/master/2018) \* \[Places-LT\](http://places2.csail.mit.edu/download.html)  Change the `data\_path` in `config/\*/\*.yaml` accordingly.  ## Training  \*\*Stage-1\*\*:  To get a model of Stage-1, you can directly download from \[MiSLAS\](https://github.com/dvlab-research/MiSLAS), or run:  ``` python train\_stage1.py --cfg .
3-1	559-561	We	_	_
3-2	562-568	revive	_	_
3-3	569-572	the	_	_
3-4	573-581	balanced	_	_
3-5	582-595	undersampling	_	_
3-6	596-604	produces	_	_
3-7	605-606	a	_	_
3-8	607-611	more	_	_
3-9	612-621	equitable	_	_
3-10	622-634	distribution	_	_
3-11	635-637	of	_	_
3-12	638-646	accuracy	_	_
3-13	647-653	across	_	_
3-14	654-664	categories	_	_
3-15	664-665	,	_	_
3-16	666-669	and	_	_
3-17	670-676	devise	_	_
3-18	677-678	a	*[326]	ONTOLOGY[326]
3-19	679-694	straightforward	*[326]	ONTOLOGY[326]
3-20	695-700	model	*[326]	ONTOLOGY[326]
3-21	701-709	ensemble	*[326]	ONTOLOGY[326]
3-22	710-718	strategy	*[326]	ONTOLOGY[326]
3-23	718-719	,	*[326]	ONTOLOGY[326]
3-24	720-725	which	*[326]	ONTOLOGY[326]
3-25	726-730	does	*[326]	ONTOLOGY[326]
3-26	731-734	not	*[326]	ONTOLOGY[326]
3-27	735-741	result	*[326]	ONTOLOGY[326]
3-28	742-744	in	*[326]	ONTOLOGY[326]
3-29	745-748	any	*[326]	ONTOLOGY[326]
3-30	749-759	additional	*[326]	ONTOLOGY[326]
3-31	760-768	overhead	*[326]	ONTOLOGY[326]
3-32	769-772	and	*[326]	ONTOLOGY[326]
3-33	773-781	achieves	*[326]	ONTOLOGY[326]
3-34	782-790	improved	*[326]	ONTOLOGY[326]
3-35	791-799	harmonic	*[326]	ONTOLOGY[326]
3-36	800-803	and	*[326]	ONTOLOGY[326]
3-37	804-813	geometric	*[326]	ONTOLOGY[326]
3-38	814-818	mean	*[326]	ONTOLOGY[326]
3-39	819-824	while	*[326]	ONTOLOGY[326]
3-40	825-832	keeping	*[326]	ONTOLOGY[326]
3-41	833-836	the	*[326]	ONTOLOGY[326]
3-42	837-844	average	*[326]	ONTOLOGY[326]
3-43	845-853	accuracy	*[326]	ONTOLOGY[326]
3-44	853-854	.	*[326]	ONTOLOGY[326]
3-45	854-855	\*	*[326]	ONTOLOGY[326]
3-46	856-859	BTM	*[326]	ONTOLOGY[326]
3-47	860-862	is	*[326]	ONTOLOGY[326]
3-48	863-864	a	*[326]	ONTOLOGY[326]
3-49	865-871	simple	*[326]	ONTOLOGY[326]
3-50	871-872	,	*[326]	ONTOLOGY[326]
3-51	873-876	and	*[326]	ONTOLOGY[326]
3-52	877-886	efficient	*[326]	ONTOLOGY[326]
3-53	887-896	framework	*[326]	ONTOLOGY[326]
3-54	897-900	for	*[326]	ONTOLOGY[326]
3-55	901-912	long-tailed	*[326]	ONTOLOGY[326]
3-56	913-924	recognition	*[326]	ONTOLOGY[326]
3-57	924-925	.	*[326]	ONTOLOGY[326]
3-58	927-928	#	*[326]	ONTOLOGY[326]
3-59	928-929	#	*[326]	ONTOLOGY[326]
3-60	930-942	Installation	*[326]	ONTOLOGY[326]
3-61	944-945	\*	*[326]	ONTOLOGY[326]
3-62	945-946	\*	*[326]	ONTOLOGY[326]
3-63	946-958	Requirements	*[326]	ONTOLOGY[326]
3-64	958-959	\*	*[326]	ONTOLOGY[326]
3-65	959-960	\*	*[326]	ONTOLOGY[326]
3-66	962-963	\*	*[326]	ONTOLOGY[326]
3-67	964-970	Python	*[326]	ONTOLOGY[326]
3-68	971-974	3.8	*[326]	ONTOLOGY[326]
3-69	975-976	\*	*[326]	ONTOLOGY[326]
3-70	977-988	torchvision	*[326]	ONTOLOGY[326]
3-71	989-995	0.13.0	*[326]	ONTOLOGY[326]
3-72	996-997	\*	*[326]	ONTOLOGY[326]
3-73	998-1005	Pytorch	*[326]	ONTOLOGY[326]
3-74	1006-1012	1.12.0	*[326]	ONTOLOGY[326]
3-75	1014-1015	\*	*[326]	ONTOLOGY[326]
3-76	1015-1016	\*	*[326]	ONTOLOGY[326]
3-77	1016-1023	Dataset	*[326]	ONTOLOGY[326]
3-78	1024-1035	Preparation	*[326]	ONTOLOGY[326]
3-79	1035-1036	\*	*[326]	ONTOLOGY[326]
3-80	1036-1037	\*	*[326]	ONTOLOGY[326]
3-81	1038-1039	\*	*[326]	ONTOLOGY[326]
3-82	1040-1041	\[	*[326]	ONTOLOGY[326]
3-83	1041-1052	ImageNet-LT	*[326]	ONTOLOGY[326]
3-84	1052-1053	\]	*[326]	ONTOLOGY[326]
3-85	1053-1054	(	*[326]	ONTOLOGY[326]
3-86	1054-1058	http	*[326]	ONTOLOGY[326]
3-87	1058-1059	:	*[326]	ONTOLOGY[326]
3-88	1059-1060	/	*[326]	ONTOLOGY[326]
3-89	1060-1061	/	*[326]	ONTOLOGY[326]
3-90	1061-1074	image-net.org	*[326]	ONTOLOGY[326]
3-91	1074-1075	/	*[326]	ONTOLOGY[326]
3-92	1075-1080	index	*[326]	ONTOLOGY[326]
3-93	1080-1081	)	*[326]	ONTOLOGY[326]
3-94	1082-1083	\*	*[326]	ONTOLOGY[326]
3-95	1084-1085	\[	*[326]	ONTOLOGY[326]
3-96	1085-1096	iNaturalist	*[326]	ONTOLOGY[326]
3-97	1097-1101	2018	*[326]	ONTOLOGY[326]
3-98	1101-1102	\]	*[326]	ONTOLOGY[326]
3-99	1102-1103	(	*[326]	ONTOLOGY[326]
3-100	1103-1108	https	*[326]	ONTOLOGY[326]
3-101	1108-1109	:	*[326]	ONTOLOGY[326]
3-102	1109-1110	/	*[326]	ONTOLOGY[326]
3-103	1110-1111	/	*[326]	ONTOLOGY[326]
3-104	1111-1121	github.com	*[326]	ONTOLOGY[326]
3-105	1121-1122	/	*[326]	ONTOLOGY[326]
3-106	1122-1131	visipedia	*[326]	ONTOLOGY[326]
3-107	1131-1132	/	*[326]	ONTOLOGY[326]
3-108	1132-1141	inat\_comp	*[326]	ONTOLOGY[326]
3-109	1141-1142	/	*[326]	ONTOLOGY[326]
3-110	1142-1146	tree	*[326]	ONTOLOGY[326]
3-111	1146-1147	/	*[326]	ONTOLOGY[326]
3-112	1147-1153	master	*[326]	ONTOLOGY[326]
3-113	1153-1154	/	*[326]	ONTOLOGY[326]
3-114	1154-1158	2018	*[326]	ONTOLOGY[326]
3-115	1158-1159	)	*[326]	ONTOLOGY[326]
3-116	1160-1161	\*	*[326]	ONTOLOGY[326]
3-117	1162-1163	\[	*[326]	ONTOLOGY[326]
3-118	1163-1172	Places-LT	*[326]	ONTOLOGY[326]
3-119	1172-1173	\]	*[326]	ONTOLOGY[326]
3-120	1173-1174	(	*[326]	ONTOLOGY[326]
3-121	1174-1178	http	*[326]	ONTOLOGY[326]
3-122	1178-1179	:	*[326]	ONTOLOGY[326]
3-123	1179-1180	/	*[326]	ONTOLOGY[326]
3-124	1180-1181	/	*[326]	ONTOLOGY[326]
3-125	1181-1188	places2	*[326]	ONTOLOGY[326]
3-126	1188-1189	.	*[326]	ONTOLOGY[326]
3-127	1189-1202	csail.mit.edu	*[326]	ONTOLOGY[326]
3-128	1202-1203	/	*[326]	ONTOLOGY[326]
3-129	1203-1216	download.html	*[326]	ONTOLOGY[326]
3-130	1216-1217	)	*[326]	ONTOLOGY[326]
3-131	1219-1225	Change	*[326]	ONTOLOGY[326]
3-132	1226-1229	the	*[326]	ONTOLOGY[326]
3-133	1230-1231	`	*[326]	ONTOLOGY[326]
3-134	1231-1240	data\_path	*[326]	ONTOLOGY[326]
3-135	1240-1241	`	*[326]	ONTOLOGY[326]
3-136	1242-1244	in	*[326]	ONTOLOGY[326]
3-137	1245-1246	`	*[326]	ONTOLOGY[326]
3-138	1246-1252	config	*[326]	ONTOLOGY[326]
3-139	1252-1253	/	*[326]	ONTOLOGY[326]
3-140	1253-1254	\*	*[326]	ONTOLOGY[326]
3-141	1254-1255	/	*[326]	ONTOLOGY[326]
3-142	1255-1256	\*	*[326]	ONTOLOGY[326]
3-143	1256-1257	.	*[326]	ONTOLOGY[326]
3-144	1257-1261	yaml	*[326]	ONTOLOGY[326]
3-145	1261-1262	`	*[326]	ONTOLOGY[326]
3-146	1263-1274	accordingly	*[326]	ONTOLOGY[326]
3-147	1274-1275	.	*[326]	ONTOLOGY[326]
3-148	1277-1278	#	*[326]	ONTOLOGY[326]
3-149	1278-1279	#	*[326]	ONTOLOGY[326]
3-150	1280-1288	Training	*[326]	ONTOLOGY[326]
3-151	1290-1291	\*	*[326]	ONTOLOGY[326]
3-152	1291-1292	\*	*[326]	ONTOLOGY[326]
3-153	1292-1297	Stage	*[326]	ONTOLOGY[326]
3-154	1297-1298	-	*[326]	ONTOLOGY[326]
3-155	1298-1299	1	*[326]	ONTOLOGY[326]
3-156	1299-1300	\*	*[326]	ONTOLOGY[326]
3-157	1300-1301	\*	*[326]	ONTOLOGY[326]
3-158	1301-1302	:	*[326]	ONTOLOGY[326]
3-159	1304-1306	To	*[326]	ONTOLOGY[326]
3-160	1307-1310	get	*[326]	ONTOLOGY[326]
3-161	1311-1312	a	_	_
3-162	1313-1318	model	_	_
3-163	1319-1321	of	_	_
3-164	1322-1327	Stage	_	_
3-165	1327-1328	-	_	_
3-166	1328-1329	1	_	_
3-167	1329-1330	,	_	_
3-168	1331-1334	you	_	_
3-169	1335-1338	can	_	_
3-170	1339-1347	directly	_	_
3-171	1348-1356	download	_	_
3-172	1357-1361	from	_	_
3-173	1362-1363	\[	_	_
3-174	1363-1369	MiSLAS	_	_
3-175	1369-1370	\]	_	_
3-176	1370-1371	(	_	_
3-177	1371-1376	https	_	_
3-178	1376-1377	:	_	_
3-179	1377-1378	/	_	_
3-180	1378-1379	/	_	_
3-181	1379-1389	github.com	_	_
3-182	1389-1390	/	_	_
3-183	1390-1404	dvlab-research	_	_
3-184	1404-1405	/	_	_
3-185	1405-1411	MiSLAS	_	_
3-186	1411-1412	)	_	_
3-187	1412-1413	,	_	_
3-188	1414-1416	or	_	_
3-189	1417-1420	run	_	_
3-190	1420-1421	:	_	_
3-191	1423-1424	`	_	_
3-192	1424-1425	`	_	_
3-193	1425-1426	`	_	_
3-194	1427-1433	python	_	_
3-195	1434-1446	train\_stage1	_	_
3-196	1446-1447	.	_	_
3-197	1447-1449	py	_	_
3-198	1450-1451	-	_	_
3-199	1451-1452	-	_	_
3-200	1452-1455	cfg	_	_
3-201	1456-1457	.	_	_

#Text=/config/DATASETNAME/DATASETNAME\_ARCH\_stage1\_mixup.yaml ```  `DATASETNAME` can be selected from `imagenet`, `ina2018`, and `places`.
4-1	1457-1458	/	_	_
4-2	1458-1464	config	_	_
4-3	1464-1465	/	_	_
4-4	1465-1476	DATASETNAME	_	_
4-5	1476-1477	/	_	_
4-6	1477-1500	DATASETNAME\_ARCH\_stage1	_	_
4-7	1500-1501	\_	*[355]	EVALMETRIC[355]
4-8	1501-1511	mixup.yaml	*[355]	EVALMETRIC[355]
4-9	1512-1513	`	*[355]	EVALMETRIC[355]
4-10	1513-1514	`	*[355]	EVALMETRIC[355]
4-11	1514-1515	`	*[355]	EVALMETRIC[355]
4-12	1517-1518	`	*[355]	EVALMETRIC[355]
4-13	1518-1529	DATASETNAME	*[355]	EVALMETRIC[355]
4-14	1529-1530	`	*[355]	EVALMETRIC[355]
4-15	1531-1534	can	*[355]	EVALMETRIC[355]
4-16	1535-1537	be	*[355]	EVALMETRIC[355]
4-17	1538-1546	selected	*[355]	EVALMETRIC[355]
4-18	1547-1551	from	_	_
4-19	1552-1553	`	_	_
4-20	1553-1561	imagenet	_	_
4-21	1561-1562	`	_	_
4-22	1562-1563	,	_	_
4-23	1564-1565	`	_	_
4-24	1565-1572	ina2018	_	_
4-25	1572-1573	`	_	_
4-26	1573-1574	,	_	_
4-27	1575-1578	and	_	_
4-28	1579-1580	`	_	_
4-29	1580-1586	places	_	_
4-30	1586-1587	`	_	_
4-31	1587-1588	.	_	_

#Text=`ARCH` can be `resnet50/101/152` for `imagenet`, `resnet50` for `ina2018`, and `resnet152` for `places`, respectively.
5-1	1590-1591	`	_	_
5-2	1591-1595	ARCH	_	_
5-3	1595-1596	`	_	_
5-4	1597-1600	can	_	_
5-5	1601-1603	be	_	_
5-6	1604-1605	`	_	_
5-7	1605-1613	resnet50	_	_
5-8	1613-1614	/	*[320]	PUBLICATION[320]
5-9	1614-1617	101	*[320]	PUBLICATION[320]
5-10	1617-1618	/	*[320]	PUBLICATION[320]
5-11	1618-1621	152	*[320]	PUBLICATION[320]
5-12	1621-1622	`	*[320]	PUBLICATION[320]
5-13	1623-1626	for	*[320]	PUBLICATION[320]
5-14	1627-1628	`	*[320]	PUBLICATION[320]
5-15	1628-1636	imagenet	*[320]	PUBLICATION[320]
5-16	1636-1637	`	*[320]	PUBLICATION[320]
5-17	1637-1638	,	*[320]	PUBLICATION[320]
5-18	1639-1640	`	*[320]	PUBLICATION[320]
5-19	1640-1648	resnet50	*[320]	PUBLICATION[320]
5-20	1648-1649	`	*[320]	PUBLICATION[320]
5-21	1650-1653	for	*[320]	PUBLICATION[320]
5-22	1654-1655	`	*[320]	PUBLICATION[320]
5-23	1655-1662	ina2018	*[320]	PUBLICATION[320]
5-24	1662-1663	`	*[320]	PUBLICATION[320]
5-25	1663-1664	,	*[320]	PUBLICATION[320]
5-26	1665-1668	and	*[320]	PUBLICATION[320]
5-27	1669-1670	`	*[320]	PUBLICATION[320]
5-28	1670-1679	resnet152	*[320]	PUBLICATION[320]
5-29	1679-1680	`	*[320]	PUBLICATION[320]
5-30	1681-1684	for	*[320]	PUBLICATION[320]
5-31	1685-1686	`	*[320]	PUBLICATION[320]
5-32	1686-1692	places	*[320]	PUBLICATION[320]
5-33	1692-1693	`	*[320]	PUBLICATION[320]
5-34	1693-1694	,	*[320]	PUBLICATION[320]
5-35	1695-1707	respectively	_	_
5-36	1707-1708	.	_	_

#Text=\*\*BTM\*\*:  To training a model with undersamping, run: ``` python train\_stage1\_bl\_10\_classifier.py --cfg .
6-1	1710-1711	\*	_	_
6-2	1711-1712	\*	_	_
6-3	1712-1715	BTM	_	_
6-4	1715-1716	\*	_	_
6-5	1716-1717	\*	_	_
6-6	1717-1718	:	_	_
6-7	1720-1722	To	_	_
6-8	1723-1731	training	_	_
6-9	1732-1733	a	_	_
6-10	1734-1739	model	_	_
6-11	1740-1744	with	_	_
6-12	1745-1757	undersamping	_	_
6-13	1757-1758	,	_	_
6-14	1759-1762	run	_	_
6-15	1762-1763	:	_	_
6-16	1764-1765	`	_	_
6-17	1765-1766	`	_	_
6-18	1766-1767	`	_	_
6-19	1768-1774	python	_	_
6-20	1775-1787	train\_stage1	_	_
6-21	1787-1788	\_	_	_
6-22	1788-1790	bl	_	_
6-23	1790-1791	\_	_	_
6-24	1791-1793	10	_	_
6-25	1793-1794	\_	_	_
6-26	1794-1807	classifier.py	_	_
6-27	1808-1809	-	_	_
6-28	1809-1810	-	_	_
6-29	1810-1813	cfg	_	_
6-30	1814-1815	.	_	_

#Text=/config/DATASETNAME/DATASETNAME\_ARCH\_stage1\_mixup\_bl\_10\_calssifier.yaml ```  Modify Line221 `train\_loader = dataset.bl\_train\_10\_0\_instance` to `bl\_train\_10\_1\_instance`, `bl\_train\_10\_2\_instance` etc. for getting different balance-training models.
7-1	1815-1816	/	_	_
7-2	1816-1822	config	_	_
7-3	1822-1823	/	_	_
7-4	1823-1834	DATASETNAME	_	_
7-5	1834-1835	/	*[350]	LICENSE[350]
7-6	1835-1858	DATASETNAME\_ARCH\_stage1	*[350]	LICENSE[350]
7-7	1858-1859	\_	*[350]	LICENSE[350]
7-8	1859-1867	mixup\_bl	*[350]	LICENSE[350]
7-9	1867-1868	\_	*[350]	LICENSE[350]
7-10	1868-1870	10	*[350]	LICENSE[350]
7-11	1870-1871	\_	*[350]	LICENSE[350]
7-12	1871-1886	calssifier.yaml	*[350]	LICENSE[350]
7-13	1887-1888	`	*[350]	LICENSE[350]
7-14	1888-1889	`	*[350]	LICENSE[350]
7-15	1889-1890	`	*[350]	LICENSE[350]
7-16	1892-1898	Modify	*[350]	LICENSE[350]
7-17	1899-1906	Line221	*[350]	LICENSE[350]
7-18	1907-1908	`	*[350]	LICENSE[350]
7-19	1908-1920	train\_loader	*[350]	LICENSE[350]
7-20	1921-1922	=	*[350]	LICENSE[350]
7-21	1923-1939	dataset.bl\_train	*[350]	LICENSE[350]
7-22	1939-1940	\_	*[350]	LICENSE[350]
7-23	1940-1942	10	*[350]	LICENSE[350]
7-24	1942-1943	\_	*[350]	LICENSE[350]
7-25	1943-1944	0	*[350]	LICENSE[350]
7-26	1944-1945	\_	*[350]	LICENSE[350]
7-27	1945-1953	instance	*[350]	LICENSE[350]
7-28	1953-1954	`	*[350]	LICENSE[350]
7-29	1955-1957	to	*[350]	LICENSE[350]
7-30	1958-1959	`	*[350]	LICENSE[350]
7-31	1959-1967	bl\_train	*[350]	LICENSE[350]
7-32	1967-1968	\_	*[350]	LICENSE[350]
7-33	1968-1970	10	*[350]	LICENSE[350]
7-34	1970-1971	\_	*[350]	LICENSE[350]
7-35	1971-1972	1	*[350]	LICENSE[350]
7-36	1972-1973	\_	*[350]	LICENSE[350]
7-37	1973-1981	instance	*[350]	LICENSE[350]
7-38	1981-1982	`	*[350]	LICENSE[350]
7-39	1982-1983	,	*[350]	LICENSE[350]
7-40	1984-1985	`	*[350]	LICENSE[350]
7-41	1985-1993	bl\_train	*[350]	LICENSE[350]
7-42	1993-1994	\_	*[350]	LICENSE[350]
7-43	1994-1996	10	*[350]	LICENSE[350]
7-44	1996-1997	\_	*[350]	LICENSE[350]
7-45	1997-1998	2	*[350]	LICENSE[350]
7-46	1998-1999	\_	*[350]	LICENSE[350]
7-47	1999-2007	instance	_	_
7-48	2007-2008	`	_	_
7-49	2009-2012	etc	_	_
7-50	2012-2013	.	_	_
7-51	2014-2017	for	_	_
7-52	2018-2025	getting	_	_
7-53	2026-2035	different	_	_
7-54	2036-2052	balance-training	_	_
7-55	2053-2059	models	_	_
7-56	2059-2060	.	_	_

#Text=Then run  ``` python merge.py ```  for getting the fusion model.
8-1	2062-2066	Then	_	_
8-2	2067-2070	run	_	_
8-3	2072-2073	`	_	_
8-4	2073-2074	`	_	_
8-5	2074-2075	`	_	_
8-6	2076-2082	python	_	_
8-7	2083-2091	merge.py	_	_
8-8	2092-2093	`	*[387]	SOFTWARE[387]
8-9	2093-2094	`	*[387]	SOFTWARE[387]
8-10	2094-2095	`	*[387]	SOFTWARE[387]
8-11	2097-2100	for	*[387]	SOFTWARE[387]
8-12	2101-2108	getting	_	_
8-13	2109-2112	the	_	_
8-14	2113-2119	fusion	_	_
8-15	2120-2125	model	_	_
8-16	2125-2126	.	_	_

#Text=Modify Line19-28 to the real model checkpoint path.
9-1	2127-2133	Modify	_	_
9-2	2134-2140	Line19	_	_
9-3	2140-2141	-	_	_
9-4	2141-2143	28	_	_
9-5	2144-2146	to	_	_
9-6	2147-2150	the	_	_
9-7	2151-2155	real	_	_
9-8	2156-2161	model	*[327]	ONTOLOGY[327]
9-9	2162-2172	checkpoint	*[327]	ONTOLOGY[327]
9-10	2173-2177	path	_	_
9-11	2177-2178	.	_	_

#Text=\*\*Stage-2\*\*:  To train a model for Stage-2, run:  ``` python train\_stage2.py --cfg .
10-1	2182-2183	\*	_	_
10-2	2183-2184	\*	_	_
10-3	2184-2189	Stage	_	_
10-4	2189-2190	-	_	_
10-5	2190-2191	2	_	_
10-6	2191-2192	\*	_	_
10-7	2192-2193	\*	_	_
10-8	2193-2194	:	_	_
10-9	2196-2198	To	_	_
10-10	2199-2204	train	_	_
10-11	2205-2206	a	_	_
10-12	2207-2212	model	_	_
10-13	2213-2216	for	_	_
10-14	2217-2222	Stage	_	_
10-15	2222-2223	-	_	_
10-16	2223-2224	2	_	_
10-17	2224-2225	,	_	_
10-18	2226-2229	run	_	_
10-19	2229-2230	:	_	_
10-20	2232-2233	`	_	_
10-21	2233-2234	`	_	_
10-22	2234-2235	`	_	_
10-23	2236-2242	python	_	_
10-24	2243-2255	train\_stage2	_	_
10-25	2255-2256	.	_	_
10-26	2256-2258	py	_	_
10-27	2259-2260	-	_	_
10-28	2260-2261	-	*[351]	LICENSE[351]
10-29	2261-2264	cfg	*[351]	LICENSE[351]
10-30	2265-2266	.	_	_

#Text=/config/DATASETNAME/DATASETNAME\_ARCH\_stage2\_mislas.yaml resume /path/to/checkpoint/BTM ```  The saved folder (including logs and checkpoints) is organized as follows. ``` MiSLAS ├── saved │   ├── modelname\_date │   │   ├── ckps │   │   │   ├── current.pth.tar │   │   │   └── model\_best.pth.tar │   │   └── logs │   │       └── modelname.txt │   ...    ``` ## Evaluation  To evaluate a trained model, run:  ``` python eval.py --cfg .
11-1	2266-2267	/	_	_
11-2	2267-2273	config	_	_
11-3	2273-2274	/	_	_
11-4	2274-2285	DATASETNAME	_	_
11-5	2285-2286	/	_	_
11-6	2286-2309	DATASETNAME\_ARCH\_stage2	_	_
11-7	2309-2310	\_	_	_
11-8	2310-2321	mislas.yaml	_	_
11-9	2322-2328	resume	_	_
11-10	2329-2330	/	_	_
11-11	2330-2334	path	_	_
11-12	2334-2335	/	_	_
11-13	2335-2337	to	_	_
11-14	2337-2338	/	_	_
11-15	2338-2348	checkpoint	_	_
11-16	2348-2349	/	*[321]	PUBLICATION[321]
11-17	2349-2352	BTM	*[321]	PUBLICATION[321]
11-18	2353-2354	`	*[321]	PUBLICATION[321]
11-19	2354-2355	`	*[321]	PUBLICATION[321]
11-20	2355-2356	`	*[321]	PUBLICATION[321]
11-21	2358-2361	The	*[321]	PUBLICATION[321]
11-22	2362-2367	saved	*[321]	PUBLICATION[321]
11-23	2368-2374	folder	*[321]	PUBLICATION[321]
11-24	2375-2376	(	*[321]	PUBLICATION[321]
11-25	2376-2385	including	*[321]	PUBLICATION[321]
11-26	2386-2390	logs	*[321]	PUBLICATION[321]
11-27	2391-2394	and	*[321]	PUBLICATION[321]
11-28	2395-2406	checkpoints	*[321]	PUBLICATION[321]
11-29	2406-2407	)	*[321]	PUBLICATION[321]
11-30	2408-2410	is	*[321]	PUBLICATION[321]
11-31	2411-2420	organized	*[321]	PUBLICATION[321]
11-32	2421-2423	as	*[321]	PUBLICATION[321]
11-33	2424-2431	follows	*[321]	PUBLICATION[321]
11-34	2431-2432	.	*[321]	PUBLICATION[321]
11-35	2433-2434	`	*[321]	PUBLICATION[321]
11-36	2434-2435	`	*[321]	PUBLICATION[321]
11-37	2435-2436	`	*[321]	PUBLICATION[321]
11-38	2437-2443	MiSLAS	*[321]	PUBLICATION[321]
11-39	2444-2445	├	*[321]	PUBLICATION[321]
11-40	2445-2446	─	*[321]	PUBLICATION[321]
11-41	2446-2447	─	*[321]	PUBLICATION[321]
11-42	2448-2453	saved	*[321]	PUBLICATION[321]
11-43	2454-2455	│	*[321]	PUBLICATION[321]
11-44	2458-2459	├	*[321]	PUBLICATION[321]
11-45	2459-2460	─	*[321]	PUBLICATION[321]
11-46	2460-2461	─	*[321]	PUBLICATION[321]
11-47	2462-2476	modelname\_date	*[321]	PUBLICATION[321]
11-48	2477-2478	│	*[321]	PUBLICATION[321]
11-49	2481-2482	│	*[321]	PUBLICATION[321]
11-50	2485-2486	├	*[321]	PUBLICATION[321]
11-51	2486-2487	─	*[321]	PUBLICATION[321]
11-52	2487-2488	─	*[321]	PUBLICATION[321]
11-53	2489-2493	ckps	*[321]	PUBLICATION[321]
11-54	2494-2495	│	*[321]	PUBLICATION[321]
11-55	2498-2499	│	*[321]	PUBLICATION[321]
11-56	2502-2503	│	*[321]	PUBLICATION[321]
11-57	2506-2507	├	*[321]	PUBLICATION[321]
11-58	2507-2508	─	*[321]	PUBLICATION[321]
11-59	2508-2509	─	*[321]	PUBLICATION[321]
11-60	2510-2525	current.pth.tar	*[321]	PUBLICATION[321]
11-61	2526-2527	│	*[321]	PUBLICATION[321]
11-62	2530-2531	│	*[321]	PUBLICATION[321]
11-63	2534-2535	│	*[321]	PUBLICATION[321]
11-64	2538-2539	└	*[321]	PUBLICATION[321]
11-65	2539-2540	─	*[321]	PUBLICATION[321]
11-66	2540-2541	─	*[321]	PUBLICATION[321]
11-67	2542-2560	model\_best.pth.tar	*[321]	PUBLICATION[321]
11-68	2561-2562	│	*[321]	PUBLICATION[321]
11-69	2565-2566	│	*[321]	PUBLICATION[321]
11-70	2569-2570	└	*[321]	PUBLICATION[321]
11-71	2570-2571	─	*[321]	PUBLICATION[321]
11-72	2571-2572	─	*[321]	PUBLICATION[321]
11-73	2573-2577	logs	*[321]	PUBLICATION[321]
11-74	2578-2579	│	*[321]	PUBLICATION[321]
11-75	2582-2583	│	*[321]	PUBLICATION[321]
11-76	2590-2591	└	*[321]	PUBLICATION[321]
11-77	2591-2592	─	*[321]	PUBLICATION[321]
11-78	2592-2593	─	*[321]	PUBLICATION[321]
11-79	2594-2607	modelname.txt	*[321]	PUBLICATION[321]
11-80	2608-2609	│	*[321]	PUBLICATION[321]
11-81	2612-2613	.	*[321]	PUBLICATION[321]
11-82	2613-2614	.	*[321]	PUBLICATION[321]
11-83	2614-2615	.	*[321]	PUBLICATION[321]
11-84	2619-2620	`	*[321]	PUBLICATION[321]
11-85	2620-2621	`	*[321]	PUBLICATION[321]
11-86	2621-2622	`	*[321]	PUBLICATION[321]
11-87	2623-2624	#	*[321]	PUBLICATION[321]
11-88	2624-2625	#	*[321]	PUBLICATION[321]
11-89	2626-2636	Evaluation	*[321]	PUBLICATION[321]
11-90	2638-2640	To	*[321]	PUBLICATION[321]
11-91	2641-2649	evaluate	*[321]	PUBLICATION[321]
11-92	2650-2651	a	*[321]	PUBLICATION[321]
11-93	2652-2659	trained	*[321]	PUBLICATION[321]
11-94	2660-2665	model	*[321]	PUBLICATION[321]
11-95	2665-2666	,	*[321]	PUBLICATION[321]
11-96	2667-2670	run	*[321]	PUBLICATION[321]
11-97	2670-2671	:	*[321]	PUBLICATION[321]
11-98	2673-2674	`	*[321]	PUBLICATION[321]
11-99	2674-2675	`	*[321]	PUBLICATION[321]
11-100	2675-2676	`	*[321]	PUBLICATION[321]
11-101	2677-2683	python	*[321]	PUBLICATION[321]
11-102	2684-2691	eval.py	*[321]	PUBLICATION[321]
11-103	2692-2693	-	*[321]	PUBLICATION[321]
11-104	2693-2694	-	*[321]	PUBLICATION[321]
11-105	2694-2697	cfg	_	_
11-106	2698-2699	.	_	_

#Text=/config/DATASETNAME/DATASETNAME\_ARCH\_stage1\_mixup.yaml  resume /path/to/checkpoint/stage1 python eval.py --cfg .
12-1	2699-2700	/	_	_
12-2	2700-2706	config	_	_
12-3	2706-2707	/	_	_
12-4	2707-2718	DATASETNAME	_	_
12-5	2718-2719	/	_	_
12-6	2719-2742	DATASETNAME\_ARCH\_stage1	_	_
12-7	2742-2743	\_	_	_
12-8	2743-2753	mixup.yaml	_	_
12-9	2755-2761	resume	_	_
12-10	2762-2763	/	_	_
12-11	2763-2767	path	_	_
12-12	2767-2768	/	_	_
12-13	2768-2770	to	_	_
12-14	2770-2771	/	_	_
12-15	2771-2781	checkpoint	_	_
12-16	2781-2782	/	_	_
12-17	2782-2788	stage1	_	_
12-18	2789-2795	python	_	_
12-19	2796-2803	eval.py	_	_
12-20	2804-2805	-	_	_
12-21	2805-2806	-	*[352]	LICENSE[352]
12-22	2806-2809	cfg	_	_
12-23	2810-2811	.	_	_

#Text=/config/DATASETNAME/DATASETNAME\_ARCH\_stage2\_mislas.yaml resume /path/to/checkpoint/stage2 ```  ## <a name="Citation"></a>Citation  ```bib @article{yu2024reviving,   title={Reviving Undersampling for Long-Tailed Learning},   author={Yu, Hao and Du, Yingxiao and Wu, Jianxin},   journal={arXiv preprint arXiv:2401.16811},   year={2024} } ```  ## Contact  If you have any questions about our work, feel free to contact us through email (Hao Yu: yuh@lamda.nju.edu.cn) or Github issues.
13-1	2811-2812	/	_	_
13-2	2812-2818	config	_	_
13-3	2818-2819	/	_	_
13-4	2819-2830	DATASETNAME	_	_
13-5	2830-2831	/	_	_
13-6	2831-2854	DATASETNAME\_ARCH\_stage2	_	_
13-7	2854-2855	\_	_	_
13-8	2855-2866	mislas.yaml	_	_
13-9	2867-2873	resume	_	_
13-10	2874-2875	/	*[328]	DATASET[328]
13-11	2875-2879	path	*[328]	DATASET[328]
13-12	2879-2880	/	*[328]	DATASET[328]
13-13	2880-2882	to	*[328]	DATASET[328]
13-14	2882-2883	/	*[328]	DATASET[328]
13-15	2883-2893	checkpoint	*[328]	DATASET[328]
13-16	2893-2894	/	*[328]	DATASET[328]
13-17	2894-2900	stage2	*[328]	DATASET[328]
13-18	2901-2902	`	*[328]	DATASET[328]
13-19	2902-2903	`	*[328]	DATASET[328]
13-20	2903-2904	`	*[328]	DATASET[328]
13-21	2906-2907	#	*[328]	DATASET[328]
13-22	2907-2908	#	*[328]	DATASET[328]
13-23	2909-2910	<	*[328]	DATASET[328]
13-24	2910-2911	a	*[328]	DATASET[328]
13-25	2912-2916	name	*[328]	DATASET[328]
13-26	2916-2917	=	*[328]	DATASET[328]
13-27	2917-2918	"	*[328]	DATASET[328]
13-28	2918-2926	Citation	*[328]	DATASET[328]
13-29	2926-2927	"	*[328]	DATASET[328]
13-30	2927-2928	>	*[328]	DATASET[328]
13-31	2928-2929	<	*[328]	DATASET[328]
13-32	2929-2930	/	*[328]	DATASET[328]
13-33	2930-2931	a	*[328]	DATASET[328]
13-34	2931-2932	>	*[328]	DATASET[328]
13-35	2932-2940	Citation	*[328]	DATASET[328]
13-36	2942-2943	`	*[328]	DATASET[328]
13-37	2943-2944	`	*[328]	DATASET[328]
13-38	2944-2945	`	*[328]	DATASET[328]
13-39	2945-2948	bib	*[328]	DATASET[328]
13-40	2949-2950	@	*[328]	DATASET[328]
13-41	2950-2957	article	*[328]	DATASET[328]
13-42	2957-2958	{	*[328]	DATASET[328]
13-43	2958-2972	yu2024reviving	*[328]	DATASET[328]
13-44	2972-2973	,	*[328]	DATASET[328]
13-45	2976-2981	title	*[328]	DATASET[328]
13-46	2981-2982	=	*[328]	DATASET[328]
13-47	2982-2983	{	*[328]	DATASET[328]
13-48	2983-2991	Reviving	*[328]	DATASET[328]
13-49	2992-3005	Undersampling	*[328]	DATASET[328]
13-50	3006-3009	for	*[328]	DATASET[328]
13-51	3010-3021	Long-Tailed	*[328]	DATASET[328]
13-52	3022-3030	Learning	*[328]	DATASET[328]
13-53	3030-3031	}	*[328]	DATASET[328]
13-54	3031-3032	,	*[328]	DATASET[328]
13-55	3035-3041	author	*[328]	DATASET[328]
13-56	3041-3042	=	*[328]	DATASET[328]
13-57	3042-3043	{	*[328]	DATASET[328]
13-58	3043-3045	Yu	*[328]	DATASET[328]
13-59	3045-3046	,	*[328]	DATASET[328]
13-60	3047-3050	Hao	*[328]	DATASET[328]
13-61	3051-3054	and	*[328]	DATASET[328]
13-62	3055-3057	Du	*[328]	DATASET[328]
13-63	3057-3058	,	*[328]	DATASET[328]
13-64	3059-3067	Yingxiao	*[328]	DATASET[328]
13-65	3068-3071	and	*[328]	DATASET[328]
13-66	3072-3074	Wu	*[328]	DATASET[328]
13-67	3074-3075	,	*[328]	DATASET[328]
13-68	3076-3083	Jianxin	*[328]	DATASET[328]
13-69	3083-3084	}	*[328]	DATASET[328]
13-70	3084-3085	,	*[328]	DATASET[328]
13-71	3088-3095	journal	*[328]	DATASET[328]
13-72	3095-3096	=	*[328]	DATASET[328]
13-73	3096-3097	{	*[328]	DATASET[328]
13-74	3097-3102	arXiv	*[328]	DATASET[328]
13-75	3103-3111	preprint	*[328]	DATASET[328]
13-76	3112-3117	arXiv	*[328]	DATASET[328]
13-77	3117-3118	:	*[328]	DATASET[328]
13-78	3118-3128	2401.16811	*[328]	DATASET[328]
13-79	3128-3129	}	*[328]	DATASET[328]
13-80	3129-3130	,	*[328]	DATASET[328]
13-81	3133-3137	year	*[328]	DATASET[328]
13-82	3137-3138	=	*[328]	DATASET[328]
13-83	3138-3139	{	*[328]	DATASET[328]
13-84	3139-3143	2024	*[328]	DATASET[328]
13-85	3143-3144	}	*[328]	DATASET[328]
13-86	3145-3146	}	*[328]	DATASET[328]
13-87	3147-3148	`	*[328]	DATASET[328]
13-88	3148-3149	`	*[328]	DATASET[328]
13-89	3149-3150	`	*[328]	DATASET[328]
13-90	3152-3153	#	*[328]	DATASET[328]
13-91	3153-3154	#	*[328]	DATASET[328]
13-92	3155-3162	Contact	*[328]	DATASET[328]
13-93	3164-3166	If	*[328]	DATASET[328]
13-94	3167-3170	you	*[328]	DATASET[328]
13-95	3171-3175	have	*[328]	DATASET[328]
13-96	3176-3179	any	*[328]	DATASET[328]
13-97	3180-3189	questions	*[328]	DATASET[328]
13-98	3190-3195	about	*[328]	DATASET[328]
13-99	3196-3199	our	*[328]	DATASET[328]
13-100	3200-3204	work	*[328]	DATASET[328]
13-101	3204-3205	,	*[328]	DATASET[328]
13-102	3206-3210	feel	*[328]	DATASET[328]
13-103	3211-3215	free	*[328]	DATASET[328]
13-104	3216-3218	to	*[328]	DATASET[328]
13-105	3219-3226	contact	*[328]	DATASET[328]
13-106	3227-3229	us	*[328]	DATASET[328]
13-107	3230-3237	through	*[328]	DATASET[328]
13-108	3238-3243	email	*[328]	DATASET[328]
13-109	3244-3245	(	*[328]	DATASET[328]
13-110	3245-3248	Hao	*[328]	DATASET[328]
13-111	3249-3251	Yu	*[328]	DATASET[328]
13-112	3251-3252	:	*[328]	DATASET[328]
13-113	3253-3256	yuh	*[328]	DATASET[328]
13-114	3256-3257	@	*[328]	DATASET[328]
13-115	3257-3273	lamda.nju.edu.cn	_	_
13-116	3273-3274	)	_	_
13-117	3275-3277	or	_	_
13-118	3278-3284	Github	_	_
13-119	3285-3291	issues	_	_
13-120	3291-3292	.	_	_