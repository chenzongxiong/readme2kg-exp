#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# üå≥  GRANDE: Gradient-Based Decision Tree Ensembles üå≥   \[!
1-1	0-1	#	_	_
1-2	2-4	üå≥	_	_
1-3	5-11	GRANDE	_	_
1-4	11-12	:	_	_
1-5	13-27	Gradient-Based	_	_
1-6	28-36	Decision	_	_
1-7	37-41	Tree	_	_
1-8	42-51	Ensembles	_	_
1-9	52-54	üå≥	_	_
1-10	56-57	\[	*[23]	DATASET[23]
1-11	57-58	!	_	_

#Text=\[PyPI version\](https://img.shields.io/pypi/v/GRANDE)\](https://pypi.org/project/GRANDE/) \[!
2-1	58-59	\[	_	_
2-2	59-63	PyPI	_	_
2-3	64-71	version	_	_
2-4	71-72	\]	_	_
2-5	72-73	(	_	_
2-6	73-78	https	_	_
2-7	78-79	:	_	_
2-8	79-80	/	_	_
2-9	80-81	/	_	_
2-10	81-95	img.shields.io	_	_
2-11	95-96	/	_	_
2-12	96-100	pypi	_	_
2-13	100-101	/	_	_
2-14	101-102	v	_	_
2-15	102-103	/	_	_
2-16	103-109	GRANDE	_	_
2-17	109-110	)	_	_
2-18	110-111	\]	_	_
2-19	111-112	(	_	_
2-20	112-117	https	_	_
2-21	117-118	:	_	_
2-22	118-119	/	_	_
2-23	119-120	/	_	_
2-24	120-128	pypi.org	_	_
2-25	128-129	/	_	_
2-26	129-136	project	_	_
2-27	136-137	/	_	_
2-28	137-143	GRANDE	_	_
2-29	143-144	/	_	_
2-30	144-145	)	_	_
2-31	146-147	\[	_	_
2-32	147-148	!	_	_

#Text=\[OpenReview\](https://img.shields.io/badge/OpenReview-XEFWBxi075-blue)\](https://openreview.net/forum?
3-1	148-149	\[	_	_
3-2	149-159	OpenReview	_	_
3-3	159-160	\]	_	_
3-4	160-161	(	_	_
3-5	161-166	https	_	_
3-6	166-167	:	_	_
3-7	167-168	/	_	_
3-8	168-169	/	_	_
3-9	169-183	img.shields.io	_	_
3-10	183-184	/	_	_
3-11	184-189	badge	_	_
3-12	189-190	/	_	_
3-13	190-211	OpenReview-XEFWBxi075	_	_
3-14	211-212	-	_	_
3-15	212-216	blue	_	_
3-16	216-217	)	_	_
3-17	217-218	\]	_	_
3-18	218-219	(	_	_
3-19	219-224	https	_	_
3-20	224-225	:	_	_
3-21	225-226	/	_	_
3-22	226-227	/	_	_
3-23	227-241	openreview.net	_	_
3-24	241-242	/	_	_
3-25	242-247	forum	_	_
3-26	247-248	?	_	_

#Text=id=XEFWBxi075) \[!
4-1	248-250	id	_	_
4-2	250-251	=	_	_
4-3	251-261	XEFWBxi075	_	_
4-4	261-262	)	*[18]	DATASET[18]
4-5	263-264	\[	*[18]	DATASET[18]
4-6	264-265	!	_	_

#Text=\[arXiv\](https://img.shields.io/badge/arXiv-2309.17130-b31b1b.svg)\](https://arxiv.org/abs/2309.17130)  üå≥  GRANDE is a novel gradient-based decision tree ensemble method for tabular data!
5-1	265-266	\[	_	_
5-2	266-271	arXiv	_	_
5-3	271-272	\]	_	_
5-4	272-273	(	_	_
5-5	273-278	https	_	_
5-6	278-279	:	_	_
5-7	279-280	/	_	_
5-8	280-281	/	_	_
5-9	281-295	img.shields.io	_	_
5-10	295-296	/	_	_
5-11	296-301	badge	_	_
5-12	301-302	/	_	_
5-13	302-307	arXiv	_	_
5-14	307-308	-	_	_
5-15	308-318	2309.17130	_	_
5-16	318-319	-	_	_
5-17	319-329	b31b1b.svg	_	_
5-18	329-330	)	_	_
5-19	330-331	\]	_	_
5-20	331-332	(	_	_
5-21	332-337	https	_	_
5-22	337-338	:	*[10]	PUBLICATION[10]
5-23	338-339	/	*[10]	PUBLICATION[10]
5-24	339-340	/	*[10]	PUBLICATION[10]
5-25	340-349	arxiv.org	*[10]	PUBLICATION[10]
5-26	349-350	/	*[10]	PUBLICATION[10]
5-27	350-353	abs	*[10]	PUBLICATION[10]
5-28	353-354	/	*[10]	PUBLICATION[10]
5-29	354-364	2309.17130	*[10]	PUBLICATION[10]
5-30	364-365	)	*[10]	PUBLICATION[10]
5-31	367-369	üå≥	*[10]	PUBLICATION[10]
5-32	370-376	GRANDE	*[10]	PUBLICATION[10]
5-33	377-379	is	*[10]	PUBLICATION[10]
5-34	380-381	a	*[10]	PUBLICATION[10]
5-35	382-387	novel	_	_
5-36	388-402	gradient-based	_	_
5-37	403-411	decision	_	_
5-38	412-416	tree	_	_
5-39	417-425	ensemble	_	_
5-40	426-432	method	_	_
5-41	433-436	for	_	_
5-42	437-444	tabular	_	_
5-43	445-449	data	_	_
5-44	449-450	!	_	_

#Text=<div align="center">  <img src="figures/grande.jpg" alt="GRANDE Overview" width="50%"/>  <p><strong>Figure 1: Overview GRANDE.
6-1	452-453	<	_	_
6-2	453-456	div	_	_
6-3	457-462	align	_	_
6-4	462-463	=	_	_
6-5	463-464	"	_	_
6-6	464-470	center	_	_
6-7	470-471	"	*[15]	SOFTWARE[15]
6-8	471-472	>	*[15]	SOFTWARE[15]
6-9	474-475	<	*[15]	SOFTWARE[15]
6-10	475-478	img	*[15]	SOFTWARE[15]
6-11	479-482	src	*[15]	SOFTWARE[15]
6-12	482-483	=	*[15]	SOFTWARE[15]
6-13	483-484	"	*[15]	SOFTWARE[15]
6-14	484-491	figures	*[15]	SOFTWARE[15]
6-15	491-492	/	*[15]	SOFTWARE[15]
6-16	492-502	grande.jpg	*[15]	SOFTWARE[15]
6-17	502-503	"	*[15]	SOFTWARE[15]
6-18	504-507	alt	*[15]	SOFTWARE[15]
6-19	507-508	=	*[15]	SOFTWARE[15]
6-20	508-509	"	*[15]	SOFTWARE[15]
6-21	509-515	GRANDE	*[15]	SOFTWARE[15]
6-22	516-524	Overview	_	_
6-23	524-525	"	_	_
6-24	526-531	width	_	_
6-25	531-532	=	_	_
6-26	532-533	"	_	_
6-27	533-536	50%	_	_
6-28	536-537	"	_	_
6-29	537-538	/	_	_
6-30	538-539	>	_	_
6-31	541-542	<	_	_
6-32	542-543	p	_	_
6-33	543-544	>	_	_
6-34	544-545	<	_	_
6-35	545-551	strong	_	_
6-36	551-552	>	_	_
6-37	552-558	Figure	_	_
6-38	559-560	1	_	_
6-39	560-561	:	_	_
6-40	562-570	Overview	_	_
6-41	571-577	GRANDE	_	_
6-42	577-578	.	_	_

#Text=</strong> GRANDE is a gradient-based decision tree ensemble that utilizes dynamic, instance-wise leaf weights.
7-1	578-579	<	_	_
7-2	579-580	/	*[15]	CONFERENCE[15]
7-3	580-586	strong	*[15]	CONFERENCE[15]
7-4	586-587	>	*[15]	CONFERENCE[15]
7-5	588-594	GRANDE	*[15]	CONFERENCE[15]
7-6	595-597	is	*[15]	CONFERENCE[15]
7-7	598-599	a	*[15]	CONFERENCE[15]
7-8	600-614	gradient-based	*[15]	CONFERENCE[15]
7-9	615-623	decision	*[15]	CONFERENCE[15]
7-10	624-628	tree	*[15]	CONFERENCE[15]
7-11	629-637	ensemble	*[15]	CONFERENCE[15]
7-12	638-642	that	*[15]	CONFERENCE[15]
7-13	643-651	utilizes	*[15]	CONFERENCE[15]
7-14	652-659	dynamic	*[15]	CONFERENCE[15]
7-15	659-660	,	*[15]	CONFERENCE[15]
7-16	661-674	instance-wise	_	_
7-17	675-679	leaf	_	_
7-18	680-687	weights	_	_
7-19	687-688	.	_	_

#Text=Each estimator is weighted based on leaf weights that are calculated individually for each input.
8-1	689-693	Each	_	_
8-2	694-703	estimator	_	_
8-3	704-706	is	_	_
8-4	707-715	weighted	_	_
8-5	716-721	based	_	_
8-6	722-724	on	_	_
8-7	725-729	leaf	_	_
8-8	730-737	weights	_	_
8-9	738-742	that	_	_
8-10	743-746	are	_	_
8-11	747-757	calculated	_	_
8-12	758-770	individually	_	_
8-13	771-774	for	_	_
8-14	775-779	each	_	_
8-15	780-785	input	_	_
8-16	785-786	.	_	_

#Text=The ensemble's prediction is then obtained as a weighted sum of the individual predictions.
9-1	787-790	The	_	_
9-2	791-801	ensemble's	_	_
9-3	802-812	prediction	*[8]	ONTOLOGY[8]
9-4	813-815	is	*[8]	ONTOLOGY[8]
9-5	816-820	then	*[8]	ONTOLOGY[8]
9-6	821-829	obtained	*[8]	ONTOLOGY[8]
9-7	830-832	as	*[8]	ONTOLOGY[8]
9-8	833-834	a	*[8]	ONTOLOGY[8]
9-9	835-843	weighted	*[8]	ONTOLOGY[8]
9-10	844-847	sum	*[8]	ONTOLOGY[8]
9-11	848-850	of	*[8]	ONTOLOGY[8]
9-12	851-854	the	*[8]	ONTOLOGY[8]
9-13	855-865	individual	*[8]	ONTOLOGY[8]
9-14	866-877	predictions	*[8]	ONTOLOGY[8]
9-15	877-878	.	_	_

#Text=</p>  </div>  üîç  What's new?
10-1	878-879	<	_	_
10-2	879-880	/	_	_
10-3	880-881	p	_	_
10-4	881-882	>	_	_
10-5	884-885	<	_	_
10-6	885-886	/	_	_
10-7	886-889	div	_	_
10-8	889-890	>	*[16]	CONFERENCE[16]
10-9	892-894	üîç	*[16]	CONFERENCE[16]
10-10	895-901	What's	_	_
10-11	902-905	new	_	_
10-12	905-906	?	_	_

#Text=- End-to-end gradient descent for tree ensembles. - Combines inductive bias of hard, axis-aligned splits with the flexibility of a gradient descent optimization. - Advanced instance-wise weighting to learn representations for both simple & complex relations in one model
11-1	907-908	-	_	_
11-2	909-919	End-to-end	_	_
11-3	920-928	gradient	_	_
11-4	929-936	descent	_	_
11-5	937-940	for	*[9]	ONTOLOGY[9]
11-6	941-945	tree	*[9]	ONTOLOGY[9]
11-7	946-955	ensembles	*[9]	ONTOLOGY[9]
11-8	955-956	.	*[9]	ONTOLOGY[9]
11-9	957-958	-	*[9]	ONTOLOGY[9]
11-10	959-967	Combines	*[9]	ONTOLOGY[9]
11-11	968-977	inductive	*[9]	ONTOLOGY[9]
11-12	978-982	bias	*[9]	ONTOLOGY[9]
11-13	983-985	of	*[9]	ONTOLOGY[9]
11-14	986-990	hard	*[9]	ONTOLOGY[9]
11-15	990-991	,	*[9]	ONTOLOGY[9]
11-16	992-1004	axis-aligned	*[9]	ONTOLOGY[9]
11-17	1005-1011	splits	*[9]	ONTOLOGY[9]
11-18	1012-1016	with	*[9]	ONTOLOGY[9]
11-19	1017-1020	the	*[9]	ONTOLOGY[9]
11-20	1021-1032	flexibility	*[9]	ONTOLOGY[9]
11-21	1033-1035	of	*[9]	ONTOLOGY[9]
11-22	1036-1037	a	*[9]	ONTOLOGY[9]
11-23	1038-1046	gradient	*[9]	ONTOLOGY[9]
11-24	1047-1054	descent	*[9]	ONTOLOGY[9]
11-25	1055-1067	optimization	*[9]	ONTOLOGY[9]
11-26	1067-1068	.	*[9]	ONTOLOGY[9]
11-27	1069-1070	-	*[9]	ONTOLOGY[9]
11-28	1071-1079	Advanced	*[9]	ONTOLOGY[9]
11-29	1080-1093	instance-wise	_	_
11-30	1094-1103	weighting	_	_
11-31	1104-1106	to	_	_
11-32	1107-1112	learn	_	_
11-33	1113-1128	representations	_	_
11-34	1129-1132	for	_	_
11-35	1133-1137	both	_	_
11-36	1138-1144	simple	_	_
11-37	1145-1146	&	_	_
11-38	1147-1154	complex	_	_
11-39	1155-1164	relations	_	_
11-40	1165-1167	in	_	_
11-41	1168-1171	one	_	_
11-42	1172-1177	model	_	_

#Text=.
12-1	1177-1178	.	_	_

#Text=üèÜ  Results?
13-1	1180-1182	üèÜ	_	_
13-2	1183-1190	Results	_	_
13-3	1190-1191	?	_	_

#Text=We outperformed leading tree ensemble methods like #XGBoost and #CatBoost on many datasets.
14-1	1192-1194	We	_	_
14-2	1195-1207	outperformed	_	_
14-3	1208-1215	leading	_	_
14-4	1216-1220	tree	_	_
14-5	1221-1229	ensemble	_	_
14-6	1230-1237	methods	_	_
14-7	1238-1242	like	_	_
14-8	1243-1244	#	_	_
14-9	1244-1251	XGBoost	_	_
14-10	1252-1255	and	_	_
14-11	1256-1257	#	_	_
14-12	1257-1265	CatBoost	_	_
14-13	1266-1268	on	_	_
14-14	1269-1273	many	_	_
14-15	1274-1282	datasets	_	_
14-16	1282-1283	.	_	_

#Text=<div align="center">  <img src="figures/results\_hpo.jpg" alt="GRANDE Results" width="70%"/>  <p><strong>Figure 2: Performance Comparison.
15-1	1285-1286	<	_	_
15-2	1286-1289	div	_	_
15-3	1290-1295	align	_	_
15-4	1295-1296	=	_	_
15-5	1296-1297	"	*[16]	SOFTWARE[16]
15-6	1297-1303	center	*[16]	SOFTWARE[16]
15-7	1303-1304	"	*[16]	SOFTWARE[16]
15-8	1304-1305	>	*[16]	SOFTWARE[16]
15-9	1307-1308	<	*[16]	SOFTWARE[16]
15-10	1308-1311	img	*[16]	SOFTWARE[16]
15-11	1312-1315	src	*[16]	SOFTWARE[16]
15-12	1315-1316	=	*[16]	SOFTWARE[16]
15-13	1316-1317	"	*[16]	SOFTWARE[16]
15-14	1317-1324	figures	*[16]	SOFTWARE[16]
15-15	1324-1325	/	*[16]	SOFTWARE[16]
15-16	1325-1340	results\_hpo.jpg	*[16]	SOFTWARE[16]
15-17	1340-1341	"	*[16]	SOFTWARE[16]
15-18	1342-1345	alt	*[16]	SOFTWARE[16]
15-19	1345-1346	=	*[16]	SOFTWARE[16]
15-20	1346-1347	"	*[16]	SOFTWARE[16]
15-21	1347-1353	GRANDE	*[16]	SOFTWARE[16]
15-22	1354-1361	Results	*[16]	SOFTWARE[16]
15-23	1361-1362	"	*[16]	SOFTWARE[16]
15-24	1363-1368	width	*[16]	SOFTWARE[16]
15-25	1368-1369	=	*[16]	SOFTWARE[16]
15-26	1369-1370	"	*[16]	SOFTWARE[16]
15-27	1370-1373	70%	*[16]	SOFTWARE[16]
15-28	1373-1374	"	*[16]	SOFTWARE[16]
15-29	1374-1375	/	*[16]	SOFTWARE[16]
15-30	1375-1376	>	*[16]	SOFTWARE[16]
15-31	1378-1379	<	*[16]	SOFTWARE[16]
15-32	1379-1380	p	*[16]	SOFTWARE[16]
15-33	1380-1381	>	*[16]	SOFTWARE[16]
15-34	1381-1382	<	*[16]	SOFTWARE[16]
15-35	1382-1388	strong	*[16]	SOFTWARE[16]
15-36	1388-1389	>	*[16]	SOFTWARE[16]
15-37	1389-1395	Figure	*[16]	SOFTWARE[16]
15-38	1396-1397	2	*[16]	SOFTWARE[16]
15-39	1397-1398	:	*[16]	SOFTWARE[16]
15-40	1399-1410	Performance	_	_
15-41	1411-1421	Comparison	_	_
15-42	1421-1422	.	_	_

#Text=</strong> We report the test macro F1-score (mean ¬± stdev for a 5-fold CV) with optimized parameters.
16-1	1422-1423	<	_	_
16-2	1423-1424	/	_	_
16-3	1424-1430	strong	_	_
16-4	1430-1431	>	_	_
16-5	1432-1434	We	*[17]	SOFTWARE[17]
16-6	1435-1441	report	*[17]	SOFTWARE[17]
16-7	1442-1445	the	*[17]	SOFTWARE[17]
16-8	1446-1450	test	*[17]	SOFTWARE[17]
16-9	1451-1456	macro	_	_
16-10	1457-1459	F1	_	_
16-11	1459-1460	-	_	_
16-12	1460-1465	score	_	_
16-13	1466-1467	(	_	_
16-14	1467-1471	mean	_	_
16-15	1472-1473	¬±	_	_
16-16	1474-1479	stdev	_	_
16-17	1480-1483	for	_	_
16-18	1484-1485	a	_	_
16-19	1486-1487	5	_	_
16-20	1487-1488	-	_	_
16-21	1488-1492	fold	_	_
16-22	1493-1495	CV	_	_
16-23	1495-1496	)	_	_
16-24	1497-1501	with	_	_
16-25	1502-1511	optimized	_	_
16-26	1512-1522	parameters	_	_
16-27	1522-1523	.	_	_

#Text=The datasets are sorted based on the data size.
17-1	1524-1527	The	_	_
17-2	1528-1536	datasets	_	_
17-3	1537-1540	are	_	_
17-4	1541-1547	sorted	_	_
17-5	1548-1553	based	_	_
17-6	1554-1556	on	_	_
17-7	1557-1560	the	_	_
17-8	1561-1565	data	_	_
17-9	1566-1570	size	_	_
17-10	1570-1571	.	_	_

#Text=</p>  </div>  üìù  More details on the method can be found in our paper available under: https://openreview.net/forum?
18-1	1571-1572	<	_	_
18-2	1572-1573	/	_	_
18-3	1573-1574	p	_	_
18-4	1574-1575	>	_	_
18-5	1577-1578	<	_	_
18-6	1578-1579	/	_	_
18-7	1579-1582	div	_	_
18-8	1582-1583	>	_	_
18-9	1585-1587	üìù	_	_
18-10	1588-1592	More	_	_
18-11	1593-1600	details	_	_
18-12	1601-1603	on	_	_
18-13	1604-1607	the	_	_
18-14	1608-1614	method	_	_
18-15	1615-1618	can	_	_
18-16	1619-1621	be	_	_
18-17	1622-1627	found	_	_
18-18	1628-1630	in	_	_
18-19	1631-1634	our	_	_
18-20	1635-1640	paper	_	_
18-21	1641-1650	available	*[19]	DATASET[19]
18-22	1651-1656	under	*[19]	DATASET[19]
18-23	1656-1657	:	*[19]	DATASET[19]
18-24	1658-1663	https	*[19]	DATASET[19]
18-25	1663-1664	:	*[19]	DATASET[19]
18-26	1664-1665	/	*[19]	DATASET[19]
18-27	1665-1666	/	*[19]	DATASET[19]
18-28	1666-1680	openreview.net	_	_
18-29	1680-1681	/	_	_
18-30	1681-1686	forum	_	_
18-31	1686-1687	?	_	_

#Text=id=XEFWBxi075  ## Installation To download the latest official release of the package, use the pip command below: ```bash pip install GRANDE ``` More details can be found under: https://pypi.org/project/GRANDE/  ## Cite us  ``` @inproceedings{ marton2024grande, title={{GRANDE}: Gradient-Based Decision Tree Ensembles}, author={Sascha Marton and Stefan L{\\"u}dtke and Christian Bartelt and Heiner Stuckenschmidt}, booktitle={The Twelfth International Conference on Learning Representations}, year={2024}, url={https://openreview.net/forum?
19-1	1687-1689	id	_	_
19-2	1689-1690	=	_	_
19-3	1690-1700	XEFWBxi075	_	_
19-4	1702-1703	#	_	_
19-5	1703-1704	#	_	_
19-6	1705-1717	Installation	_	_
19-7	1718-1720	To	_	_
19-8	1721-1729	download	_	_
19-9	1730-1733	the	_	_
19-10	1734-1740	latest	_	_
19-11	1741-1749	official	_	_
19-12	1750-1757	release	_	_
19-13	1758-1760	of	_	_
19-14	1761-1764	the	_	_
19-15	1765-1772	package	_	_
19-16	1772-1773	,	_	_
19-17	1774-1777	use	_	_
19-18	1778-1781	the	_	_
19-19	1782-1785	pip	_	_
19-20	1786-1793	command	_	_
19-21	1794-1799	below	_	_
19-22	1799-1800	:	_	_
19-23	1801-1802	`	_	_
19-24	1802-1803	`	_	_
19-25	1803-1804	`	_	_
19-26	1804-1808	bash	_	_
19-27	1809-1812	pip	_	_
19-28	1813-1820	install	_	_
19-29	1821-1827	GRANDE	_	_
19-30	1828-1829	`	_	_
19-31	1829-1830	`	_	_
19-32	1830-1831	`	_	_
19-33	1832-1836	More	_	_
19-34	1837-1844	details	_	_
19-35	1845-1848	can	*[15]	PROGLANG[15]
19-36	1849-1851	be	*[15]	PROGLANG[15]
19-37	1852-1857	found	*[15]	PROGLANG[15]
19-38	1858-1863	under	*[15]	PROGLANG[15]
19-39	1863-1864	:	*[15]	PROGLANG[15]
19-40	1865-1870	https	*[15]	PROGLANG[15]
19-41	1870-1871	:	*[15]	PROGLANG[15]
19-42	1871-1872	/	*[15]	PROGLANG[15]
19-43	1872-1873	/	*[15]	PROGLANG[15]
19-44	1873-1881	pypi.org	*[15]	PROGLANG[15]
19-45	1881-1882	/	*[15]	PROGLANG[15]
19-46	1882-1889	project	*[15]	PROGLANG[15]
19-47	1889-1890	/	*[15]	PROGLANG[15]
19-48	1890-1896	GRANDE	*[15]	PROGLANG[15]
19-49	1896-1897	/	*[15]	PROGLANG[15]
19-50	1899-1900	#	*[15]	PROGLANG[15]
19-51	1900-1901	#	*[15]	PROGLANG[15]
19-52	1902-1906	Cite	*[15]	PROGLANG[15]
19-53	1907-1909	us	*[15]	PROGLANG[15]
19-54	1911-1912	`	*[15]	PROGLANG[15]
19-55	1912-1913	`	*[15]	PROGLANG[15]
19-56	1913-1914	`	*[15]	PROGLANG[15]
19-57	1915-1916	@	*[15]	PROGLANG[15]
19-58	1916-1929	inproceedings	*[15]	PROGLANG[15]
19-59	1929-1930	{	*[15]	PROGLANG[15]
19-60	1931-1947	marton2024grande	*[15]	PROGLANG[15]
19-61	1947-1948	,	*[15]	PROGLANG[15]
19-62	1949-1954	title	*[15]	PROGLANG[15]
19-63	1954-1955	=	*[15]	PROGLANG[15]
19-64	1955-1956	{	*[15]	PROGLANG[15]
19-65	1956-1957	{	*[15]	PROGLANG[15]
19-66	1957-1963	GRANDE	*[15]	PROGLANG[15]
19-67	1963-1964	}	*[15]	PROGLANG[15]
19-68	1964-1965	:	*[15]	PROGLANG[15]
19-69	1966-1980	Gradient-Based	*[15]	PROGLANG[15]
19-70	1981-1989	Decision	*[15]	PROGLANG[15]
19-71	1990-1994	Tree	*[15]	PROGLANG[15]
19-72	1995-2004	Ensembles	*[15]	PROGLANG[15]
19-73	2004-2005	}	*[15]	PROGLANG[15]
19-74	2005-2006	,	*[15]	PROGLANG[15]
19-75	2007-2013	author	*[15]	PROGLANG[15]
19-76	2013-2014	=	*[15]	PROGLANG[15]
19-77	2014-2015	{	*[15]	PROGLANG[15]
19-78	2015-2021	Sascha	*[15]	PROGLANG[15]
19-79	2022-2028	Marton	*[15]	PROGLANG[15]
19-80	2029-2032	and	*[15]	PROGLANG[15]
19-81	2033-2039	Stefan	*[15]	PROGLANG[15]
19-82	2040-2041	L	*[15]	PROGLANG[15]
19-83	2041-2042	{	*[15]	PROGLANG[15]
19-84	2042-2043	\\	*[15]	PROGLANG[15]
19-85	2043-2044	"	*[15]	PROGLANG[15]
19-86	2044-2045	u	*[15]	PROGLANG[15]
19-87	2045-2046	}	*[15]	PROGLANG[15]
19-88	2046-2050	dtke	*[15]	PROGLANG[15]
19-89	2051-2054	and	*[15]	PROGLANG[15]
19-90	2055-2064	Christian	_	_
19-91	2065-2072	Bartelt	_	_
19-92	2073-2076	and	_	_
19-93	2077-2083	Heiner	_	_
19-94	2084-2098	Stuckenschmidt	_	_
19-95	2098-2099	}	_	_
19-96	2099-2100	,	_	_
19-97	2101-2110	booktitle	_	_
19-98	2110-2111	=	_	_
19-99	2111-2112	{	_	_
19-100	2112-2115	The	_	_
19-101	2116-2123	Twelfth	_	_
19-102	2124-2137	International	_	_
19-103	2138-2148	Conference	_	_
19-104	2149-2151	on	_	_
19-105	2152-2160	Learning	_	_
19-106	2161-2176	Representations	_	_
19-107	2176-2177	}	_	_
19-108	2177-2178	,	_	_
19-109	2179-2183	year	_	_
19-110	2183-2184	=	_	_
19-111	2184-2185	{	_	_
19-112	2185-2189	2024	_	_
19-113	2189-2190	}	_	_
19-114	2190-2191	,	_	_
19-115	2192-2195	url	_	_
19-116	2195-2196	=	_	_
19-117	2196-2197	{	_	_
19-118	2197-2202	https	_	_
19-119	2202-2203	:	_	_
19-120	2203-2204	/	_	_
19-121	2204-2205	/	_	_
19-122	2205-2219	openreview.net	_	_
19-123	2219-2220	/	_	_
19-124	2220-2225	forum	_	_
19-125	2225-2226	?	_	_

#Text=id=XEFWBxi075} } ```   ## Usage Example usage is in the following or available in the jupyter notebook files.
20-1	2226-2228	id	_	_
20-2	2228-2229	=	_	_
20-3	2229-2239	XEFWBxi075	_	_
20-4	2239-2240	}	*[22]	EVALMETRIC[22]
20-5	2241-2242	}	*[22]	EVALMETRIC[22]
20-6	2243-2244	`	*[22]	EVALMETRIC[22]
20-7	2244-2245	`	*[22]	EVALMETRIC[22]
20-8	2245-2246	`	*[22]	EVALMETRIC[22]
20-9	2249-2250	#	*[22]	EVALMETRIC[22]
20-10	2250-2251	#	*[22]	EVALMETRIC[22]
20-11	2252-2257	Usage	*[22]	EVALMETRIC[22]
20-12	2258-2265	Example	*[22]	EVALMETRIC[22]
20-13	2266-2271	usage	*[22]	EVALMETRIC[22]
20-14	2272-2274	is	*[22]	EVALMETRIC[22]
20-15	2275-2277	in	*[22]	EVALMETRIC[22]
20-16	2278-2281	the	*[22]	EVALMETRIC[22]
20-17	2282-2291	following	*[22]	EVALMETRIC[22]
20-18	2292-2294	or	*[22]	EVALMETRIC[22]
20-19	2295-2304	available	_	_
20-20	2305-2307	in	_	_
20-21	2308-2311	the	_	_
20-22	2312-2319	jupyter	_	_
20-23	2320-2328	notebook	_	_
20-24	2329-2334	files	_	_
20-25	2334-2335	.	_	_

#Text=Please note that a GPU is required to achieve competitive runtimes.
21-1	2336-2342	Please	_	_
21-2	2343-2347	note	_	_
21-3	2348-2352	that	_	_
21-4	2353-2354	a	_	_
21-5	2355-2358	GPU	_	_
21-6	2359-2361	is	_	_
21-7	2362-2370	required	_	_
21-8	2371-2373	to	_	_
21-9	2374-2381	achieve	_	_
21-10	2382-2393	competitive	_	_
21-11	2394-2402	runtimes	_	_
21-12	2402-2403	.	_	_

#Text=Also, please set 'objective' to 'binary', 'classification' or 'regression' based on your task.  ### Enable and specify GPU ```python import os os.environ\['CUDA\_VISIBLE\_DEVICES'\] = '0' os.environ\['TF\_FORCE\_GPU\_ALLOW\_GROWTH'\] = 'true' ```  ### Load Data ```python from sklearn.model\_selection import train\_test\_split import openml  dataset = openml.datasets.get\_dataset(40536) X, y, categorical\_indicator, attribute\_names = dataset.get\_data(target=dataset.default\_target\_attribute) categorical\_feature\_indices = \[idx for idx, idx\_bool in enumerate(categorical\_indicator) if idx\_bool\]  X\_temp, X\_test, y\_temp, y\_test = train\_test\_split(X, y, test\_size=0.2, random\_state=42)  X\_train, X\_valid, y\_train, y\_valid = train\_test\_split(X\_temp, y\_temp, test\_size=0.2, random\_state=42) ```  ### Preprocessing, Hyperparameters and Training  GRANDE requires categorical features to be encoded appropriately.
22-1	2404-2408	Also	_	_
22-2	2408-2409	,	_	_
22-3	2410-2416	please	_	_
22-4	2417-2420	set	_	_
22-5	2421-2422	'	_	_
22-6	2422-2431	objective	_	_
22-7	2431-2432	'	_	_
22-8	2433-2435	to	_	_
22-9	2436-2437	'	_	_
22-10	2437-2443	binary	_	_
22-11	2443-2444	'	_	_
22-12	2444-2445	,	_	_
22-13	2446-2447	'	_	_
22-14	2447-2461	classification	_	_
22-15	2461-2462	'	_	_
22-16	2463-2465	or	_	_
22-17	2466-2467	'	_	_
22-18	2467-2477	regression	_	_
22-19	2477-2478	'	_	_
22-20	2479-2484	based	_	_
22-21	2485-2487	on	_	_
22-22	2488-2492	your	_	_
22-23	2493-2497	task	_	_
22-24	2497-2498	.	_	_
22-25	2500-2501	#	_	_
22-26	2501-2502	#	_	_
22-27	2502-2503	#	_	_
22-28	2504-2510	Enable	_	_
22-29	2511-2514	and	_	_
22-30	2515-2522	specify	_	_
22-31	2523-2526	GPU	_	_
22-32	2527-2528	`	_	_
22-33	2528-2529	`	_	_
22-34	2529-2530	`	_	_
22-35	2530-2536	python	_	_
22-36	2537-2543	import	_	_
22-37	2544-2546	os	_	_
22-38	2547-2557	os.environ	_	_
22-39	2557-2558	\[	_	_
22-40	2558-2559	'	_	_
22-41	2559-2579	CUDA\_VISIBLE\_DEVICES	_	_
22-42	2579-2580	'	_	_
22-43	2580-2581	\]	_	_
22-44	2582-2583	=	_	_
22-45	2584-2585	'	_	_
22-46	2585-2586	0	_	_
22-47	2586-2587	'	_	_
22-48	2588-2598	os.environ	_	_
22-49	2598-2599	\[	_	_
22-50	2599-2600	'	_	_
22-51	2600-2625	TF\_FORCE\_GPU\_ALLOW\_GROWTH	_	_
22-52	2625-2626	'	_	_
22-53	2626-2627	\]	_	_
22-54	2628-2629	=	_	_
22-55	2630-2631	'	_	_
22-56	2631-2635	true	_	_
22-57	2635-2636	'	_	_
22-58	2637-2638	`	_	_
22-59	2638-2639	`	_	_
22-60	2639-2640	`	_	_
22-61	2642-2643	#	_	_
22-62	2643-2644	#	_	_
22-63	2644-2645	#	_	_
22-64	2646-2650	Load	_	_
22-65	2651-2655	Data	_	_
22-66	2656-2657	`	_	_
22-67	2657-2658	`	_	_
22-68	2658-2659	`	_	_
22-69	2659-2665	python	_	_
22-70	2666-2670	from	_	_
22-71	2671-2694	sklearn.model\_selection	_	_
22-72	2695-2701	import	_	_
22-73	2702-2718	train\_test\_split	_	_
22-74	2719-2725	import	_	_
22-75	2726-2732	openml	_	_
22-76	2734-2741	dataset	_	_
22-77	2742-2743	=	_	_
22-78	2744-2771	openml.datasets.get\_dataset	_	_
22-79	2771-2772	(	_	_
22-80	2772-2777	40536	_	_
22-81	2777-2778	)	_	_
22-82	2779-2780	X	_	_
22-83	2780-2781	,	_	_
22-84	2782-2783	y	*[20]	DATASET[20]
22-85	2783-2784	,	*[20]	DATASET[20]
22-86	2785-2806	categorical\_indicator	*[20]	DATASET[20]
22-87	2806-2807	,	*[20]	DATASET[20]
22-88	2808-2823	attribute\_names	*[20]	DATASET[20]
22-89	2824-2825	=	*[20]	DATASET[20]
22-90	2826-2842	dataset.get\_data	*[20]	DATASET[20]
22-91	2842-2843	(	*[20]	DATASET[20]
22-92	2843-2849	target	*[20]	DATASET[20]
22-93	2849-2850	=	*[20]	DATASET[20]
22-94	2850-2882	dataset.default\_target\_attribute	*[20]	DATASET[20]
22-95	2882-2883	)	*[20]	DATASET[20]
22-96	2884-2911	categorical\_feature\_indices	*[20]	DATASET[20]
22-97	2912-2913	=	*[20]	DATASET[20]
22-98	2914-2915	\[	*[20]	DATASET[20]
22-99	2915-2918	idx	*[20]	DATASET[20]
22-100	2919-2922	for	*[20]	DATASET[20]
22-101	2923-2926	idx	*[20]	DATASET[20]
22-102	2926-2927	,	*[20]	DATASET[20]
22-103	2928-2936	idx\_bool	*[20]	DATASET[20]
22-104	2937-2939	in	*[20]	DATASET[20]
22-105	2940-2949	enumerate	*[20]	DATASET[20]
22-106	2949-2950	(	*[20]	DATASET[20]
22-107	2950-2971	categorical\_indicator	*[20]	DATASET[20]
22-108	2971-2972	)	*[20]	DATASET[20]
22-109	2973-2975	if	*[20]	DATASET[20]
22-110	2976-2984	idx\_bool	*[20]	DATASET[20]
22-111	2984-2985	\]	*[20]	DATASET[20]
22-112	2987-2993	X\_temp	*[20]	DATASET[20]
22-113	2993-2994	,	*[20]	DATASET[20]
22-114	2995-3001	X\_test	*[20]	DATASET[20]
22-115	3001-3002	,	*[20]	DATASET[20]
22-116	3003-3009	y\_temp	*[20]	DATASET[20]
22-117	3009-3010	,	*[20]	DATASET[20]
22-118	3011-3017	y\_test	*[20]	DATASET[20]
22-119	3018-3019	=	*[20]	DATASET[20]
22-120	3020-3036	train\_test\_split	*[20]	DATASET[20]
22-121	3036-3037	(	*[20]	DATASET[20]
22-122	3037-3038	X	*[20]	DATASET[20]
22-123	3038-3039	,	*[20]	DATASET[20]
22-124	3040-3041	y	*[20]	DATASET[20]
22-125	3041-3042	,	*[20]	DATASET[20]
22-126	3043-3052	test\_size	*[20]	DATASET[20]
22-127	3052-3053	=	*[20]	DATASET[20]
22-128	3053-3056	0.2	*[20]	DATASET[20]
22-129	3056-3057	,	*[20]	DATASET[20]
22-130	3058-3070	random\_state	*[20]	DATASET[20]
22-131	3070-3071	=	*[20]	DATASET[20]
22-132	3071-3073	42	*[20]	DATASET[20]
22-133	3073-3074	)	*[20]	DATASET[20]
22-134	3076-3083	X\_train	*[20]	DATASET[20]
22-135	3083-3084	,	*[20]	DATASET[20]
22-136	3085-3092	X\_valid	*[20]	DATASET[20]
22-137	3092-3093	,	*[20]	DATASET[20]
22-138	3094-3101	y\_train	*[20]	DATASET[20]
22-139	3101-3102	,	*[20]	DATASET[20]
22-140	3103-3110	y\_valid	*[20]	DATASET[20]
22-141	3111-3112	=	*[20]	DATASET[20]
22-142	3113-3129	train\_test\_split	*[20]	DATASET[20]
22-143	3129-3130	(	*[20]	DATASET[20]
22-144	3130-3136	X\_temp	*[20]	DATASET[20]
22-145	3136-3137	,	*[20]	DATASET[20]
22-146	3138-3144	y\_temp	_	_
22-147	3144-3145	,	_	_
22-148	3146-3155	test\_size	_	_
22-149	3155-3156	=	_	_
22-150	3156-3159	0.2	_	_
22-151	3159-3160	,	_	_
22-152	3161-3173	random\_state	_	_
22-153	3173-3174	=	_	_
22-154	3174-3176	42	_	_
22-155	3176-3177	)	_	_
22-156	3178-3179	`	_	_
22-157	3179-3180	`	_	_
22-158	3180-3181	`	_	_
22-159	3183-3184	#	_	_
22-160	3184-3185	#	_	_
22-161	3185-3186	#	_	_
22-162	3187-3200	Preprocessing	_	_
22-163	3200-3201	,	_	_
22-164	3202-3217	Hyperparameters	_	_
22-165	3218-3221	and	_	_
22-166	3222-3230	Training	_	_
22-167	3232-3238	GRANDE	_	_
22-168	3239-3247	requires	_	_
22-169	3248-3259	categorical	_	_
22-170	3260-3268	features	_	_
22-171	3269-3271	to	_	_
22-172	3272-3274	be	_	_
22-173	3275-3282	encoded	_	_
22-174	3283-3296	appropriately	_	_
22-175	3296-3297	.	_	_

#Text=The best results are achieved using Leave-One-Out Encoding for high-cardinality categorical features and One-Hot Encoding for low-cardinality categorical features.
23-1	3298-3301	The	_	_
23-2	3302-3306	best	_	_
23-3	3307-3314	results	_	_
23-4	3315-3318	are	*[18]	SOFTWARE[18]
23-5	3319-3327	achieved	*[18]	SOFTWARE[18]
23-6	3328-3333	using	*[18]	SOFTWARE[18]
23-7	3334-3347	Leave-One-Out	*[18]	SOFTWARE[18]
23-8	3348-3356	Encoding	*[18]	SOFTWARE[18]
23-9	3357-3360	for	*[18]	SOFTWARE[18]
23-10	3361-3377	high-cardinality	_	_
23-11	3378-3389	categorical	_	_
23-12	3390-3398	features	_	_
23-13	3399-3402	and	_	_
23-14	3403-3410	One-Hot	_	_
23-15	3411-3419	Encoding	_	_
23-16	3420-3423	for	_	_
23-17	3424-3439	low-cardinality	_	_
23-18	3440-3451	categorical	_	_
23-19	3452-3460	features	_	_
23-20	3460-3461	.	_	_

#Text=Furthermore, all features should be normalized using a quantile transformation.
24-1	3462-3473	Furthermore	_	_
24-2	3473-3474	,	_	_
24-3	3475-3478	all	_	_
24-4	3479-3487	features	_	_
24-5	3488-3494	should	_	_
24-6	3495-3497	be	_	_
24-7	3498-3508	normalized	*[12]	LICENSE[12]
24-8	3509-3514	using	_	_
24-9	3515-3516	a	_	_
24-10	3517-3525	quantile	_	_
24-11	3526-3540	transformation	_	_
24-12	3540-3541	.	_	_

#Text=Passing the categorical indices to the model wil automatically preprocess the data accordingly.
25-1	3542-3549	Passing	_	_
25-2	3550-3553	the	_	_
25-3	3554-3565	categorical	_	_
25-4	3566-3573	indices	_	_
25-5	3574-3576	to	_	_
25-6	3577-3580	the	_	_
25-7	3581-3586	model	_	_
25-8	3587-3590	wil	_	_
25-9	3591-3604	automatically	_	_
25-10	3605-3615	preprocess	_	_
25-11	3616-3619	the	_	_
25-12	3620-3624	data	_	_
25-13	3625-3636	accordingly	_	_
25-14	3636-3637	.	_	_

#Text=In the following, we will train the model using the default parameters.
26-1	3639-3641	In	_	_
26-2	3642-3645	the	_	_
26-3	3646-3655	following	_	_
26-4	3655-3656	,	_	_
26-5	3657-3659	we	_	_
26-6	3660-3664	will	_	_
26-7	3665-3670	train	_	_
26-8	3671-3674	the	*[10]	ONTOLOGY[10]
26-9	3675-3680	model	*[10]	ONTOLOGY[10]
26-10	3681-3686	using	*[10]	ONTOLOGY[10]
26-11	3687-3690	the	*[10]	ONTOLOGY[10]
26-12	3691-3698	default	_	_
26-13	3699-3709	parameters	_	_
26-14	3709-3710	.	_	_

#Text=GRANDE already archives great results with its default parameters, but a HPO can increase the performance even further.
27-1	3711-3717	GRANDE	_	_
27-2	3718-3725	already	_	_
27-3	3726-3734	archives	_	_
27-4	3735-3740	great	*[16]	PROGLANG[16]
27-5	3741-3748	results	*[16]	PROGLANG[16]
27-6	3749-3753	with	*[16]	PROGLANG[16]
27-7	3754-3757	its	*[16]	PROGLANG[16]
27-8	3758-3765	default	*[16]	PROGLANG[16]
27-9	3766-3776	parameters	*[16]	PROGLANG[16]
27-10	3776-3777	,	*[16]	PROGLANG[16]
27-11	3778-3781	but	*[16]	PROGLANG[16]
27-12	3782-3783	a	*[16]	PROGLANG[16]
27-13	3784-3787	HPO	*[16]	PROGLANG[16]
27-14	3788-3791	can	*[16]	PROGLANG[16]
27-15	3792-3800	increase	*[16]	PROGLANG[16]
27-16	3801-3804	the	*[16]	PROGLANG[16]
27-17	3805-3816	performance	*[16]	PROGLANG[16]
27-18	3817-3821	even	*[16]	PROGLANG[16]
27-19	3822-3829	further	_	_
27-20	3829-3830	.	_	_

#Text=An appropriate grid is specified in the model class.
28-1	3831-3833	An	_	_
28-2	3834-3845	appropriate	_	_
28-3	3846-3850	grid	_	_
28-4	3851-3853	is	_	_
28-5	3854-3863	specified	_	_
28-6	3864-3866	in	*[19]	SOFTWARE[19]
28-7	3867-3870	the	*[19]	SOFTWARE[19]
28-8	3871-3876	model	*[19]	SOFTWARE[19]
28-9	3877-3882	class	_	_
28-10	3882-3883	.	_	_

#Text=```python from GRANDE import GRANDE  params = {         'depth': 5, # tree depth         'n\_estimators': 2048, # number of estimators / trees          'learning\_rate\_weights': 0.005, # learning rate for leaf weights         'learning\_rate\_index': 0.01, # learning rate for split indices         'learning\_rate\_values': 0.01, # learning rate for split values         'learning\_rate\_leaf': 0.01, # learning rate for leafs (logits)          'optimizer': 'adam', # optimizer         'cosine\_decay\_steps': 0, # decay steps for lr schedule (CosineDecayRestarts)          'loss': 'crossentropy', # loss function (default 'crossentropy' for binary & multi-class classification and 'mse' for regression)         'focal\_loss': False, # use focal loss {True, False}         'temperature': 0.0, # temperature for stochastic re-weighted GD (0.0, 1.0)          'from\_logits': True, # use logits for weighting {True, False}         'use\_class\_weights': True, # use class weights for training {True, False}          'dropout': 0.0, # dropout rate (here, dropout randomly disables individual estimators of the ensemble during training)          'selected\_variables': 0.8, # feature subset percentage (0.0, 1.0)         'data\_subset\_fraction': 1.0, # data subset percentage (0.0, 1.0) }  args = {     'epochs': 1\_000, # number of epochs for training     'early\_stopping\_epochs': 25, # patience for early stopping (best weights are restored)     'batch\_size': 64,  # batch size for training      'cat\_idx': categorical\_feature\_indices, # put list of categorical indices     'objective': 'binary', # objective / task {'binary', 'classification', 'regression'}          'random\_seed': 42,     'verbose': 1,        }  model\_grande = GRANDE(params=params, args=args)  model\_grande.fit(X\_train=X\_train,           y\_train=y\_train,           X\_val=X\_valid,           y\_val=y\_valid)  preds\_grande = model\_grande.predict(X\_test)  ```  ### Evaluate Model  ```python preds = model\_grande.predict(X\_test)  if args\['objective'\] == 'binary':     accuracy = sklearn.metrics.accuracy\_score(y\_test, np.round(preds\_grande\[:,1\]))     f1\_score = sklearn.metrics.f1\_score(y\_test, np.round(preds\_grande\[:,1\]), average='macro')     roc\_auc = sklearn.metrics.roc\_auc\_score(y\_test, preds\_grande\[:,1\], average='macro')          print('Accuracy:', accuracy)     print('F1 Score:', f1\_score)     print('ROC AUC:', roc\_auc) elif args\['objective'\] == 'classification':     accuracy = sklearn.metrics.accuracy\_score(y\_test, np.argmax(preds\_grande, axis=1))     f1\_score = sklearn.metrics.f1\_score(y\_test, np.argmax(preds\_grande, axis=1), average='macro')     roc\_auc = sklearn.metrics.roc\_auc\_score(y\_test, preds\_grande, average='macro', multi\_class='ovo', labels=\[i for i in range(preds\_grande.shape\[1\])\])      print('Accuracy GRANDE:', accuracy)     print('F1 Score GRANDE:', f1\_score)     print('ROC AUC GRANDE:', roc\_auc) else:     mean\_absolute\_error = sklearn.metrics.mean\_absolute\_error(y\_test, np.round(preds\_grande))     r2\_score = sklearn.metrics.r2\_score(y\_test, np.round(preds\_grande))      print('MAE GRANDE:', mean\_absolute\_error)     print('R2 Score GRANDE:', r2\_score) ```  ## More  Please note that this is an experimental implementation which is not fully tested yet.
29-1	3885-3886	`	_	_
29-2	3886-3887	`	_	_
29-3	3887-3888	`	_	_
29-4	3888-3894	python	_	_
29-5	3895-3899	from	_	_
29-6	3900-3906	GRANDE	_	_
29-7	3907-3913	import	_	_
29-8	3914-3920	GRANDE	_	_
29-9	3922-3928	params	_	_
29-10	3929-3930	=	_	_
29-11	3931-3932	{	_	_
29-12	3941-3942	'	_	_
29-13	3942-3947	depth	_	_
29-14	3947-3948	'	_	_
29-15	3948-3949	:	_	_
29-16	3950-3951	5	_	_
29-17	3951-3952	,	_	_
29-18	3953-3954	#	_	_
29-19	3955-3959	tree	_	_
29-20	3960-3965	depth	_	_
29-21	3974-3975	'	_	_
29-22	3975-3987	n\_estimators	_	_
29-23	3987-3988	'	_	_
29-24	3988-3989	:	_	_
29-25	3990-3994	2048	_	_
29-26	3994-3995	,	_	_
29-27	3996-3997	#	_	_
29-28	3998-4004	number	_	_
29-29	4005-4007	of	_	_
29-30	4008-4018	estimators	_	_
29-31	4019-4020	/	_	_
29-32	4021-4026	trees	_	_
29-33	4036-4037	'	_	_
29-34	4037-4058	learning\_rate\_weights	_	_
29-35	4058-4059	'	_	_
29-36	4059-4060	:	_	_
29-37	4061-4066	0.005	_	_
29-38	4066-4067	,	_	_
29-39	4068-4069	#	_	_
29-40	4070-4078	learning	_	_
29-41	4079-4083	rate	_	_
29-42	4084-4087	for	_	_
29-43	4088-4092	leaf	_	_
29-44	4093-4100	weights	_	_
29-45	4109-4110	'	_	_
29-46	4110-4129	learning\_rate\_index	_	_
29-47	4129-4130	'	_	_
29-48	4130-4131	:	_	_
29-49	4132-4136	0.01	_	_
29-50	4136-4137	,	_	_
29-51	4138-4139	#	_	_
29-52	4140-4148	learning	_	_
29-53	4149-4153	rate	_	_
29-54	4154-4157	for	_	_
29-55	4158-4163	split	_	_
29-56	4164-4171	indices	_	_
29-57	4180-4181	'	_	_
29-58	4181-4201	learning\_rate\_values	_	_
29-59	4201-4202	'	_	_
29-60	4202-4203	:	_	_
29-61	4204-4208	0.01	_	_
29-62	4208-4209	,	_	_
29-63	4210-4211	#	_	_
29-64	4212-4220	learning	_	_
29-65	4221-4225	rate	_	_
29-66	4226-4229	for	_	_
29-67	4230-4235	split	_	_
29-68	4236-4242	values	_	_
29-69	4251-4252	'	_	_
29-70	4252-4270	learning\_rate\_leaf	_	_
29-71	4270-4271	'	_	_
29-72	4271-4272	:	_	_
29-73	4273-4277	0.01	_	_
29-74	4277-4278	,	_	_
29-75	4279-4280	#	_	_
29-76	4281-4289	learning	_	_
29-77	4290-4294	rate	_	_
29-78	4295-4298	for	_	_
29-79	4299-4304	leafs	_	_
29-80	4305-4306	(	_	_
29-81	4306-4312	logits	_	_
29-82	4312-4313	)	_	_
29-83	4323-4324	'	_	_
29-84	4324-4333	optimizer	_	_
29-85	4333-4334	'	_	_
29-86	4334-4335	:	_	_
29-87	4336-4337	'	_	_
29-88	4337-4341	adam	_	_
29-89	4341-4342	'	_	_
29-90	4342-4343	,	_	_
29-91	4344-4345	#	_	_
29-92	4346-4355	optimizer	_	_
29-93	4364-4365	'	_	_
29-94	4365-4383	cosine\_decay\_steps	_	_
29-95	4383-4384	'	_	_
29-96	4384-4385	:	_	_
29-97	4386-4387	0	_	_
29-98	4387-4388	,	_	_
29-99	4389-4390	#	_	_
29-100	4391-4396	decay	_	_
29-101	4397-4402	steps	_	_
29-102	4403-4406	for	_	_
29-103	4407-4409	lr	_	_
29-104	4410-4418	schedule	_	_
29-105	4419-4420	(	_	_
29-106	4420-4439	CosineDecayRestarts	_	_
29-107	4439-4440	)	_	_
29-108	4450-4451	'	_	_
29-109	4451-4455	loss	_	_
29-110	4455-4456	'	_	_
29-111	4456-4457	:	_	_
29-112	4458-4459	'	_	_
29-113	4459-4471	crossentropy	_	_
29-114	4471-4472	'	_	_
29-115	4472-4473	,	_	_
29-116	4474-4475	#	_	_
29-117	4476-4480	loss	_	_
29-118	4481-4489	function	_	_
29-119	4490-4491	(	_	_
29-120	4491-4498	default	_	_
29-121	4499-4500	'	_	_
29-122	4500-4512	crossentropy	_	_
29-123	4512-4513	'	_	_
29-124	4514-4517	for	_	_
29-125	4518-4524	binary	_	_
29-126	4525-4526	&	_	_
29-127	4527-4538	multi-class	_	_
29-128	4539-4553	classification	_	_
29-129	4554-4557	and	_	_
29-130	4558-4559	'	_	_
29-131	4559-4562	mse	_	_
29-132	4562-4563	'	_	_
29-133	4564-4567	for	_	_
29-134	4568-4578	regression	_	_
29-135	4578-4579	)	_	_
29-136	4588-4589	'	_	_
29-137	4589-4599	focal\_loss	_	_
29-138	4599-4600	'	_	_
29-139	4600-4601	:	_	_
29-140	4602-4607	False	_	_
29-141	4607-4608	,	_	_
29-142	4609-4610	#	_	_
29-143	4611-4614	use	_	_
29-144	4615-4620	focal	_	_
29-145	4621-4625	loss	_	_
29-146	4626-4627	{	_	_
29-147	4627-4631	True	_	_
29-148	4631-4632	,	_	_
29-149	4633-4638	False	_	_
29-150	4638-4639	}	_	_
29-151	4648-4649	'	_	_
29-152	4649-4660	temperature	_	_
29-153	4660-4661	'	_	_
29-154	4661-4662	:	_	_
29-155	4663-4666	0.0	_	_
29-156	4666-4667	,	_	_
29-157	4668-4669	#	_	_
29-158	4670-4681	temperature	_	_
29-159	4682-4685	for	_	_
29-160	4686-4696	stochastic	_	_
29-161	4697-4708	re-weighted	_	_
29-162	4709-4711	GD	_	_
29-163	4712-4713	(	_	_
29-164	4713-4716	0.0	_	_
29-165	4716-4717	,	_	_
29-166	4718-4721	1.0	_	_
29-167	4721-4722	)	_	_
29-168	4732-4733	'	_	_
29-169	4733-4744	from\_logits	_	_
29-170	4744-4745	'	_	_
29-171	4745-4746	:	_	_
29-172	4747-4751	True	_	_
29-173	4751-4752	,	_	_
29-174	4753-4754	#	_	_
29-175	4755-4758	use	_	_
29-176	4759-4765	logits	_	_
29-177	4766-4769	for	_	_
29-178	4770-4779	weighting	_	_
29-179	4780-4781	{	_	_
29-180	4781-4785	True	_	_
29-181	4785-4786	,	_	_
29-182	4787-4792	False	_	_
29-183	4792-4793	}	_	_
29-184	4802-4803	'	_	_
29-185	4803-4820	use\_class\_weights	_	_
29-186	4820-4821	'	_	_
29-187	4821-4822	:	_	_
29-188	4823-4827	True	_	_
29-189	4827-4828	,	_	_
29-190	4829-4830	#	_	_
29-191	4831-4834	use	_	_
29-192	4835-4840	class	_	_
29-193	4841-4848	weights	_	_
29-194	4849-4852	for	_	_
29-195	4853-4861	training	_	_
29-196	4862-4863	{	_	_
29-197	4863-4867	True	_	_
29-198	4867-4868	,	_	_
29-199	4869-4874	False	_	_
29-200	4874-4875	}	_	_
29-201	4885-4886	'	_	_
29-202	4886-4893	dropout	_	_
29-203	4893-4894	'	_	_
29-204	4894-4895	:	_	_
29-205	4896-4899	0.0	_	_
29-206	4899-4900	,	_	_
29-207	4901-4902	#	_	_
29-208	4903-4910	dropout	_	_
29-209	4911-4915	rate	_	_
29-210	4916-4917	(	_	_
29-211	4917-4921	here	_	_
29-212	4921-4922	,	_	_
29-213	4923-4930	dropout	_	_
29-214	4931-4939	randomly	_	_
29-215	4940-4948	disables	_	_
29-216	4949-4959	individual	_	_
29-217	4960-4970	estimators	_	_
29-218	4971-4973	of	_	_
29-219	4974-4977	the	_	_
29-220	4978-4986	ensemble	_	_
29-221	4987-4993	during	_	_
29-222	4994-5002	training	_	_
29-223	5002-5003	)	_	_
29-224	5013-5014	'	_	_
29-225	5014-5032	selected\_variables	_	_
29-226	5032-5033	'	_	_
29-227	5033-5034	:	_	_
29-228	5035-5038	0.8	_	_
29-229	5038-5039	,	_	_
29-230	5040-5041	#	_	_
29-231	5042-5049	feature	_	_
29-232	5050-5056	subset	_	_
29-233	5057-5067	percentage	_	_
29-234	5068-5069	(	_	_
29-235	5069-5072	0.0	_	_
29-236	5072-5073	,	_	_
29-237	5074-5077	1.0	_	_
29-238	5077-5078	)	_	_
29-239	5087-5088	'	_	_
29-240	5088-5108	data\_subset\_fraction	_	_
29-241	5108-5109	'	_	_
29-242	5109-5110	:	_	_
29-243	5111-5114	1.0	_	_
29-244	5114-5115	,	_	_
29-245	5116-5117	#	_	_
29-246	5118-5122	data	_	_
29-247	5123-5129	subset	_	_
29-248	5130-5140	percentage	_	_
29-249	5141-5142	(	_	_
29-250	5142-5145	0.0	_	_
29-251	5145-5146	,	_	_
29-252	5147-5150	1.0	_	_
29-253	5150-5151	)	_	_
29-254	5152-5153	}	_	_
29-255	5155-5159	args	_	_
29-256	5160-5161	=	_	_
29-257	5162-5163	{	_	_
29-258	5168-5169	'	_	_
29-259	5169-5175	epochs	_	_
29-260	5175-5176	'	_	_
29-261	5176-5177	:	_	_
29-262	5178-5179	1	_	_
29-263	5179-5180	\_	_	_
29-264	5180-5183	000	_	_
29-265	5183-5184	,	_	_
29-266	5185-5186	#	_	_
29-267	5187-5193	number	_	_
29-268	5194-5196	of	_	_
29-269	5197-5203	epochs	_	_
29-270	5204-5207	for	_	_
29-271	5208-5216	training	_	_
29-272	5221-5222	'	_	_
29-273	5222-5243	early\_stopping\_epochs	_	_
29-274	5243-5244	'	_	_
29-275	5244-5245	:	_	_
29-276	5246-5248	25	_	_
29-277	5248-5249	,	_	_
29-278	5250-5251	#	_	_
29-279	5252-5260	patience	_	_
29-280	5261-5264	for	_	_
29-281	5265-5270	early	_	_
29-282	5271-5279	stopping	_	_
29-283	5280-5281	(	_	_
29-284	5281-5285	best	_	_
29-285	5286-5293	weights	_	_
29-286	5294-5297	are	_	_
29-287	5298-5306	restored	_	_
29-288	5306-5307	)	_	_
29-289	5312-5313	'	_	_
29-290	5313-5323	batch\_size	_	_
29-291	5323-5324	'	_	_
29-292	5324-5325	:	_	_
29-293	5326-5328	64	_	_
29-294	5328-5329	,	_	_
29-295	5331-5332	#	_	_
29-296	5333-5338	batch	_	_
29-297	5339-5343	size	_	_
29-298	5344-5347	for	_	_
29-299	5348-5356	training	_	_
29-300	5362-5363	'	_	_
29-301	5363-5370	cat\_idx	_	_
29-302	5370-5371	'	_	_
29-303	5371-5372	:	_	_
29-304	5373-5400	categorical\_feature\_indices	_	_
29-305	5400-5401	,	_	_
29-306	5402-5403	#	_	_
29-307	5404-5407	put	_	_
29-308	5408-5412	list	_	_
29-309	5413-5415	of	_	_
29-310	5416-5427	categorical	_	_
29-311	5428-5435	indices	_	_
29-312	5440-5441	'	_	_
29-313	5441-5450	objective	_	_
29-314	5450-5451	'	_	_
29-315	5451-5452	:	_	_
29-316	5453-5454	'	_	_
29-317	5454-5460	binary	_	_
29-318	5460-5461	'	_	_
29-319	5461-5462	,	_	_
29-320	5463-5464	#	_	_
29-321	5465-5474	objective	_	_
29-322	5475-5476	/	_	_
29-323	5477-5481	task	_	_
29-324	5482-5483	{	_	_
29-325	5483-5484	'	_	_
29-326	5484-5490	binary	_	_
29-327	5490-5491	'	_	_
29-328	5491-5492	,	_	_
29-329	5493-5494	'	_	_
29-330	5494-5508	classification	_	_
29-331	5508-5509	'	_	_
29-332	5509-5510	,	_	_
29-333	5511-5512	'	_	_
29-334	5512-5522	regression	_	_
29-335	5522-5523	'	_	_
29-336	5523-5524	}	_	_
29-337	5534-5535	'	_	_
29-338	5535-5546	random\_seed	_	_
29-339	5546-5547	'	_	_
29-340	5547-5548	:	_	_
29-341	5549-5551	42	_	_
29-342	5551-5552	,	_	_
29-343	5557-5558	'	_	_
29-344	5558-5565	verbose	_	_
29-345	5565-5566	'	_	_
29-346	5566-5567	:	_	_
29-347	5568-5569	1	_	_
29-348	5569-5570	,	_	_
29-349	5578-5579	}	_	_
29-350	5581-5593	model\_grande	_	_
29-351	5594-5595	=	_	_
29-352	5596-5602	GRANDE	_	_
29-353	5602-5603	(	_	_
29-354	5603-5609	params	_	_
29-355	5609-5610	=	_	_
29-356	5610-5616	params	_	_
29-357	5616-5617	,	_	_
29-358	5618-5622	args	_	_
29-359	5622-5623	=	_	_
29-360	5623-5627	args	_	_
29-361	5627-5628	)	_	_
29-362	5630-5646	model\_grande.fit	_	_
29-363	5646-5647	(	_	_
29-364	5647-5654	X\_train	_	_
29-365	5654-5655	=	_	_
29-366	5655-5662	X\_train	_	_
29-367	5662-5663	,	_	_
29-368	5674-5681	y\_train	_	_
29-369	5681-5682	=	_	_
29-370	5682-5689	y\_train	_	_
29-371	5689-5690	,	_	_
29-372	5701-5706	X\_val	_	_
29-373	5706-5707	=	*[16]	PROJECT[16]
29-374	5707-5714	X\_valid	*[16]	PROJECT[16]
29-375	5714-5715	,	*[16]	PROJECT[16]
29-376	5726-5731	y\_val	*[16]	PROJECT[16]
29-377	5731-5732	=	*[16]	PROJECT[16]
29-378	5732-5739	y\_valid	*[16]	PROJECT[16]
29-379	5739-5740	)	*[16]	PROJECT[16]
29-380	5742-5754	preds\_grande	*[16]	PROJECT[16]
29-381	5755-5756	=	*[16]	PROJECT[16]
29-382	5757-5777	model\_grande.predict	*[16]	PROJECT[16]
29-383	5777-5778	(	*[16]	PROJECT[16]
29-384	5778-5784	X\_test	*[16]	PROJECT[16]
29-385	5784-5785	)	*[16]	PROJECT[16]
29-386	5787-5788	`	*[16]	PROJECT[16]
29-387	5788-5789	`	*[16]	PROJECT[16]
29-388	5789-5790	`	*[16]	PROJECT[16]
29-389	5792-5793	#	*[16]	PROJECT[16]
29-390	5793-5794	#	*[16]	PROJECT[16]
29-391	5794-5795	#	*[16]	PROJECT[16]
29-392	5796-5804	Evaluate	*[16]	PROJECT[16]
29-393	5805-5810	Model	*[16]	PROJECT[16]
29-394	5812-5813	`	*[16]	PROJECT[16]
29-395	5813-5814	`	*[16]	PROJECT[16]
29-396	5814-5815	`	*[16]	PROJECT[16]
29-397	5815-5821	python	*[16]	PROJECT[16]
29-398	5822-5827	preds	*[16]	PROJECT[16]
29-399	5828-5829	=	*[16]	PROJECT[16]
29-400	5830-5850	model\_grande.predict	*[16]	PROJECT[16]
29-401	5850-5851	(	*[16]	PROJECT[16]
29-402	5851-5857	X\_test	*[16]	PROJECT[16]
29-403	5857-5858	)	*[16]	PROJECT[16]
29-404	5860-5862	if	*[16]	PROJECT[16]
29-405	5863-5867	args	*[16]	PROJECT[16]
29-406	5867-5868	\[	*[16]	PROJECT[16]
29-407	5868-5869	'	*[16]	PROJECT[16]
29-408	5869-5878	objective	*[16]	PROJECT[16]
29-409	5878-5879	'	*[16]	PROJECT[16]
29-410	5879-5880	\]	*[16]	PROJECT[16]
29-411	5881-5882	=	*[16]	PROJECT[16]
29-412	5882-5883	=	*[16]	PROJECT[16]
29-413	5884-5885	'	*[16]	PROJECT[16]
29-414	5885-5891	binary	*[16]	PROJECT[16]
29-415	5891-5892	'	*[16]	PROJECT[16]
29-416	5892-5893	:	*[16]	PROJECT[16]
29-417	5898-5906	accuracy	*[16]	PROJECT[16]
29-418	5907-5908	=	*[16]	PROJECT[16]
29-419	5909-5939	sklearn.metrics.accuracy\_score	*[16]	PROJECT[16]
29-419	5925-5939	accuracy\_score	*[16]	PROJECT[16]
29-420	5939-5940	(	*[16]	PROJECT[16]
29-421	5940-5946	y\_test	*[16]	PROJECT[16]
29-422	5946-5947	,	*[16]	PROJECT[16]
29-423	5948-5956	np.round	*[16]	PROJECT[16]
29-424	5956-5957	(	*[16]	PROJECT[16]
29-425	5957-5969	preds\_grande	*[16]	PROJECT[16]
29-426	5969-5970	\[	*[16]	PROJECT[16]
29-427	5970-5971	:	*[16]	PROJECT[16]
29-428	5971-5972	,	*[16]	PROJECT[16]
29-429	5972-5973	1	*[16]	PROJECT[16]
29-430	5973-5974	\]	*[16]	PROJECT[16]
29-431	5974-5975	)	*[16]	PROJECT[16]
29-432	5975-5976	)	*[16]	PROJECT[16]
29-433	5981-5983	f1	*[16]	PROJECT[16]
29-434	5983-5984	\_	*[16]	PROJECT[16]
29-435	5984-5989	score	*[16]	PROJECT[16]
29-436	5990-5991	=	*[16]	PROJECT[16]
29-437	5992-6010	sklearn.metrics.f1	*[16]	PROJECT[16]
29-437	6008-6010	f1	*[16]	PROJECT[16]
29-438	6010-6011	\_	*[16]	PROJECT[16]
29-439	6011-6016	score	*[16]	PROJECT[16]
29-440	6016-6017	(	*[16]	PROJECT[16]
29-441	6017-6023	y\_test	*[16]	PROJECT[16]
29-442	6023-6024	,	*[16]	PROJECT[16]
29-443	6025-6033	np.round	*[16]	PROJECT[16]
29-444	6033-6034	(	*[16]	PROJECT[16]
29-445	6034-6046	preds\_grande	*[16]	PROJECT[16]
29-446	6046-6047	\[	*[16]	PROJECT[16]
29-447	6047-6048	:	*[16]	PROJECT[16]
29-448	6048-6049	,	*[16]	PROJECT[16]
29-449	6049-6050	1	*[16]	PROJECT[16]
29-450	6050-6051	\]	*[16]	PROJECT[16]
29-451	6051-6052	)	*[16]	PROJECT[16]
29-452	6052-6053	,	*[16]	PROJECT[16]
29-453	6054-6061	average	*[16]	PROJECT[16]
29-454	6061-6062	=	*[16]	PROJECT[16]
29-455	6062-6063	'	*[16]	PROJECT[16]
29-456	6063-6068	macro	*[16]	PROJECT[16]
29-457	6068-6069	'	*[16]	PROJECT[16]
29-458	6069-6070	)	*[16]	PROJECT[16]
29-459	6075-6082	roc\_auc	*[16]	PROJECT[16]
29-460	6083-6084	=	*[16]	PROJECT[16]
29-461	6085-6114	sklearn.metrics.roc\_auc\_score	*[16]	PROJECT[16]
29-461	6101-6114	roc\_auc\_score	*[16]	PROJECT[16]
29-462	6114-6115	(	*[16]	PROJECT[16]
29-463	6115-6121	y\_test	*[16]	PROJECT[16]
29-464	6121-6122	,	*[16]	PROJECT[16]
29-465	6123-6135	preds\_grande	*[16]	PROJECT[16]
29-466	6135-6136	\[	*[16]	PROJECT[16]
29-467	6136-6137	:	*[16]	PROJECT[16]
29-468	6137-6138	,	*[16]	PROJECT[16]
29-469	6138-6139	1	*[16]	PROJECT[16]
29-470	6139-6140	\]	*[16]	PROJECT[16]
29-471	6140-6141	,	*[16]	PROJECT[16]
29-472	6142-6149	average	*[16]	PROJECT[16]
29-473	6149-6150	=	*[16]	PROJECT[16]
29-474	6150-6151	'	*[16]	PROJECT[16]
29-475	6151-6156	macro	*[16]	PROJECT[16]
29-476	6156-6157	'	*[16]	PROJECT[16]
29-477	6157-6158	)	*[16]	PROJECT[16]
29-478	6168-6173	print	*[16]	PROJECT[16]
29-479	6173-6174	(	*[16]	PROJECT[16]
29-480	6174-6175	'	*[16]	PROJECT[16]
29-481	6175-6183	Accuracy	*[16]	PROJECT[16]
29-482	6183-6184	:	*[16]	PROJECT[16]
29-483	6184-6185	'	*[16]	PROJECT[16]
29-484	6185-6186	,	*[16]	PROJECT[16]
29-485	6187-6195	accuracy	*[16]	PROJECT[16]
29-486	6195-6196	)	*[16]	PROJECT[16]
29-487	6201-6206	print	*[16]	PROJECT[16]
29-488	6206-6207	(	*[16]	PROJECT[16]
29-489	6207-6208	'	*[16]	PROJECT[16]
29-490	6208-6210	F1	*[16]	PROJECT[16]
29-491	6211-6216	Score	*[16]	PROJECT[16]
29-492	6216-6217	:	*[16]	PROJECT[16]
29-493	6217-6218	'	*[16]	PROJECT[16]
29-494	6218-6219	,	*[16]	PROJECT[16]
29-495	6220-6222	f1	*[16]	PROJECT[16]
29-496	6222-6223	\_	*[16]	PROJECT[16]
29-497	6223-6228	score	*[16]	PROJECT[16]
29-498	6228-6229	)	*[16]	PROJECT[16]
29-499	6234-6239	print	*[16]	PROJECT[16]
29-500	6239-6240	(	*[16]	PROJECT[16]
29-501	6240-6241	'	*[16]	PROJECT[16]
29-502	6241-6244	ROC	*[16]	PROJECT[16]
29-503	6245-6248	AUC	*[16]	PROJECT[16]
29-504	6248-6249	:	*[16]	PROJECT[16]
29-505	6249-6250	'	*[16]	PROJECT[16]
29-506	6250-6251	,	*[16]	PROJECT[16]
29-507	6252-6259	roc\_auc	*[16]	PROJECT[16]
29-508	6259-6260	)	*[16]	PROJECT[16]
29-509	6261-6265	elif	*[16]	PROJECT[16]
29-510	6266-6270	args	*[16]	PROJECT[16]
29-511	6270-6271	\[	*[16]	PROJECT[16]
29-512	6271-6272	'	*[16]	PROJECT[16]
29-513	6272-6281	objective	*[16]	PROJECT[16]
29-514	6281-6282	'	*[16]	PROJECT[16]
29-515	6282-6283	\]	*[16]	PROJECT[16]
29-516	6284-6285	=	*[16]	PROJECT[16]
29-517	6285-6286	=	*[16]	PROJECT[16]
29-518	6287-6288	'	*[16]	PROJECT[16]
29-519	6288-6302	classification	*[16]	PROJECT[16]
29-520	6302-6303	'	*[16]	PROJECT[16]
29-521	6303-6304	:	*[16]	PROJECT[16]
29-522	6309-6317	accuracy	*[16]	PROJECT[16]
29-523	6318-6319	=	*[16]	PROJECT[16]
29-524	6320-6350	sklearn.metrics.accuracy\_score	*[16]	PROJECT[16]
29-524	6336-6350	accuracy\_score	*[16]	PROJECT[16]
29-525	6350-6351	(	*[16]	PROJECT[16]
29-526	6351-6357	y\_test	*[16]	PROJECT[16]
29-527	6357-6358	,	*[16]	PROJECT[16]
29-528	6359-6368	np.argmax	*[16]	PROJECT[16]
29-529	6368-6369	(	*[16]	PROJECT[16]
29-530	6369-6381	preds\_grande	*[16]	PROJECT[16]
29-531	6381-6382	,	*[16]	PROJECT[16]
29-532	6383-6387	axis	*[16]	PROJECT[16]
29-533	6387-6388	=	*[16]	PROJECT[16]
29-534	6388-6389	1	*[16]	PROJECT[16]
29-535	6389-6390	)	*[16]	PROJECT[16]
29-536	6390-6391	)	*[16]	PROJECT[16]
29-537	6396-6398	f1	*[16]	PROJECT[16]
29-538	6398-6399	\_	*[16]	PROJECT[16]
29-539	6399-6404	score	*[16]	PROJECT[16]
29-540	6405-6406	=	*[16]	PROJECT[16]
29-541	6407-6425	sklearn.metrics.f1	*[16]	PROJECT[16]
29-541	6423-6425	f1	*[16]	PROJECT[16]
29-542	6425-6426	\_	*[16]	PROJECT[16]
29-543	6426-6431	score	*[16]	PROJECT[16]
29-544	6431-6432	(	*[16]	PROJECT[16]
29-545	6432-6438	y\_test	*[16]	PROJECT[16]
29-546	6438-6439	,	*[16]	PROJECT[16]
29-547	6440-6449	np.argmax	*[16]	PROJECT[16]
29-548	6449-6450	(	*[16]	PROJECT[16]
29-549	6450-6462	preds\_grande	*[16]	PROJECT[16]
29-550	6462-6463	,	*[16]	PROJECT[16]
29-551	6464-6468	axis	*[16]	PROJECT[16]
29-552	6468-6469	=	*[16]	PROJECT[16]
29-553	6469-6470	1	*[16]	PROJECT[16]
29-554	6470-6471	)	*[16]	PROJECT[16]
29-555	6471-6472	,	*[16]	PROJECT[16]
29-556	6473-6480	average	*[16]	PROJECT[16]
29-557	6480-6481	=	*[16]	PROJECT[16]
29-558	6481-6482	'	*[16]	PROJECT[16]
29-559	6482-6487	macro	*[16]	PROJECT[16]
29-560	6487-6488	'	*[16]	PROJECT[16]
29-561	6488-6489	)	*[16]	PROJECT[16]
29-562	6494-6501	roc\_auc	*[16]	PROJECT[16]
29-563	6502-6503	=	*[16]	PROJECT[16]
29-564	6504-6533	sklearn.metrics.roc\_auc\_score	_	_
29-564	6520-6533	roc\_auc\_score	_	_
29-565	6533-6534	(	_	_
29-566	6534-6540	y\_test	_	_
29-567	6540-6541	,	_	_
29-568	6542-6554	preds\_grande	_	_
29-569	6554-6555	,	_	_
29-570	6556-6563	average	_	_
29-571	6563-6564	=	_	_
29-572	6564-6565	'	_	_
29-573	6565-6570	macro	_	_
29-574	6570-6571	'	_	_
29-575	6571-6572	,	_	_
29-576	6573-6584	multi\_class	_	_
29-577	6584-6585	=	_	_
29-578	6585-6586	'	_	_
29-579	6586-6589	ovo	_	_
29-580	6589-6590	'	_	_
29-581	6590-6591	,	_	_
29-582	6592-6598	labels	_	_
29-583	6598-6599	=	_	_
29-584	6599-6600	\[	_	_
29-585	6600-6601	i	_	_
29-586	6602-6605	for	_	_
29-587	6606-6607	i	_	_
29-588	6608-6610	in	_	_
29-589	6611-6616	range	_	_
29-590	6616-6617	(	_	_
29-591	6617-6635	preds\_grande.shape	_	_
29-592	6635-6636	\[	_	_
29-593	6636-6637	1	_	_
29-594	6637-6638	\]	_	_
29-595	6638-6639	)	_	_
29-596	6639-6640	\]	_	_
29-597	6640-6641	)	_	_
29-598	6647-6652	print	_	_
29-599	6652-6653	(	_	_
29-600	6653-6654	'	_	_
29-601	6654-6662	Accuracy	_	_
29-602	6663-6669	GRANDE	_	_
29-603	6669-6670	:	_	_
29-604	6670-6671	'	_	_
29-605	6671-6672	,	_	_
29-606	6673-6681	accuracy	_	_
29-607	6681-6682	)	_	_
29-608	6687-6692	print	_	_
29-609	6692-6693	(	_	_
29-610	6693-6694	'	_	_
29-611	6694-6696	F1	_	_
29-612	6697-6702	Score	_	_
29-613	6703-6709	GRANDE	_	_
29-614	6709-6710	:	_	_
29-615	6710-6711	'	_	_
29-616	6711-6712	,	_	_
29-617	6713-6715	f1	_	_
29-618	6715-6716	\_	_	_
29-619	6716-6721	score	_	_
29-620	6721-6722	)	_	_
29-621	6727-6732	print	_	_
29-622	6732-6733	(	_	_
29-623	6733-6734	'	_	_
29-624	6734-6737	ROC	_	_
29-625	6738-6741	AUC	_	_
29-626	6742-6748	GRANDE	_	_
29-627	6748-6749	:	_	_
29-628	6749-6750	'	_	_
29-629	6750-6751	,	_	_
29-630	6752-6759	roc\_auc	_	_
29-631	6759-6760	)	_	_
29-632	6761-6765	else	_	_
29-633	6765-6766	:	_	_
29-634	6771-6790	mean\_absolute\_error	_	_
29-635	6791-6792	=	_	_
29-636	6793-6828	sklearn.metrics.mean\_absolute\_error	_	_
29-636	6809-6828	mean\_absolute\_error	_	_
29-637	6828-6829	(	_	_
29-638	6829-6835	y\_test	_	_
29-639	6835-6836	,	_	_
29-640	6837-6845	np.round	_	_
29-641	6845-6846	(	_	_
29-642	6846-6858	preds\_grande	_	_
29-643	6858-6859	)	_	_
29-644	6859-6860	)	_	_
29-645	6865-6867	r2	_	_
29-646	6867-6868	\_	_	_
29-647	6868-6873	score	_	_
29-648	6874-6875	=	_	_
29-649	6876-6894	sklearn.metrics.r2	_	_
29-649	6892-6894	r2	_	_
29-650	6894-6895	\_	_	_
29-651	6895-6900	score	_	_
29-652	6900-6901	(	_	_
29-653	6901-6907	y\_test	_	_
29-654	6907-6908	,	_	_
29-655	6909-6917	np.round	_	_
29-656	6917-6918	(	_	_
29-657	6918-6930	preds\_grande	_	_
29-658	6930-6931	)	_	_
29-659	6931-6932	)	_	_
29-660	6938-6943	print	_	_
29-661	6943-6944	(	_	_
29-662	6944-6945	'	_	_
29-663	6945-6948	MAE	_	_
29-664	6949-6955	GRANDE	_	_
29-665	6955-6956	:	_	_
29-666	6956-6957	'	_	_
29-667	6957-6958	,	_	_
29-668	6959-6978	mean\_absolute\_error	_	_
29-669	6978-6979	)	_	_
29-670	6984-6989	print	_	_
29-671	6989-6990	(	_	_
29-672	6990-6991	'	_	_
29-673	6991-6993	R2	_	_
29-674	6994-6999	Score	_	_
29-675	7000-7006	GRANDE	_	_
29-676	7006-7007	:	_	_
29-677	7007-7008	'	_	_
29-678	7008-7009	,	_	_
29-679	7010-7012	r2	_	_
29-680	7012-7013	\_	_	_
29-681	7013-7018	score	_	_
29-682	7018-7019	)	_	_
29-683	7020-7021	`	_	_
29-684	7021-7022	`	_	_
29-685	7022-7023	`	_	_
29-686	7025-7026	#	_	_
29-687	7026-7027	#	_	_
29-688	7028-7032	More	_	_
29-689	7034-7040	Please	_	_
29-690	7041-7045	note	_	_
29-691	7046-7050	that	_	_
29-692	7051-7055	this	_	_
29-693	7056-7058	is	_	_
29-694	7059-7061	an	_	_
29-695	7062-7074	experimental	_	_
29-696	7075-7089	implementation	_	_
29-697	7090-7095	which	_	_
29-698	7096-7098	is	_	_
29-699	7099-7102	not	_	_
29-700	7103-7108	fully	_	_
29-701	7109-7115	tested	_	_
29-702	7116-7119	yet	_	_
29-703	7119-7120	.	_	_

#Text=If you encounter any errors, or you observe unexpected behavior, please let me know.
30-1	7121-7123	If	_	_
30-2	7124-7127	you	_	_
30-3	7128-7137	encounter	_	_
30-4	7138-7141	any	_	_
30-5	7142-7148	errors	_	_
30-6	7148-7149	,	_	_
30-7	7150-7152	or	_	_
30-8	7153-7156	you	_	_
30-9	7157-7164	observe	_	_
30-10	7165-7175	unexpected	_	_
30-11	7176-7184	behavior	_	_
30-12	7184-7185	,	*[11]	ONTOLOGY[11]
30-13	7186-7192	please	_	_
30-14	7193-7196	let	_	_
30-15	7197-7199	me	_	_
30-16	7200-7204	know	_	_
30-17	7204-7205	.	_	_