Use the above training scripts and set `--epochs` to be 0 for evaluation. ### Retrieval Results | val `<EVALMETRIC>Recall@100</EVALMETRIC>` | test `<EVALMETRIC>Recall@100</EVALMETRIC>` | val `<EVALMETRIC>LRAP</EVALMETRIC>` | test `<EVALMETRIC>LRAP</EVALMETRIC>` | val passage-level `<EVALMETRIC>Recall@100</EVALMETRIC>` | test passage-level `<EVALMETRIC>Recall@100</EVALMETRIC>`| |:----------------:|:-----------------:|:----------:|:-----------:|:---------------------:|:---------------------:| |     98.17%     |     96.62%      |  83.98%  |  82.65%   |      97.03%         |        94.59%       |   **<EVALMETRIC>Recall@k</EVALMETRIC>** is the percentage of total number of positive entities retrieved by the topk candidates with respect to the total number of gold entities for all the query passages. \ **passage-level `<EVALMETRIC>Recall@k</EVALMETRIC>** is the percentage of the number of passages with all the gold entities retrieved in the topk candidates with respect to the number of passages. \ **<EVALMETRIC>LRAP</EVALMETRIC>** is [Label ranking average precision ](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.label_ranking_average_precision_score.html) which measures the multi-label ranking performance.    ## Train Reader   Train reader by  ``` <PROGLANG>python</PROGLANG> run_reader.py  \ --model /model_reader/reader.pt   --data_dir /reader_input/  \ --C 64  --B 2  --L 180  --C_val 100  --gpus 0,1   --val_bsz 32 \ --gradient_accumulation_steps 2  --warmup_proportion 0.06  \ --epochs 4  --lr 1e-5 --thresd  0.05  --logging_steps 100  \ --k 3  --stride 16 --max_passage_len 32  --filter_span  \ --type_encoder squad2_electra_large  \ --type_span_loss sum_log  --type_rank_loss sum_log  \ --do_rerank  --add_topic  --results_dir /reader_results/  --kb_dir /kb/  ``` It takes about 6 hours on 2 A100 GPUs to finish the reader training experiment.
