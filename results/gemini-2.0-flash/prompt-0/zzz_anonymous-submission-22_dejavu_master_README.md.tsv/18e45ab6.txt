Run experiments in the shell of the <SOFTWARE>Docker</SOFTWARE> container following the usage table as follows.   ### Usage |Algorithm|Usage| |---|---| |DejaVu|Run for dataset A1: `python exp/run_GAT_node_classification.py -H=4 -L=8 -fe=GRU -bal=True --data_dir=data/A1`| |JSS'20|Run for dataset A1: `python exp/DejaVu/run_JSS20.py --data_dir=data/A1`| |iSQUAD|Run for dataset A1: `python exp/DejaVu/run_iSQ.py --data_dir=data/A1`| |Decision Tree|Run for dataset A1: `python exp/run_DT_node_classification.py --data_dir=data/A1`| |RandomWalk@Metric|Run for dataset A1: `python exp/DejaVu/run_random_walk_single_metric.py --data_dir=data/A1 --window_size 60 10 --score_aggregation_method=min`| |RandomWalk@FI|Run for dataset A1: `python exp/DejaVu/run_random_walk_failure_instance.py --data_dir=data/A1 --window_size 60 10 --anomaly_score_aggregation_method=min --corr_aggregation_method=max`| |Global interpretation|Run `notebooks/explain.py` as a jupyter notebook with `jupytext`| |Local interpretation|`DejaVu/explanability/similar_faults.py`|  The commands would print a `one-line summary` in the end, including the following fields: `A@1`, `A@2`, `A@3`, `A@5`, `<EVALMETRIC>MAR</EVALMETRIC>`, `Time`, `Epoch`, `Valid Epoch`, `output_dir`, `val_loss`, `val_<EVALMETRIC>MAR</EVALMETRIC>`, `val_A@1`, `command`, `git_commit_url`, which are the desrired results.
