Run following script to setup `cache` directory: ``` sh scripts/prepare_data.sh ``` This should generate following files under `cache` directory: - vocabulary file: `std_vocab_<DATASET>_<split_by>.txt` - selected GloVe feature: `std_glove_<DATASET>_<split_by>.npy` - referring expression database: `std_refdb_<DATASET>_<split_by>.json` - critical objects database: `std_ctxdb_<DATASET>_<split_by>.json` ## Train **Train with binary XE loss:** ``` PYTHONPATH=$PWD <PROGLANG>python</PROGLANG> tools/train_att_vanilla.py --dataset refcoco --split-by unc ``` **Train with ranking loss:** ``` PYTHONPATH=$PWD <PROGLANG>python</PROGLANG> tools/train_att_rank.py --dataset refcoco --split-by unc ``` We use tensorboard to monitor the training process.
