#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Neural Jump Ordinary Differential Equations  \[!
1-1	0-1	#	*[0]	SOFTWARE[0]
1-2	2-8	Neural	*[0]	SOFTWARE[0]
1-3	9-13	Jump	*[0]	SOFTWARE[0]
1-4	14-22	Ordinary	*[0]	SOFTWARE[0]
1-5	23-35	Differential	*[0]	SOFTWARE[0]
1-6	36-45	Equations	*[0]	SOFTWARE[0]
1-7	47-48	\[	*[0]	SOFTWARE[0]
1-8	48-49	!	*[0]	SOFTWARE[0]

#Text=\[DOI\](https://zenodo.org/badge/269355048.svg)\](https://zenodo.org/badge/latestdoi/269355048)  This repository is the official implementation of  \[Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering\](https://openreview.net/forum?
2-1	49-50	\[	*[0]	SOFTWARE[0]
2-2	50-53	DOI	*[0]	SOFTWARE[0]
2-3	53-54	\]	*[0]	SOFTWARE[0]
2-4	54-55	(	*[0]	SOFTWARE[0]
2-5	55-60	https	*[0]	SOFTWARE[0]
2-6	60-61	:	*[0]	SOFTWARE[0]
2-7	61-62	/	*[0]	SOFTWARE[0]
2-8	62-63	/	*[0]	SOFTWARE[0]
2-9	63-73	zenodo.org	*[0]	SOFTWARE[0]
2-10	73-74	/	*[0]	SOFTWARE[0]
2-11	74-79	badge	_	_
2-12	79-80	/	_	_
2-13	80-89	269355048	_	_
2-14	89-90	.	_	_
2-15	90-93	svg	_	_
2-16	93-94	)	_	_
2-17	94-95	\]	_	_
2-18	95-96	(	_	_
2-19	96-101	https	_	_
2-20	101-102	:	_	_
2-21	102-103	/	_	_
2-22	103-104	/	_	_
2-23	104-114	zenodo.org	_	_
2-24	114-115	/	_	_
2-25	115-120	badge	_	_
2-26	120-121	/	_	_
2-27	121-130	latestdoi	_	_
2-28	130-131	/	_	_
2-29	131-140	269355048	_	_
2-30	140-141	)	_	_
2-31	143-147	This	_	_
2-32	148-158	repository	_	_
2-33	159-161	is	_	_
2-34	162-165	the	_	_
2-35	166-174	official	_	_
2-36	175-189	implementation	_	_
2-37	190-192	of	_	_
2-38	194-195	\[	_	_
2-39	195-201	Neural	*[1]	PUBLICATION[1]
2-40	202-206	Jump	*[1]	PUBLICATION[1]
2-41	207-215	Ordinary	*[1]	PUBLICATION[1]
2-42	216-228	Differential	*[1]	PUBLICATION[1]
2-43	229-238	Equations	*[1]	PUBLICATION[1]
2-44	238-239	:	*[1]	PUBLICATION[1]
2-45	240-250	Consistent	*[1]	PUBLICATION[1]
2-46	251-266	Continuous-Time	*[1]	PUBLICATION[1]
2-47	267-277	Prediction	*[1]	PUBLICATION[1]
2-48	278-281	and	*[1]	PUBLICATION[1]
2-49	282-291	Filtering	*[1]	PUBLICATION[1]
2-50	291-292	\]	_	_
2-51	292-293	(	_	_
2-52	293-298	https	_	_
2-53	298-299	:	_	_
2-54	299-300	/	_	_
2-55	300-301	/	_	_
2-56	301-315	openreview.net	_	_
2-57	315-316	/	_	_
2-58	316-321	forum	_	_
2-59	321-322	?	_	_

#Text=id=JFKR3WqwyXR).
3-1	322-324	id	_	_
3-2	324-325	=	_	_
3-3	325-336	JFKR3WqwyXR	_	_
3-4	336-337	)	_	_
3-5	337-338	.	_	_

#Text=For a short summary of the paper see our video-presentation at the  \[ICLR conference\](https://iclr.cc/virtual/2021/poster/3339).
4-1	341-344	For	_	_
4-2	345-346	a	_	_
4-3	347-352	short	_	_
4-4	353-360	summary	_	_
4-5	361-363	of	_	_
4-6	364-367	the	_	_
4-7	368-373	paper	_	_
4-8	374-377	see	_	_
4-9	378-381	our	_	_
4-10	382-400	video-presentation	_	_
4-11	401-403	at	_	_
4-12	404-407	the	_	_
4-13	409-410	\[	_	_
4-14	410-414	ICLR	*	CONFERENCE
4-15	415-425	conference	_	_
4-16	425-426	\]	_	_
4-17	426-427	(	_	_
4-18	427-432	https	_	_
4-19	432-433	:	_	_
4-20	433-434	/	_	_
4-21	434-435	/	_	_
4-22	435-442	iclr.cc	_	_
4-22	435-439	iclr	*	CONFERENCE
4-23	442-443	/	_	_
4-24	443-450	virtual	_	_
4-25	450-451	/	_	_
4-26	451-455	2021	_	_
4-27	455-456	/	_	_
4-28	456-462	poster	_	_
4-29	462-463	/	_	_
4-30	463-467	3339	_	_
4-31	467-468	)	_	_
4-32	468-469	.	_	_

#Text=Below we also provide the poster summarizing our work that we presented there.  !
5-1	470-475	Below	_	_
5-2	476-478	we	_	_
5-3	479-483	also	_	_
5-4	484-491	provide	_	_
5-5	492-495	the	_	_
5-6	496-502	poster	_	_
5-7	503-514	summarizing	_	_
5-8	515-518	our	_	_
5-9	519-523	work	_	_
5-10	524-528	that	_	_
5-11	529-531	we	_	_
5-12	532-541	presented	_	_
5-13	542-547	there	_	_
5-14	547-548	.	_	_
5-15	550-551	!	_	_

#Text=\[alt text\](ICLR-conference-material/NJODE\_poster.png)    ## Requirements  This code was executed using Python 3.7.
6-1	551-552	\[	_	_
6-2	552-555	alt	_	_
6-3	556-560	text	_	_
6-4	560-561	\]	_	_
6-5	561-562	(	_	_
6-6	562-586	ICLR-conference-material	_	_
6-6	562-566	ICLR	*	CONFERENCE
6-7	586-587	/	_	_
6-8	587-603	NJODE\_poster.png	_	_
6-9	603-604	)	_	_
6-10	608-609	#	_	_
6-11	609-610	#	_	_
6-12	611-623	Requirements	_	_
6-13	625-629	This	_	_
6-14	630-634	code	_	_
6-15	635-638	was	_	_
6-16	639-647	executed	_	_
6-17	648-653	using	_	_
6-18	654-660	Python	*[2]	SOFTWARE[2]
6-19	661-664	3.7	*[2]	SOFTWARE[2]
6-20	664-665	.	_	_

#Text=To install requirements, download this Repo and cd into it.
7-1	667-669	To	_	_
7-2	670-677	install	_	_
7-3	678-690	requirements	_	_
7-4	690-691	,	_	_
7-5	692-700	download	_	_
7-6	701-705	this	_	_
7-7	706-710	Repo	_	_
7-8	711-714	and	_	_
7-9	715-717	cd	_	_
7-10	718-722	into	_	_
7-11	723-725	it	_	_
7-12	725-726	.	_	_

#Text=Then:  ```setup pip install -r requirements.txt ```   ## Training & Testing  To train and test the model(s) of the paper, run these commands (other  hyperparameters can be changed in the main section of demo.py):  go to the source directory: ```train cd NJODE ```  for Black-Scholes model: ```train python demo.py --dataset='BlackScholes' ```  for Heston model: ```train python demo.py --dataset='Heston' ```  for Ornstein-Uhlenbeck model: ```train python demo.py --dataset='OrnsteinUhlenbeck' ```  If no dataset for the model was generated yet, it will be generated  automatically before the training starts.
8-1	727-731	Then	_	_
8-2	731-732	:	_	_
8-3	734-735	`	_	_
8-4	735-736	`	_	_
8-5	736-737	`	_	_
8-6	737-742	setup	_	_
8-7	743-746	pip	_	_
8-8	747-754	install	_	_
8-9	755-756	-	_	_
8-10	756-757	r	_	_
8-11	758-774	requirements.txt	_	_
8-12	775-776	`	_	_
8-13	776-777	`	_	_
8-14	777-778	`	_	_
8-15	781-782	#	_	_
8-16	782-783	#	_	_
8-17	784-792	Training	_	_
8-18	793-794	&	_	_
8-19	795-802	Testing	_	_
8-20	804-806	To	_	_
8-21	807-812	train	_	_
8-22	813-816	and	_	_
8-23	817-821	test	_	_
8-24	822-825	the	_	_
8-25	826-831	model	_	_
8-26	831-832	(	_	_
8-27	832-833	s	_	_
8-28	833-834	)	_	_
8-29	835-837	of	_	_
8-30	838-841	the	_	_
8-31	842-847	paper	_	_
8-32	847-848	,	_	_
8-33	849-852	run	_	_
8-34	853-858	these	_	_
8-35	859-867	commands	_	_
8-36	868-869	(	_	_
8-37	869-874	other	_	_
8-38	876-891	hyperparameters	_	_
8-39	892-895	can	_	_
8-40	896-898	be	_	_
8-41	899-906	changed	_	_
8-42	907-909	in	_	_
8-43	910-913	the	_	_
8-44	914-918	main	_	_
8-45	919-926	section	_	_
8-46	927-929	of	_	_
8-47	930-937	demo.py	_	_
8-48	937-938	)	_	_
8-49	938-939	:	_	_
8-50	941-943	go	_	_
8-51	944-946	to	_	_
8-52	947-950	the	_	_
8-53	951-957	source	_	_
8-54	958-967	directory	_	_
8-55	967-968	:	_	_
8-56	969-970	`	_	_
8-57	970-971	`	_	_
8-58	971-972	`	_	_
8-59	972-977	train	_	_
8-60	978-980	cd	_	_
8-61	981-986	NJODE	_	_
8-62	987-988	`	_	_
8-63	988-989	`	_	_
8-64	989-990	`	_	_
8-65	992-995	for	_	_
8-66	996-1009	Black-Scholes	_	_
8-67	1010-1015	model	_	_
8-68	1015-1016	:	_	_
8-69	1017-1018	`	_	_
8-70	1018-1019	`	_	_
8-71	1019-1020	`	_	_
8-72	1020-1025	train	_	_
8-73	1026-1032	python	_	_
8-74	1033-1040	demo.py	_	_
8-75	1041-1042	-	_	_
8-76	1042-1043	-	_	_
8-77	1043-1050	dataset	_	_
8-78	1050-1051	=	_	_
8-79	1051-1052	'	_	_
8-80	1052-1064	BlackScholes	*	DATASET
8-81	1064-1065	'	_	_
8-82	1066-1067	`	_	_
8-83	1067-1068	`	_	_
8-84	1068-1069	`	_	_
8-85	1071-1074	for	_	_
8-86	1075-1081	Heston	_	_
8-87	1082-1087	model	_	_
8-88	1087-1088	:	_	_
8-89	1089-1090	`	_	_
8-90	1090-1091	`	_	_
8-91	1091-1092	`	_	_
8-92	1092-1097	train	_	_
8-93	1098-1104	python	_	_
8-94	1105-1112	demo.py	_	_
8-95	1113-1114	-	_	_
8-96	1114-1115	-	_	_
8-97	1115-1122	dataset	_	_
8-98	1122-1123	=	_	_
8-99	1123-1124	'	_	_
8-100	1124-1130	Heston	*	DATASET
8-101	1130-1131	'	_	_
8-102	1132-1133	`	_	_
8-103	1133-1134	`	_	_
8-104	1134-1135	`	_	_
8-105	1137-1140	for	_	_
8-106	1141-1159	Ornstein-Uhlenbeck	*	DATASET
8-107	1160-1165	model	_	_
8-108	1165-1166	:	_	_
8-109	1167-1168	`	_	_
8-110	1168-1169	`	_	_
8-111	1169-1170	`	_	_
8-112	1170-1175	train	_	_
8-113	1176-1182	python	_	_
8-114	1183-1190	demo.py	_	_
8-115	1191-1192	-	_	_
8-116	1192-1193	-	_	_
8-117	1193-1200	dataset	_	_
8-118	1200-1201	=	_	_
8-119	1201-1202	'	_	_
8-120	1202-1219	OrnsteinUhlenbeck	*	DATASET
8-121	1219-1220	'	_	_
8-122	1221-1222	`	_	_
8-123	1222-1223	`	_	_
8-124	1223-1224	`	_	_
8-125	1226-1228	If	_	_
8-126	1229-1231	no	_	_
8-127	1232-1239	dataset	_	_
8-128	1240-1243	for	_	_
8-129	1244-1247	the	_	_
8-130	1248-1253	model	_	_
8-131	1254-1257	was	_	_
8-132	1258-1267	generated	_	_
8-133	1268-1271	yet	_	_
8-134	1271-1272	,	_	_
8-135	1273-1275	it	_	_
8-136	1276-1280	will	_	_
8-137	1281-1283	be	_	_
8-138	1284-1293	generated	_	_
8-139	1295-1308	automatically	_	_
8-140	1309-1315	before	_	_
8-141	1316-1319	the	_	_
8-142	1320-1328	training	_	_
8-143	1329-1335	starts	_	_
8-144	1335-1336	.	_	_

#Text=ATTENTION: if you run the demo for a pretrained model first, a dataset with  only 100 samples (instead of 20'000) will be generated for plotting.
9-1	1337-1346	ATTENTION	_	_
9-2	1346-1347	:	_	_
9-3	1348-1350	if	_	_
9-4	1351-1354	you	_	_
9-5	1355-1358	run	_	_
9-6	1359-1362	the	_	_
9-7	1363-1367	demo	_	_
9-8	1368-1371	for	_	_
9-9	1372-1373	a	_	_
9-10	1374-1384	pretrained	_	_
9-11	1385-1390	model	_	_
9-12	1391-1396	first	_	_
9-13	1396-1397	,	_	_
9-14	1398-1399	a	_	_
9-15	1400-1407	dataset	_	_
9-16	1408-1412	with	_	_
9-17	1414-1418	only	_	_
9-18	1419-1422	100	_	_
9-19	1423-1430	samples	_	_
9-20	1431-1432	(	_	_
9-21	1432-1439	instead	_	_
9-22	1440-1442	of	_	_
9-23	1443-1449	20'000	_	_
9-24	1449-1450	)	_	_
9-25	1451-1455	will	_	_
9-26	1456-1458	be	_	_
9-27	1459-1468	generated	_	_
9-28	1469-1472	for	_	_
9-29	1473-1481	plotting	_	_
9-30	1481-1482	.	_	_

#Text=This should be deleted before training a new model, such that a bigger dataset is generated and used.
10-1	1483-1487	This	_	_
10-2	1488-1494	should	_	_
10-3	1495-1497	be	_	_
10-4	1498-1505	deleted	_	_
10-5	1506-1512	before	_	_
10-6	1513-1521	training	_	_
10-7	1522-1523	a	_	_
10-8	1524-1527	new	_	_
10-9	1528-1533	model	_	_
10-10	1533-1534	,	_	_
10-11	1535-1539	such	_	_
10-12	1540-1544	that	_	_
10-13	1545-1546	a	_	_
10-14	1547-1553	bigger	_	_
10-15	1554-1561	dataset	_	_
10-16	1562-1564	is	_	_
10-17	1565-1574	generated	_	_
10-18	1575-1578	and	_	_
10-19	1579-1583	used	_	_
10-20	1583-1584	.	_	_

#Text=The model is trained and concurrently saved and tested after every <save\_every> epoch.
11-1	1586-1589	The	_	_
11-2	1590-1595	model	_	_
11-3	1596-1598	is	_	_
11-4	1599-1606	trained	_	_
11-5	1607-1610	and	_	_
11-6	1611-1623	concurrently	_	_
11-7	1624-1629	saved	_	_
11-8	1630-1633	and	_	_
11-9	1634-1640	tested	_	_
11-10	1641-1646	after	_	_
11-11	1647-1652	every	_	_
11-12	1653-1654	<	_	_
11-13	1654-1664	save\_every	_	_
11-14	1664-1665	>	_	_
11-15	1666-1671	epoch	_	_
11-16	1671-1672	.	_	_

#Text=The plots that are generated are saved in "..
12-1	1673-1676	The	_	_
12-2	1677-1682	plots	_	_
12-3	1683-1687	that	_	_
12-4	1688-1691	are	_	_
12-5	1692-1701	generated	_	_
12-6	1702-1705	are	_	_
12-7	1706-1711	saved	_	_
12-8	1712-1714	in	_	_
12-9	1715-1716	"	_	_
12-10	1716-1717	.	_	_
12-11	1717-1718	.	_	_

#Text=/data/saved\_models/id-<model\_id>/plots/" and the training progress is printed.     ## Pre-trained Models  Pre-trained models for each of the 3 stochastic models are distributed with the code and saved in "..
13-1	1718-1719	/	_	_
13-2	1719-1723	data	_	_
13-3	1723-1724	/	_	_
13-4	1724-1736	saved\_models	_	_
13-5	1736-1737	/	_	_
13-6	1737-1739	id	_	_
13-7	1739-1740	-	_	_
13-8	1740-1741	<	_	_
13-9	1741-1749	model\_id	_	_
13-10	1749-1750	>	_	_
13-11	1750-1751	/	_	_
13-12	1751-1756	plots	_	_
13-13	1756-1757	/	_	_
13-14	1757-1758	"	_	_
13-15	1759-1762	and	_	_
13-16	1763-1766	the	_	_
13-17	1767-1775	training	_	_
13-18	1776-1784	progress	_	_
13-19	1785-1787	is	_	_
13-20	1788-1795	printed	_	_
13-21	1795-1796	.	_	_
13-22	1801-1802	#	_	_
13-23	1802-1803	#	_	_
13-24	1804-1815	Pre-trained	_	_
13-25	1816-1822	Models	_	_
13-26	1824-1835	Pre-trained	_	_
13-27	1836-1842	models	_	_
13-28	1843-1846	for	_	_
13-29	1847-1851	each	_	_
13-30	1852-1854	of	_	_
13-31	1855-1858	the	_	_
13-32	1859-1860	3	_	_
13-33	1861-1871	stochastic	_	_
13-34	1872-1878	models	_	_
13-35	1879-1882	are	_	_
13-36	1883-1894	distributed	_	_
13-37	1895-1899	with	_	_
13-38	1900-1903	the	_	_
13-39	1904-1908	code	_	_
13-40	1909-1912	and	_	_
13-41	1913-1918	saved	_	_
13-42	1919-1921	in	_	_
13-43	1922-1923	"	_	_
13-44	1923-1924	.	_	_
13-45	1924-1925	.	_	_

#Text=/data/saved\_models/id-x" for x=1,2,3.
14-1	1925-1926	/	_	_
14-2	1926-1930	data	_	_
14-3	1930-1931	/	_	_
14-4	1931-1943	saved\_models	_	_
14-5	1943-1944	/	_	_
14-6	1944-1948	id-x	_	_
14-7	1948-1949	"	_	_
14-8	1950-1953	for	_	_
14-9	1954-1955	x	_	_
14-10	1955-1956	=	_	_
14-11	1956-1961	1,2,3	_	_
14-12	1961-1962	.	_	_

#Text=These pre-trained models can be loaded and used to generate sample paths with  the following commands:  go to the source directory: ```demo cd controlled\_ODE\_RNN ```  - for Black-Scholes model: ```demo python demo.py --model\_id=1 ```  - for Heston model: ```demo python demo.py --model\_id=2 ```  - for Ornstein-Uhlenbeck model: ```demo python demo.py --model\_id=3 ```  If no dataset for the model was generated yet, a small version of the dataset  with 100 samples will be generated automatically, such that plots can be  produced.
15-1	1963-1968	These	_	_
15-2	1969-1980	pre-trained	_	_
15-3	1981-1987	models	_	_
15-4	1988-1991	can	_	_
15-5	1992-1994	be	_	_
15-6	1995-2001	loaded	_	_
15-7	2002-2005	and	_	_
15-8	2006-2010	used	_	_
15-9	2011-2013	to	_	_
15-10	2014-2022	generate	_	_
15-11	2023-2029	sample	_	_
15-12	2030-2035	paths	_	_
15-13	2036-2040	with	_	_
15-14	2042-2045	the	_	_
15-15	2046-2055	following	_	_
15-16	2056-2064	commands	_	_
15-17	2064-2065	:	_	_
15-18	2067-2069	go	_	_
15-19	2070-2072	to	_	_
15-20	2073-2076	the	_	_
15-21	2077-2083	source	_	_
15-22	2084-2093	directory	_	_
15-23	2093-2094	:	_	_
15-24	2095-2096	`	_	_
15-25	2096-2097	`	_	_
15-26	2097-2098	`	_	_
15-27	2098-2102	demo	_	_
15-28	2103-2105	cd	_	_
15-29	2106-2124	controlled\_ODE\_RNN	_	_
15-30	2125-2126	`	_	_
15-31	2126-2127	`	_	_
15-32	2127-2128	`	_	_
15-33	2130-2131	-	_	_
15-34	2132-2135	for	_	_
15-35	2136-2149	Black-Scholes	_	_
15-36	2150-2155	model	_	_
15-37	2155-2156	:	_	_
15-38	2157-2158	`	_	_
15-39	2158-2159	`	_	_
15-40	2159-2160	`	_	_
15-41	2160-2164	demo	_	_
15-42	2165-2171	python	_	_
15-43	2172-2179	demo.py	_	_
15-44	2180-2181	-	_	_
15-45	2181-2182	-	_	_
15-46	2182-2190	model\_id	_	_
15-47	2190-2191	=	_	_
15-48	2191-2192	1	_	_
15-49	2193-2194	`	_	_
15-50	2194-2195	`	_	_
15-51	2195-2196	`	_	_
15-52	2198-2199	-	_	_
15-53	2200-2203	for	_	_
15-54	2204-2210	Heston	_	_
15-55	2211-2216	model	_	_
15-56	2216-2217	:	_	_
15-57	2218-2219	`	_	_
15-58	2219-2220	`	_	_
15-59	2220-2221	`	_	_
15-60	2221-2225	demo	_	_
15-61	2226-2232	python	_	_
15-62	2233-2240	demo.py	_	_
15-63	2241-2242	-	_	_
15-64	2242-2243	-	_	_
15-65	2243-2251	model\_id	_	_
15-66	2251-2252	=	_	_
15-67	2252-2253	2	_	_
15-68	2254-2255	`	_	_
15-69	2255-2256	`	_	_
15-70	2256-2257	`	_	_
15-71	2259-2260	-	_	_
15-72	2261-2264	for	_	_
15-73	2265-2283	Ornstein-Uhlenbeck	_	_
15-74	2284-2289	model	_	_
15-75	2289-2290	:	_	_
15-76	2291-2292	`	_	_
15-77	2292-2293	`	_	_
15-78	2293-2294	`	_	_
15-79	2294-2298	demo	_	_
15-80	2299-2305	python	_	_
15-81	2306-2313	demo.py	_	_
15-82	2314-2315	-	_	_
15-83	2315-2316	-	_	_
15-84	2316-2324	model\_id	_	_
15-85	2324-2325	=	_	_
15-86	2325-2326	3	_	_
15-87	2327-2328	`	_	_
15-88	2328-2329	`	_	_
15-89	2329-2330	`	_	_
15-90	2332-2334	If	_	_
15-91	2335-2337	no	_	_
15-92	2338-2345	dataset	_	_
15-93	2346-2349	for	_	_
15-94	2350-2353	the	_	_
15-95	2354-2359	model	_	_
15-96	2360-2363	was	_	_
15-97	2364-2373	generated	_	_
15-98	2374-2377	yet	_	_
15-99	2377-2378	,	_	_
15-100	2379-2380	a	_	_
15-101	2381-2386	small	_	_
15-102	2387-2394	version	_	_
15-103	2395-2397	of	_	_
15-104	2398-2401	the	_	_
15-105	2402-2409	dataset	_	_
15-106	2411-2415	with	_	_
15-107	2416-2419	100	_	_
15-108	2420-2427	samples	_	_
15-109	2428-2432	will	_	_
15-110	2433-2435	be	_	_
15-111	2436-2445	generated	_	_
15-112	2446-2459	automatically	_	_
15-113	2459-2460	,	_	_
15-114	2461-2465	such	_	_
15-115	2466-2470	that	_	_
15-116	2471-2476	plots	_	_
15-117	2477-2480	can	_	_
15-118	2481-2483	be	_	_
15-119	2485-2493	produced	_	_
15-120	2493-2494	.	_	_

#Text=ATTENTION: this dataset should be replaced with a bigger one for training (the  datasets are saved in "..
16-1	2495-2504	ATTENTION	_	_
16-2	2504-2505	:	_	_
16-3	2506-2510	this	_	_
16-4	2511-2518	dataset	_	_
16-5	2519-2525	should	_	_
16-6	2526-2528	be	_	_
16-7	2529-2537	replaced	_	_
16-8	2538-2542	with	_	_
16-9	2543-2544	a	_	_
16-10	2545-2551	bigger	_	_
16-11	2552-2555	one	_	_
16-12	2556-2559	for	_	_
16-13	2560-2568	training	_	_
16-14	2569-2570	(	_	_
16-15	2570-2573	the	_	_
16-16	2575-2583	datasets	_	_
16-17	2584-2587	are	_	_
16-18	2588-2593	saved	_	_
16-19	2594-2596	in	_	_
16-20	2597-2598	"	_	_
16-21	2598-2599	.	_	_
16-22	2599-2600	.	_	_

#Text=/data/training\_data/" and can be deleted there).
17-1	2600-2601	/	_	_
17-2	2601-2605	data	_	_
17-3	2605-2606	/	_	_
17-4	2606-2619	training\_data	_	_
17-5	2619-2620	/	_	_
17-6	2620-2621	"	_	_
17-7	2622-2625	and	_	_
17-8	2626-2629	can	_	_
17-9	2630-2632	be	_	_
17-10	2633-2640	deleted	_	_
17-11	2641-2646	there	_	_
17-12	2646-2647	)	_	_
17-13	2647-2648	.	_	_

#Text=The pretrained models are loaded and used for plotting.
18-1	2650-2653	The	_	_
18-2	2654-2664	pretrained	_	_
18-3	2665-2671	models	_	_
18-4	2672-2675	are	_	_
18-5	2676-2682	loaded	_	_
18-6	2683-2686	and	_	_
18-7	2687-2691	used	_	_
18-8	2692-2695	for	_	_
18-9	2696-2704	plotting	_	_
18-10	2704-2705	.	_	_

#Text=No training.
19-1	2706-2708	No	_	_
19-2	2709-2717	training	_	_
19-3	2717-2718	.	_	_

#Text=The plots are saved in "..
20-1	2719-2722	The	_	_
20-2	2723-2728	plots	_	_
20-3	2729-2732	are	_	_
20-4	2733-2738	saved	_	_
20-5	2739-2741	in	_	_
20-6	2742-2743	"	_	_
20-7	2743-2744	.	_	_
20-8	2744-2745	.	_	_

#Text=/data/saved\_models/id-x/plots/" for x=1,2,3.    ## Empirical convergence study Models for the empirical convergence study were trained using parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training for convergence analysis # ========================================================================== ``` in the main part of the file parallel\_train.py.
21-1	2745-2746	/	_	_
21-2	2746-2750	data	_	_
21-3	2750-2751	/	_	_
21-4	2751-2763	saved\_models	_	_
21-5	2763-2764	/	_	_
21-6	2764-2768	id-x	_	_
21-7	2768-2769	/	_	_
21-8	2769-2774	plots	_	_
21-9	2774-2775	/	_	_
21-10	2775-2776	"	_	_
21-11	2777-2780	for	_	_
21-12	2781-2782	x	_	_
21-13	2782-2783	=	_	_
21-14	2783-2788	1,2,3	_	_
21-15	2788-2789	.	_	_
21-16	2793-2794	#	_	_
21-17	2794-2795	#	_	_
21-18	2796-2805	Empirical	_	_
21-19	2806-2817	convergence	_	_
21-20	2818-2823	study	_	_
21-21	2824-2830	Models	_	_
21-22	2831-2834	for	_	_
21-23	2835-2838	the	_	_
21-24	2839-2848	empirical	_	_
21-25	2849-2860	convergence	_	_
21-26	2861-2866	study	_	_
21-27	2867-2871	were	_	_
21-28	2872-2879	trained	_	_
21-29	2880-2885	using	_	_
21-30	2886-2903	parallel\_train.py	_	_
21-31	2904-2908	with	_	_
21-32	2909-2912	the	_	_
21-33	2913-2918	model	_	_
21-34	2919-2929	parameters	_	_
21-35	2930-2939	specified	_	_
21-36	2940-2945	below	_	_
21-37	2946-2947	`	_	_
21-38	2947-2948	`	_	_
21-39	2948-2949	`	_	_
21-40	2950-2951	#	_	_
21-41	2952-2953	=	_	_
21-42	2953-2954	=	_	_
21-43	2954-2955	=	_	_
21-44	2955-2956	=	_	_
21-45	2956-2957	=	_	_
21-46	2957-2958	=	_	_
21-47	2958-2959	=	_	_
21-48	2959-2960	=	_	_
21-49	2960-2961	=	_	_
21-50	2961-2962	=	_	_
21-51	2962-2963	=	_	_
21-52	2963-2964	=	_	_
21-53	2964-2965	=	_	_
21-54	2965-2966	=	_	_
21-55	2966-2967	=	_	_
21-56	2967-2968	=	_	_
21-57	2968-2969	=	_	_
21-58	2969-2970	=	_	_
21-59	2970-2971	=	_	_
21-60	2971-2972	=	_	_
21-61	2972-2973	=	_	_
21-62	2973-2974	=	_	_
21-63	2974-2975	=	_	_
21-64	2975-2976	=	_	_
21-65	2976-2977	=	_	_
21-66	2977-2978	=	_	_
21-67	2978-2979	=	_	_
21-68	2979-2980	=	_	_
21-69	2980-2981	=	_	_
21-70	2981-2982	=	_	_
21-71	2982-2983	=	_	_
21-72	2983-2984	=	_	_
21-73	2984-2985	=	_	_
21-74	2985-2986	=	_	_
21-75	2986-2987	=	_	_
21-76	2987-2988	=	_	_
21-77	2988-2989	=	_	_
21-78	2989-2990	=	_	_
21-79	2990-2991	=	_	_
21-80	2991-2992	=	_	_
21-81	2992-2993	=	_	_
21-82	2993-2994	=	_	_
21-83	2994-2995	=	_	_
21-84	2995-2996	=	_	_
21-85	2996-2997	=	_	_
21-86	2997-2998	=	_	_
21-87	2998-2999	=	_	_
21-88	2999-3000	=	_	_
21-89	3000-3001	=	_	_
21-90	3001-3002	=	_	_
21-91	3002-3003	=	_	_
21-92	3003-3004	=	_	_
21-93	3004-3005	=	_	_
21-94	3005-3006	=	_	_
21-95	3006-3007	=	_	_
21-96	3007-3008	=	_	_
21-97	3008-3009	=	_	_
21-98	3009-3010	=	_	_
21-99	3010-3011	=	_	_
21-100	3011-3012	=	_	_
21-101	3012-3013	=	_	_
21-102	3013-3014	=	_	_
21-103	3014-3015	=	_	_
21-104	3015-3016	=	_	_
21-105	3016-3017	=	_	_
21-106	3017-3018	=	_	_
21-107	3018-3019	=	_	_
21-108	3019-3020	=	_	_
21-109	3020-3021	=	_	_
21-110	3021-3022	=	_	_
21-111	3022-3023	=	_	_
21-112	3023-3024	=	_	_
21-113	3024-3025	=	_	_
21-114	3025-3026	=	_	_
21-115	3027-3028	#	_	_
21-116	3029-3037	parallel	_	_
21-117	3038-3046	training	_	_
21-118	3047-3050	for	_	_
21-119	3051-3062	convergence	_	_
21-120	3063-3071	analysis	_	_
21-121	3072-3073	#	_	_
21-122	3074-3075	=	_	_
21-123	3075-3076	=	_	_
21-124	3076-3077	=	_	_
21-125	3077-3078	=	_	_
21-126	3078-3079	=	_	_
21-127	3079-3080	=	_	_
21-128	3080-3081	=	_	_
21-129	3081-3082	=	_	_
21-130	3082-3083	=	_	_
21-131	3083-3084	=	_	_
21-132	3084-3085	=	_	_
21-133	3085-3086	=	_	_
21-134	3086-3087	=	_	_
21-135	3087-3088	=	_	_
21-136	3088-3089	=	_	_
21-137	3089-3090	=	_	_
21-138	3090-3091	=	_	_
21-139	3091-3092	=	_	_
21-140	3092-3093	=	_	_
21-141	3093-3094	=	_	_
21-142	3094-3095	=	_	_
21-143	3095-3096	=	_	_
21-144	3096-3097	=	_	_
21-145	3097-3098	=	_	_
21-146	3098-3099	=	_	_
21-147	3099-3100	=	_	_
21-148	3100-3101	=	_	_
21-149	3101-3102	=	_	_
21-150	3102-3103	=	_	_
21-151	3103-3104	=	_	_
21-152	3104-3105	=	_	_
21-153	3105-3106	=	_	_
21-154	3106-3107	=	_	_
21-155	3107-3108	=	_	_
21-156	3108-3109	=	_	_
21-157	3109-3110	=	_	_
21-158	3110-3111	=	_	_
21-159	3111-3112	=	_	_
21-160	3112-3113	=	_	_
21-161	3113-3114	=	_	_
21-162	3114-3115	=	_	_
21-163	3115-3116	=	_	_
21-164	3116-3117	=	_	_
21-165	3117-3118	=	_	_
21-166	3118-3119	=	_	_
21-167	3119-3120	=	_	_
21-168	3120-3121	=	_	_
21-169	3121-3122	=	_	_
21-170	3122-3123	=	_	_
21-171	3123-3124	=	_	_
21-172	3124-3125	=	_	_
21-173	3125-3126	=	_	_
21-174	3126-3127	=	_	_
21-175	3127-3128	=	_	_
21-176	3128-3129	=	_	_
21-177	3129-3130	=	_	_
21-178	3130-3131	=	_	_
21-179	3131-3132	=	_	_
21-180	3132-3133	=	_	_
21-181	3133-3134	=	_	_
21-182	3134-3135	=	_	_
21-183	3135-3136	=	_	_
21-184	3136-3137	=	_	_
21-185	3137-3138	=	_	_
21-186	3138-3139	=	_	_
21-187	3139-3140	=	_	_
21-188	3140-3141	=	_	_
21-189	3141-3142	=	_	_
21-190	3142-3143	=	_	_
21-191	3143-3144	=	_	_
21-192	3144-3145	=	_	_
21-193	3145-3146	=	_	_
21-194	3146-3147	=	_	_
21-195	3147-3148	=	_	_
21-196	3149-3150	`	_	_
21-197	3150-3151	`	_	_
21-198	3151-3152	`	_	_
21-199	3153-3155	in	_	_
21-200	3156-3159	the	_	_
21-201	3160-3164	main	_	_
21-202	3165-3169	part	_	_
21-203	3170-3172	of	_	_
21-204	3173-3176	the	_	_
21-205	3177-3181	file	_	_
21-206	3182-3199	parallel\_train.py	_	_
21-207	3199-3200	.	_	_

#Text=For training: uncomment the code below the model params and run the file.   ## Heston dataset without Feller condition Models for the Heston dataset without Feller condition were trained using  parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training for Heston without Feller # ========================================================================== ``` in the main part of the file parallel\_train.py.
22-1	3202-3205	For	_	_
22-2	3206-3214	training	_	_
22-3	3214-3215	:	_	_
22-4	3216-3225	uncomment	_	_
22-5	3226-3229	the	_	_
22-6	3230-3234	code	_	_
22-7	3235-3240	below	_	_
22-8	3241-3244	the	_	_
22-9	3245-3250	model	_	_
22-10	3251-3257	params	_	_
22-11	3258-3261	and	_	_
22-12	3262-3265	run	_	_
22-13	3266-3269	the	_	_
22-14	3270-3274	file	_	_
22-15	3274-3275	.	_	_
22-16	3278-3279	#	_	_
22-17	3279-3280	#	_	_
22-18	3281-3287	Heston	*	DATASET
22-19	3288-3295	dataset	_	_
22-20	3296-3303	without	_	_
22-21	3304-3310	Feller	_	_
22-22	3311-3320	condition	_	_
22-23	3321-3327	Models	_	_
22-24	3328-3331	for	_	_
22-25	3332-3335	the	_	_
22-26	3336-3342	Heston	*	DATASET
22-27	3343-3350	dataset	_	_
22-28	3351-3358	without	_	_
22-29	3359-3365	Feller	_	_
22-30	3366-3375	condition	_	_
22-31	3376-3380	were	_	_
22-32	3381-3388	trained	_	_
22-33	3389-3394	using	_	_
22-34	3396-3413	parallel\_train.py	_	_
22-35	3414-3418	with	_	_
22-36	3419-3422	the	_	_
22-37	3423-3428	model	_	_
22-38	3429-3439	parameters	_	_
22-39	3440-3449	specified	_	_
22-40	3450-3455	below	_	_
22-41	3456-3457	`	_	_
22-42	3457-3458	`	_	_
22-43	3458-3459	`	_	_
22-44	3460-3461	#	_	_
22-45	3462-3463	=	_	_
22-46	3463-3464	=	_	_
22-47	3464-3465	=	_	_
22-48	3465-3466	=	_	_
22-49	3466-3467	=	_	_
22-50	3467-3468	=	_	_
22-51	3468-3469	=	_	_
22-52	3469-3470	=	_	_
22-53	3470-3471	=	_	_
22-54	3471-3472	=	_	_
22-55	3472-3473	=	_	_
22-56	3473-3474	=	_	_
22-57	3474-3475	=	_	_
22-58	3475-3476	=	_	_
22-59	3476-3477	=	_	_
22-60	3477-3478	=	_	_
22-61	3478-3479	=	_	_
22-62	3479-3480	=	_	_
22-63	3480-3481	=	_	_
22-64	3481-3482	=	_	_
22-65	3482-3483	=	_	_
22-66	3483-3484	=	_	_
22-67	3484-3485	=	_	_
22-68	3485-3486	=	_	_
22-69	3486-3487	=	_	_
22-70	3487-3488	=	_	_
22-71	3488-3489	=	_	_
22-72	3489-3490	=	_	_
22-73	3490-3491	=	_	_
22-74	3491-3492	=	_	_
22-75	3492-3493	=	_	_
22-76	3493-3494	=	_	_
22-77	3494-3495	=	_	_
22-78	3495-3496	=	_	_
22-79	3496-3497	=	_	_
22-80	3497-3498	=	_	_
22-81	3498-3499	=	_	_
22-82	3499-3500	=	_	_
22-83	3500-3501	=	_	_
22-84	3501-3502	=	_	_
22-85	3502-3503	=	_	_
22-86	3503-3504	=	_	_
22-87	3504-3505	=	_	_
22-88	3505-3506	=	_	_
22-89	3506-3507	=	_	_
22-90	3507-3508	=	_	_
22-91	3508-3509	=	_	_
22-92	3509-3510	=	_	_
22-93	3510-3511	=	_	_
22-94	3511-3512	=	_	_
22-95	3512-3513	=	_	_
22-96	3513-3514	=	_	_
22-97	3514-3515	=	_	_
22-98	3515-3516	=	_	_
22-99	3516-3517	=	_	_
22-100	3517-3518	=	_	_
22-101	3518-3519	=	_	_
22-102	3519-3520	=	_	_
22-103	3520-3521	=	_	_
22-104	3521-3522	=	_	_
22-105	3522-3523	=	_	_
22-106	3523-3524	=	_	_
22-107	3524-3525	=	_	_
22-108	3525-3526	=	_	_
22-109	3526-3527	=	_	_
22-110	3527-3528	=	_	_
22-111	3528-3529	=	_	_
22-112	3529-3530	=	_	_
22-113	3530-3531	=	_	_
22-114	3531-3532	=	_	_
22-115	3532-3533	=	_	_
22-116	3533-3534	=	_	_
22-117	3534-3535	=	_	_
22-118	3535-3536	=	_	_
22-119	3537-3538	#	_	_
22-120	3539-3547	parallel	_	_
22-121	3548-3556	training	_	_
22-122	3557-3560	for	_	_
22-123	3561-3567	Heston	_	_
22-124	3568-3575	without	_	_
22-125	3576-3582	Feller	_	_
22-126	3583-3584	#	_	_
22-127	3585-3586	=	_	_
22-128	3586-3587	=	_	_
22-129	3587-3588	=	_	_
22-130	3588-3589	=	_	_
22-131	3589-3590	=	_	_
22-132	3590-3591	=	_	_
22-133	3591-3592	=	_	_
22-134	3592-3593	=	_	_
22-135	3593-3594	=	_	_
22-136	3594-3595	=	_	_
22-137	3595-3596	=	_	_
22-138	3596-3597	=	_	_
22-139	3597-3598	=	_	_
22-140	3598-3599	=	_	_
22-141	3599-3600	=	_	_
22-142	3600-3601	=	_	_
22-143	3601-3602	=	_	_
22-144	3602-3603	=	_	_
22-145	3603-3604	=	_	_
22-146	3604-3605	=	_	_
22-147	3605-3606	=	_	_
22-148	3606-3607	=	_	_
22-149	3607-3608	=	_	_
22-150	3608-3609	=	_	_
22-151	3609-3610	=	_	_
22-152	3610-3611	=	_	_
22-153	3611-3612	=	_	_
22-154	3612-3613	=	_	_
22-155	3613-3614	=	_	_
22-156	3614-3615	=	_	_
22-157	3615-3616	=	_	_
22-158	3616-3617	=	_	_
22-159	3617-3618	=	_	_
22-160	3618-3619	=	_	_
22-161	3619-3620	=	_	_
22-162	3620-3621	=	_	_
22-163	3621-3622	=	_	_
22-164	3622-3623	=	_	_
22-165	3623-3624	=	_	_
22-166	3624-3625	=	_	_
22-167	3625-3626	=	_	_
22-168	3626-3627	=	_	_
22-169	3627-3628	=	_	_
22-170	3628-3629	=	_	_
22-171	3629-3630	=	_	_
22-172	3630-3631	=	_	_
22-173	3631-3632	=	_	_
22-174	3632-3633	=	_	_
22-175	3633-3634	=	_	_
22-176	3634-3635	=	_	_
22-177	3635-3636	=	_	_
22-178	3636-3637	=	_	_
22-179	3637-3638	=	_	_
22-180	3638-3639	=	_	_
22-181	3639-3640	=	_	_
22-182	3640-3641	=	_	_
22-183	3641-3642	=	_	_
22-184	3642-3643	=	_	_
22-185	3643-3644	=	_	_
22-186	3644-3645	=	_	_
22-187	3645-3646	=	_	_
22-188	3646-3647	=	_	_
22-189	3647-3648	=	_	_
22-190	3648-3649	=	_	_
22-191	3649-3650	=	_	_
22-192	3650-3651	=	_	_
22-193	3651-3652	=	_	_
22-194	3652-3653	=	_	_
22-195	3653-3654	=	_	_
22-196	3654-3655	=	_	_
22-197	3655-3656	=	_	_
22-198	3656-3657	=	_	_
22-199	3657-3658	=	_	_
22-200	3658-3659	=	_	_
22-201	3660-3661	`	_	_
22-202	3661-3662	`	_	_
22-203	3662-3663	`	_	_
22-204	3664-3666	in	_	_
22-205	3667-3670	the	_	_
22-206	3671-3675	main	_	_
22-207	3676-3680	part	_	_
22-208	3681-3683	of	_	_
22-209	3684-3687	the	_	_
22-210	3688-3692	file	_	_
22-211	3693-3710	parallel\_train.py	_	_
22-212	3710-3711	.	_	_

#Text=For training: uncomment the code below the model params and run the file.   ## Combined stock models (regime switch) Models for the combined stock model dataset were trained using  parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training for Combined stock models # ========================================================================== ``` in the main part of the file parallel\_train.py.
23-1	3713-3716	For	_	_
23-2	3717-3725	training	_	_
23-3	3725-3726	:	_	_
23-4	3727-3736	uncomment	_	_
23-5	3737-3740	the	_	_
23-6	3741-3745	code	_	_
23-7	3746-3751	below	_	_
23-8	3752-3755	the	_	_
23-9	3756-3761	model	_	_
23-10	3762-3768	params	_	_
23-11	3769-3772	and	_	_
23-12	3773-3776	run	_	_
23-13	3777-3780	the	_	_
23-14	3781-3785	file	_	_
23-15	3785-3786	.	_	_
23-16	3789-3790	#	_	_
23-17	3790-3791	#	_	_
23-18	3792-3800	Combined	_	_
23-19	3801-3806	stock	_	_
23-20	3807-3813	models	_	_
23-21	3814-3815	(	_	_
23-22	3815-3821	regime	_	_
23-23	3822-3828	switch	_	_
23-24	3828-3829	)	_	_
23-25	3830-3836	Models	_	_
23-26	3837-3840	for	_	_
23-27	3841-3844	the	_	_
23-28	3845-3853	combined	_	_
23-29	3854-3859	stock	_	_
23-30	3860-3865	model	_	_
23-31	3866-3873	dataset	_	_
23-32	3874-3878	were	_	_
23-33	3879-3886	trained	_	_
23-34	3887-3892	using	_	_
23-35	3894-3911	parallel\_train.py	_	_
23-36	3912-3916	with	_	_
23-37	3917-3920	the	_	_
23-38	3921-3926	model	_	_
23-39	3927-3937	parameters	_	_
23-40	3938-3947	specified	_	_
23-41	3948-3953	below	_	_
23-42	3954-3955	`	_	_
23-43	3955-3956	`	_	_
23-44	3956-3957	`	_	_
23-45	3958-3959	#	_	_
23-46	3960-3961	=	_	_
23-47	3961-3962	=	_	_
23-48	3962-3963	=	_	_
23-49	3963-3964	=	_	_
23-50	3964-3965	=	_	_
23-51	3965-3966	=	_	_
23-52	3966-3967	=	_	_
23-53	3967-3968	=	_	_
23-54	3968-3969	=	_	_
23-55	3969-3970	=	_	_
23-56	3970-3971	=	_	_
23-57	3971-3972	=	_	_
23-58	3972-3973	=	_	_
23-59	3973-3974	=	_	_
23-60	3974-3975	=	_	_
23-61	3975-3976	=	_	_
23-62	3976-3977	=	_	_
23-63	3977-3978	=	_	_
23-64	3978-3979	=	_	_
23-65	3979-3980	=	_	_
23-66	3980-3981	=	_	_
23-67	3981-3982	=	_	_
23-68	3982-3983	=	_	_
23-69	3983-3984	=	_	_
23-70	3984-3985	=	_	_
23-71	3985-3986	=	_	_
23-72	3986-3987	=	_	_
23-73	3987-3988	=	_	_
23-74	3988-3989	=	_	_
23-75	3989-3990	=	_	_
23-76	3990-3991	=	_	_
23-77	3991-3992	=	_	_
23-78	3992-3993	=	_	_
23-79	3993-3994	=	_	_
23-80	3994-3995	=	_	_
23-81	3995-3996	=	_	_
23-82	3996-3997	=	_	_
23-83	3997-3998	=	_	_
23-84	3998-3999	=	_	_
23-85	3999-4000	=	_	_
23-86	4000-4001	=	_	_
23-87	4001-4002	=	_	_
23-88	4002-4003	=	_	_
23-89	4003-4004	=	_	_
23-90	4004-4005	=	_	_
23-91	4005-4006	=	_	_
23-92	4006-4007	=	_	_
23-93	4007-4008	=	_	_
23-94	4008-4009	=	_	_
23-95	4009-4010	=	_	_
23-96	4010-4011	=	_	_
23-97	4011-4012	=	_	_
23-98	4012-4013	=	_	_
23-99	4013-4014	=	_	_
23-100	4014-4015	=	_	_
23-101	4015-4016	=	_	_
23-102	4016-4017	=	_	_
23-103	4017-4018	=	_	_
23-104	4018-4019	=	_	_
23-105	4019-4020	=	_	_
23-106	4020-4021	=	_	_
23-107	4021-4022	=	_	_
23-108	4022-4023	=	_	_
23-109	4023-4024	=	_	_
23-110	4024-4025	=	_	_
23-111	4025-4026	=	_	_
23-112	4026-4027	=	_	_
23-113	4027-4028	=	_	_
23-114	4028-4029	=	_	_
23-115	4029-4030	=	_	_
23-116	4030-4031	=	_	_
23-117	4031-4032	=	_	_
23-118	4032-4033	=	_	_
23-119	4033-4034	=	_	_
23-120	4035-4036	#	_	_
23-121	4037-4045	parallel	_	_
23-122	4046-4054	training	_	_
23-123	4055-4058	for	_	_
23-124	4059-4067	Combined	_	_
23-125	4068-4073	stock	_	_
23-126	4074-4080	models	_	_
23-127	4081-4082	#	_	_
23-128	4083-4084	=	_	_
23-129	4084-4085	=	_	_
23-130	4085-4086	=	_	_
23-131	4086-4087	=	_	_
23-132	4087-4088	=	_	_
23-133	4088-4089	=	_	_
23-134	4089-4090	=	_	_
23-135	4090-4091	=	_	_
23-136	4091-4092	=	_	_
23-137	4092-4093	=	_	_
23-138	4093-4094	=	_	_
23-139	4094-4095	=	_	_
23-140	4095-4096	=	_	_
23-141	4096-4097	=	_	_
23-142	4097-4098	=	_	_
23-143	4098-4099	=	_	_
23-144	4099-4100	=	_	_
23-145	4100-4101	=	_	_
23-146	4101-4102	=	_	_
23-147	4102-4103	=	_	_
23-148	4103-4104	=	_	_
23-149	4104-4105	=	_	_
23-150	4105-4106	=	_	_
23-151	4106-4107	=	_	_
23-152	4107-4108	=	_	_
23-153	4108-4109	=	_	_
23-154	4109-4110	=	_	_
23-155	4110-4111	=	_	_
23-156	4111-4112	=	_	_
23-157	4112-4113	=	_	_
23-158	4113-4114	=	_	_
23-159	4114-4115	=	_	_
23-160	4115-4116	=	_	_
23-161	4116-4117	=	_	_
23-162	4117-4118	=	_	_
23-163	4118-4119	=	_	_
23-164	4119-4120	=	_	_
23-165	4120-4121	=	_	_
23-166	4121-4122	=	_	_
23-167	4122-4123	=	_	_
23-168	4123-4124	=	_	_
23-169	4124-4125	=	_	_
23-170	4125-4126	=	_	_
23-171	4126-4127	=	_	_
23-172	4127-4128	=	_	_
23-173	4128-4129	=	_	_
23-174	4129-4130	=	_	_
23-175	4130-4131	=	_	_
23-176	4131-4132	=	_	_
23-177	4132-4133	=	_	_
23-178	4133-4134	=	_	_
23-179	4134-4135	=	_	_
23-180	4135-4136	=	_	_
23-181	4136-4137	=	_	_
23-182	4137-4138	=	_	_
23-183	4138-4139	=	_	_
23-184	4139-4140	=	_	_
23-185	4140-4141	=	_	_
23-186	4141-4142	=	_	_
23-187	4142-4143	=	_	_
23-188	4143-4144	=	_	_
23-189	4144-4145	=	_	_
23-190	4145-4146	=	_	_
23-191	4146-4147	=	_	_
23-192	4147-4148	=	_	_
23-193	4148-4149	=	_	_
23-194	4149-4150	=	_	_
23-195	4150-4151	=	_	_
23-196	4151-4152	=	_	_
23-197	4152-4153	=	_	_
23-198	4153-4154	=	_	_
23-199	4154-4155	=	_	_
23-200	4155-4156	=	_	_
23-201	4156-4157	=	_	_
23-202	4158-4159	`	_	_
23-203	4159-4160	`	_	_
23-204	4160-4161	`	_	_
23-205	4162-4164	in	_	_
23-206	4165-4168	the	_	_
23-207	4169-4173	main	_	_
23-208	4174-4178	part	_	_
23-209	4179-4181	of	_	_
23-210	4182-4185	the	_	_
23-211	4186-4190	file	_	_
23-212	4191-4208	parallel\_train.py	_	_
23-213	4208-4209	.	_	_

#Text=For training: uncomment the code below the model params and run the file.   ## Sine stock models (explicit time dependence) Models for the sine stock model dataset were trained using  parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training for sine stock models # ========================================================================== ``` in the main part of the file parallel\_train.py.
24-1	4211-4214	For	_	_
24-2	4215-4223	training	_	_
24-3	4223-4224	:	_	_
24-4	4225-4234	uncomment	_	_
24-5	4235-4238	the	_	_
24-6	4239-4243	code	_	_
24-7	4244-4249	below	_	_
24-8	4250-4253	the	_	_
24-9	4254-4259	model	_	_
24-10	4260-4266	params	_	_
24-11	4267-4270	and	_	_
24-12	4271-4274	run	_	_
24-13	4275-4278	the	_	_
24-14	4279-4283	file	_	_
24-15	4283-4284	.	_	_
24-16	4287-4288	#	_	_
24-17	4288-4289	#	_	_
24-18	4290-4294	Sine	_	_
24-19	4295-4300	stock	_	_
24-20	4301-4307	models	_	_
24-21	4308-4309	(	_	_
24-22	4309-4317	explicit	_	_
24-23	4318-4322	time	_	_
24-24	4323-4333	dependence	_	_
24-25	4333-4334	)	_	_
24-26	4335-4341	Models	_	_
24-27	4342-4345	for	_	_
24-28	4346-4349	the	_	_
24-29	4350-4354	sine	_	_
24-30	4355-4360	stock	_	_
24-31	4361-4366	model	_	_
24-32	4367-4374	dataset	_	_
24-33	4375-4379	were	_	_
24-34	4380-4387	trained	_	_
24-35	4388-4393	using	_	_
24-36	4395-4412	parallel\_train.py	_	_
24-37	4413-4417	with	_	_
24-38	4418-4421	the	_	_
24-39	4422-4427	model	_	_
24-40	4428-4438	parameters	_	_
24-41	4439-4448	specified	_	_
24-42	4449-4454	below	_	_
24-43	4455-4456	`	_	_
24-44	4456-4457	`	_	_
24-45	4457-4458	`	_	_
24-46	4459-4460	#	_	_
24-47	4461-4462	=	_	_
24-48	4462-4463	=	_	_
24-49	4463-4464	=	_	_
24-50	4464-4465	=	_	_
24-51	4465-4466	=	_	_
24-52	4466-4467	=	_	_
24-53	4467-4468	=	_	_
24-54	4468-4469	=	_	_
24-55	4469-4470	=	_	_
24-56	4470-4471	=	_	_
24-57	4471-4472	=	_	_
24-58	4472-4473	=	_	_
24-59	4473-4474	=	_	_
24-60	4474-4475	=	_	_
24-61	4475-4476	=	_	_
24-62	4476-4477	=	_	_
24-63	4477-4478	=	_	_
24-64	4478-4479	=	_	_
24-65	4479-4480	=	_	_
24-66	4480-4481	=	_	_
24-67	4481-4482	=	_	_
24-68	4482-4483	=	_	_
24-69	4483-4484	=	_	_
24-70	4484-4485	=	_	_
24-71	4485-4486	=	_	_
24-72	4486-4487	=	_	_
24-73	4487-4488	=	_	_
24-74	4488-4489	=	_	_
24-75	4489-4490	=	_	_
24-76	4490-4491	=	_	_
24-77	4491-4492	=	_	_
24-78	4492-4493	=	_	_
24-79	4493-4494	=	_	_
24-80	4494-4495	=	_	_
24-81	4495-4496	=	_	_
24-82	4496-4497	=	_	_
24-83	4497-4498	=	_	_
24-84	4498-4499	=	_	_
24-85	4499-4500	=	_	_
24-86	4500-4501	=	_	_
24-87	4501-4502	=	_	_
24-88	4502-4503	=	_	_
24-89	4503-4504	=	_	_
24-90	4504-4505	=	_	_
24-91	4505-4506	=	_	_
24-92	4506-4507	=	_	_
24-93	4507-4508	=	_	_
24-94	4508-4509	=	_	_
24-95	4509-4510	=	_	_
24-96	4510-4511	=	_	_
24-97	4511-4512	=	_	_
24-98	4512-4513	=	_	_
24-99	4513-4514	=	_	_
24-100	4514-4515	=	_	_
24-101	4515-4516	=	_	_
24-102	4516-4517	=	_	_
24-103	4517-4518	=	_	_
24-104	4518-4519	=	_	_
24-105	4519-4520	=	_	_
24-106	4520-4521	=	_	_
24-107	4521-4522	=	_	_
24-108	4522-4523	=	_	_
24-109	4523-4524	=	_	_
24-110	4524-4525	=	_	_
24-111	4525-4526	=	_	_
24-112	4526-4527	=	_	_
24-113	4527-4528	=	_	_
24-114	4528-4529	=	_	_
24-115	4529-4530	=	_	_
24-116	4530-4531	=	_	_
24-117	4531-4532	=	_	_
24-118	4532-4533	=	_	_
24-119	4533-4534	=	_	_
24-120	4534-4535	=	_	_
24-121	4536-4537	#	_	_
24-122	4538-4546	parallel	_	_
24-123	4547-4555	training	_	_
24-124	4556-4559	for	_	_
24-125	4560-4564	sine	_	_
24-126	4565-4570	stock	_	_
24-127	4571-4577	models	_	_
24-128	4578-4579	#	_	_
24-129	4580-4581	=	_	_
24-130	4581-4582	=	_	_
24-131	4582-4583	=	_	_
24-132	4583-4584	=	_	_
24-133	4584-4585	=	_	_
24-134	4585-4586	=	_	_
24-135	4586-4587	=	_	_
24-136	4587-4588	=	_	_
24-137	4588-4589	=	_	_
24-138	4589-4590	=	_	_
24-139	4590-4591	=	_	_
24-140	4591-4592	=	_	_
24-141	4592-4593	=	_	_
24-142	4593-4594	=	_	_
24-143	4594-4595	=	_	_
24-144	4595-4596	=	_	_
24-145	4596-4597	=	_	_
24-146	4597-4598	=	_	_
24-147	4598-4599	=	_	_
24-148	4599-4600	=	_	_
24-149	4600-4601	=	_	_
24-150	4601-4602	=	_	_
24-151	4602-4603	=	_	_
24-152	4603-4604	=	_	_
24-153	4604-4605	=	_	_
24-154	4605-4606	=	_	_
24-155	4606-4607	=	_	_
24-156	4607-4608	=	_	_
24-157	4608-4609	=	_	_
24-158	4609-4610	=	_	_
24-159	4610-4611	=	_	_
24-160	4611-4612	=	_	_
24-161	4612-4613	=	_	_
24-162	4613-4614	=	_	_
24-163	4614-4615	=	_	_
24-164	4615-4616	=	_	_
24-165	4616-4617	=	_	_
24-166	4617-4618	=	_	_
24-167	4618-4619	=	_	_
24-168	4619-4620	=	_	_
24-169	4620-4621	=	_	_
24-170	4621-4622	=	_	_
24-171	4622-4623	=	_	_
24-172	4623-4624	=	_	_
24-173	4624-4625	=	_	_
24-174	4625-4626	=	_	_
24-175	4626-4627	=	_	_
24-176	4627-4628	=	_	_
24-177	4628-4629	=	_	_
24-178	4629-4630	=	_	_
24-179	4630-4631	=	_	_
24-180	4631-4632	=	_	_
24-181	4632-4633	=	_	_
24-182	4633-4634	=	_	_
24-183	4634-4635	=	_	_
24-184	4635-4636	=	_	_
24-185	4636-4637	=	_	_
24-186	4637-4638	=	_	_
24-187	4638-4639	=	_	_
24-188	4639-4640	=	_	_
24-189	4640-4641	=	_	_
24-190	4641-4642	=	_	_
24-191	4642-4643	=	_	_
24-192	4643-4644	=	_	_
24-193	4644-4645	=	_	_
24-194	4645-4646	=	_	_
24-195	4646-4647	=	_	_
24-196	4647-4648	=	_	_
24-197	4648-4649	=	_	_
24-198	4649-4650	=	_	_
24-199	4650-4651	=	_	_
24-200	4651-4652	=	_	_
24-201	4652-4653	=	_	_
24-202	4653-4654	=	_	_
24-203	4655-4656	`	_	_
24-204	4656-4657	`	_	_
24-205	4657-4658	`	_	_
24-206	4659-4661	in	_	_
24-207	4662-4665	the	_	_
24-208	4666-4670	main	_	_
24-209	4671-4675	part	_	_
24-210	4676-4678	of	_	_
24-211	4679-4682	the	_	_
24-212	4683-4687	file	_	_
24-213	4688-4705	parallel\_train.py	_	_
24-214	4705-4706	.	_	_

#Text=For training: uncomment the code below the model params and run the file.       ## Comparison to GRU-ODE-Bayes on synthetic dataset Models for the comparison to GRU-ODE-Bayes were trained using parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training for GRU-ODE-Bayes # ========================================================================== ``` in the main part of the file parallel\_train.py.
25-1	4708-4711	For	_	_
25-2	4712-4720	training	_	_
25-3	4720-4721	:	_	_
25-4	4722-4731	uncomment	_	_
25-5	4732-4735	the	_	_
25-6	4736-4740	code	_	_
25-7	4741-4746	below	_	_
25-8	4747-4750	the	_	_
25-9	4751-4756	model	_	_
25-10	4757-4763	params	_	_
25-11	4764-4767	and	_	_
25-12	4768-4771	run	_	_
25-13	4772-4775	the	_	_
25-14	4776-4780	file	_	_
25-15	4780-4781	.	_	_
25-16	4788-4789	#	_	_
25-17	4789-4790	#	_	_
25-18	4791-4801	Comparison	_	_
25-19	4802-4804	to	_	_
25-20	4805-4818	GRU-ODE-Bayes	_	_
25-21	4819-4821	on	_	_
25-22	4822-4831	synthetic	_	_
25-23	4832-4839	dataset	_	_
25-24	4840-4846	Models	_	_
25-25	4847-4850	for	_	_
25-26	4851-4854	the	_	_
25-27	4855-4865	comparison	_	_
25-28	4866-4868	to	_	_
25-29	4869-4882	GRU-ODE-Bayes	_	_
25-30	4883-4887	were	_	_
25-31	4888-4895	trained	_	_
25-32	4896-4901	using	_	_
25-33	4902-4919	parallel\_train.py	_	_
25-34	4920-4924	with	_	_
25-35	4925-4928	the	_	_
25-36	4929-4934	model	_	_
25-37	4935-4945	parameters	_	_
25-38	4946-4955	specified	_	_
25-39	4956-4961	below	_	_
25-40	4962-4963	`	_	_
25-41	4963-4964	`	_	_
25-42	4964-4965	`	_	_
25-43	4966-4967	#	_	_
25-44	4968-4969	=	_	_
25-45	4969-4970	=	_	_
25-46	4970-4971	=	_	_
25-47	4971-4972	=	_	_
25-48	4972-4973	=	_	_
25-49	4973-4974	=	_	_
25-50	4974-4975	=	_	_
25-51	4975-4976	=	_	_
25-52	4976-4977	=	_	_
25-53	4977-4978	=	_	_
25-54	4978-4979	=	_	_
25-55	4979-4980	=	_	_
25-56	4980-4981	=	_	_
25-57	4981-4982	=	_	_
25-58	4982-4983	=	_	_
25-59	4983-4984	=	_	_
25-60	4984-4985	=	_	_
25-61	4985-4986	=	_	_
25-62	4986-4987	=	_	_
25-63	4987-4988	=	_	_
25-64	4988-4989	=	_	_
25-65	4989-4990	=	_	_
25-66	4990-4991	=	_	_
25-67	4991-4992	=	_	_
25-68	4992-4993	=	_	_
25-69	4993-4994	=	_	_
25-70	4994-4995	=	_	_
25-71	4995-4996	=	_	_
25-72	4996-4997	=	_	_
25-73	4997-4998	=	_	_
25-74	4998-4999	=	_	_
25-75	4999-5000	=	_	_
25-76	5000-5001	=	_	_
25-77	5001-5002	=	_	_
25-78	5002-5003	=	_	_
25-79	5003-5004	=	_	_
25-80	5004-5005	=	_	_
25-81	5005-5006	=	_	_
25-82	5006-5007	=	_	_
25-83	5007-5008	=	_	_
25-84	5008-5009	=	_	_
25-85	5009-5010	=	_	_
25-86	5010-5011	=	_	_
25-87	5011-5012	=	_	_
25-88	5012-5013	=	_	_
25-89	5013-5014	=	_	_
25-90	5014-5015	=	_	_
25-91	5015-5016	=	_	_
25-92	5016-5017	=	_	_
25-93	5017-5018	=	_	_
25-94	5018-5019	=	_	_
25-95	5019-5020	=	_	_
25-96	5020-5021	=	_	_
25-97	5021-5022	=	_	_
25-98	5022-5023	=	_	_
25-99	5023-5024	=	_	_
25-100	5024-5025	=	_	_
25-101	5025-5026	=	_	_
25-102	5026-5027	=	_	_
25-103	5027-5028	=	_	_
25-104	5028-5029	=	_	_
25-105	5029-5030	=	_	_
25-106	5030-5031	=	_	_
25-107	5031-5032	=	_	_
25-108	5032-5033	=	_	_
25-109	5033-5034	=	_	_
25-110	5034-5035	=	_	_
25-111	5035-5036	=	_	_
25-112	5036-5037	=	_	_
25-113	5037-5038	=	_	_
25-114	5038-5039	=	_	_
25-115	5039-5040	=	_	_
25-116	5040-5041	=	_	_
25-117	5041-5042	=	_	_
25-118	5043-5044	#	_	_
25-119	5045-5053	parallel	_	_
25-120	5054-5062	training	_	_
25-121	5063-5066	for	_	_
25-122	5067-5080	GRU-ODE-Bayes	_	_
25-123	5081-5082	#	_	_
25-124	5083-5084	=	_	_
25-125	5084-5085	=	_	_
25-126	5085-5086	=	_	_
25-127	5086-5087	=	_	_
25-128	5087-5088	=	_	_
25-129	5088-5089	=	_	_
25-130	5089-5090	=	_	_
25-131	5090-5091	=	_	_
25-132	5091-5092	=	_	_
25-133	5092-5093	=	_	_
25-134	5093-5094	=	_	_
25-135	5094-5095	=	_	_
25-136	5095-5096	=	_	_
25-137	5096-5097	=	_	_
25-138	5097-5098	=	_	_
25-139	5098-5099	=	_	_
25-140	5099-5100	=	_	_
25-141	5100-5101	=	_	_
25-142	5101-5102	=	_	_
25-143	5102-5103	=	_	_
25-144	5103-5104	=	_	_
25-145	5104-5105	=	_	_
25-146	5105-5106	=	_	_
25-147	5106-5107	=	_	_
25-148	5107-5108	=	_	_
25-149	5108-5109	=	_	_
25-150	5109-5110	=	_	_
25-151	5110-5111	=	_	_
25-152	5111-5112	=	_	_
25-153	5112-5113	=	_	_
25-154	5113-5114	=	_	_
25-155	5114-5115	=	_	_
25-156	5115-5116	=	_	_
25-157	5116-5117	=	_	_
25-158	5117-5118	=	_	_
25-159	5118-5119	=	_	_
25-160	5119-5120	=	_	_
25-161	5120-5121	=	_	_
25-162	5121-5122	=	_	_
25-163	5122-5123	=	_	_
25-164	5123-5124	=	_	_
25-165	5124-5125	=	_	_
25-166	5125-5126	=	_	_
25-167	5126-5127	=	_	_
25-168	5127-5128	=	_	_
25-169	5128-5129	=	_	_
25-170	5129-5130	=	_	_
25-171	5130-5131	=	_	_
25-172	5131-5132	=	_	_
25-173	5132-5133	=	_	_
25-174	5133-5134	=	_	_
25-175	5134-5135	=	_	_
25-176	5135-5136	=	_	_
25-177	5136-5137	=	_	_
25-178	5137-5138	=	_	_
25-179	5138-5139	=	_	_
25-180	5139-5140	=	_	_
25-181	5140-5141	=	_	_
25-182	5141-5142	=	_	_
25-183	5142-5143	=	_	_
25-184	5143-5144	=	_	_
25-185	5144-5145	=	_	_
25-186	5145-5146	=	_	_
25-187	5146-5147	=	_	_
25-188	5147-5148	=	_	_
25-189	5148-5149	=	_	_
25-190	5149-5150	=	_	_
25-191	5150-5151	=	_	_
25-192	5151-5152	=	_	_
25-193	5152-5153	=	_	_
25-194	5153-5154	=	_	_
25-195	5154-5155	=	_	_
25-196	5155-5156	=	_	_
25-197	5156-5157	=	_	_
25-198	5158-5159	`	_	_
25-199	5159-5160	`	_	_
25-200	5160-5161	`	_	_
25-201	5162-5164	in	_	_
25-202	5165-5168	the	_	_
25-203	5169-5173	main	_	_
25-204	5174-5178	part	_	_
25-205	5179-5181	of	_	_
25-206	5182-5185	the	_	_
25-207	5186-5190	file	_	_
25-208	5191-5208	parallel\_train.py	_	_
25-209	5208-5209	.	_	_

#Text=For training: uncomment the code below the model params and run the file.
26-1	5211-5214	For	_	_
26-2	5215-5223	training	_	_
26-3	5223-5224	:	_	_
26-4	5225-5234	uncomment	_	_
26-5	5235-5238	the	_	_
26-6	5239-5243	code	_	_
26-7	5244-5249	below	_	_
26-8	5250-5253	the	_	_
26-9	5254-5259	model	_	_
26-10	5260-5266	params	_	_
26-11	5267-5270	and	_	_
26-12	5271-5274	run	_	_
26-13	5275-5278	the	_	_
26-14	5279-5283	file	_	_
26-15	5283-5284	.	_	_

#Text=For easier evaluation after training, use the function-call: ``` get\_training\_overview(     params\_extract\_desc=('dataset', "other\_model",                          'network\_size', 'training\_size',                          'hidden\_size', "GRU\_ODE\_Bayes-mixing",                          "GRU\_ODE\_Bayes-logvar", "GRU\_ODE\_Bayes-impute",                          "GRU\_ODE\_Bayes-mixing"),     val\_test\_params\_extract=(("max", "epoch", "epoch", "epochs\_trained"),                              ("min", "evaluation\_mean\_diff",                               "evaluation\_mean\_diff", "eval\_metric\_min"),                              ("last", "evaluation\_mean\_diff",                               "evaluation\_mean\_diff", "eval\_metric\_last"),                              ("average", "evaluation\_mean\_diff",                               "evaluation\_mean\_diff", "eval\_metric\_average")                              ) ) ```  in extras.py.    ## Training on Climate Dataset The preprocessed climate data that was provided by \[GRU-ODE-Bayes\](https://arxiv.org/abs/1905.12374) together with the cross-validation indices generated with their provided  code, is saved in data/training\_data/climate/, s.t. models can be trained right  away.
27-1	5286-5289	For	_	_
27-2	5290-5296	easier	_	_
27-3	5297-5307	evaluation	_	_
27-4	5308-5313	after	_	_
27-5	5314-5322	training	_	_
27-6	5322-5323	,	_	_
27-7	5324-5327	use	_	_
27-8	5328-5331	the	_	_
27-9	5332-5345	function-call	_	_
27-10	5345-5346	:	_	_
27-11	5347-5348	`	_	_
27-12	5348-5349	`	_	_
27-13	5349-5350	`	_	_
27-14	5351-5372	get\_training\_overview	_	_
27-15	5372-5373	(	_	_
27-16	5378-5397	params\_extract\_desc	_	_
27-17	5397-5398	=	_	_
27-18	5398-5399	(	_	_
27-19	5399-5400	'	_	_
27-20	5400-5407	dataset	_	_
27-21	5407-5408	'	_	_
27-22	5408-5409	,	_	_
27-23	5410-5411	"	_	_
27-24	5411-5422	other\_model	_	_
27-25	5422-5423	"	_	_
27-26	5423-5424	,	_	_
27-27	5450-5451	'	_	_
27-28	5451-5463	network\_size	_	_
27-29	5463-5464	'	_	_
27-30	5464-5465	,	_	_
27-31	5466-5467	'	_	_
27-32	5467-5480	training\_size	_	_
27-33	5480-5481	'	_	_
27-34	5481-5482	,	_	_
27-35	5508-5509	'	_	_
27-36	5509-5520	hidden\_size	_	_
27-37	5520-5521	'	_	_
27-38	5521-5522	,	_	_
27-39	5523-5524	"	_	_
27-40	5524-5544	GRU\_ODE\_Bayes-mixing	_	_
27-41	5544-5545	"	_	_
27-42	5545-5546	,	_	_
27-43	5572-5573	"	_	_
27-44	5573-5593	GRU\_ODE\_Bayes-logvar	_	_
27-45	5593-5594	"	_	_
27-46	5594-5595	,	_	_
27-47	5596-5597	"	_	_
27-48	5597-5617	GRU\_ODE\_Bayes-impute	_	_
27-49	5617-5618	"	_	_
27-50	5618-5619	,	_	_
27-51	5645-5646	"	_	_
27-52	5646-5666	GRU\_ODE\_Bayes-mixing	_	_
27-53	5666-5667	"	_	_
27-54	5667-5668	)	_	_
27-55	5668-5669	,	_	_
27-56	5674-5697	val\_test\_params\_extract	_	_
27-57	5697-5698	=	_	_
27-58	5698-5699	(	_	_
27-59	5699-5700	(	_	_
27-60	5700-5701	"	_	_
27-61	5701-5704	max	_	_
27-62	5704-5705	"	_	_
27-63	5705-5706	,	_	_
27-64	5707-5708	"	_	_
27-65	5708-5713	epoch	_	_
27-66	5713-5714	"	_	_
27-67	5714-5715	,	_	_
27-68	5716-5717	"	_	_
27-69	5717-5722	epoch	_	_
27-70	5722-5723	"	_	_
27-71	5723-5724	,	_	_
27-72	5725-5726	"	_	_
27-73	5726-5740	epochs\_trained	_	_
27-74	5740-5741	"	_	_
27-75	5741-5742	)	_	_
27-76	5742-5743	,	_	_
27-77	5773-5774	(	_	_
27-78	5774-5775	"	_	_
27-79	5775-5778	min	_	_
27-80	5778-5779	"	_	_
27-81	5779-5780	,	_	_
27-82	5781-5782	"	_	_
27-83	5782-5802	evaluation\_mean\_diff	_	_
27-84	5802-5803	"	_	_
27-85	5803-5804	,	_	_
27-86	5835-5836	"	_	_
27-87	5836-5856	evaluation\_mean\_diff	_	_
27-88	5856-5857	"	_	_
27-89	5857-5858	,	_	_
27-90	5859-5860	"	_	_
27-91	5860-5875	eval\_metric\_min	_	_
27-92	5875-5876	"	_	_
27-93	5876-5877	)	_	_
27-94	5877-5878	,	_	_
27-95	5908-5909	(	_	_
27-96	5909-5910	"	_	_
27-97	5910-5914	last	_	_
27-98	5914-5915	"	_	_
27-99	5915-5916	,	_	_
27-100	5917-5918	"	_	_
27-101	5918-5938	evaluation\_mean\_diff	_	_
27-102	5938-5939	"	_	_
27-103	5939-5940	,	_	_
27-104	5971-5972	"	_	_
27-105	5972-5992	evaluation\_mean\_diff	_	_
27-106	5992-5993	"	_	_
27-107	5993-5994	,	_	_
27-108	5995-5996	"	_	_
27-109	5996-6012	eval\_metric\_last	_	_
27-110	6012-6013	"	_	_
27-111	6013-6014	)	_	_
27-112	6014-6015	,	_	_
27-113	6045-6046	(	_	_
27-114	6046-6047	"	_	_
27-115	6047-6054	average	_	_
27-116	6054-6055	"	_	_
27-117	6055-6056	,	_	_
27-118	6057-6058	"	_	_
27-119	6058-6078	evaluation\_mean\_diff	_	_
27-120	6078-6079	"	_	_
27-121	6079-6080	,	_	_
27-122	6111-6112	"	_	_
27-123	6112-6132	evaluation\_mean\_diff	_	_
27-124	6132-6133	"	_	_
27-125	6133-6134	,	_	_
27-126	6135-6136	"	_	_
27-127	6136-6155	eval\_metric\_average	_	_
27-128	6155-6156	"	_	_
27-129	6156-6157	)	_	_
27-130	6187-6188	)	_	_
27-131	6189-6190	)	_	_
27-132	6191-6192	`	_	_
27-133	6192-6193	`	_	_
27-134	6193-6194	`	_	_
27-135	6196-6198	in	_	_
27-136	6199-6208	extras.py	_	_
27-137	6208-6209	.	_	_
27-138	6213-6214	#	_	_
27-139	6214-6215	#	_	_
27-140	6216-6224	Training	_	_
27-141	6225-6227	on	_	_
27-142	6228-6235	Climate	_	_
27-143	6236-6243	Dataset	_	_
27-144	6244-6247	The	_	_
27-145	6248-6260	preprocessed	_	_
27-146	6261-6268	climate	_	_
27-147	6269-6273	data	_	_
27-148	6274-6278	that	_	_
27-149	6279-6282	was	_	_
27-150	6283-6291	provided	_	_
27-151	6292-6294	by	_	_
27-152	6295-6296	\[	_	_
27-153	6296-6309	GRU-ODE-Bayes	_	_
27-154	6309-6310	\]	_	_
27-155	6310-6311	(	_	_
27-156	6311-6316	https	_	_
27-157	6316-6317	:	_	_
27-158	6317-6318	/	_	_
27-159	6318-6319	/	_	_
27-160	6319-6328	arxiv.org	_	_
27-161	6328-6329	/	_	_
27-162	6329-6332	abs	_	_
27-163	6332-6333	/	_	_
27-164	6333-6343	1905.12374	_	_
27-165	6343-6344	)	_	_
27-166	6345-6353	together	_	_
27-167	6354-6358	with	_	_
27-168	6359-6362	the	_	_
27-169	6363-6379	cross-validation	_	_
27-170	6380-6387	indices	_	_
27-171	6388-6397	generated	_	_
27-172	6398-6402	with	_	_
27-173	6403-6408	their	_	_
27-174	6409-6417	provided	_	_
27-175	6419-6423	code	_	_
27-176	6423-6424	,	_	_
27-177	6425-6427	is	_	_
27-178	6428-6433	saved	_	_
27-179	6434-6436	in	_	_
27-180	6437-6441	data	_	_
27-181	6441-6442	/	_	_
27-182	6442-6455	training\_data	_	_
27-183	6455-6456	/	_	_
27-184	6456-6463	climate	_	_
27-185	6463-6464	/	_	_
27-186	6464-6465	,	_	_
27-187	6466-6469	s.t	_	_
27-188	6469-6470	.	_	_
27-189	6471-6477	models	_	_
27-190	6478-6481	can	_	_
27-191	6482-6484	be	_	_
27-192	6485-6492	trained	_	_
27-193	6493-6498	right	_	_
27-194	6500-6504	away	_	_
27-195	6504-6505	.	_	_

#Text=Models for cross-validation on the climate dataset were trained using  parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training on climate dataset # ========================================================================== ``` in the main part of the file parallel\_train.py.
28-1	6507-6513	Models	_	_
28-2	6514-6517	for	_	_
28-3	6518-6534	cross-validation	_	_
28-4	6535-6537	on	_	_
28-5	6538-6541	the	_	_
28-6	6542-6549	climate	_	_
28-7	6550-6557	dataset	_	_
28-8	6558-6562	were	_	_
28-9	6563-6570	trained	_	_
28-10	6571-6576	using	_	_
28-11	6578-6595	parallel\_train.py	_	_
28-12	6596-6600	with	_	_
28-13	6601-6604	the	_	_
28-14	6605-6610	model	_	_
28-15	6611-6621	parameters	_	_
28-16	6622-6631	specified	_	_
28-17	6632-6637	below	_	_
28-18	6638-6639	`	_	_
28-19	6639-6640	`	_	_
28-20	6640-6641	`	_	_
28-21	6642-6643	#	_	_
28-22	6644-6645	=	_	_
28-23	6645-6646	=	_	_
28-24	6646-6647	=	_	_
28-25	6647-6648	=	_	_
28-26	6648-6649	=	_	_
28-27	6649-6650	=	_	_
28-28	6650-6651	=	_	_
28-29	6651-6652	=	_	_
28-30	6652-6653	=	_	_
28-31	6653-6654	=	_	_
28-32	6654-6655	=	_	_
28-33	6655-6656	=	_	_
28-34	6656-6657	=	_	_
28-35	6657-6658	=	_	_
28-36	6658-6659	=	_	_
28-37	6659-6660	=	_	_
28-38	6660-6661	=	_	_
28-39	6661-6662	=	_	_
28-40	6662-6663	=	_	_
28-41	6663-6664	=	_	_
28-42	6664-6665	=	_	_
28-43	6665-6666	=	_	_
28-44	6666-6667	=	_	_
28-45	6667-6668	=	_	_
28-46	6668-6669	=	_	_
28-47	6669-6670	=	_	_
28-48	6670-6671	=	_	_
28-49	6671-6672	=	_	_
28-50	6672-6673	=	_	_
28-51	6673-6674	=	_	_
28-52	6674-6675	=	_	_
28-53	6675-6676	=	_	_
28-54	6676-6677	=	_	_
28-55	6677-6678	=	_	_
28-56	6678-6679	=	_	_
28-57	6679-6680	=	_	_
28-58	6680-6681	=	_	_
28-59	6681-6682	=	_	_
28-60	6682-6683	=	_	_
28-61	6683-6684	=	_	_
28-62	6684-6685	=	_	_
28-63	6685-6686	=	_	_
28-64	6686-6687	=	_	_
28-65	6687-6688	=	_	_
28-66	6688-6689	=	_	_
28-67	6689-6690	=	_	_
28-68	6690-6691	=	_	_
28-69	6691-6692	=	_	_
28-70	6692-6693	=	_	_
28-71	6693-6694	=	_	_
28-72	6694-6695	=	_	_
28-73	6695-6696	=	_	_
28-74	6696-6697	=	_	_
28-75	6697-6698	=	_	_
28-76	6698-6699	=	_	_
28-77	6699-6700	=	_	_
28-78	6700-6701	=	_	_
28-79	6701-6702	=	_	_
28-80	6702-6703	=	_	_
28-81	6703-6704	=	_	_
28-82	6704-6705	=	_	_
28-83	6705-6706	=	_	_
28-84	6706-6707	=	_	_
28-85	6707-6708	=	_	_
28-86	6708-6709	=	_	_
28-87	6709-6710	=	_	_
28-88	6710-6711	=	_	_
28-89	6711-6712	=	_	_
28-90	6712-6713	=	_	_
28-91	6713-6714	=	_	_
28-92	6714-6715	=	_	_
28-93	6715-6716	=	_	_
28-94	6716-6717	=	_	_
28-95	6717-6718	=	_	_
28-96	6719-6720	#	_	_
28-97	6721-6729	parallel	_	_
28-98	6730-6738	training	_	_
28-99	6739-6741	on	_	_
28-100	6742-6749	climate	_	_
28-101	6750-6757	dataset	_	_
28-102	6758-6759	#	_	_
28-103	6760-6761	=	_	_
28-104	6761-6762	=	_	_
28-105	6762-6763	=	_	_
28-106	6763-6764	=	_	_
28-107	6764-6765	=	_	_
28-108	6765-6766	=	_	_
28-109	6766-6767	=	_	_
28-110	6767-6768	=	_	_
28-111	6768-6769	=	_	_
28-112	6769-6770	=	_	_
28-113	6770-6771	=	_	_
28-114	6771-6772	=	_	_
28-115	6772-6773	=	_	_
28-116	6773-6774	=	_	_
28-117	6774-6775	=	_	_
28-118	6775-6776	=	_	_
28-119	6776-6777	=	_	_
28-120	6777-6778	=	_	_
28-121	6778-6779	=	_	_
28-122	6779-6780	=	_	_
28-123	6780-6781	=	_	_
28-124	6781-6782	=	_	_
28-125	6782-6783	=	_	_
28-126	6783-6784	=	_	_
28-127	6784-6785	=	_	_
28-128	6785-6786	=	_	_
28-129	6786-6787	=	_	_
28-130	6787-6788	=	_	_
28-131	6788-6789	=	_	_
28-132	6789-6790	=	_	_
28-133	6790-6791	=	_	_
28-134	6791-6792	=	_	_
28-135	6792-6793	=	_	_
28-136	6793-6794	=	_	_
28-137	6794-6795	=	_	_
28-138	6795-6796	=	_	_
28-139	6796-6797	=	_	_
28-140	6797-6798	=	_	_
28-141	6798-6799	=	_	_
28-142	6799-6800	=	_	_
28-143	6800-6801	=	_	_
28-144	6801-6802	=	_	_
28-145	6802-6803	=	_	_
28-146	6803-6804	=	_	_
28-147	6804-6805	=	_	_
28-148	6805-6806	=	_	_
28-149	6806-6807	=	_	_
28-150	6807-6808	=	_	_
28-151	6808-6809	=	_	_
28-152	6809-6810	=	_	_
28-153	6810-6811	=	_	_
28-154	6811-6812	=	_	_
28-155	6812-6813	=	_	_
28-156	6813-6814	=	_	_
28-157	6814-6815	=	_	_
28-158	6815-6816	=	_	_
28-159	6816-6817	=	_	_
28-160	6817-6818	=	_	_
28-161	6818-6819	=	_	_
28-162	6819-6820	=	_	_
28-163	6820-6821	=	_	_
28-164	6821-6822	=	_	_
28-165	6822-6823	=	_	_
28-166	6823-6824	=	_	_
28-167	6824-6825	=	_	_
28-168	6825-6826	=	_	_
28-169	6826-6827	=	_	_
28-170	6827-6828	=	_	_
28-171	6828-6829	=	_	_
28-172	6829-6830	=	_	_
28-173	6830-6831	=	_	_
28-174	6831-6832	=	_	_
28-175	6832-6833	=	_	_
28-176	6833-6834	=	_	_
28-177	6835-6836	`	_	_
28-178	6836-6837	`	_	_
28-179	6837-6838	`	_	_
28-180	6839-6841	in	_	_
28-181	6842-6845	the	_	_
28-182	6846-6850	main	_	_
28-183	6851-6855	part	_	_
28-184	6856-6858	of	_	_
28-185	6859-6862	the	_	_
28-186	6863-6867	file	_	_
28-187	6868-6885	parallel\_train.py	_	_
28-188	6885-6886	.	_	_

#Text=For training: uncomment the code below the model params and run the file.
29-1	6888-6891	For	_	_
29-2	6892-6900	training	_	_
29-3	6900-6901	:	_	_
29-4	6902-6911	uncomment	_	_
29-5	6912-6915	the	_	_
29-6	6916-6920	code	_	_
29-7	6921-6926	below	_	_
29-8	6927-6930	the	_	_
29-9	6931-6936	model	_	_
29-10	6937-6943	params	_	_
29-11	6944-6947	and	_	_
29-12	6948-6951	run	_	_
29-13	6952-6955	the	_	_
29-14	6956-6960	file	_	_
29-15	6960-6961	.	_	_

#Text=For performing/evaluating the cross-validation use the function-call: ``` get\_training\_overview(     params\_extract\_desc=('dataset', 'network\_size', 'dropout\_rate',                          'hidden\_size', 'data\_index'),     val\_test\_params\_extract=(("max", "epoch", "epoch", "epochs\_trained"),                              ("min", "eval\_metric",                               "eval\_metric", "eval\_metric\_min"),                              ("min", "test\_metric",                               "test\_metric", "test\_metric\_min"),                              ("min", "eval\_metric",                               "test\_metric", "test\_metric\_evaluation\_min"),                              ("min", "eval\_loss",                               "test\_metric", "test\_metric\_eval\_loss\_min"),                              ) )  get\_climate\_cross\_validation(early\_stop\_after\_epoch=100) ```  in extras.py.   ## Training on Physionet Dataset The Physionet dataset that was used by  \[Latent ODEs for Irregularly-Sampled Time Series\](https://arxiv.org/abs/1907.03907) is downloaded and saved automatically when training for the first time.
30-1	6963-6966	For	_	_
30-2	6967-6977	performing	_	_
30-3	6977-6978	/	_	_
30-4	6978-6988	evaluating	_	_
30-5	6989-6992	the	_	_
30-6	6993-7009	cross-validation	_	_
30-7	7010-7013	use	_	_
30-8	7014-7017	the	_	_
30-9	7018-7031	function-call	_	_
30-10	7031-7032	:	_	_
30-11	7033-7034	`	_	_
30-12	7034-7035	`	_	_
30-13	7035-7036	`	_	_
30-14	7037-7058	get\_training\_overview	_	_
30-15	7058-7059	(	_	_
30-16	7064-7083	params\_extract\_desc	_	_
30-17	7083-7084	=	_	_
30-18	7084-7085	(	_	_
30-19	7085-7086	'	_	_
30-20	7086-7093	dataset	_	_
30-21	7093-7094	'	_	_
30-22	7094-7095	,	_	_
30-23	7096-7097	'	_	_
30-24	7097-7109	network\_size	_	_
30-25	7109-7110	'	_	_
30-26	7110-7111	,	_	_
30-27	7112-7113	'	_	_
30-28	7113-7125	dropout\_rate	_	_
30-29	7125-7126	'	_	_
30-30	7126-7127	,	_	_
30-31	7153-7154	'	_	_
30-32	7154-7165	hidden\_size	_	_
30-33	7165-7166	'	_	_
30-34	7166-7167	,	_	_
30-35	7168-7169	'	_	_
30-36	7169-7179	data\_index	_	_
30-37	7179-7180	'	_	_
30-38	7180-7181	)	_	_
30-39	7181-7182	,	_	_
30-40	7187-7210	val\_test\_params\_extract	_	_
30-41	7210-7211	=	_	_
30-42	7211-7212	(	_	_
30-43	7212-7213	(	_	_
30-44	7213-7214	"	_	_
30-45	7214-7217	max	_	_
30-46	7217-7218	"	_	_
30-47	7218-7219	,	_	_
30-48	7220-7221	"	_	_
30-49	7221-7226	epoch	_	_
30-50	7226-7227	"	_	_
30-51	7227-7228	,	_	_
30-52	7229-7230	"	_	_
30-53	7230-7235	epoch	_	_
30-54	7235-7236	"	_	_
30-55	7236-7237	,	_	_
30-56	7238-7239	"	_	_
30-57	7239-7253	epochs\_trained	_	_
30-58	7253-7254	"	_	_
30-59	7254-7255	)	_	_
30-60	7255-7256	,	_	_
30-61	7286-7287	(	_	_
30-62	7287-7288	"	_	_
30-63	7288-7291	min	_	_
30-64	7291-7292	"	_	_
30-65	7292-7293	,	_	_
30-66	7294-7295	"	_	_
30-67	7295-7306	eval\_metric	_	_
30-68	7306-7307	"	_	_
30-69	7307-7308	,	_	_
30-70	7339-7340	"	_	_
30-71	7340-7351	eval\_metric	_	_
30-72	7351-7352	"	_	_
30-73	7352-7353	,	_	_
30-74	7354-7355	"	_	_
30-75	7355-7370	eval\_metric\_min	_	_
30-76	7370-7371	"	_	_
30-77	7371-7372	)	_	_
30-78	7372-7373	,	_	_
30-79	7403-7404	(	_	_
30-80	7404-7405	"	_	_
30-81	7405-7408	min	_	_
30-82	7408-7409	"	_	_
30-83	7409-7410	,	_	_
30-84	7411-7412	"	_	_
30-85	7412-7423	test\_metric	_	_
30-86	7423-7424	"	_	_
30-87	7424-7425	,	_	_
30-88	7456-7457	"	_	_
30-89	7457-7468	test\_metric	_	_
30-90	7468-7469	"	_	_
30-91	7469-7470	,	_	_
30-92	7471-7472	"	_	_
30-93	7472-7487	test\_metric\_min	_	_
30-94	7487-7488	"	_	_
30-95	7488-7489	)	_	_
30-96	7489-7490	,	_	_
30-97	7520-7521	(	_	_
30-98	7521-7522	"	_	_
30-99	7522-7525	min	_	_
30-100	7525-7526	"	_	_
30-101	7526-7527	,	_	_
30-102	7528-7529	"	_	_
30-103	7529-7540	eval\_metric	_	_
30-104	7540-7541	"	_	_
30-105	7541-7542	,	_	_
30-106	7573-7574	"	_	_
30-107	7574-7585	test\_metric	_	_
30-108	7585-7586	"	_	_
30-109	7586-7587	,	_	_
30-110	7588-7589	"	_	_
30-111	7589-7615	test\_metric\_evaluation\_min	_	_
30-112	7615-7616	"	_	_
30-113	7616-7617	)	_	_
30-114	7617-7618	,	_	_
30-115	7648-7649	(	_	_
30-116	7649-7650	"	_	_
30-117	7650-7653	min	_	_
30-118	7653-7654	"	_	_
30-119	7654-7655	,	_	_
30-120	7656-7657	"	_	_
30-121	7657-7666	eval\_loss	_	_
30-122	7666-7667	"	_	_
30-123	7667-7668	,	_	_
30-124	7699-7700	"	_	_
30-125	7700-7711	test\_metric	_	_
30-126	7711-7712	"	_	_
30-127	7712-7713	,	_	_
30-128	7714-7715	"	_	_
30-129	7715-7740	test\_metric\_eval\_loss\_min	_	_
30-130	7740-7741	"	_	_
30-131	7741-7742	)	_	_
30-132	7742-7743	,	_	_
30-133	7773-7774	)	_	_
30-134	7775-7776	)	_	_
30-135	7778-7806	get\_climate\_cross\_validation	_	_
30-136	7806-7807	(	_	_
30-137	7807-7829	early\_stop\_after\_epoch	_	_
30-138	7829-7830	=	_	_
30-139	7830-7833	100	_	_
30-140	7833-7834	)	_	_
30-141	7835-7836	`	_	_
30-142	7836-7837	`	_	_
30-143	7837-7838	`	_	_
30-144	7840-7842	in	_	_
30-145	7843-7852	extras.py	_	_
30-146	7852-7853	.	_	_
30-147	7856-7857	#	_	_
30-148	7857-7858	#	_	_
30-149	7859-7867	Training	_	_
30-150	7868-7870	on	_	_
30-151	7871-7880	Physionet	*	DATASET
30-152	7881-7888	Dataset	_	_
30-153	7889-7892	The	_	_
30-154	7893-7902	Physionet	*	DATASET
30-155	7903-7910	dataset	_	_
30-156	7911-7915	that	_	_
30-157	7916-7919	was	_	_
30-158	7920-7924	used	_	_
30-159	7925-7927	by	_	_
30-160	7929-7930	\[	_	_
30-161	7930-7936	Latent	*[3]	PUBLICATION[3]
30-162	7937-7941	ODEs	*[3]	PUBLICATION[3]
30-163	7942-7945	for	*[3]	PUBLICATION[3]
30-164	7946-7965	Irregularly-Sampled	*[3]	PUBLICATION[3]
30-165	7966-7970	Time	*[3]	PUBLICATION[3]
30-166	7971-7977	Series	*[3]	PUBLICATION[3]
30-167	7977-7978	\]	_	_
30-168	7978-7979	(	_	_
30-169	7979-7984	https	_	_
30-170	7984-7985	:	_	_
30-171	7985-7986	/	_	_
30-172	7986-7987	/	_	_
30-173	7987-7996	arxiv.org	_	_
30-174	7996-7997	/	_	_
30-175	7997-8000	abs	_	_
30-176	8000-8001	/	_	_
30-177	8001-8011	1907.03907	_	_
30-178	8011-8012	)	_	_
30-179	8013-8015	is	_	_
30-180	8016-8026	downloaded	_	_
30-181	8027-8030	and	_	_
30-182	8031-8036	saved	_	_
30-183	8037-8050	automatically	_	_
30-184	8051-8055	when	_	_
30-185	8056-8064	training	_	_
30-186	8065-8068	for	_	_
30-187	8069-8072	the	_	_
30-188	8073-8078	first	_	_
30-189	8079-8083	time	_	_
30-190	8083-8084	.	_	_

#Text=Moreover, the preprocessing steps provided in this paper are applied automatically.
31-1	8085-8093	Moreover	_	_
31-2	8093-8094	,	_	_
31-3	8095-8098	the	_	_
31-4	8099-8112	preprocessing	_	_
31-5	8113-8118	steps	_	_
31-6	8119-8127	provided	_	_
31-7	8128-8130	in	_	_
31-8	8131-8135	this	_	_
31-9	8136-8141	paper	_	_
31-10	8142-8145	are	_	_
31-11	8146-8153	applied	_	_
31-12	8154-8167	automatically	_	_
31-13	8167-8168	.	_	_

#Text=Models for validation on the Physionet dataset were trained using  parallel\_train.py with the model parameters specified below ``` # ========================================================================== # parallel training on physionet dataset # ========================================================================== ``` in the main part of the file parallel\_train.py.
32-1	8170-8176	Models	_	_
32-2	8177-8180	for	_	_
32-3	8181-8191	validation	_	_
32-4	8192-8194	on	_	_
32-5	8195-8198	the	_	_
32-6	8199-8208	Physionet	*	DATASET
32-7	8209-8216	dataset	_	_
32-8	8217-8221	were	_	_
32-9	8222-8229	trained	_	_
32-10	8230-8235	using	_	_
32-11	8237-8254	parallel\_train.py	_	_
32-12	8255-8259	with	_	_
32-13	8260-8263	the	_	_
32-14	8264-8269	model	_	_
32-15	8270-8280	parameters	_	_
32-16	8281-8290	specified	_	_
32-17	8291-8296	below	_	_
32-18	8297-8298	`	_	_
32-19	8298-8299	`	_	_
32-20	8299-8300	`	_	_
32-21	8301-8302	#	_	_
32-22	8303-8304	=	_	_
32-23	8304-8305	=	_	_
32-24	8305-8306	=	_	_
32-25	8306-8307	=	_	_
32-26	8307-8308	=	_	_
32-27	8308-8309	=	_	_
32-28	8309-8310	=	_	_
32-29	8310-8311	=	_	_
32-30	8311-8312	=	_	_
32-31	8312-8313	=	_	_
32-32	8313-8314	=	_	_
32-33	8314-8315	=	_	_
32-34	8315-8316	=	_	_
32-35	8316-8317	=	_	_
32-36	8317-8318	=	_	_
32-37	8318-8319	=	_	_
32-38	8319-8320	=	_	_
32-39	8320-8321	=	_	_
32-40	8321-8322	=	_	_
32-41	8322-8323	=	_	_
32-42	8323-8324	=	_	_
32-43	8324-8325	=	_	_
32-44	8325-8326	=	_	_
32-45	8326-8327	=	_	_
32-46	8327-8328	=	_	_
32-47	8328-8329	=	_	_
32-48	8329-8330	=	_	_
32-49	8330-8331	=	_	_
32-50	8331-8332	=	_	_
32-51	8332-8333	=	_	_
32-52	8333-8334	=	_	_
32-53	8334-8335	=	_	_
32-54	8335-8336	=	_	_
32-55	8336-8337	=	_	_
32-56	8337-8338	=	_	_
32-57	8338-8339	=	_	_
32-58	8339-8340	=	_	_
32-59	8340-8341	=	_	_
32-60	8341-8342	=	_	_
32-61	8342-8343	=	_	_
32-62	8343-8344	=	_	_
32-63	8344-8345	=	_	_
32-64	8345-8346	=	_	_
32-65	8346-8347	=	_	_
32-66	8347-8348	=	_	_
32-67	8348-8349	=	_	_
32-68	8349-8350	=	_	_
32-69	8350-8351	=	_	_
32-70	8351-8352	=	_	_
32-71	8352-8353	=	_	_
32-72	8353-8354	=	_	_
32-73	8354-8355	=	_	_
32-74	8355-8356	=	_	_
32-75	8356-8357	=	_	_
32-76	8357-8358	=	_	_
32-77	8358-8359	=	_	_
32-78	8359-8360	=	_	_
32-79	8360-8361	=	_	_
32-80	8361-8362	=	_	_
32-81	8362-8363	=	_	_
32-82	8363-8364	=	_	_
32-83	8364-8365	=	_	_
32-84	8365-8366	=	_	_
32-85	8366-8367	=	_	_
32-86	8367-8368	=	_	_
32-87	8368-8369	=	_	_
32-88	8369-8370	=	_	_
32-89	8370-8371	=	_	_
32-90	8371-8372	=	_	_
32-91	8372-8373	=	_	_
32-92	8373-8374	=	_	_
32-93	8374-8375	=	_	_
32-94	8375-8376	=	_	_
32-95	8376-8377	=	_	_
32-96	8378-8379	#	_	_
32-97	8380-8388	parallel	_	_
32-98	8389-8397	training	_	_
32-99	8398-8400	on	_	_
32-100	8401-8410	physionet	*	DATASET
32-101	8411-8418	dataset	_	_
32-102	8419-8420	#	_	_
32-103	8421-8422	=	_	_
32-104	8422-8423	=	_	_
32-105	8423-8424	=	_	_
32-106	8424-8425	=	_	_
32-107	8425-8426	=	_	_
32-108	8426-8427	=	_	_
32-109	8427-8428	=	_	_
32-110	8428-8429	=	_	_
32-111	8429-8430	=	_	_
32-112	8430-8431	=	_	_
32-113	8431-8432	=	_	_
32-114	8432-8433	=	_	_
32-115	8433-8434	=	_	_
32-116	8434-8435	=	_	_
32-117	8435-8436	=	_	_
32-118	8436-8437	=	_	_
32-119	8437-8438	=	_	_
32-120	8438-8439	=	_	_
32-121	8439-8440	=	_	_
32-122	8440-8441	=	_	_
32-123	8441-8442	=	_	_
32-124	8442-8443	=	_	_
32-125	8443-8444	=	_	_
32-126	8444-8445	=	_	_
32-127	8445-8446	=	_	_
32-128	8446-8447	=	_	_
32-129	8447-8448	=	_	_
32-130	8448-8449	=	_	_
32-131	8449-8450	=	_	_
32-132	8450-8451	=	_	_
32-133	8451-8452	=	_	_
32-134	8452-8453	=	_	_
32-135	8453-8454	=	_	_
32-136	8454-8455	=	_	_
32-137	8455-8456	=	_	_
32-138	8456-8457	=	_	_
32-139	8457-8458	=	_	_
32-140	8458-8459	=	_	_
32-141	8459-8460	=	_	_
32-142	8460-8461	=	_	_
32-143	8461-8462	=	_	_
32-144	8462-8463	=	_	_
32-145	8463-8464	=	_	_
32-146	8464-8465	=	_	_
32-147	8465-8466	=	_	_
32-148	8466-8467	=	_	_
32-149	8467-8468	=	_	_
32-150	8468-8469	=	_	_
32-151	8469-8470	=	_	_
32-152	8470-8471	=	_	_
32-153	8471-8472	=	_	_
32-154	8472-8473	=	_	_
32-155	8473-8474	=	_	_
32-156	8474-8475	=	_	_
32-157	8475-8476	=	_	_
32-158	8476-8477	=	_	_
32-159	8477-8478	=	_	_
32-160	8478-8479	=	_	_
32-161	8479-8480	=	_	_
32-162	8480-8481	=	_	_
32-163	8481-8482	=	_	_
32-164	8482-8483	=	_	_
32-165	8483-8484	=	_	_
32-166	8484-8485	=	_	_
32-167	8485-8486	=	_	_
32-168	8486-8487	=	_	_
32-169	8487-8488	=	_	_
32-170	8488-8489	=	_	_
32-171	8489-8490	=	_	_
32-172	8490-8491	=	_	_
32-173	8491-8492	=	_	_
32-174	8492-8493	=	_	_
32-175	8493-8494	=	_	_
32-176	8494-8495	=	_	_
32-177	8496-8497	`	_	_
32-178	8497-8498	`	_	_
32-179	8498-8499	`	_	_
32-180	8500-8502	in	_	_
32-181	8503-8506	the	_	_
32-182	8507-8511	main	_	_
32-183	8512-8516	part	_	_
32-184	8517-8519	of	_	_
32-185	8520-8523	the	_	_
32-186	8524-8528	file	_	_
32-187	8529-8546	parallel\_train.py	_	_
32-188	8546-8547	.	_	_

#Text=For training: uncomment the code below the model params and run the file.
33-1	8549-8552	For	_	_
33-2	8553-8561	training	_	_
33-3	8561-8562	:	_	_
33-4	8563-8572	uncomment	_	_
33-5	8573-8576	the	_	_
33-6	8577-8581	code	_	_
33-7	8582-8587	below	_	_
33-8	8588-8591	the	_	_
33-9	8592-8597	model	_	_
33-10	8598-8604	params	_	_
33-11	8605-8608	and	_	_
33-12	8609-8612	run	_	_
33-13	8613-8616	the	_	_
33-14	8617-8621	file	_	_
33-15	8621-8622	.	_	_

#Text=For performing/evaluating the validation (based on 5 runs) use the function-call: ``` # ------------ validation of physionet training ------------- get\_training\_overview(     path='{}saved\_models\_physionet\_comparison/'.format(train.data\_path),     params\_extract\_desc=('dataset', 'network\_size', 'dropout\_rate',                          'hidden\_size', 'data\_index'),     val\_test\_params\_extract=(("max", "epoch", "epoch", "epochs\_trained"),                              ("min", "eval\_metric",                               "eval\_metric", "eval\_metric\_min"),                              ("min", "eval\_metric\_2",                               "eval\_metric\_2", "eval\_metric\_2\_min"),                              ) )  get\_cross\_validation(     path='{}saved\_models\_physionet\_comparison/'.format(train.data\_path),     save\_path='{}saved\_models\_physionet\_comparison/'               'cross\_val.csv'.format(train.data\_path),     param\_combinations=({'network\_size': 50},                         {'network\_size': 200},                         {'network\_size': 400}),     val\_test\_params\_extract=(("max", "epoch", "epoch", "epochs\_trained"),                              ("min", "eval\_metric",                               "eval\_metric", "eval\_metric\_min"),                              ("min", "eval\_metric\_2",                               "eval\_metric\_2", "eval\_metric\_2\_min"),                              ("last", "eval\_metric\_2",                               "eval\_metric\_2", "eval\_metric\_2\_last"),                              ("min", "train\_loss",                               "eval\_metric\_2", "eval\_metric\_2\_eval\_min"),                              ),     target\_col=('eval\_metric\_min', 'eval\_metric\_2\_min',                 'eval\_metric\_2\_last', 'eval\_metric\_2\_eval\_min') ) ```  in extras.py.       ## Results  ### Evolution of model predictions during training Evolution of the model output (with old name "controlled ODE-RNN") on sample test paths  during training (i.e. increasing umber of epochs) for the 3 synthetic datasets.
34-1	8624-8627	For	_	_
34-2	8628-8638	performing	_	_
34-3	8638-8639	/	_	_
34-4	8639-8649	evaluating	_	_
34-5	8650-8653	the	_	_
34-6	8654-8664	validation	_	_
34-7	8665-8666	(	_	_
34-8	8666-8671	based	_	_
34-9	8672-8674	on	_	_
34-10	8675-8676	5	_	_
34-11	8677-8681	runs	_	_
34-12	8681-8682	)	_	_
34-13	8683-8686	use	_	_
34-14	8687-8690	the	_	_
34-15	8691-8704	function-call	_	_
34-16	8704-8705	:	_	_
34-17	8706-8707	`	_	_
34-18	8707-8708	`	_	_
34-19	8708-8709	`	_	_
34-20	8710-8711	#	_	_
34-21	8712-8713	-	_	_
34-22	8713-8714	-	_	_
34-23	8714-8715	-	_	_
34-24	8715-8716	-	_	_
34-25	8716-8717	-	_	_
34-26	8717-8718	-	_	_
34-27	8718-8719	-	_	_
34-28	8719-8720	-	_	_
34-29	8720-8721	-	_	_
34-30	8721-8722	-	_	_
34-31	8722-8723	-	_	_
34-32	8723-8724	-	_	_
34-33	8725-8735	validation	_	_
34-34	8736-8738	of	_	_
34-35	8739-8748	physionet	_	_
34-36	8749-8757	training	_	_
34-37	8758-8759	-	_	_
34-38	8759-8760	-	_	_
34-39	8760-8761	-	_	_
34-40	8761-8762	-	_	_
34-41	8762-8763	-	_	_
34-42	8763-8764	-	_	_
34-43	8764-8765	-	_	_
34-44	8765-8766	-	_	_
34-45	8766-8767	-	_	_
34-46	8767-8768	-	_	_
34-47	8768-8769	-	_	_
34-48	8769-8770	-	_	_
34-49	8770-8771	-	_	_
34-50	8772-8793	get\_training\_overview	_	_
34-51	8793-8794	(	_	_
34-52	8799-8803	path	_	_
34-53	8803-8804	=	_	_
34-54	8804-8805	'	_	_
34-55	8805-8806	{	_	_
34-56	8806-8807	}	_	_
34-57	8807-8840	saved\_models\_physionet\_comparison	_	_
34-58	8840-8841	/	_	_
34-59	8841-8842	'	_	_
34-60	8842-8843	.	_	_
34-61	8843-8849	format	_	_
34-62	8849-8850	(	_	_
34-63	8850-8865	train.data\_path	_	_
34-64	8865-8866	)	_	_
34-65	8866-8867	,	_	_
34-66	8872-8891	params\_extract\_desc	_	_
34-67	8891-8892	=	_	_
34-68	8892-8893	(	_	_
34-69	8893-8894	'	_	_
34-70	8894-8901	dataset	_	_
34-71	8901-8902	'	_	_
34-72	8902-8903	,	_	_
34-73	8904-8905	'	_	_
34-74	8905-8917	network\_size	_	_
34-75	8917-8918	'	_	_
34-76	8918-8919	,	_	_
34-77	8920-8921	'	_	_
34-78	8921-8933	dropout\_rate	_	_
34-79	8933-8934	'	_	_
34-80	8934-8935	,	_	_
34-81	8961-8962	'	_	_
34-82	8962-8973	hidden\_size	_	_
34-83	8973-8974	'	_	_
34-84	8974-8975	,	_	_
34-85	8976-8977	'	_	_
34-86	8977-8987	data\_index	_	_
34-87	8987-8988	'	_	_
34-88	8988-8989	)	_	_
34-89	8989-8990	,	_	_
34-90	8995-9018	val\_test\_params\_extract	_	_
34-91	9018-9019	=	_	_
34-92	9019-9020	(	_	_
34-93	9020-9021	(	_	_
34-94	9021-9022	"	_	_
34-95	9022-9025	max	_	_
34-96	9025-9026	"	_	_
34-97	9026-9027	,	_	_
34-98	9028-9029	"	_	_
34-99	9029-9034	epoch	_	_
34-100	9034-9035	"	_	_
34-101	9035-9036	,	_	_
34-102	9037-9038	"	_	_
34-103	9038-9043	epoch	_	_
34-104	9043-9044	"	_	_
34-105	9044-9045	,	_	_
34-106	9046-9047	"	_	_
34-107	9047-9061	epochs\_trained	_	_
34-108	9061-9062	"	_	_
34-109	9062-9063	)	_	_
34-110	9063-9064	,	_	_
34-111	9094-9095	(	_	_
34-112	9095-9096	"	_	_
34-113	9096-9099	min	_	_
34-114	9099-9100	"	_	_
34-115	9100-9101	,	_	_
34-116	9102-9103	"	_	_
34-117	9103-9114	eval\_metric	_	_
34-118	9114-9115	"	_	_
34-119	9115-9116	,	_	_
34-120	9147-9148	"	_	_
34-121	9148-9159	eval\_metric	_	_
34-122	9159-9160	"	_	_
34-123	9160-9161	,	_	_
34-124	9162-9163	"	_	_
34-125	9163-9178	eval\_metric\_min	_	_
34-126	9178-9179	"	_	_
34-127	9179-9180	)	_	_
34-128	9180-9181	,	_	_
34-129	9211-9212	(	_	_
34-130	9212-9213	"	_	_
34-131	9213-9216	min	_	_
34-132	9216-9217	"	_	_
34-133	9217-9218	,	_	_
34-134	9219-9220	"	_	_
34-135	9220-9231	eval\_metric	_	_
34-136	9231-9232	\_	_	_
34-137	9232-9233	2	_	_
34-138	9233-9234	"	_	_
34-139	9234-9235	,	_	_
34-140	9266-9267	"	_	_
34-141	9267-9278	eval\_metric	_	_
34-142	9278-9279	\_	_	_
34-143	9279-9280	2	_	_
34-144	9280-9281	"	_	_
34-145	9281-9282	,	_	_
34-146	9283-9284	"	_	_
34-147	9284-9295	eval\_metric	_	_
34-148	9295-9296	\_	_	_
34-149	9296-9297	2	_	_
34-150	9297-9298	\_	_	_
34-151	9298-9301	min	_	_
34-152	9301-9302	"	_	_
34-153	9302-9303	)	_	_
34-154	9303-9304	,	_	_
34-155	9334-9335	)	_	_
34-156	9336-9337	)	_	_
34-157	9339-9359	get\_cross\_validation	_	_
34-158	9359-9360	(	_	_
34-159	9365-9369	path	_	_
34-160	9369-9370	=	_	_
34-161	9370-9371	'	_	_
34-162	9371-9372	{	_	_
34-163	9372-9373	}	_	_
34-164	9373-9406	saved\_models\_physionet\_comparison	_	_
34-165	9406-9407	/	_	_
34-166	9407-9408	'	_	_
34-167	9408-9409	.	_	_
34-168	9409-9415	format	_	_
34-169	9415-9416	(	_	_
34-170	9416-9431	train.data\_path	_	_
34-171	9431-9432	)	_	_
34-172	9432-9433	,	_	_
34-173	9438-9447	save\_path	_	_
34-174	9447-9448	=	_	_
34-175	9448-9449	'	_	_
34-176	9449-9450	{	_	_
34-177	9450-9451	}	_	_
34-178	9451-9484	saved\_models\_physionet\_comparison	_	_
34-179	9484-9485	/	_	_
34-180	9485-9486	'	_	_
34-181	9501-9502	'	_	_
34-182	9502-9515	cross\_val.csv	_	_
34-183	9515-9516	'	_	_
34-184	9516-9517	.	_	_
34-185	9517-9523	format	_	_
34-186	9523-9524	(	_	_
34-187	9524-9539	train.data\_path	_	_
34-188	9539-9540	)	_	_
34-189	9540-9541	,	_	_
34-190	9546-9564	param\_combinations	_	_
34-191	9564-9565	=	_	_
34-192	9565-9566	(	_	_
34-193	9566-9567	{	_	_
34-194	9567-9568	'	_	_
34-195	9568-9580	network\_size	_	_
34-196	9580-9581	'	_	_
34-197	9581-9582	:	_	_
34-198	9583-9585	50	_	_
34-199	9585-9586	}	_	_
34-200	9586-9587	,	_	_
34-201	9612-9613	{	_	_
34-202	9613-9614	'	_	_
34-203	9614-9626	network\_size	_	_
34-204	9626-9627	'	_	_
34-205	9627-9628	:	_	_
34-206	9629-9632	200	_	_
34-207	9632-9633	}	_	_
34-208	9633-9634	,	_	_
34-209	9659-9660	{	_	_
34-210	9660-9661	'	_	_
34-211	9661-9673	network\_size	_	_
34-212	9673-9674	'	_	_
34-213	9674-9675	:	_	_
34-214	9676-9679	400	_	_
34-215	9679-9680	}	_	_
34-216	9680-9681	)	_	_
34-217	9681-9682	,	_	_
34-218	9687-9710	val\_test\_params\_extract	_	_
34-219	9710-9711	=	_	_
34-220	9711-9712	(	_	_
34-221	9712-9713	(	_	_
34-222	9713-9714	"	_	_
34-223	9714-9717	max	_	_
34-224	9717-9718	"	_	_
34-225	9718-9719	,	_	_
34-226	9720-9721	"	_	_
34-227	9721-9726	epoch	_	_
34-228	9726-9727	"	_	_
34-229	9727-9728	,	_	_
34-230	9729-9730	"	_	_
34-231	9730-9735	epoch	_	_
34-232	9735-9736	"	_	_
34-233	9736-9737	,	_	_
34-234	9738-9739	"	_	_
34-235	9739-9753	epochs\_trained	_	_
34-236	9753-9754	"	_	_
34-237	9754-9755	)	_	_
34-238	9755-9756	,	_	_
34-239	9786-9787	(	_	_
34-240	9787-9788	"	_	_
34-241	9788-9791	min	_	_
34-242	9791-9792	"	_	_
34-243	9792-9793	,	_	_
34-244	9794-9795	"	_	_
34-245	9795-9806	eval\_metric	_	_
34-246	9806-9807	"	_	_
34-247	9807-9808	,	_	_
34-248	9839-9840	"	_	_
34-249	9840-9851	eval\_metric	_	_
34-250	9851-9852	"	_	_
34-251	9852-9853	,	_	_
34-252	9854-9855	"	_	_
34-253	9855-9870	eval\_metric\_min	_	_
34-254	9870-9871	"	_	_
34-255	9871-9872	)	_	_
34-256	9872-9873	,	_	_
34-257	9903-9904	(	_	_
34-258	9904-9905	"	_	_
34-259	9905-9908	min	_	_
34-260	9908-9909	"	_	_
34-261	9909-9910	,	_	_
34-262	9911-9912	"	_	_
34-263	9912-9923	eval\_metric	_	_
34-264	9923-9924	\_	_	_
34-265	9924-9925	2	_	_
34-266	9925-9926	"	_	_
34-267	9926-9927	,	_	_
34-268	9958-9959	"	_	_
34-269	9959-9970	eval\_metric	_	_
34-270	9970-9971	\_	_	_
34-271	9971-9972	2	_	_
34-272	9972-9973	"	_	_
34-273	9973-9974	,	_	_
34-274	9975-9976	"	_	_
34-275	9976-9987	eval\_metric	_	_
34-276	9987-9988	\_	_	_
34-277	9988-9989	2	_	_
34-278	9989-9990	\_	_	_
34-279	9990-9993	min	_	_
34-280	9993-9994	"	_	_
34-281	9994-9995	)	_	_
34-282	9995-9996	,	_	_
34-283	10026-10027	(	_	_
34-284	10027-10028	"	_	_
34-285	10028-10032	last	_	_
34-286	10032-10033	"	_	_
34-287	10033-10034	,	_	_
34-288	10035-10036	"	_	_
34-289	10036-10047	eval\_metric	_	_
34-290	10047-10048	\_	_	_
34-291	10048-10049	2	_	_
34-292	10049-10050	"	_	_
34-293	10050-10051	,	_	_
34-294	10082-10083	"	_	_
34-295	10083-10094	eval\_metric	_	_
34-296	10094-10095	\_	_	_
34-297	10095-10096	2	_	_
34-298	10096-10097	"	_	_
34-299	10097-10098	,	_	_
34-300	10099-10100	"	_	_
34-301	10100-10111	eval\_metric	_	_
34-302	10111-10112	\_	_	_
34-303	10112-10113	2	_	_
34-304	10113-10114	\_	_	_
34-305	10114-10118	last	_	_
34-306	10118-10119	"	_	_
34-307	10119-10120	)	_	_
34-308	10120-10121	,	_	_
34-309	10151-10152	(	_	_
34-310	10152-10153	"	_	_
34-311	10153-10156	min	_	_
34-312	10156-10157	"	_	_
34-313	10157-10158	,	_	_
34-314	10159-10160	"	_	_
34-315	10160-10170	train\_loss	_	_
34-316	10170-10171	"	_	_
34-317	10171-10172	,	_	_
34-318	10203-10204	"	_	_
34-319	10204-10215	eval\_metric	_	_
34-320	10215-10216	\_	_	_
34-321	10216-10217	2	_	_
34-322	10217-10218	"	_	_
34-323	10218-10219	,	_	_
34-324	10220-10221	"	_	_
34-325	10221-10232	eval\_metric	_	_
34-326	10232-10233	\_	_	_
34-327	10233-10234	2	_	_
34-328	10234-10235	\_	_	_
34-329	10235-10243	eval\_min	_	_
34-330	10243-10244	"	_	_
34-331	10244-10245	)	_	_
34-332	10245-10246	,	_	_
34-333	10276-10277	)	_	_
34-334	10277-10278	,	_	_
34-335	10283-10293	target\_col	_	_
34-336	10293-10294	=	_	_
34-337	10294-10295	(	_	_
34-338	10295-10296	'	_	_
34-339	10296-10311	eval\_metric\_min	_	_
34-340	10311-10312	'	_	_
34-341	10312-10313	,	_	_
34-342	10314-10315	'	_	_
34-343	10315-10326	eval\_metric	_	_
34-344	10326-10327	\_	_	_
34-345	10327-10328	2	_	_
34-346	10328-10329	\_	_	_
34-347	10329-10332	min	_	_
34-348	10332-10333	'	_	_
34-349	10333-10334	,	_	_
34-350	10351-10352	'	_	_
34-351	10352-10363	eval\_metric	_	_
34-352	10363-10364	\_	_	_
34-353	10364-10365	2	_	_
34-354	10365-10366	\_	_	_
34-355	10366-10370	last	_	_
34-356	10370-10371	'	_	_
34-357	10371-10372	,	_	_
34-358	10373-10374	'	_	_
34-359	10374-10385	eval\_metric	_	_
34-360	10385-10386	\_	_	_
34-361	10386-10387	2	_	_
34-362	10387-10388	\_	_	_
34-363	10388-10396	eval\_min	_	_
34-364	10396-10397	'	_	_
34-365	10397-10398	)	_	_
34-366	10399-10400	)	_	_
34-367	10401-10402	`	_	_
34-368	10402-10403	`	_	_
34-369	10403-10404	`	_	_
34-370	10406-10408	in	_	_
34-371	10409-10418	extras.py	_	_
34-372	10418-10419	.	_	_
34-373	10426-10427	#	_	_
34-374	10427-10428	#	_	_
34-375	10429-10436	Results	_	_
34-376	10438-10439	#	_	_
34-377	10439-10440	#	_	_
34-378	10440-10441	#	_	_
34-379	10442-10451	Evolution	_	_
34-380	10452-10454	of	_	_
34-381	10455-10460	model	_	_
34-382	10461-10472	predictions	_	_
34-383	10473-10479	during	_	_
34-384	10480-10488	training	_	_
34-385	10489-10498	Evolution	_	_
34-386	10499-10501	of	_	_
34-387	10502-10505	the	_	_
34-388	10506-10511	model	_	_
34-389	10512-10518	output	_	_
34-390	10519-10520	(	_	_
34-391	10520-10524	with	_	_
34-392	10525-10528	old	_	_
34-393	10529-10533	name	_	_
34-394	10534-10535	"	_	_
34-395	10535-10545	controlled	_	_
34-396	10546-10553	ODE-RNN	_	_
34-397	10553-10554	"	_	_
34-398	10554-10555	)	_	_
34-399	10556-10558	on	_	_
34-400	10559-10565	sample	_	_
34-401	10566-10570	test	_	_
34-402	10571-10576	paths	_	_
34-403	10578-10584	during	_	_
34-404	10585-10593	training	_	_
34-405	10594-10595	(	_	_
34-406	10595-10598	i.e	_	_
34-407	10598-10599	.	_	_
34-408	10600-10610	increasing	_	_
34-409	10611-10616	umber	_	_
34-410	10617-10619	of	_	_
34-411	10620-10626	epochs	_	_
34-412	10626-10627	)	_	_
34-413	10628-10631	for	_	_
34-414	10632-10635	the	_	_
34-415	10636-10637	3	_	_
34-416	10638-10647	synthetic	_	_
34-417	10648-10656	datasets	_	_
34-418	10656-10657	.	_	_

#Text=Black-Scholes:  !
35-1	10660-10673	Black-Scholes	_	_
35-2	10673-10674	:	_	_
35-3	10676-10677	!	_	_

#Text=\[alt text\](data/model\_id-1\_training-progress.gif)  Heston:  !
36-1	10677-10678	\[	_	_
36-2	10678-10681	alt	_	_
36-3	10682-10686	text	_	_
36-4	10686-10687	\]	_	_
36-5	10687-10688	(	_	_
36-6	10688-10692	data	_	_
36-7	10692-10693	/	_	_
36-8	10693-10701	model\_id	_	_
36-9	10701-10702	-	_	_
36-10	10702-10703	1	_	_
36-11	10703-10704	\_	_	_
36-12	10704-10725	training-progress.gif	_	_
36-13	10725-10726	)	_	_
36-14	10728-10734	Heston	_	_
36-15	10734-10735	:	_	_
36-16	10737-10738	!	_	_

#Text=\[alt text\](data/model\_id-2\_training-progress.gif)  Ornstein-Uhlenbeck:  !
37-1	10738-10739	\[	_	_
37-2	10739-10742	alt	_	_
37-3	10743-10747	text	_	_
37-4	10747-10748	\]	_	_
37-5	10748-10749	(	_	_
37-6	10749-10753	data	_	_
37-7	10753-10754	/	_	_
37-8	10754-10762	model\_id	_	_
37-9	10762-10763	-	_	_
37-10	10763-10764	2	_	_
37-11	10764-10765	\_	_	_
37-12	10765-10786	training-progress.gif	_	_
37-13	10786-10787	)	_	_
37-14	10789-10807	Ornstein-Uhlenbeck	_	_
37-15	10807-10808	:	_	_
37-16	10810-10811	!	_	_

#Text=\[alt text\](data/model\_id-3\_training-progress.gif)    ## Usage, License & Citation  This code can be used in accordance with the LICENSE.txt.
38-1	10811-10812	\[	_	_
38-2	10812-10815	alt	_	_
38-3	10816-10820	text	_	_
38-4	10820-10821	\]	_	_
38-5	10821-10822	(	_	_
38-6	10822-10826	data	_	_
38-7	10826-10827	/	_	_
38-8	10827-10835	model\_id	_	_
38-9	10835-10836	-	_	_
38-10	10836-10837	3	_	_
38-11	10837-10838	\_	_	_
38-12	10838-10859	training-progress.gif	_	_
38-13	10859-10860	)	_	_
38-14	10864-10865	#	_	_
38-15	10865-10866	#	_	_
38-16	10867-10872	Usage	_	_
38-17	10872-10873	,	_	_
38-18	10874-10881	License	_	_
38-19	10882-10883	&	_	_
38-20	10884-10892	Citation	_	_
38-21	10894-10898	This	_	_
38-22	10899-10903	code	_	_
38-23	10904-10907	can	_	_
38-24	10908-10910	be	_	_
38-25	10911-10915	used	_	_
38-26	10916-10918	in	_	_
38-27	10919-10929	accordance	_	_
38-28	10930-10934	with	_	_
38-29	10935-10938	the	_	_
38-30	10939-10950	LICENSE.txt	_	_
38-31	10950-10951	.	_	_

#Text=If you find this code useful, please cite our paper: \[Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering\](https://openreview.net/forum?
39-1	10953-10955	If	_	_
39-2	10956-10959	you	_	_
39-3	10960-10964	find	_	_
39-4	10965-10969	this	_	_
39-5	10970-10974	code	_	_
39-6	10975-10981	useful	_	_
39-7	10981-10982	,	_	_
39-8	10983-10989	please	_	_
39-9	10990-10994	cite	_	_
39-10	10995-10998	our	_	_
39-11	10999-11004	paper	_	_
39-12	11004-11005	:	_	_
39-13	11006-11007	\[	_	_
39-14	11007-11013	Neural	*[4]	PUBLICATION[4]
39-15	11014-11018	Jump	*[4]	PUBLICATION[4]
39-16	11019-11027	Ordinary	*[4]	PUBLICATION[4]
39-17	11028-11040	Differential	*[4]	PUBLICATION[4]
39-18	11041-11050	Equations	*[4]	PUBLICATION[4]
39-19	11050-11051	:	*[4]	PUBLICATION[4]
39-20	11052-11062	Consistent	*[4]	PUBLICATION[4]
39-21	11063-11078	Continuous-Time	*[4]	PUBLICATION[4]
39-22	11079-11089	Prediction	*[4]	PUBLICATION[4]
39-23	11090-11093	and	*[4]	PUBLICATION[4]
39-24	11094-11103	Filtering	*[4]	PUBLICATION[4]
39-25	11103-11104	\]	_	_
39-26	11104-11105	(	_	_
39-27	11105-11110	https	_	_
39-28	11110-11111	:	_	_
39-29	11111-11112	/	_	_
39-30	11112-11113	/	_	_
39-31	11113-11127	openreview.net	_	_
39-32	11127-11128	/	_	_
39-33	11128-11133	forum	_	_
39-34	11133-11134	?	_	_

#Text=id=JFKR3WqwyXR).  ``` @inproceedings{ herrera2021neural, title={Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering}, author={Calypso Herrera and Florian Krach and Josef Teichmann}, booktitle={International Conference on Learning Representations}, year={2021}, url={https://openreview.net/forum?
40-1	11134-11136	id	_	_
40-2	11136-11137	=	_	_
40-3	11137-11148	JFKR3WqwyXR	_	_
40-4	11148-11149	)	_	_
40-5	11149-11150	.	_	_
40-6	11152-11153	`	_	_
40-7	11153-11154	`	_	_
40-8	11154-11155	`	_	_
40-9	11156-11157	@	_	_
40-10	11157-11170	inproceedings	_	_
40-11	11170-11171	{	_	_
40-12	11172-11189	herrera2021neural	_	_
40-13	11189-11190	,	_	_
40-14	11191-11196	title	_	_
40-15	11196-11197	=	_	_
40-16	11197-11198	{	_	_
40-17	11198-11204	Neural	*[5]	PUBLICATION[5]
40-18	11205-11209	Jump	*[5]	PUBLICATION[5]
40-19	11210-11218	Ordinary	*[5]	PUBLICATION[5]
40-20	11219-11231	Differential	*[5]	PUBLICATION[5]
40-21	11232-11241	Equations	*[5]	PUBLICATION[5]
40-22	11241-11242	:	*[5]	PUBLICATION[5]
40-23	11243-11253	Consistent	*[5]	PUBLICATION[5]
40-24	11254-11269	Continuous-Time	*[5]	PUBLICATION[5]
40-25	11270-11280	Prediction	*[5]	PUBLICATION[5]
40-26	11281-11284	and	*[5]	PUBLICATION[5]
40-27	11285-11294	Filtering	*[5]	PUBLICATION[5]
40-28	11294-11295	}	_	_
40-29	11295-11296	,	_	_
40-30	11297-11303	author	_	_
40-31	11303-11304	=	_	_
40-32	11304-11305	{	_	_
40-33	11305-11312	Calypso	_	_
40-34	11313-11320	Herrera	_	_
40-35	11321-11324	and	_	_
40-36	11325-11332	Florian	_	_
40-37	11333-11338	Krach	_	_
40-38	11339-11342	and	_	_
40-39	11343-11348	Josef	_	_
40-40	11349-11358	Teichmann	_	_
40-41	11358-11359	}	_	_
40-42	11359-11360	,	_	_
40-43	11361-11370	booktitle	_	_
40-44	11370-11371	=	_	_
40-45	11371-11372	{	_	_
40-46	11372-11385	International	*[6]	CONFERENCE[6]
40-47	11386-11396	Conference	*[6]	CONFERENCE[6]
40-48	11397-11399	on	*[6]	CONFERENCE[6]
40-49	11400-11408	Learning	*[6]	CONFERENCE[6]
40-50	11409-11424	Representations	*[6]	CONFERENCE[6]
40-51	11424-11425	}	_	_
40-52	11425-11426	,	_	_
40-53	11427-11431	year	_	_
40-54	11431-11432	=	_	_
40-55	11432-11433	{	_	_
40-56	11433-11437	2021	_	_
40-57	11437-11438	}	_	_
40-58	11438-11439	,	_	_
40-59	11440-11443	url	_	_
40-60	11443-11444	=	_	_
40-61	11444-11445	{	_	_
40-62	11445-11450	https	_	_
40-63	11450-11451	:	_	_
40-64	11451-11452	/	_	_
40-65	11452-11453	/	_	_
40-66	11453-11467	openreview.net	_	_
40-67	11467-11468	/	_	_
40-68	11468-11473	forum	_	_
40-69	11473-11474	?	_	_

#Text=id=JFKR3WqwyXR} } ```   ## Acknowledgements and References Parts of this code are based on and/or copied from the code of:  https://github.com/edebrouwer/gru\_ode\_bayes, of the paper  \[GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series\](https://arxiv.org/abs/1905.12374) and the code of: https://github.com/YuliaRubanova/latent\_ode, of the paper \[Latent ODEs for Irregularly-Sampled Time Series\](https://arxiv.org/abs/1907.03907).
41-1	11474-11476	id	_	_
41-2	11476-11477	=	_	_
41-3	11477-11488	JFKR3WqwyXR	_	_
41-4	11488-11489	}	_	_
41-5	11490-11491	}	_	_
41-6	11492-11493	`	_	_
41-7	11493-11494	`	_	_
41-8	11494-11495	`	_	_
41-9	11498-11499	#	_	_
41-10	11499-11500	#	_	_
41-11	11501-11517	Acknowledgements	_	_
41-12	11518-11521	and	_	_
41-13	11522-11532	References	_	_
41-14	11533-11538	Parts	_	_
41-15	11539-11541	of	_	_
41-16	11542-11546	this	_	_
41-17	11547-11551	code	_	_
41-18	11552-11555	are	_	_
41-19	11556-11561	based	_	_
41-20	11562-11564	on	_	_
41-21	11565-11568	and	_	_
41-22	11568-11569	/	_	_
41-23	11569-11571	or	_	_
41-24	11572-11578	copied	_	_
41-25	11579-11583	from	_	_
41-26	11584-11587	the	_	_
41-27	11588-11592	code	_	_
41-28	11593-11595	of	_	_
41-29	11595-11596	:	_	_
41-30	11598-11603	https	_	_
41-31	11603-11604	:	_	_
41-32	11604-11605	/	_	_
41-33	11605-11606	/	_	_
41-34	11606-11616	github.com	_	_
41-35	11616-11617	/	_	_
41-36	11617-11627	edebrouwer	_	_
41-37	11627-11628	/	_	_
41-38	11628-11641	gru\_ode\_bayes	_	_
41-39	11641-11642	,	_	_
41-40	11643-11645	of	_	_
41-41	11646-11649	the	_	_
41-42	11650-11655	paper	_	_
41-43	11657-11658	\[	_	_
41-44	11658-11671	GRU-ODE-Bayes	*[7]	PUBLICATION[7]
41-45	11671-11672	:	*[7]	PUBLICATION[7]
41-46	11673-11683	Continuous	*[7]	PUBLICATION[7]
41-47	11684-11692	modeling	*[7]	PUBLICATION[7]
41-48	11693-11695	of	*[7]	PUBLICATION[7]
41-49	11696-11717	sporadically-observed	*[7]	PUBLICATION[7]
41-50	11718-11722	time	*[7]	PUBLICATION[7]
41-51	11723-11729	series	*[7]	PUBLICATION[7]
41-52	11729-11730	\]	_	_
41-53	11730-11731	(	_	_
41-54	11731-11736	https	_	_
41-55	11736-11737	:	_	_
41-56	11737-11738	/	_	_
41-57	11738-11739	/	_	_
41-58	11739-11748	arxiv.org	_	_
41-59	11748-11749	/	_	_
41-60	11749-11752	abs	_	_
41-61	11752-11753	/	_	_
41-62	11753-11763	1905.12374	_	_
41-63	11763-11764	)	_	_
41-64	11765-11768	and	_	_
41-65	11769-11772	the	_	_
41-66	11773-11777	code	_	_
41-67	11778-11780	of	_	_
41-68	11780-11781	:	_	_
41-69	11782-11787	https	_	_
41-70	11787-11788	:	_	_
41-71	11788-11789	/	_	_
41-72	11789-11790	/	_	_
41-73	11790-11800	github.com	_	_
41-74	11800-11801	/	_	_
41-75	11801-11814	YuliaRubanova	_	_
41-76	11814-11815	/	_	_
41-77	11815-11825	latent\_ode	_	_
41-78	11825-11826	,	_	_
41-79	11827-11829	of	_	_
41-80	11830-11833	the	_	_
41-81	11834-11839	paper	_	_
41-82	11840-11841	\[	_	_
41-83	11841-11847	Latent	*[8]	PUBLICATION[8]
41-84	11848-11852	ODEs	*[8]	PUBLICATION[8]
41-85	11853-11856	for	*[8]	PUBLICATION[8]
41-86	11857-11876	Irregularly-Sampled	*[8]	PUBLICATION[8]
41-87	11877-11881	Time	*[8]	PUBLICATION[8]
41-88	11882-11888	Series	*[8]	PUBLICATION[8]
41-89	11888-11889	\]	_	_
41-90	11889-11890	(	_	_
41-91	11890-11895	https	_	_
41-92	11895-11896	:	_	_
41-93	11896-11897	/	_	_
41-94	11897-11898	/	_	_
41-95	11898-11907	arxiv.org	_	_
41-96	11907-11908	/	_	_
41-97	11908-11911	abs	_	_
41-98	11911-11912	/	_	_
41-99	11912-11922	1907.03907	_	_
41-100	11922-11923	)	_	_
41-101	11923-11924	.	_	_

#Text=The GIFs of the training progress were generated with imageio: \[!
42-1	11926-11929	The	_	_
42-2	11930-11934	GIFs	_	_
42-3	11935-11937	of	_	_
42-4	11938-11941	the	_	_
42-5	11942-11950	training	_	_
42-6	11951-11959	progress	_	_
42-7	11960-11964	were	_	_
42-8	11965-11974	generated	_	_
42-9	11975-11979	with	_	_
42-10	11980-11987	imageio	_	_
42-11	11987-11988	:	_	_
42-12	11989-11990	\[	_	_
42-13	11990-11991	!	_	_

#Text=\[DOI\](https://zenodo.org/badge/DOI/10.5281/zenodo.3674137.svg)\](https://doi.org/10.5281/zenodo.3674137)
43-1	11991-11992	\[	_	_
43-2	11992-11995	DOI	_	_
43-3	11995-11996	\]	_	_
43-4	11996-11997	(	_	_
43-5	11997-12002	https	_	_
43-6	12002-12003	:	_	_
43-7	12003-12004	/	_	_
43-8	12004-12005	/	_	_
43-9	12005-12015	zenodo.org	_	_
43-10	12015-12016	/	_	_
43-11	12016-12021	badge	_	_
43-12	12021-12022	/	_	_
43-13	12022-12025	DOI	_	_
43-14	12025-12026	/	_	_
43-15	12026-12033	10.5281	_	_
43-16	12033-12034	/	_	_
43-17	12034-12040	zenodo	_	_
43-18	12040-12048	.3674137	_	_
43-19	12048-12049	.	_	_
43-20	12049-12052	svg	_	_
43-21	12052-12053	)	_	_
43-22	12053-12054	\]	_	_
43-23	12054-12055	(	_	_
43-24	12055-12060	https	_	_
43-25	12060-12061	:	_	_
43-26	12061-12062	/	_	_
43-27	12062-12063	/	_	_
43-28	12063-12070	doi.org	_	_
43-29	12070-12071	/	_	_
43-30	12071-12078	10.5281	_	_
43-31	12078-12079	/	_	_
43-32	12079-12085	zenodo	_	_
43-33	12085-12093	.3674137	_	_
43-34	12093-12094	)	_	_