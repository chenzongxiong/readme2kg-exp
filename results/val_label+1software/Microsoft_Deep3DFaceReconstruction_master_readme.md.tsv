#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=## Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set ##  <p align="center">  <img src="/images/example.gif"> </p>  ### \*\*\_\\\*\\\*\\\*07/20/2021: A \[PyTorch implementation\](https://github.com/sicxu/Deep3DFaceRecon\_pytorch) which has much better performance and is much easier to use is available now.
1-1	0-1	#	*[11]	SOFTWARE[11]
1-2	1-2	#	*[11]	SOFTWARE[11]
1-3	3-11	Accurate	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-4	12-14	3D	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-5	15-19	Face	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-6	20-34	Reconstruction	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-7	35-39	with	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-8	40-57	Weakly-Supervised	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-9	58-66	Learning	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-10	66-67	:	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-11	68-72	From	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-12	73-79	Single	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-13	80-85	Image	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-14	86-88	to	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-15	89-94	Image	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-16	95-98	Set	*[1]|*[11]	PUBLICATION[1]|SOFTWARE[11]
1-17	99-100	#	*[11]	SOFTWARE[11]
1-18	100-101	#	*[11]	SOFTWARE[11]
1-19	103-104	<	_	_
1-20	104-105	p	_	_
1-21	106-111	align	_	_
1-22	111-112	=	_	_
1-23	112-113	"	_	_
1-24	113-119	center	_	_
1-25	119-120	"	_	_
1-26	120-121	>	_	_
1-27	123-124	<	_	_
1-28	124-127	img	_	_
1-29	128-131	src	_	_
1-30	131-132	=	_	_
1-31	132-133	"	_	_
1-32	133-134	/	_	_
1-33	134-140	images	_	_
1-34	140-141	/	_	_
1-35	141-152	example.gif	_	_
1-36	152-153	"	_	_
1-37	153-154	>	_	_
1-38	155-156	<	_	_
1-39	156-157	/	_	_
1-40	157-158	p	_	_
1-41	158-159	>	_	_
1-42	161-162	#	_	_
1-43	162-163	#	_	_
1-44	163-164	#	_	_
1-45	165-166	\*	_	_
1-46	166-167	\*	_	_
1-47	167-168	\_	_	_
1-48	168-169	\\	_	_
1-49	169-170	\*	_	_
1-50	170-171	\\	_	_
1-51	171-172	\*	_	_
1-52	172-173	\\	_	_
1-53	173-174	\*	_	_
1-54	174-176	07	_	_
1-55	176-177	/	_	_
1-56	177-179	20	_	_
1-57	179-180	/	_	_
1-58	180-184	2021	_	_
1-59	184-185	:	_	_
1-60	186-187	A	_	_
1-61	188-189	\[	_	_
1-62	189-196	PyTorch	*	SOFTWARE
1-63	197-211	implementation	_	_
1-64	211-212	\]	_	_
1-65	212-213	(	_	_
1-66	213-218	https	_	_
1-67	218-219	:	_	_
1-68	219-220	/	_	_
1-69	220-221	/	_	_
1-70	221-231	github.com	_	_
1-71	231-232	/	_	_
1-72	232-237	sicxu	_	_
1-73	237-238	/	_	_
1-74	238-261	Deep3DFaceRecon\_pytorch	_	_
1-74	238-253	Deep3DFaceRecon	*	PROJECT
1-74	254-261	pytorch	*	SOFTWARE
1-75	261-262	)	_	_
1-76	263-268	which	_	_
1-77	269-272	has	_	_
1-78	273-277	much	_	_
1-79	278-284	better	_	_
1-80	285-296	performance	_	_
1-81	297-300	and	_	_
1-82	301-303	is	_	_
1-83	304-308	much	_	_
1-84	309-315	easier	_	_
1-85	316-318	to	_	_
1-86	319-322	use	_	_
1-87	323-325	is	_	_
1-88	326-335	available	_	_
1-89	336-339	now	_	_
1-90	339-340	.	_	_

#Text=This repo will not be maintained in future. \\\*\\\*\\\*\_\*\*   This is a tensorflow implementation of the following paper:  Y.
2-1	341-345	This	_	_
2-2	346-350	repo	_	_
2-3	351-355	will	_	_
2-4	356-359	not	_	_
2-5	360-362	be	_	_
2-6	363-373	maintained	_	_
2-7	374-376	in	_	_
2-8	377-383	future	_	_
2-9	383-384	.	_	_
2-10	385-386	\\	_	_
2-11	386-387	\*	_	_
2-12	387-388	\\	_	_
2-13	388-389	\*	_	_
2-14	389-390	\\	_	_
2-15	390-391	\*	_	_
2-16	391-392	\_	_	_
2-17	392-393	\*	_	_
2-18	393-394	\*	_	_
2-19	397-401	This	_	_
2-20	402-404	is	_	_
2-21	405-406	a	_	_
2-22	407-417	tensorflow	*	SOFTWARE
2-23	418-432	implementation	_	_
2-24	433-435	of	_	_
2-25	436-439	the	_	_
2-26	440-449	following	_	_
2-27	450-455	paper	_	_
2-28	455-456	:	_	_
2-29	458-459	Y	_	_
2-30	459-460	.	_	_

#Text=Deng, J.
3-1	461-465	Deng	_	_
3-2	465-466	,	_	_
3-3	467-468	J	_	_
3-4	468-469	.	_	_

#Text=Yang, S.
4-1	470-474	Yang	_	_
4-2	474-475	,	_	_
4-3	476-477	S	_	_
4-4	477-478	.	_	_

#Text=Xu, D.
5-1	479-481	Xu	_	_
5-2	481-482	,	_	_
5-3	483-484	D	_	_
5-4	484-485	.	_	_

#Text=Chen, Y.
6-1	486-490	Chen	_	_
6-2	490-491	,	_	_
6-3	492-493	Y	_	_
6-4	493-494	.	_	_

#Text=Jia, and X.
7-1	495-498	Jia	_	_
7-2	498-499	,	_	_
7-3	500-503	and	_	_
7-4	504-505	X	_	_
7-5	505-506	.	_	_

#Text=Tong, \[Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set\](https://arxiv.org/abs/1903.08527), IEEE Computer Vision and Pattern Recognition Workshop (CVPRW) on Analysis and Modeling of Faces and Gestures (AMFG), 2019.
8-1	507-511	Tong	_	_
8-2	511-512	,	_	_
8-3	513-514	\[	_	_
8-4	514-522	Accurate	*[2]	PUBLICATION[2]
8-5	523-525	3D	*[2]	PUBLICATION[2]
8-6	526-530	Face	*[2]	PUBLICATION[2]
8-7	531-545	Reconstruction	*[2]	PUBLICATION[2]
8-8	546-550	with	*[2]	PUBLICATION[2]
8-9	551-568	Weakly-Supervised	*[2]	PUBLICATION[2]
8-10	569-577	Learning	*[2]	PUBLICATION[2]
8-11	577-578	:	*[2]	PUBLICATION[2]
8-12	579-583	From	*[2]	PUBLICATION[2]
8-13	584-590	Single	*[2]	PUBLICATION[2]
8-14	591-596	Image	*[2]	PUBLICATION[2]
8-15	597-599	to	*[2]	PUBLICATION[2]
8-16	600-605	Image	*[2]	PUBLICATION[2]
8-17	606-609	Set	*[2]	PUBLICATION[2]
8-18	609-610	\]	_	_
8-19	610-611	(	_	_
8-20	611-616	https	_	_
8-21	616-617	:	_	_
8-22	617-618	/	_	_
8-23	618-619	/	_	_
8-24	619-628	arxiv.org	_	_
8-25	628-629	/	_	_
8-26	629-632	abs	_	_
8-27	632-633	/	_	_
8-28	633-643	1903.08527	_	_
8-29	643-644	)	_	_
8-30	644-645	,	_	_
8-31	646-650	IEEE	*[3]	PUBLICATION[3]
8-32	651-659	Computer	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-33	660-666	Vision	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-34	667-670	and	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-35	671-678	Pattern	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-36	679-690	Recognition	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-37	691-699	Workshop	*[3]|*[4]	PUBLICATION[3]|WORKSHOP[4]
8-38	700-701	(	*[3]	PUBLICATION[3]
8-39	701-706	CVPRW	*[3]|*[5]	PUBLICATION[3]|WORKSHOP[5]
8-40	706-707	)	*[3]	PUBLICATION[3]
8-41	708-710	on	*[3]	PUBLICATION[3]
8-42	711-719	Analysis	*[3]	PUBLICATION[3]
8-43	720-723	and	*[3]	PUBLICATION[3]
8-44	724-732	Modeling	*[3]	PUBLICATION[3]
8-45	733-735	of	*[3]	PUBLICATION[3]
8-46	736-741	Faces	*[3]	PUBLICATION[3]
8-47	742-745	and	*[3]	PUBLICATION[3]
8-48	746-754	Gestures	*[3]	PUBLICATION[3]
8-49	755-756	(	*[3]	PUBLICATION[3]
8-50	756-760	AMFG	*[3]	PUBLICATION[3]
8-51	760-761	)	*[3]	PUBLICATION[3]
8-52	761-762	,	_	_
8-53	763-767	2019	_	_
8-54	767-768	.	_	_

#Text=(\*\*\_Best Paper Award!
9-1	769-770	(	_	_
9-2	770-771	\*	_	_
9-3	771-772	\*	_	_
9-4	772-773	\_	_	_
9-5	773-777	Best	_	_
9-6	778-783	Paper	_	_
9-7	784-789	Award	_	_
9-8	789-790	!	_	_

#Text=\_\*\*)  The method enforces a hybrid-level weakly-supervised training for CNN-based 3D face reconstruction.
10-1	790-791	\_	_	_
10-2	791-792	\*	_	_
10-3	792-793	\*	_	_
10-4	793-794	)	_	_
10-5	796-799	The	_	_
10-6	800-806	method	_	_
10-7	807-815	enforces	_	_
10-8	816-817	a	_	_
10-9	818-830	hybrid-level	_	_
10-10	831-848	weakly-supervised	_	_
10-11	849-857	training	_	_
10-12	858-861	for	_	_
10-13	862-871	CNN-based	_	_
10-14	872-874	3D	_	_
10-15	875-879	face	_	_
10-16	880-894	reconstruction	_	_
10-17	894-895	.	_	_

#Text=It is fast, accurate, and robust to pose and occlussions.
11-1	896-898	It	_	_
11-2	899-901	is	_	_
11-3	902-906	fast	_	_
11-4	906-907	,	_	_
11-5	908-916	accurate	_	_
11-6	916-917	,	_	_
11-7	918-921	and	_	_
11-8	922-928	robust	_	_
11-9	929-931	to	_	_
11-10	932-936	pose	_	_
11-11	937-940	and	_	_
11-12	941-952	occlussions	_	_
11-13	952-953	.	_	_

#Text=It achieves state-of-the-art performance on multiple datasets such as FaceWarehouse, MICC Florence and BU-3DFE.     ## Features  ### ● Accurate shapes The method reconstructs faces with high accuracy.
12-1	954-956	It	_	_
12-2	957-965	achieves	_	_
12-3	966-982	state-of-the-art	_	_
12-4	983-994	performance	_	_
12-5	995-997	on	_	_
12-6	998-1006	multiple	_	_
12-7	1007-1015	datasets	_	_
12-8	1016-1020	such	_	_
12-9	1021-1023	as	_	_
12-10	1024-1037	FaceWarehouse	*	DATASET
12-11	1037-1038	,	_	_
12-12	1039-1043	MICC	*[6]	DATASET[6]
12-13	1044-1052	Florence	*[6]	DATASET[6]
12-14	1053-1056	and	_	_
12-15	1057-1059	BU	*[7]	DATASET[7]
12-16	1059-1060	-	*[7]	DATASET[7]
12-17	1060-1064	3DFE	*[7]	DATASET[7]
12-18	1064-1065	.	_	_
12-19	1070-1071	#	_	_
12-20	1071-1072	#	_	_
12-21	1073-1081	Features	_	_
12-22	1083-1084	#	_	_
12-23	1084-1085	#	_	_
12-24	1085-1086	#	_	_
12-25	1087-1088	●	_	_
12-26	1089-1097	Accurate	_	_
12-27	1098-1104	shapes	_	_
12-28	1105-1108	The	_	_
12-29	1109-1115	method	_	_
12-30	1116-1128	reconstructs	_	_
12-31	1129-1134	faces	_	_
12-32	1135-1139	with	_	_
12-33	1140-1144	high	_	_
12-34	1145-1153	accuracy	_	_
12-35	1153-1154	.	_	_

#Text=Quantitative evaluations (shape errors in mm) on several benchmarks show its state-of-the-art performance:   \|Method\|FaceWareHouse\|Florence\|BU3DFE\| \|:---:\|:---:\|:---:\|:---:\| \|\[Tewari et al. 17\](https://arxiv.org/abs/1703.10580)</center>\|2.19±0.54\|-\|-\| \|\[Tewari et al. 18\](https://arxiv.org/abs/1712.02859)\|1.84±0.38\|-\|-\| \|\[Genova et al. 18\](https://arxiv.org/abs/1806.06098)\|-\|1.77±0.53\|-\| \|\[Sela et al. 17\](https://arxiv.org/abs/1703.10131)\|-\|-\|2.91±0.60\| \|\[PRN 18\](https://arxiv.org/abs/1803.07835)\|-\|-\|1.86±0.47\| \|Ours\|\*\*1.81±0.50\*\*\|\*\*1.67±0.50\*\*\|\*\*1.40±0.31\*\*\|  (Please refer to our paper for more details about these results)  ### ● High fidelity textures The method produces high fidelity face textures meanwhile preserves identity information of input images.
13-1	1155-1167	Quantitative	_	_
13-2	1168-1179	evaluations	_	_
13-3	1180-1181	(	_	_
13-4	1181-1186	shape	_	_
13-5	1187-1193	errors	_	_
13-6	1194-1196	in	_	_
13-7	1197-1199	mm	_	_
13-8	1199-1200	)	_	_
13-9	1201-1203	on	_	_
13-10	1204-1211	several	_	_
13-11	1212-1222	benchmarks	_	_
13-12	1223-1227	show	_	_
13-13	1228-1231	its	_	_
13-14	1232-1248	state-of-the-art	_	_
13-15	1249-1260	performance	_	_
13-16	1260-1261	:	_	_
13-17	1264-1265	\|	_	_
13-18	1265-1271	Method	_	_
13-19	1271-1272	\|	_	_
13-20	1272-1285	FaceWareHouse	*	DATASET
13-21	1285-1286	\|	_	_
13-22	1286-1294	Florence	*	DATASET
13-23	1294-1295	\|	_	_
13-24	1295-1301	BU3DFE	*	DATASET
13-25	1301-1302	\|	_	_
13-26	1303-1304	\|	_	_
13-27	1304-1305	:	_	_
13-28	1305-1306	-	_	_
13-29	1306-1307	-	_	_
13-30	1307-1308	-	_	_
13-31	1308-1309	:	_	_
13-32	1309-1310	\|	_	_
13-33	1310-1311	:	_	_
13-34	1311-1312	-	_	_
13-35	1312-1313	-	_	_
13-36	1313-1314	-	_	_
13-37	1314-1315	:	_	_
13-38	1315-1316	\|	_	_
13-39	1316-1317	:	_	_
13-40	1317-1318	-	_	_
13-41	1318-1319	-	_	_
13-42	1319-1320	-	_	_
13-43	1320-1321	:	_	_
13-44	1321-1322	\|	_	_
13-45	1322-1323	:	_	_
13-46	1323-1324	-	_	_
13-47	1324-1325	-	_	_
13-48	1325-1326	-	_	_
13-49	1326-1327	:	_	_
13-50	1327-1328	\|	_	_
13-51	1329-1330	\|	_	_
13-52	1330-1331	\[	_	_
13-53	1331-1337	Tewari	_	_
13-54	1338-1340	et	_	_
13-55	1341-1343	al	_	_
13-56	1343-1344	.	_	_
13-57	1345-1347	17	_	_
13-58	1347-1348	\]	_	_
13-59	1348-1349	(	_	_
13-60	1349-1354	https	_	_
13-61	1354-1355	:	_	_
13-62	1355-1356	/	_	_
13-63	1356-1357	/	_	_
13-64	1357-1366	arxiv.org	_	_
13-65	1366-1367	/	_	_
13-66	1367-1370	abs	_	_
13-67	1370-1371	/	_	_
13-68	1371-1381	1703.10580	_	_
13-69	1381-1382	)	_	_
13-70	1382-1383	<	_	_
13-71	1383-1384	/	_	_
13-72	1384-1390	center	_	_
13-73	1390-1391	>	_	_
13-74	1391-1392	\|	_	_
13-75	1392-1396	2.19	_	_
13-76	1396-1397	±	_	_
13-77	1397-1401	0.54	_	_
13-78	1401-1402	\|	_	_
13-79	1402-1403	-	_	_
13-80	1403-1404	\|	_	_
13-81	1404-1405	-	_	_
13-82	1405-1406	\|	_	_
13-83	1407-1408	\|	_	_
13-84	1408-1409	\[	_	_
13-85	1409-1415	Tewari	_	_
13-86	1416-1418	et	_	_
13-87	1419-1421	al	_	_
13-88	1421-1422	.	_	_
13-89	1423-1425	18	_	_
13-90	1425-1426	\]	_	_
13-91	1426-1427	(	_	_
13-92	1427-1432	https	_	_
13-93	1432-1433	:	_	_
13-94	1433-1434	/	_	_
13-95	1434-1435	/	_	_
13-96	1435-1444	arxiv.org	_	_
13-97	1444-1445	/	_	_
13-98	1445-1448	abs	_	_
13-99	1448-1449	/	_	_
13-100	1449-1459	1712.02859	_	_
13-101	1459-1460	)	_	_
13-102	1460-1461	\|	_	_
13-103	1461-1465	1.84	_	_
13-104	1465-1466	±	_	_
13-105	1466-1470	0.38	_	_
13-106	1470-1471	\|	_	_
13-107	1471-1472	-	_	_
13-108	1472-1473	\|	_	_
13-109	1473-1474	-	_	_
13-110	1474-1475	\|	_	_
13-111	1476-1477	\|	_	_
13-112	1477-1478	\[	_	_
13-113	1478-1484	Genova	_	_
13-114	1485-1487	et	_	_
13-115	1488-1490	al	_	_
13-116	1490-1491	.	_	_
13-117	1492-1494	18	_	_
13-118	1494-1495	\]	_	_
13-119	1495-1496	(	_	_
13-120	1496-1501	https	_	_
13-121	1501-1502	:	_	_
13-122	1502-1503	/	_	_
13-123	1503-1504	/	_	_
13-124	1504-1513	arxiv.org	_	_
13-125	1513-1514	/	_	_
13-126	1514-1517	abs	_	_
13-127	1517-1518	/	_	_
13-128	1518-1528	1806.06098	_	_
13-129	1528-1529	)	_	_
13-130	1529-1530	\|	_	_
13-131	1530-1531	-	_	_
13-132	1531-1532	\|	_	_
13-133	1532-1536	1.77	_	_
13-134	1536-1537	±	_	_
13-135	1537-1541	0.53	_	_
13-136	1541-1542	\|	_	_
13-137	1542-1543	-	_	_
13-138	1543-1544	\|	_	_
13-139	1545-1546	\|	_	_
13-140	1546-1547	\[	_	_
13-141	1547-1551	Sela	_	_
13-142	1552-1554	et	_	_
13-143	1555-1557	al	_	_
13-144	1557-1558	.	_	_
13-145	1559-1561	17	_	_
13-146	1561-1562	\]	_	_
13-147	1562-1563	(	_	_
13-148	1563-1568	https	_	_
13-149	1568-1569	:	_	_
13-150	1569-1570	/	_	_
13-151	1570-1571	/	_	_
13-152	1571-1580	arxiv.org	_	_
13-153	1580-1581	/	_	_
13-154	1581-1584	abs	_	_
13-155	1584-1585	/	_	_
13-156	1585-1595	1703.10131	_	_
13-157	1595-1596	)	_	_
13-158	1596-1597	\|	_	_
13-159	1597-1598	-	_	_
13-160	1598-1599	\|	_	_
13-161	1599-1600	-	_	_
13-162	1600-1601	\|	_	_
13-163	1601-1605	2.91	_	_
13-164	1605-1606	±	_	_
13-165	1606-1610	0.60	_	_
13-166	1610-1611	\|	_	_
13-167	1612-1613	\|	_	_
13-168	1613-1614	\[	_	_
13-169	1614-1617	PRN	_	_
13-170	1618-1620	18	_	_
13-171	1620-1621	\]	_	_
13-172	1621-1622	(	_	_
13-173	1622-1627	https	_	_
13-174	1627-1628	:	_	_
13-175	1628-1629	/	_	_
13-176	1629-1630	/	_	_
13-177	1630-1639	arxiv.org	_	_
13-178	1639-1640	/	_	_
13-179	1640-1643	abs	_	_
13-180	1643-1644	/	_	_
13-181	1644-1654	1803.07835	_	_
13-182	1654-1655	)	_	_
13-183	1655-1656	\|	_	_
13-184	1656-1657	-	_	_
13-185	1657-1658	\|	_	_
13-186	1658-1659	-	_	_
13-187	1659-1660	\|	_	_
13-188	1660-1664	1.86	_	_
13-189	1664-1665	±	_	_
13-190	1665-1669	0.47	_	_
13-191	1669-1670	\|	_	_
13-192	1671-1672	\|	_	_
13-193	1672-1676	Ours	_	_
13-194	1676-1677	\|	_	_
13-195	1677-1678	\*	_	_
13-196	1678-1679	\*	_	_
13-197	1679-1683	1.81	_	_
13-198	1683-1684	±	_	_
13-199	1684-1688	0.50	_	_
13-200	1688-1689	\*	_	_
13-201	1689-1690	\*	_	_
13-202	1690-1691	\|	_	_
13-203	1691-1692	\*	_	_
13-204	1692-1693	\*	_	_
13-205	1693-1697	1.67	_	_
13-206	1697-1698	±	_	_
13-207	1698-1702	0.50	_	_
13-208	1702-1703	\*	_	_
13-209	1703-1704	\*	_	_
13-210	1704-1705	\|	_	_
13-211	1705-1706	\*	_	_
13-212	1706-1707	\*	_	_
13-213	1707-1711	1.40	_	_
13-214	1711-1712	±	_	_
13-215	1712-1716	0.31	_	_
13-216	1716-1717	\*	_	_
13-217	1717-1718	\*	_	_
13-218	1718-1719	\|	_	_
13-219	1721-1722	(	_	_
13-220	1722-1728	Please	_	_
13-221	1729-1734	refer	_	_
13-222	1735-1737	to	_	_
13-223	1738-1741	our	_	_
13-224	1742-1747	paper	_	_
13-225	1748-1751	for	_	_
13-226	1752-1756	more	_	_
13-227	1757-1764	details	_	_
13-228	1765-1770	about	_	_
13-229	1771-1776	these	_	_
13-230	1777-1784	results	_	_
13-231	1784-1785	)	_	_
13-232	1787-1788	#	_	_
13-233	1788-1789	#	_	_
13-234	1789-1790	#	_	_
13-235	1791-1792	●	_	_
13-236	1793-1797	High	_	_
13-237	1798-1806	fidelity	_	_
13-238	1807-1815	textures	_	_
13-239	1816-1819	The	_	_
13-240	1820-1826	method	_	_
13-241	1827-1835	produces	_	_
13-242	1836-1840	high	_	_
13-243	1841-1849	fidelity	_	_
13-244	1850-1854	face	_	_
13-245	1855-1863	textures	_	_
13-246	1864-1873	meanwhile	_	_
13-247	1874-1883	preserves	_	_
13-248	1884-1892	identity	_	_
13-249	1893-1904	information	_	_
13-250	1905-1907	of	_	_
13-251	1908-1913	input	_	_
13-252	1914-1920	images	_	_
13-253	1920-1921	.	_	_

#Text=Scene illumination is also disentangled to generate a pure albedo.
14-1	1922-1927	Scene	_	_
14-2	1928-1940	illumination	_	_
14-3	1941-1943	is	_	_
14-4	1944-1948	also	_	_
14-5	1949-1961	disentangled	_	_
14-6	1962-1964	to	_	_
14-7	1965-1973	generate	_	_
14-8	1974-1975	a	_	_
14-9	1976-1980	pure	_	_
14-10	1981-1987	albedo	_	_
14-11	1987-1988	.	_	_

#Text=<p align="center">  <img src="/images/albedo.png"> </p>  ### ● Robust The method can provide reasonable results under extreme conditions such as large pose and occlusions.
15-1	1989-1990	<	_	_
15-2	1990-1991	p	_	_
15-3	1992-1997	align	_	_
15-4	1997-1998	=	_	_
15-5	1998-1999	"	_	_
15-6	1999-2005	center	_	_
15-7	2005-2006	"	_	_
15-8	2006-2007	>	_	_
15-9	2009-2010	<	_	_
15-10	2010-2013	img	_	_
15-11	2014-2017	src	_	_
15-12	2017-2018	=	_	_
15-13	2018-2019	"	_	_
15-14	2019-2020	/	_	_
15-15	2020-2026	images	_	_
15-16	2026-2027	/	_	_
15-17	2027-2037	albedo.png	_	_
15-18	2037-2038	"	_	_
15-19	2038-2039	>	_	_
15-20	2040-2041	<	_	_
15-21	2041-2042	/	_	_
15-22	2042-2043	p	_	_
15-23	2043-2044	>	_	_
15-24	2046-2047	#	_	_
15-25	2047-2048	#	_	_
15-26	2048-2049	#	_	_
15-27	2050-2051	●	_	_
15-28	2052-2058	Robust	_	_
15-29	2059-2062	The	_	_
15-30	2063-2069	method	_	_
15-31	2070-2073	can	_	_
15-32	2074-2081	provide	_	_
15-33	2082-2092	reasonable	_	_
15-34	2093-2100	results	_	_
15-35	2101-2106	under	_	_
15-36	2107-2114	extreme	_	_
15-37	2115-2125	conditions	_	_
15-38	2126-2130	such	_	_
15-39	2131-2133	as	_	_
15-40	2134-2139	large	_	_
15-41	2140-2144	pose	_	_
15-42	2145-2148	and	_	_
15-43	2149-2159	occlusions	_	_
15-44	2159-2160	.	_	_

#Text=<p align="center">  <img src="/images/extreme.png"> </p>  ### ● Aligned with images Our method aligns reconstruction faces with input images.
16-1	2161-2162	<	_	_
16-2	2162-2163	p	_	_
16-3	2164-2169	align	_	_
16-4	2169-2170	=	_	_
16-5	2170-2171	"	_	_
16-6	2171-2177	center	_	_
16-7	2177-2178	"	_	_
16-8	2178-2179	>	_	_
16-9	2181-2182	<	_	_
16-10	2182-2185	img	_	_
16-11	2186-2189	src	_	_
16-12	2189-2190	=	_	_
16-13	2190-2191	"	_	_
16-14	2191-2192	/	_	_
16-15	2192-2198	images	_	_
16-16	2198-2199	/	_	_
16-17	2199-2210	extreme.png	_	_
16-18	2210-2211	"	_	_
16-19	2211-2212	>	_	_
16-20	2213-2214	<	_	_
16-21	2214-2215	/	_	_
16-22	2215-2216	p	_	_
16-23	2216-2217	>	_	_
16-24	2219-2220	#	_	_
16-25	2220-2221	#	_	_
16-26	2221-2222	#	_	_
16-27	2223-2224	●	_	_
16-28	2225-2232	Aligned	_	_
16-29	2233-2237	with	_	_
16-30	2238-2244	images	_	_
16-31	2245-2248	Our	_	_
16-32	2249-2255	method	_	_
16-33	2256-2262	aligns	_	_
16-34	2263-2277	reconstruction	_	_
16-35	2278-2283	faces	_	_
16-36	2284-2288	with	_	_
16-37	2289-2294	input	_	_
16-38	2295-2301	images	_	_
16-39	2301-2302	.	_	_

#Text=It provides face pose estimation and 68 facial landmarks which are useful for other tasks.
17-1	2303-2305	It	_	_
17-2	2306-2314	provides	_	_
17-3	2315-2319	face	_	_
17-4	2320-2324	pose	_	_
17-5	2325-2335	estimation	_	_
17-6	2336-2339	and	_	_
17-7	2340-2342	68	_	_
17-8	2343-2349	facial	_	_
17-9	2350-2359	landmarks	_	_
17-10	2360-2365	which	_	_
17-11	2366-2369	are	_	_
17-12	2370-2376	useful	_	_
17-13	2377-2380	for	_	_
17-14	2381-2386	other	_	_
17-15	2387-2392	tasks	_	_
17-16	2392-2393	.	_	_

#Text=We conduct an experiment on AFLW\_2000 dataset (NME) to evaluate the performance, as shown in the table below: <p align="center">  <img src="/images/alignment.png"> </p>  \|Method\|\[0°,30°\]\|\[30°,60°\]\|\[60°,90°\]\|Overall\| \|:---:\|:---:\|:---:\|:---:\|:---:\| \|\[3DDFA 16\](https://arxiv.org/abs/1511.07212)</center>\|3.78\|4.54\|7.93\|5.42\| \|\[3DDFA+SDM 16\](https://arxiv.org/abs/1511.07212)\|3.43\|4.24\|7.17\|4.94\| \|\[Bulat et al. 17\](https://arxiv.org/abs/1703.00862)\|\*\*2.47\*\*\|\*\*3.01\*\*\|\*\*4.31\*\*\|\*\*3.26\*\*\| \|\[PRN 18\](https://arxiv.org/abs/1803.07835)\|2.75\|3.51\|4.61\|3.62\| \|Ours\|2.56\|3.11\|4.45\|3.37\|   ### ● Easy and Fast Faces are represented with Basel Face Model 2009, which is easy for further manipulations (e.g expression transfer).
18-1	2394-2396	We	_	_
18-2	2397-2404	conduct	_	_
18-3	2405-2407	an	_	_
18-4	2408-2418	experiment	_	_
18-5	2419-2421	on	_	_
18-6	2422-2426	AFLW	*[8]	DATASET[8]
18-7	2426-2427	\_	*[8]	DATASET[8]
18-8	2427-2431	2000	*[8]	DATASET[8]
18-9	2432-2439	dataset	_	_
18-10	2440-2441	(	_	_
18-11	2441-2444	NME	_	_
18-12	2444-2445	)	_	_
18-13	2446-2448	to	_	_
18-14	2449-2457	evaluate	_	_
18-15	2458-2461	the	_	_
18-16	2462-2473	performance	_	_
18-17	2473-2474	,	_	_
18-18	2475-2477	as	_	_
18-19	2478-2483	shown	_	_
18-20	2484-2486	in	_	_
18-21	2487-2490	the	_	_
18-22	2491-2496	table	_	_
18-23	2497-2502	below	_	_
18-24	2502-2503	:	_	_
18-25	2504-2505	<	_	_
18-26	2505-2506	p	_	_
18-27	2507-2512	align	_	_
18-28	2512-2513	=	_	_
18-29	2513-2514	"	_	_
18-30	2514-2520	center	_	_
18-31	2520-2521	"	_	_
18-32	2521-2522	>	_	_
18-33	2524-2525	<	_	_
18-34	2525-2528	img	_	_
18-35	2529-2532	src	_	_
18-36	2532-2533	=	_	_
18-37	2533-2534	"	_	_
18-38	2534-2535	/	_	_
18-39	2535-2541	images	_	_
18-40	2541-2542	/	_	_
18-41	2542-2555	alignment.png	_	_
18-42	2555-2556	"	_	_
18-43	2556-2557	>	_	_
18-44	2558-2559	<	_	_
18-45	2559-2560	/	_	_
18-46	2560-2561	p	_	_
18-47	2561-2562	>	_	_
18-48	2564-2565	\|	_	_
18-49	2565-2571	Method	_	_
18-50	2571-2572	\|	_	_
18-51	2572-2573	\[	_	_
18-52	2573-2574	0	_	_
18-53	2574-2575	°	_	_
18-54	2575-2576	,	_	_
18-55	2576-2578	30	_	_
18-56	2578-2579	°	_	_
18-57	2579-2580	\]	_	_
18-58	2580-2581	\|	_	_
18-59	2581-2582	\[	_	_
18-60	2582-2584	30	_	_
18-61	2584-2585	°	_	_
18-62	2585-2586	,	_	_
18-63	2586-2588	60	_	_
18-64	2588-2589	°	_	_
18-65	2589-2590	\]	_	_
18-66	2590-2591	\|	_	_
18-67	2591-2592	\[	_	_
18-68	2592-2594	60	_	_
18-69	2594-2595	°	_	_
18-70	2595-2596	,	_	_
18-71	2596-2598	90	_	_
18-72	2598-2599	°	_	_
18-73	2599-2600	\]	_	_
18-74	2600-2601	\|	_	_
18-75	2601-2608	Overall	_	_
18-76	2608-2609	\|	_	_
18-77	2610-2611	\|	_	_
18-78	2611-2612	:	_	_
18-79	2612-2613	-	_	_
18-80	2613-2614	-	_	_
18-81	2614-2615	-	_	_
18-82	2615-2616	:	_	_
18-83	2616-2617	\|	_	_
18-84	2617-2618	:	_	_
18-85	2618-2619	-	_	_
18-86	2619-2620	-	_	_
18-87	2620-2621	-	_	_
18-88	2621-2622	:	_	_
18-89	2622-2623	\|	_	_
18-90	2623-2624	:	_	_
18-91	2624-2625	-	_	_
18-92	2625-2626	-	_	_
18-93	2626-2627	-	_	_
18-94	2627-2628	:	_	_
18-95	2628-2629	\|	_	_
18-96	2629-2630	:	_	_
18-97	2630-2631	-	_	_
18-98	2631-2632	-	_	_
18-99	2632-2633	-	_	_
18-100	2633-2634	:	_	_
18-101	2634-2635	\|	_	_
18-102	2635-2636	:	_	_
18-103	2636-2637	-	_	_
18-104	2637-2638	-	_	_
18-105	2638-2639	-	_	_
18-106	2639-2640	:	_	_
18-107	2640-2641	\|	_	_
18-108	2642-2643	\|	_	_
18-109	2643-2644	\[	_	_
18-110	2644-2649	3DDFA	_	_
18-111	2650-2652	16	_	_
18-112	2652-2653	\]	_	_
18-113	2653-2654	(	_	_
18-114	2654-2659	https	_	_
18-115	2659-2660	:	_	_
18-116	2660-2661	/	_	_
18-117	2661-2662	/	_	_
18-118	2662-2671	arxiv.org	_	_
18-119	2671-2672	/	_	_
18-120	2672-2675	abs	_	_
18-121	2675-2676	/	_	_
18-122	2676-2686	1511.07212	_	_
18-123	2686-2687	)	_	_
18-124	2687-2688	<	_	_
18-125	2688-2689	/	_	_
18-126	2689-2695	center	_	_
18-127	2695-2696	>	_	_
18-128	2696-2697	\|	_	_
18-129	2697-2701	3.78	_	_
18-130	2701-2702	\|	_	_
18-131	2702-2706	4.54	_	_
18-132	2706-2707	\|	_	_
18-133	2707-2711	7.93	_	_
18-134	2711-2712	\|	_	_
18-135	2712-2716	5.42	_	_
18-136	2716-2717	\|	_	_
18-137	2718-2719	\|	_	_
18-138	2719-2720	\[	_	_
18-139	2720-2725	3DDFA	_	_
18-140	2725-2726	+	_	_
18-141	2726-2729	SDM	_	_
18-142	2730-2732	16	_	_
18-143	2732-2733	\]	_	_
18-144	2733-2734	(	_	_
18-145	2734-2739	https	_	_
18-146	2739-2740	:	_	_
18-147	2740-2741	/	_	_
18-148	2741-2742	/	_	_
18-149	2742-2751	arxiv.org	_	_
18-150	2751-2752	/	_	_
18-151	2752-2755	abs	_	_
18-152	2755-2756	/	_	_
18-153	2756-2766	1511.07212	_	_
18-154	2766-2767	)	_	_
18-155	2767-2768	\|	_	_
18-156	2768-2772	3.43	_	_
18-157	2772-2773	\|	_	_
18-158	2773-2777	4.24	_	_
18-159	2777-2778	\|	_	_
18-160	2778-2782	7.17	_	_
18-161	2782-2783	\|	_	_
18-162	2783-2787	4.94	_	_
18-163	2787-2788	\|	_	_
18-164	2789-2790	\|	_	_
18-165	2790-2791	\[	_	_
18-166	2791-2796	Bulat	_	_
18-167	2797-2799	et	_	_
18-168	2800-2802	al	_	_
18-169	2802-2803	.	_	_
18-170	2804-2806	17	_	_
18-171	2806-2807	\]	_	_
18-172	2807-2808	(	_	_
18-173	2808-2813	https	_	_
18-174	2813-2814	:	_	_
18-175	2814-2815	/	_	_
18-176	2815-2816	/	_	_
18-177	2816-2825	arxiv.org	_	_
18-178	2825-2826	/	_	_
18-179	2826-2829	abs	_	_
18-180	2829-2830	/	_	_
18-181	2830-2840	1703.00862	_	_
18-182	2840-2841	)	_	_
18-183	2841-2842	\|	_	_
18-184	2842-2843	\*	_	_
18-185	2843-2844	\*	_	_
18-186	2844-2848	2.47	_	_
18-187	2848-2849	\*	_	_
18-188	2849-2850	\*	_	_
18-189	2850-2851	\|	_	_
18-190	2851-2852	\*	_	_
18-191	2852-2853	\*	_	_
18-192	2853-2857	3.01	_	_
18-193	2857-2858	\*	_	_
18-194	2858-2859	\*	_	_
18-195	2859-2860	\|	_	_
18-196	2860-2861	\*	_	_
18-197	2861-2862	\*	_	_
18-198	2862-2866	4.31	_	_
18-199	2866-2867	\*	_	_
18-200	2867-2868	\*	_	_
18-201	2868-2869	\|	_	_
18-202	2869-2870	\*	_	_
18-203	2870-2871	\*	_	_
18-204	2871-2875	3.26	_	_
18-205	2875-2876	\*	_	_
18-206	2876-2877	\*	_	_
18-207	2877-2878	\|	_	_
18-208	2879-2880	\|	_	_
18-209	2880-2881	\[	_	_
18-210	2881-2884	PRN	_	_
18-211	2885-2887	18	_	_
18-212	2887-2888	\]	_	_
18-213	2888-2889	(	_	_
18-214	2889-2894	https	_	_
18-215	2894-2895	:	_	_
18-216	2895-2896	/	_	_
18-217	2896-2897	/	_	_
18-218	2897-2906	arxiv.org	_	_
18-219	2906-2907	/	_	_
18-220	2907-2910	abs	_	_
18-221	2910-2911	/	_	_
18-222	2911-2921	1803.07835	_	_
18-223	2921-2922	)	_	_
18-224	2922-2923	\|	_	_
18-225	2923-2927	2.75	_	_
18-226	2927-2928	\|	_	_
18-227	2928-2932	3.51	_	_
18-228	2932-2933	\|	_	_
18-229	2933-2937	4.61	_	_
18-230	2937-2938	\|	_	_
18-231	2938-2942	3.62	_	_
18-232	2942-2943	\|	_	_
18-233	2944-2945	\|	_	_
18-234	2945-2949	Ours	_	_
18-235	2949-2950	\|	_	_
18-236	2950-2954	2.56	_	_
18-237	2954-2955	\|	_	_
18-238	2955-2959	3.11	_	_
18-239	2959-2960	\|	_	_
18-240	2960-2964	4.45	_	_
18-241	2964-2965	\|	_	_
18-242	2965-2969	3.37	_	_
18-243	2969-2970	\|	_	_
18-244	2973-2974	#	_	_
18-245	2974-2975	#	_	_
18-246	2975-2976	#	_	_
18-247	2977-2978	●	_	_
18-248	2979-2983	Easy	_	_
18-249	2984-2987	and	_	_
18-250	2988-2992	Fast	_	_
18-251	2993-2998	Faces	_	_
18-252	2999-3002	are	_	_
18-253	3003-3014	represented	_	_
18-254	3015-3019	with	_	_
18-255	3020-3025	Basel	_	_
18-256	3026-3030	Face	_	_
18-257	3031-3036	Model	_	_
18-258	3037-3041	2009	_	_
18-259	3041-3042	,	_	_
18-260	3043-3048	which	_	_
18-261	3049-3051	is	_	_
18-262	3052-3056	easy	_	_
18-263	3057-3060	for	_	_
18-264	3061-3068	further	_	_
18-265	3069-3082	manipulations	_	_
18-266	3083-3084	(	_	_
18-267	3084-3087	e.g	_	_
18-268	3088-3098	expression	_	_
18-269	3099-3107	transfer	_	_
18-270	3107-3108	)	_	_
18-271	3108-3109	.	_	_

#Text=ResNet-50 is used as backbone network to achieve over 50 fps (on GTX 1080) for reconstructions.   ## Getting Started ### Testing Requirements ###  - Reconstructions can be done on both Windows and Linux.
19-1	3110-3116	ResNet	_	_
19-2	3116-3117	-	_	_
19-3	3117-3119	50	_	_
19-4	3120-3122	is	_	_
19-5	3123-3127	used	_	_
19-6	3128-3130	as	_	_
19-7	3131-3139	backbone	_	_
19-8	3140-3147	network	_	_
19-9	3148-3150	to	_	_
19-10	3151-3158	achieve	_	_
19-11	3159-3163	over	_	_
19-12	3164-3166	50	_	_
19-13	3167-3170	fps	_	_
19-14	3171-3172	(	_	_
19-15	3172-3174	on	_	_
19-16	3175-3178	GTX	_	_
19-17	3179-3183	1080	_	_
19-18	3183-3184	)	_	_
19-19	3185-3188	for	_	_
19-20	3189-3204	reconstructions	_	_
19-21	3204-3205	.	_	_
19-22	3208-3209	#	_	_
19-23	3209-3210	#	_	_
19-24	3211-3218	Getting	_	_
19-25	3219-3226	Started	_	_
19-26	3227-3228	#	_	_
19-27	3228-3229	#	_	_
19-28	3229-3230	#	_	_
19-29	3231-3238	Testing	_	_
19-30	3239-3251	Requirements	_	_
19-31	3252-3253	#	_	_
19-32	3253-3254	#	_	_
19-33	3254-3255	#	_	_
19-34	3257-3258	-	_	_
19-35	3259-3274	Reconstructions	_	_
19-36	3275-3278	can	_	_
19-37	3279-3281	be	_	_
19-38	3282-3286	done	_	_
19-39	3287-3289	on	_	_
19-40	3290-3294	both	_	_
19-41	3295-3302	Windows	_	_
19-42	3303-3306	and	_	_
19-43	3307-3312	Linux	_	_
19-44	3312-3313	.	_	_

#Text=However, we suggest running on Linux because the rendering process is only supported on Linux. - Python 3.6 (numpy, scipy, pillow, argparse). - Tensorflow 1.12. - \[Basel Face Model 2009 (BFM09)\](https://faces.dmi.unibas.ch/bfm/main.php?
20-1	3314-3321	However	_	_
20-2	3321-3322	,	_	_
20-3	3323-3325	we	_	_
20-4	3326-3333	suggest	_	_
20-5	3334-3341	running	_	_
20-6	3342-3344	on	_	_
20-7	3345-3350	Linux	_	_
20-8	3351-3358	because	_	_
20-9	3359-3362	the	_	_
20-10	3363-3372	rendering	_	_
20-11	3373-3380	process	_	_
20-12	3381-3383	is	_	_
20-13	3384-3388	only	_	_
20-14	3389-3398	supported	_	_
20-15	3399-3401	on	_	_
20-16	3402-3407	Linux	_	_
20-17	3407-3408	.	_	_
20-18	3409-3410	-	_	_
20-19	3411-3417	Python	*[9]	SOFTWARE[9]
20-20	3418-3421	3.6	*[9]	SOFTWARE[9]
20-21	3422-3423	(	_	_
20-22	3423-3428	numpy	*	SOFTWARE
20-23	3428-3429	,	_	_
20-24	3430-3435	scipy	*	SOFTWARE
20-25	3435-3436	,	_	_
20-26	3437-3443	pillow	*	SOFTWARE
20-27	3443-3444	,	_	_
20-28	3445-3453	argparse	*	SOFTWARE
20-29	3453-3454	)	_	_
20-30	3454-3455	.	_	_
20-31	3456-3457	-	_	_
20-32	3458-3468	Tensorflow	*[10]	SOFTWARE[10]
20-33	3469-3473	1.12	*[10]	SOFTWARE[10]
20-34	3473-3474	.	_	_
20-35	3475-3476	-	_	_
20-36	3477-3478	\[	_	_
20-37	3478-3483	Basel	_	_
20-38	3484-3488	Face	_	_
20-39	3489-3494	Model	_	_
20-40	3495-3499	2009	_	_
20-41	3500-3501	(	_	_
20-42	3501-3506	BFM09	_	_
20-43	3506-3507	)	_	_
20-44	3507-3508	\]	_	_
20-45	3508-3509	(	_	_
20-46	3509-3514	https	_	_
20-47	3514-3515	:	_	_
20-48	3515-3516	/	_	_
20-49	3516-3517	/	_	_
20-50	3517-3536	faces.dmi.unibas.ch	_	_
20-51	3536-3537	/	_	_
20-52	3537-3540	bfm	_	_
20-53	3540-3541	/	_	_
20-54	3541-3549	main.php	_	_
20-55	3549-3550	?	_	_

#Text=nav=1-0&id=basel\_face\_model)
21-1	3550-3553	nav	_	_
21-2	3553-3554	=	_	_
21-3	3554-3555	1	_	_
21-4	3555-3556	-	_	_
21-5	3556-3558	0&	_	_
21-6	3558-3560	id	_	_
21-7	3560-3561	=	_	_
21-8	3561-3577	basel\_face\_model	_	_
21-9	3577-3578	)	_	_

#Text=.
22-1	3578-3579	.	_	_

#Text=- \[Expression Basis (transferred from Facewarehouse by Guo et al.)\]
23-1	3581-3582	-	_	_
23-2	3583-3584	\[	_	_
23-3	3584-3594	Expression	_	_
23-4	3595-3600	Basis	_	_
23-5	3601-3602	(	_	_
23-6	3602-3613	transferred	_	_
23-7	3614-3618	from	_	_
23-8	3619-3632	Facewarehouse	_	_
23-9	3633-3635	by	_	_
23-10	3636-3639	Guo	_	_
23-11	3640-3642	et	_	_
23-12	3643-3645	al	_	_
23-13	3645-3646	.	_	_
23-14	3646-3647	)	_	_
23-15	3647-3648	\]	_	_

#Text=(https://github.com/Juyong/3DFace).
24-1	3648-3649	(	_	_
24-2	3649-3654	https	_	_
24-3	3654-3655	:	_	_
24-4	3655-3656	/	_	_
24-5	3656-3657	/	_	_
24-6	3657-3667	github.com	_	_
24-7	3667-3668	/	_	_
24-8	3668-3674	Juyong	_	_
24-9	3674-3675	/	_	_
24-10	3675-3681	3DFace	*	PROJECT
24-11	3681-3682	)	_	_
24-12	3682-3683	.	_	_

#Text=The original BFM09 model does not handle expression variations so extra expression basis are needed
25-1	3684-3687	The	_	_
25-2	3688-3696	original	_	_
25-3	3697-3702	BFM09	_	_
25-4	3703-3708	model	_	_
25-5	3709-3713	does	_	_
25-6	3714-3717	not	_	_
25-7	3718-3724	handle	_	_
25-8	3725-3735	expression	_	_
25-9	3736-3746	variations	_	_
25-10	3747-3749	so	_	_
25-11	3750-3755	extra	_	_
25-12	3756-3766	expression	_	_
25-13	3767-3772	basis	_	_
25-14	3773-3776	are	_	_
25-15	3777-3783	needed	_	_

#Text=.
26-1	3783-3784	.	_	_

#Text=- \[tf mesh renderer\](https://github.com/google/tf\_mesh\_renderer/tree/ba27ea1798f6ee8d03ddbc52f42ab4241f9328bb).
27-1	3786-3787	-	_	_
27-2	3788-3789	\[	_	_
27-3	3789-3791	tf	*[11]	SOFTWARE[11]
27-4	3792-3796	mesh	*[11]	SOFTWARE[11]
27-5	3797-3805	renderer	*[11]	SOFTWARE[11]
27-6	3805-3806	\]	_	_
27-7	3806-3807	(	_	_
27-8	3807-3812	https	_	_
27-9	3812-3813	:	_	_
27-10	3813-3814	/	_	_
27-11	3814-3815	/	_	_
27-12	3815-3825	github.com	_	_
27-13	3825-3826	/	_	_
27-14	3826-3832	google	_	_
27-15	3832-3833	/	_	_
27-16	3833-3849	tf\_mesh\_renderer	_	_
27-17	3849-3850	/	_	_
27-18	3850-3854	tree	_	_
27-19	3854-3855	/	_	_
27-20	3855-3895	ba27ea1798f6ee8d03ddbc52f42ab4241f9328bb	_	_
27-21	3895-3896	)	_	_
27-22	3896-3897	.	_	_

#Text=We use the library to render reconstruction images.
28-1	3899-3901	We	_	_
28-2	3902-3905	use	_	_
28-3	3906-3909	the	_	_
28-4	3910-3917	library	_	_
28-5	3918-3920	to	_	_
28-6	3921-3927	render	_	_
28-7	3928-3942	reconstruction	_	_
28-8	3943-3949	images	_	_
28-9	3949-3950	.	_	_

#Text=\*\*Note that the rendering tool can only be used on Linux.\*\*  ### Installation ### #### 1.
29-1	3951-3952	\*	_	_
29-2	3952-3953	\*	_	_
29-3	3953-3957	Note	_	_
29-4	3958-3962	that	_	_
29-5	3963-3966	the	_	_
29-6	3967-3976	rendering	_	_
29-7	3977-3981	tool	_	_
29-8	3982-3985	can	_	_
29-9	3986-3990	only	_	_
29-10	3991-3993	be	_	_
29-11	3994-3998	used	_	_
29-12	3999-4001	on	_	_
29-13	4002-4007	Linux	_	_
29-14	4007-4008	.	_	_
29-15	4008-4009	\*	_	_
29-16	4009-4010	\*	_	_
29-17	4012-4013	#	_	_
29-18	4013-4014	#	_	_
29-19	4014-4015	#	_	_
29-20	4016-4028	Installation	_	_
29-21	4029-4030	#	_	_
29-22	4030-4031	#	_	_
29-23	4031-4032	#	_	_
29-24	4033-4034	#	_	_
29-25	4034-4035	#	_	_
29-26	4035-4036	#	_	_
29-27	4036-4037	#	_	_
29-28	4038-4039	1	_	_
29-29	4039-4040	.	_	_

#Text=Clone the repository ``` git clone https://github.com/Microsoft/Deep3DFaceReconstruction --recursive cd Deep3DFaceReconstruction ```  #### 2.
30-1	4041-4046	Clone	_	_
30-2	4047-4050	the	_	_
30-3	4051-4061	repository	_	_
30-4	4062-4063	`	_	_
30-5	4063-4064	`	_	_
30-6	4064-4065	`	_	_
30-7	4066-4069	git	*	SOFTWARE
30-8	4070-4075	clone	_	_
30-9	4076-4081	https	_	_
30-10	4081-4082	:	_	_
30-11	4082-4083	/	_	_
30-12	4083-4084	/	_	_
30-13	4084-4094	github.com	_	_
30-14	4094-4095	/	_	_
30-15	4095-4104	Microsoft	_	_
30-16	4104-4105	/	_	_
30-17	4105-4129	Deep3DFaceReconstruction	*	PROJECT
30-18	4130-4131	-	_	_
30-19	4131-4132	-	_	_
30-20	4132-4141	recursive	_	_
30-21	4142-4144	cd	_	_
30-22	4145-4169	Deep3DFaceReconstruction	*	PROJECT
30-23	4170-4171	`	_	_
30-24	4171-4172	`	_	_
30-25	4172-4173	`	_	_
30-26	4175-4176	#	_	_
30-27	4176-4177	#	_	_
30-28	4177-4178	#	_	_
30-29	4178-4179	#	_	_
30-30	4180-4181	2	_	_
30-31	4181-4182	.	_	_

#Text=Set up the python environment If you use anaconda, run the following: ``` conda create -n deep3d python=3.6 source activate deep3d conda install tensorflow-gpu==1.12.0 scipy pip install pillow argparse ```  Alternatively, you can install tensorflow via pip install (In this way, you need to link /usr/local/cuda to cuda-9.0): ``` pip install tensorflow-gpu==1.12.0 ```  #### 3.
31-1	4183-4186	Set	_	_
31-2	4187-4189	up	_	_
31-3	4190-4193	the	_	_
31-4	4194-4200	python	*	PROGLANG
31-5	4201-4212	environment	_	_
31-6	4213-4215	If	_	_
31-7	4216-4219	you	_	_
31-8	4220-4223	use	_	_
31-9	4224-4232	anaconda	*	SOFTWARE
31-10	4232-4233	,	_	_
31-11	4234-4237	run	_	_
31-12	4238-4241	the	_	_
31-13	4242-4251	following	_	_
31-14	4251-4252	:	_	_
31-15	4253-4254	`	_	_
31-16	4254-4255	`	_	_
31-17	4255-4256	`	_	_
31-18	4257-4262	conda	*	SOFTWARE
31-19	4263-4269	create	_	_
31-20	4270-4271	-	_	_
31-21	4271-4272	n	_	_
31-22	4273-4279	deep3d	_	_
31-23	4280-4286	python	*[12]	PROGLANG[12]
31-24	4286-4287	=	*[12]	PROGLANG[12]
31-25	4287-4290	3.6	*[12]	PROGLANG[12]
31-26	4291-4297	source	_	_
31-27	4298-4306	activate	_	_
31-28	4307-4313	deep3d	_	_
31-29	4314-4319	conda	*	SOFTWARE
31-30	4320-4327	install	_	_
31-31	4328-4342	tensorflow-gpu	*[13]	SOFTWARE[13]
31-32	4342-4343	=	*[13]	SOFTWARE[13]
31-33	4343-4344	=	*[13]	SOFTWARE[13]
31-34	4344-4350	1.12.0	*[13]	SOFTWARE[13]
31-35	4351-4356	scipy	*	PROGLANG
31-36	4357-4360	pip	*	SOFTWARE
31-37	4361-4368	install	_	_
31-38	4369-4375	pillow	*	SOFTWARE
31-39	4376-4384	argparse	*	SOFTWARE
31-40	4385-4386	`	_	_
31-41	4386-4387	`	_	_
31-42	4387-4388	`	_	_
31-43	4390-4403	Alternatively	_	_
31-44	4403-4404	,	_	_
31-45	4405-4408	you	_	_
31-46	4409-4412	can	_	_
31-47	4413-4420	install	_	_
31-48	4421-4431	tensorflow	*	SOFTWARE
31-49	4432-4435	via	_	_
31-50	4436-4439	pip	*	SOFTWARE
31-51	4440-4447	install	_	_
31-52	4448-4449	(	_	_
31-53	4449-4451	In	_	_
31-54	4452-4456	this	_	_
31-55	4457-4460	way	_	_
31-56	4460-4461	,	_	_
31-57	4462-4465	you	_	_
31-58	4466-4470	need	_	_
31-59	4471-4473	to	_	_
31-60	4474-4478	link	_	_
31-61	4479-4480	/	_	_
31-62	4480-4483	usr	_	_
31-63	4483-4484	/	_	_
31-64	4484-4489	local	_	_
31-65	4489-4490	/	_	_
31-66	4490-4494	cuda	*	SOFTWARE
31-67	4495-4497	to	_	_
31-68	4498-4502	cuda	*[14]	SOFTWARE[14]
31-69	4502-4503	-	*[14]	SOFTWARE[14]
31-70	4503-4506	9.0	*[14]	SOFTWARE[14]
31-71	4506-4507	)	*[14]	SOFTWARE[14]
31-72	4507-4508	:	_	_
31-73	4509-4510	`	_	_
31-74	4510-4511	`	_	_
31-75	4511-4512	`	_	_
31-76	4513-4516	pip	*	SOFTWARE
31-77	4517-4524	install	_	_
31-78	4525-4539	tensorflow-gpu	*[15]	SOFTWARE[15]
31-79	4539-4540	=	*[15]	SOFTWARE[15]
31-80	4540-4541	=	*[15]	SOFTWARE[15]
31-81	4541-4547	1.12.0	*[15]	SOFTWARE[15]
31-82	4548-4549	`	_	_
31-83	4549-4550	`	_	_
31-84	4550-4551	`	_	_
31-85	4553-4554	#	_	_
31-86	4554-4555	#	_	_
31-87	4555-4556	#	_	_
31-88	4556-4557	#	_	_
31-89	4558-4559	3	_	_
31-90	4559-4560	.	_	_

#Text=Compile tf\_mesh\_renderer  If you install tensorflow using pip,  we provide a \[pre-compiled binary file (rasterize\_triangles\_kernel.so)\](https://drive.google.com/file/d/1VUtJPdg0UiJkKWxkACs8ZTf5L7Y4P9Wj/view?
32-1	4561-4568	Compile	_	_
32-2	4569-4585	tf\_mesh\_renderer	*	SOFTWARE
32-3	4587-4589	If	_	_
32-4	4590-4593	you	_	_
32-5	4594-4601	install	_	_
32-6	4602-4612	tensorflow	*	SOFTWARE
32-7	4613-4618	using	_	_
32-8	4619-4622	pip	*	SOFTWARE
32-9	4622-4623	,	_	_
32-10	4625-4627	we	_	_
32-11	4628-4635	provide	_	_
32-12	4636-4637	a	_	_
32-13	4638-4639	\[	_	_
32-14	4639-4651	pre-compiled	_	_
32-15	4652-4658	binary	_	_
32-16	4659-4663	file	_	_
32-17	4664-4665	(	_	_
32-18	4665-4694	rasterize\_triangles\_kernel.so	_	_
32-19	4694-4695	)	_	_
32-20	4695-4696	\]	_	_
32-21	4696-4697	(	_	_
32-22	4697-4702	https	_	_
32-23	4702-4703	:	_	_
32-24	4703-4704	/	_	_
32-25	4704-4705	/	_	_
32-26	4705-4721	drive.google.com	_	_
32-27	4721-4722	/	_	_
32-28	4722-4726	file	_	_
32-29	4726-4727	/	_	_
32-30	4727-4728	d	_	_
32-31	4728-4729	/	_	_
32-32	4729-4762	1VUtJPdg0UiJkKWxkACs8ZTf5L7Y4P9Wj	_	_
32-33	4762-4763	/	_	_
32-34	4763-4767	view	_	_
32-35	4767-4768	?	_	_

#Text=usp=sharing) of the library.
33-1	4768-4771	usp	_	_
33-2	4771-4772	=	_	_
33-3	4772-4779	sharing	_	_
33-4	4779-4780	)	_	_
33-5	4781-4783	of	_	_
33-6	4784-4787	the	_	_
33-7	4788-4795	library	_	_
33-8	4795-4796	.	_	_

#Text=\*\*Note that the pre-compiled file can only be run with tensorflow 1.12.\*\*  If you install tensorflow using conda, you have to compile tf\_mesh\_renderer from sources.
34-1	4797-4798	\*	_	_
34-2	4798-4799	\*	_	_
34-3	4799-4803	Note	_	_
34-4	4804-4808	that	_	_
34-5	4809-4812	the	_	_
34-6	4813-4825	pre-compiled	_	_
34-7	4826-4830	file	_	_
34-8	4831-4834	can	_	_
34-9	4835-4839	only	_	_
34-10	4840-4842	be	_	_
34-11	4843-4846	run	_	_
34-12	4847-4851	with	_	_
34-13	4852-4862	tensorflow	*[16]	SOFTWARE[16]
34-14	4863-4867	1.12	*[16]	SOFTWARE[16]
34-15	4867-4868	.	_	_
34-16	4868-4869	\*	_	_
34-17	4869-4870	\*	_	_
34-18	4872-4874	If	_	_
34-19	4875-4878	you	_	_
34-20	4879-4886	install	_	_
34-21	4887-4897	tensorflow	*	SOFTWARE
34-22	4898-4903	using	_	_
34-23	4904-4909	conda	*	SOFTWARE
34-24	4909-4910	,	_	_
34-25	4911-4914	you	_	_
34-26	4915-4919	have	_	_
34-27	4920-4922	to	_	_
34-28	4923-4930	compile	_	_
34-29	4931-4947	tf\_mesh\_renderer	*	SOFTWARE
34-30	4948-4952	from	_	_
34-31	4953-4960	sources	_	_
34-32	4960-4961	.	_	_

#Text=Compile tf\_mesh\_renderer with Bazel.
35-1	4962-4969	Compile	_	_
35-2	4970-4986	tf\_mesh\_renderer	*	SOFTWARE
35-3	4987-4991	with	_	_
35-4	4992-4997	Bazel	*	SOFTWARE
35-5	4997-4998	.	_	_

#Text=\*\*Set -D\_GLIBCXX\_USE\_CXX11\_ABI=1 in .
36-1	4999-5000	\*	_	_
36-2	5000-5001	\*	_	_
36-3	5001-5004	Set	_	_
36-4	5005-5006	-	_	_
36-5	5006-5025	D\_GLIBCXX\_USE\_CXX11	_	_
36-6	5025-5026	\_	_	_
36-7	5026-5029	ABI	_	_
36-8	5029-5030	=	_	_
36-9	5030-5031	1	_	_
36-10	5032-5034	in	_	_
36-11	5035-5036	.	_	_

#Text=/mesh\_renderer/kernels/BUILD before the compilation\*\*: ``` cd tf\_mesh\_renderer git checkout ba27ea1798 git checkout master WORKSPACE bazel test ... cd .. ``` If the library is compiled correctly, there should be a file named "rasterize\_triangles\_kernel.so" in .
37-1	5036-5037	/	_	_
37-2	5037-5050	mesh\_renderer	_	_
37-3	5050-5051	/	_	_
37-4	5051-5058	kernels	_	_
37-5	5058-5059	/	_	_
37-6	5059-5064	BUILD	_	_
37-7	5065-5071	before	_	_
37-8	5072-5075	the	_	_
37-9	5076-5087	compilation	_	_
37-10	5087-5088	\*	_	_
37-11	5088-5089	\*	_	_
37-12	5089-5090	:	_	_
37-13	5091-5092	`	_	_
37-14	5092-5093	`	_	_
37-15	5093-5094	`	_	_
37-16	5095-5097	cd	_	_
37-17	5098-5114	tf\_mesh\_renderer	*	SOFTWARE
37-18	5115-5118	git	*	SOFTWARE
37-19	5119-5127	checkout	_	_
37-20	5128-5138	ba27ea1798	_	_
37-21	5139-5142	git	*	SOFTWARE
37-22	5143-5151	checkout	_	_
37-23	5152-5158	master	_	_
37-24	5159-5168	WORKSPACE	_	_
37-25	5169-5174	bazel	*	SOFTWARE
37-26	5175-5179	test	_	_
37-27	5180-5181	.	_	_
37-28	5181-5182	.	_	_
37-29	5182-5183	.	_	_
37-30	5184-5186	cd	_	_
37-31	5187-5188	.	_	_
37-32	5188-5189	.	_	_
37-33	5190-5191	`	_	_
37-34	5191-5192	`	_	_
37-35	5192-5193	`	_	_
37-36	5194-5196	If	_	_
37-37	5197-5200	the	_	_
37-38	5201-5208	library	_	_
37-39	5209-5211	is	_	_
37-40	5212-5220	compiled	_	_
37-41	5221-5230	correctly	_	_
37-42	5230-5231	,	_	_
37-43	5232-5237	there	_	_
37-44	5238-5244	should	_	_
37-45	5245-5247	be	_	_
37-46	5248-5249	a	_	_
37-47	5250-5254	file	_	_
37-48	5255-5260	named	_	_
37-49	5261-5262	"	_	_
37-50	5262-5291	rasterize\_triangles\_kernel.so	_	_
37-51	5291-5292	"	_	_
37-52	5293-5295	in	_	_
37-53	5296-5297	.	_	_

#Text=/tf\_mesh\_renderer/bazel-bin/mesh\_renderer/kernels.
38-1	5297-5298	/	_	_
38-2	5298-5314	tf\_mesh\_renderer	*	SOFTWARE
38-3	5314-5315	/	_	_
38-4	5315-5324	bazel-bin	_	_
38-5	5324-5325	/	_	_
38-6	5325-5338	mesh\_renderer	_	_
38-7	5338-5339	/	_	_
38-8	5339-5346	kernels	_	_
38-9	5346-5347	.	_	_

#Text=After compilation, copy corresponding files to .
39-1	5350-5355	After	_	_
39-2	5356-5367	compilation	_	_
39-3	5367-5368	,	_	_
39-4	5369-5373	copy	_	_
39-5	5374-5387	corresponding	_	_
39-6	5388-5393	files	_	_
39-7	5394-5396	to	_	_
39-8	5397-5398	.	_	_

#Text=/renderer subfolder: ``` cd renderer cp .
40-1	5398-5399	/	_	_
40-2	5399-5407	renderer	_	_
40-3	5408-5417	subfolder	_	_
40-4	5417-5418	:	_	_
40-5	5419-5420	`	_	_
40-6	5420-5421	`	_	_
40-7	5421-5422	`	_	_
40-8	5423-5425	cd	_	_
40-9	5426-5434	renderer	_	_
40-10	5435-5437	cp	_	_
40-11	5438-5439	.	_	_

#Text=/tf\_mesh\_renderer/mesh\_renderer/{camera\_utils.py,mesh\_renderer.py,rasterize\_triangles.py} .
41-1	5439-5440	/	_	_
41-2	5440-5456	tf\_mesh\_renderer	_	_
41-3	5456-5457	/	_	_
41-4	5457-5470	mesh\_renderer	_	_
41-5	5470-5471	/	_	_
41-6	5471-5472	{	_	_
41-7	5472-5487	camera\_utils.py	_	_
41-8	5487-5488	,	_	_
41-9	5488-5504	mesh\_renderer.py	_	_
41-10	5504-5505	,	_	_
41-11	5505-5527	rasterize\_triangles.py	_	_
41-12	5527-5528	}	_	_
41-13	5529-5530	.	_	_

#Text=/renderer/ cp .
42-1	5530-5531	/	_	_
42-2	5531-5539	renderer	_	_
42-3	5539-5540	/	_	_
42-4	5541-5543	cp	_	_
42-5	5544-5545	.	_	_

#Text=/tf\_mesh\_renderer/bazel-bin/mesh\_renderer/kernels/rasterize\_triangles\_kernel.so .
43-1	5545-5546	/	_	_
43-2	5546-5562	tf\_mesh\_renderer	_	_
43-3	5562-5563	/	_	_
43-4	5563-5572	bazel-bin	_	_
43-5	5572-5573	/	_	_
43-6	5573-5586	mesh\_renderer	_	_
43-7	5586-5587	/	_	_
43-8	5587-5594	kernels	_	_
43-9	5594-5595	/	_	_
43-10	5595-5624	rasterize\_triangles\_kernel.so	_	_
43-11	5625-5626	.	_	_

#Text=/renderer/ ``` If you download our pre-compiled binary file, put it into .
44-1	5626-5627	/	_	_
44-2	5627-5635	renderer	_	_
44-3	5635-5636	/	_	_
44-4	5637-5638	`	_	_
44-5	5638-5639	`	_	_
44-6	5639-5640	`	_	_
44-7	5641-5643	If	_	_
44-8	5644-5647	you	_	_
44-9	5648-5656	download	_	_
44-10	5657-5660	our	_	_
44-11	5661-5673	pre-compiled	_	_
44-12	5674-5680	binary	_	_
44-13	5681-5685	file	_	_
44-14	5685-5686	,	_	_
44-15	5687-5690	put	_	_
44-16	5691-5693	it	_	_
44-17	5694-5698	into	_	_
44-18	5699-5700	.	_	_

#Text=/renderer subfolder as well.
45-1	5700-5701	/	_	_
45-2	5701-5709	renderer	_	_
45-3	5710-5719	subfolder	_	_
45-4	5720-5722	as	_	_
45-5	5723-5727	well	_	_
45-6	5727-5728	.	_	_

#Text=Replace the library path in Line 26 in .
46-1	5730-5737	Replace	_	_
46-2	5738-5741	the	_	_
46-3	5742-5749	library	_	_
46-4	5750-5754	path	_	_
46-5	5755-5757	in	_	_
46-6	5758-5762	Line	_	_
46-7	5763-5765	26	_	_
46-8	5766-5768	in	_	_
46-9	5769-5770	.	_	_

#Text=/renderer/rasterize\_triangles.py with ".
47-1	5770-5771	/	_	_
47-2	5771-5779	renderer	_	_
47-3	5779-5780	/	_	_
47-4	5780-5802	rasterize\_triangles.py	_	_
47-5	5803-5807	with	_	_
47-6	5808-5809	"	_	_
47-7	5809-5810	.	_	_

#Text=/renderer/rasterize\_triangles\_kernel.so".
48-1	5810-5811	/	_	_
48-2	5811-5819	renderer	_	_
48-3	5819-5820	/	_	_
48-4	5820-5849	rasterize\_triangles\_kernel.so	_	_
48-5	5849-5850	"	_	_
48-6	5850-5851	.	_	_

#Text=Replace "xrange" function in Line 109 in .
49-1	5853-5860	Replace	_	_
49-2	5861-5862	"	_	_
49-3	5862-5868	xrange	_	_
49-4	5868-5869	"	_	_
49-5	5870-5878	function	_	_
49-6	5879-5881	in	_	_
49-7	5882-5886	Line	_	_
49-8	5887-5890	109	_	_
49-9	5891-5893	in	_	_
49-10	5894-5895	.	_	_

#Text=/renderer/rasterize\_triangles.py with "range" function for compatibility with python3.   ### Testing with pre-trained network ###  1.
50-1	5895-5896	/	_	_
50-2	5896-5904	renderer	_	_
50-3	5904-5905	/	_	_
50-4	5905-5927	rasterize\_triangles.py	_	_
50-5	5928-5932	with	_	_
50-6	5933-5934	"	_	_
50-7	5934-5939	range	_	_
50-8	5939-5940	"	_	_
50-9	5941-5949	function	_	_
50-10	5950-5953	for	_	_
50-11	5954-5967	compatibility	_	_
50-12	5968-5972	with	_	_
50-13	5973-5980	python3	_	_
50-14	5980-5981	.	_	_
50-15	5984-5985	#	_	_
50-16	5985-5986	#	_	_
50-17	5986-5987	#	_	_
50-18	5988-5995	Testing	_	_
50-19	5996-6000	with	_	_
50-20	6001-6012	pre-trained	_	_
50-21	6013-6020	network	_	_
50-22	6021-6022	#	_	_
50-23	6022-6023	#	_	_
50-24	6023-6024	#	_	_
50-25	6026-6027	1	_	_
50-26	6027-6028	.	_	_

#Text=Download the Basel Face Model.
51-1	6029-6037	Download	_	_
51-2	6038-6041	the	_	_
51-3	6042-6047	Basel	_	_
51-4	6048-6052	Face	_	_
51-5	6053-6058	Model	_	_
51-6	6058-6059	.	_	_

#Text=Due to the license agreement of Basel Face Model, you have to download the BFM09 model after submitting an application on its \[home page\](https://faces.dmi.unibas.ch/bfm/main.php?
52-1	6060-6063	Due	_	_
52-2	6064-6066	to	_	_
52-3	6067-6070	the	_	_
52-4	6071-6078	license	_	_
52-5	6079-6088	agreement	_	_
52-6	6089-6091	of	_	_
52-7	6092-6097	Basel	_	_
52-8	6098-6102	Face	_	_
52-9	6103-6108	Model	_	_
52-10	6108-6109	,	_	_
52-11	6110-6113	you	_	_
52-12	6114-6118	have	_	_
52-13	6119-6121	to	_	_
52-14	6122-6130	download	_	_
52-15	6131-6134	the	_	_
52-16	6135-6140	BFM09	_	_
52-17	6141-6146	model	_	_
52-18	6147-6152	after	_	_
52-19	6153-6163	submitting	_	_
52-20	6164-6166	an	_	_
52-21	6167-6178	application	_	_
52-22	6179-6181	on	_	_
52-23	6182-6185	its	_	_
52-24	6186-6187	\[	_	_
52-25	6187-6191	home	_	_
52-26	6192-6196	page	_	_
52-27	6196-6197	\]	_	_
52-28	6197-6198	(	_	_
52-29	6198-6203	https	_	_
52-30	6203-6204	:	_	_
52-31	6204-6205	/	_	_
52-32	6205-6206	/	_	_
52-33	6206-6225	faces.dmi.unibas.ch	_	_
52-34	6225-6226	/	_	_
52-35	6226-6229	bfm	_	_
52-36	6229-6230	/	_	_
52-37	6230-6238	main.php	_	_
52-38	6238-6239	?	_	_

#Text=nav=1-2&id=downloads).
53-1	6239-6242	nav	_	_
53-2	6242-6243	=	_	_
53-3	6243-6244	1	_	_
53-4	6244-6245	-	_	_
53-5	6245-6247	2&	_	_
53-6	6247-6249	id	_	_
53-7	6249-6250	=	_	_
53-8	6250-6259	downloads	_	_
53-9	6259-6260	)	_	_
53-10	6260-6261	.	_	_

#Text=After getting the access to BFM data, download "01\_MorphableModel.mat" and put it into .
54-1	6262-6267	After	_	_
54-2	6268-6275	getting	_	_
54-3	6276-6279	the	_	_
54-4	6280-6286	access	_	_
54-5	6287-6289	to	_	_
54-6	6290-6293	BFM	_	_
54-7	6294-6298	data	_	_
54-8	6298-6299	,	_	_
54-9	6300-6308	download	_	_
54-10	6309-6310	"	_	_
54-11	6310-6312	01	_	_
54-12	6312-6313	\_	_	_
54-13	6313-6331	MorphableModel.mat	_	_
54-14	6331-6332	"	_	_
54-15	6333-6336	and	_	_
54-16	6337-6340	put	_	_
54-17	6341-6343	it	_	_
54-18	6344-6348	into	_	_
54-19	6349-6350	.	_	_

#Text=/BFM subfolder.  2.
55-1	6350-6351	/	_	_
55-2	6351-6354	BFM	_	_
55-3	6355-6364	subfolder	_	_
55-4	6364-6365	.	_	_
55-5	6367-6368	2	_	_
55-6	6368-6369	.	_	_

#Text=Download the Expression Basis provided by \[Guo et al.\]
56-1	6370-6378	Download	_	_
56-2	6379-6382	the	_	_
56-3	6383-6393	Expression	_	_
56-4	6394-6399	Basis	_	_
56-5	6400-6408	provided	_	_
56-6	6409-6411	by	_	_
56-7	6412-6413	\[	_	_
56-8	6413-6416	Guo	_	_
56-9	6417-6419	et	_	_
56-10	6420-6422	al	_	_
56-11	6422-6423	.	_	_
56-12	6423-6424	\]	_	_

#Text=(https://github.com/Juyong/3DFace) You can find a link named "CoarseData" in the first row of Introduction part in their repository.
57-1	6424-6425	(	_	_
57-2	6425-6430	https	_	_
57-3	6430-6431	:	_	_
57-4	6431-6432	/	_	_
57-5	6432-6433	/	_	_
57-6	6433-6443	github.com	_	_
57-7	6443-6444	/	_	_
57-8	6444-6450	Juyong	_	_
57-9	6450-6451	/	_	_
57-10	6451-6457	3DFace	*	PROJECT
57-11	6457-6458	)	_	_
57-12	6459-6462	You	_	_
57-13	6463-6466	can	_	_
57-14	6467-6471	find	_	_
57-15	6472-6473	a	_	_
57-16	6474-6478	link	_	_
57-17	6479-6484	named	_	_
57-18	6485-6486	"	_	_
57-19	6486-6496	CoarseData	*	DATASET
57-20	6496-6497	"	_	_
57-21	6498-6500	in	_	_
57-22	6501-6504	the	_	_
57-23	6505-6510	first	_	_
57-24	6511-6514	row	_	_
57-25	6515-6517	of	_	_
57-26	6518-6530	Introduction	_	_
57-27	6531-6535	part	_	_
57-28	6536-6538	in	_	_
57-29	6539-6544	their	_	_
57-30	6545-6555	repository	_	_
57-31	6555-6556	.	_	_

#Text=Download and unzip the Coarse\_Dataset.zip.
58-1	6557-6565	Download	_	_
58-2	6566-6569	and	_	_
58-3	6570-6575	unzip	_	_
58-4	6576-6579	the	_	_
58-5	6580-6598	Coarse\_Dataset.zip	_	_
58-5	6580-6586	Coarse	*	DATASET
58-6	6598-6599	.	_	_

#Text=Put "Exp\_Pca.bin" into .
59-1	6600-6603	Put	_	_
59-2	6604-6605	"	_	_
59-3	6605-6616	Exp\_Pca.bin	_	_
59-4	6616-6617	"	_	_
59-5	6618-6622	into	_	_
59-6	6623-6624	.	_	_

#Text=/BFM subfolder.
60-1	6624-6625	/	_	_
60-2	6625-6628	BFM	_	_
60-3	6629-6638	subfolder	_	_
60-4	6638-6639	.	_	_

#Text=The expression basis are constructed using \[Facewarehouse\](http://kunzhou.net/zjugaps/facewarehouse/) data and transferred to BFM topology.  3.
61-1	6640-6643	The	_	_
61-2	6644-6654	expression	_	_
61-3	6655-6660	basis	_	_
61-4	6661-6664	are	_	_
61-5	6665-6676	constructed	_	_
61-6	6677-6682	using	_	_
61-7	6683-6684	\[	_	_
61-8	6684-6697	Facewarehouse	*	DATASET
61-9	6697-6698	\]	_	_
61-10	6698-6699	(	_	_
61-11	6699-6703	http	_	_
61-12	6703-6704	:	_	_
61-13	6704-6705	/	_	_
61-14	6705-6706	/	_	_
61-15	6706-6717	kunzhou.net	_	_
61-16	6717-6718	/	_	_
61-17	6718-6725	zjugaps	_	_
61-18	6725-6726	/	_	_
61-19	6726-6739	facewarehouse	_	_
61-20	6739-6740	/	_	_
61-21	6740-6741	)	_	_
61-22	6742-6746	data	_	_
61-23	6747-6750	and	_	_
61-24	6751-6762	transferred	_	_
61-25	6763-6765	to	_	_
61-26	6766-6769	BFM	_	_
61-27	6770-6778	topology	_	_
61-28	6778-6779	.	_	_
61-29	6781-6782	3	_	_
61-30	6782-6783	.	_	_

#Text=Download the pre-trained \[reconstruction network\](https://drive.google.com/file/d/176LCdUDxAj7T2awQ5knPMPawq5Q2RUWM/view?
62-1	6784-6792	Download	_	_
62-2	6793-6796	the	_	_
62-3	6797-6808	pre-trained	_	_
62-4	6809-6810	\[	_	_
62-5	6810-6824	reconstruction	_	_
62-6	6825-6832	network	_	_
62-7	6832-6833	\]	_	_
62-8	6833-6834	(	_	_
62-9	6834-6839	https	_	_
62-10	6839-6840	:	_	_
62-11	6840-6841	/	_	_
62-12	6841-6842	/	_	_
62-13	6842-6858	drive.google.com	_	_
62-14	6858-6859	/	_	_
62-15	6859-6863	file	_	_
62-16	6863-6864	/	_	_
62-17	6864-6865	d	_	_
62-18	6865-6866	/	_	_
62-19	6866-6899	176LCdUDxAj7T2awQ5knPMPawq5Q2RUWM	_	_
62-20	6899-6900	/	_	_
62-21	6900-6904	view	_	_
62-22	6904-6905	?	_	_

#Text=usp=sharing), unzip it and put "FaceReconModel.pb" into .
63-1	6905-6908	usp	_	_
63-2	6908-6909	=	_	_
63-3	6909-6916	sharing	_	_
63-4	6916-6917	)	_	_
63-5	6917-6918	,	_	_
63-6	6919-6924	unzip	_	_
63-7	6925-6927	it	_	_
63-8	6928-6931	and	_	_
63-9	6932-6935	put	_	_
63-10	6936-6937	"	_	_
63-11	6937-6954	FaceReconModel.pb	_	_
63-12	6954-6955	"	_	_
63-13	6956-6960	into	_	_
63-14	6961-6962	.	_	_

#Text=/network subfolder.  4.
64-1	6962-6963	/	_	_
64-2	6963-6970	network	_	_
64-3	6971-6980	subfolder	_	_
64-4	6980-6981	.	_	_
64-5	6983-6984	4	_	_
64-6	6984-6985	.	_	_

#Text=Run the demo code.  ``` python demo.py ```  5. .
65-1	6986-6989	Run	_	_
65-2	6990-6993	the	_	_
65-3	6994-6998	demo	_	_
65-4	6999-7003	code	_	_
65-5	7003-7004	.	_	_
65-6	7006-7007	`	_	_
65-7	7007-7008	`	_	_
65-8	7008-7009	`	_	_
65-9	7010-7016	python	_	_
65-10	7017-7024	demo.py	_	_
65-11	7025-7026	`	_	_
65-12	7026-7027	`	_	_
65-13	7027-7028	`	_	_
65-14	7030-7031	5	_	_
65-15	7031-7032	.	_	_
65-16	7033-7034	.	_	_

#Text=/input subfolder contains several test images and .
66-1	7034-7035	/	_	_
66-2	7035-7040	input	_	_
66-3	7041-7050	subfolder	_	_
66-4	7051-7059	contains	_	_
66-5	7060-7067	several	_	_
66-6	7068-7072	test	_	_
66-7	7073-7079	images	_	_
66-8	7080-7083	and	_	_
66-9	7084-7085	.	_	_

#Text=/output subfolder stores their reconstruction results.
67-1	7085-7086	/	_	_
67-2	7086-7092	output	_	_
67-3	7093-7102	subfolder	_	_
67-4	7103-7109	stores	_	_
67-5	7110-7115	their	_	_
67-6	7116-7130	reconstruction	_	_
67-7	7131-7138	results	_	_
67-8	7138-7139	.	_	_

#Text=For each input test image, two output files can be obtained after running the demo code:  - "xxx.mat" :    - cropped\_img: an RGB image after alignment, which is the input to the R-Net   - recon\_img: an RGBA reconstruction image aligned with the input image (only on Linux)
68-1	7140-7143	For	_	_
68-2	7144-7148	each	_	_
68-3	7149-7154	input	_	_
68-4	7155-7159	test	_	_
68-5	7160-7165	image	_	_
68-6	7165-7166	,	_	_
68-7	7167-7170	two	_	_
68-8	7171-7177	output	_	_
68-9	7178-7183	files	_	_
68-10	7184-7187	can	_	_
68-11	7188-7190	be	_	_
68-12	7191-7199	obtained	_	_
68-13	7200-7205	after	_	_
68-14	7206-7213	running	_	_
68-15	7214-7217	the	_	_
68-16	7218-7222	demo	_	_
68-17	7223-7227	code	_	_
68-18	7227-7228	:	_	_
68-19	7230-7231	-	_	_
68-20	7232-7233	"	_	_
68-21	7233-7240	xxx.mat	_	_
68-22	7240-7241	"	_	_
68-23	7242-7243	:	_	_
68-24	7247-7248	-	_	_
68-25	7249-7260	cropped\_img	_	_
68-26	7260-7261	:	_	_
68-27	7262-7264	an	_	_
68-28	7265-7268	RGB	_	_
68-29	7269-7274	image	_	_
68-30	7275-7280	after	_	_
68-31	7281-7290	alignment	_	_
68-32	7290-7291	,	_	_
68-33	7292-7297	which	_	_
68-34	7298-7300	is	_	_
68-35	7301-7304	the	_	_
68-36	7305-7310	input	_	_
68-37	7311-7313	to	_	_
68-38	7314-7317	the	_	_
68-39	7318-7323	R-Net	_	_
68-40	7326-7327	-	_	_
68-41	7328-7337	recon\_img	_	_
68-42	7337-7338	:	_	_
68-43	7339-7341	an	_	_
68-44	7342-7346	RGBA	_	_
68-45	7347-7361	reconstruction	_	_
68-46	7362-7367	image	_	_
68-47	7368-7375	aligned	_	_
68-48	7376-7380	with	_	_
68-49	7381-7384	the	_	_
68-50	7385-7390	input	_	_
68-51	7391-7396	image	_	_
68-52	7397-7398	(	_	_
68-53	7398-7402	only	_	_
68-54	7403-7405	on	_	_
68-55	7406-7411	Linux	_	_
68-56	7411-7412	)	_	_

#Text=.
69-1	7412-7413	.	_	_

#Text=- coeff: output coefficients of R-Net
70-1	7416-7417	-	_	_
70-2	7418-7423	coeff	_	_
70-3	7423-7424	:	_	_
70-4	7425-7431	output	_	_
70-5	7432-7444	coefficients	_	_
70-6	7445-7447	of	_	_
70-7	7448-7453	R-Net	_	_

#Text=.
71-1	7453-7454	.	_	_

#Text=- face\_shape: vertex positions of 3D face in the world coordinate
72-1	7457-7458	-	_	_
72-2	7459-7469	face\_shape	_	_
72-3	7469-7470	:	_	_
72-4	7471-7477	vertex	_	_
72-5	7478-7487	positions	_	_
72-6	7488-7490	of	_	_
72-7	7491-7493	3D	_	_
72-8	7494-7498	face	_	_
72-9	7499-7501	in	_	_
72-10	7502-7505	the	_	_
72-11	7506-7511	world	_	_
72-12	7512-7522	coordinate	_	_

#Text=.
73-1	7522-7523	.	_	_

#Text=- face\_texture: vertex texture of 3D face, which excludes lighting effect
74-1	7526-7527	-	_	_
74-2	7528-7540	face\_texture	_	_
74-3	7540-7541	:	_	_
74-4	7542-7548	vertex	_	_
74-5	7549-7556	texture	_	_
74-6	7557-7559	of	_	_
74-7	7560-7562	3D	_	_
74-8	7563-7567	face	_	_
74-9	7567-7568	,	_	_
74-10	7569-7574	which	_	_
74-11	7575-7583	excludes	_	_
74-12	7584-7592	lighting	_	_
74-13	7593-7599	effect	_	_

#Text=.
75-1	7599-7600	.	_	_

#Text=- face\_color: vertex color of 3D face, which takes lighting into consideration
76-1	7603-7604	-	_	_
76-2	7605-7615	face\_color	_	_
76-3	7615-7616	:	_	_
76-4	7617-7623	vertex	_	_
76-5	7624-7629	color	_	_
76-6	7630-7632	of	_	_
76-7	7633-7635	3D	_	_
76-8	7636-7640	face	_	_
76-9	7640-7641	,	_	_
76-10	7642-7647	which	_	_
76-11	7648-7653	takes	_	_
76-12	7654-7662	lighting	_	_
76-13	7663-7667	into	_	_
76-14	7668-7681	consideration	_	_

#Text=.
77-1	7681-7682	.	_	_

#Text=- lm\\\_68p: 68 2D facial landmarks derived from the reconstructed 3D face.
78-1	7685-7686	-	_	_
78-2	7687-7689	lm	_	_
78-3	7689-7690	\\	_	_
78-4	7690-7691	\_	_	_
78-5	7691-7694	68p	_	_
78-6	7694-7695	:	_	_
78-7	7696-7698	68	_	_
78-8	7699-7701	2D	_	_
78-9	7702-7708	facial	_	_
78-10	7709-7718	landmarks	_	_
78-11	7719-7726	derived	_	_
78-12	7727-7731	from	_	_
78-13	7732-7735	the	_	_
78-14	7736-7749	reconstructed	_	_
78-15	7750-7752	3D	_	_
78-16	7753-7757	face	_	_
78-17	7757-7758	.	_	_

#Text=The landmarks are aligned with cropped\_img
79-1	7759-7762	The	_	_
79-2	7763-7772	landmarks	_	_
79-3	7773-7776	are	_	_
79-4	7777-7784	aligned	_	_
79-5	7785-7789	with	_	_
79-6	7790-7801	cropped\_img	_	_

#Text=.
80-1	7801-7802	.	_	_

#Text=- lm\\\_5p: 5 detected landmarks aligned with cropped\_img
81-1	7805-7806	-	_	_
81-2	7807-7809	lm	_	_
81-3	7809-7810	\\	_	_
81-4	7810-7811	\_	_	_
81-5	7811-7813	5p	_	_
81-6	7813-7814	:	_	_
81-7	7815-7816	5	_	_
81-8	7817-7825	detected	_	_
81-9	7826-7835	landmarks	_	_
81-10	7836-7843	aligned	_	_
81-11	7844-7848	with	_	_
81-12	7849-7860	cropped\_img	_	_

#Text=.
82-1	7860-7861	.	_	_

#Text=- "xxx\_mesh.obj" : 3D face mesh in the world coordinate (best viewed in MeshLab).  ### Training requirements ###  - Training is only supported on Linux.
83-1	7864-7865	-	_	_
83-2	7866-7867	"	_	_
83-3	7867-7879	xxx\_mesh.obj	_	_
83-4	7879-7880	"	_	_
83-5	7881-7882	:	_	_
83-6	7883-7885	3D	_	_
83-7	7886-7890	face	_	_
83-8	7891-7895	mesh	_	_
83-9	7896-7898	in	_	_
83-10	7899-7902	the	_	_
83-11	7903-7908	world	_	_
83-12	7909-7919	coordinate	_	_
83-13	7920-7921	(	_	_
83-14	7921-7925	best	_	_
83-15	7926-7932	viewed	_	_
83-16	7933-7935	in	_	_
83-17	7936-7943	MeshLab	_	_
83-18	7943-7944	)	_	_
83-19	7944-7945	.	_	_
83-20	7947-7948	#	_	_
83-21	7948-7949	#	_	_
83-22	7949-7950	#	_	_
83-23	7951-7959	Training	_	_
83-24	7960-7972	requirements	_	_
83-25	7973-7974	#	_	_
83-26	7974-7975	#	_	_
83-27	7975-7976	#	_	_
83-28	7978-7979	-	_	_
83-29	7980-7988	Training	_	_
83-30	7989-7991	is	_	_
83-31	7992-7996	only	_	_
83-32	7997-8006	supported	_	_
83-33	8007-8009	on	_	_
83-34	8010-8015	Linux	_	_
83-35	8015-8016	.	_	_

#Text=To train new model from scratch, more requirements are needed on top of the requirements listed in the testing stage. - \[Facenet\](https://github.com/davidsandberg/facenet) provided by  Sandberg et al.
84-1	8017-8019	To	_	_
84-2	8020-8025	train	_	_
84-3	8026-8029	new	_	_
84-4	8030-8035	model	_	_
84-5	8036-8040	from	_	_
84-6	8041-8048	scratch	_	_
84-7	8048-8049	,	_	_
84-8	8050-8054	more	_	_
84-9	8055-8067	requirements	_	_
84-10	8068-8071	are	_	_
84-11	8072-8078	needed	_	_
84-12	8079-8081	on	_	_
84-13	8082-8085	top	_	_
84-14	8086-8088	of	_	_
84-15	8089-8092	the	_	_
84-16	8093-8105	requirements	_	_
84-17	8106-8112	listed	_	_
84-18	8113-8115	in	_	_
84-19	8116-8119	the	_	_
84-20	8120-8127	testing	_	_
84-21	8128-8133	stage	_	_
84-22	8133-8134	.	_	_
84-23	8135-8136	-	_	_
84-24	8137-8138	\[	_	_
84-25	8138-8145	Facenet	_	_
84-26	8145-8146	\]	_	_
84-27	8146-8147	(	_	_
84-28	8147-8152	https	_	_
84-29	8152-8153	:	_	_
84-30	8153-8154	/	_	_
84-31	8154-8155	/	_	_
84-32	8155-8165	github.com	_	_
84-33	8165-8166	/	_	_
84-34	8166-8179	davidsandberg	_	_
84-35	8179-8180	/	_	_
84-36	8180-8187	facenet	_	_
84-37	8187-8188	)	_	_
84-38	8189-8197	provided	_	_
84-39	8198-8200	by	_	_
84-40	8202-8210	Sandberg	_	_
84-41	8211-8213	et	_	_
84-42	8214-8216	al	_	_
84-43	8216-8217	.	_	_

#Text=In our paper, we use a network to exrtact perceptual face features.
85-1	8218-8220	In	_	_
85-2	8221-8224	our	_	_
85-3	8225-8230	paper	_	_
85-4	8230-8231	,	_	_
85-5	8232-8234	we	_	_
85-6	8235-8238	use	_	_
85-7	8239-8240	a	_	_
85-8	8241-8248	network	_	_
85-9	8249-8251	to	_	_
85-10	8252-8259	exrtact	_	_
85-11	8260-8270	perceptual	_	_
85-12	8271-8275	face	_	_
85-13	8276-8284	features	_	_
85-14	8284-8285	.	_	_

#Text=This network model cannot be publicly released.
86-1	8286-8290	This	_	_
86-2	8291-8298	network	_	_
86-3	8299-8304	model	_	_
86-4	8305-8311	cannot	_	_
86-5	8312-8314	be	_	_
86-6	8315-8323	publicly	_	_
86-7	8324-8332	released	_	_
86-8	8332-8333	.	_	_

#Text=As an alternative, we recommend using the Facenet from Sandberg et al.
87-1	8334-8336	As	_	_
87-2	8337-8339	an	_	_
87-3	8340-8351	alternative	_	_
87-4	8351-8352	,	_	_
87-5	8353-8355	we	_	_
87-6	8356-8365	recommend	_	_
87-7	8366-8371	using	_	_
87-8	8372-8375	the	_	_
87-9	8376-8383	Facenet	_	_
87-10	8384-8388	from	_	_
87-11	8389-8397	Sandberg	_	_
87-12	8398-8400	et	_	_
87-13	8401-8403	al	_	_
87-14	8403-8404	.	_	_

#Text=This repo uses the version \[20170512-110547\](https://github.com/davidsandberg/facenet/blob/529c3b0b5fc8da4e0f48d2818906120f2e5687e6/README.md) trained on MS-Celeb-1M.
88-1	8405-8409	This	_	_
88-2	8410-8414	repo	_	_
88-3	8415-8419	uses	_	_
88-4	8420-8423	the	_	_
88-5	8424-8431	version	_	_
88-6	8432-8433	\[	_	_
88-7	8433-8441	20170512	_	_
88-8	8441-8442	-	_	_
88-9	8442-8448	110547	_	_
88-10	8448-8449	\]	_	_
88-11	8449-8450	(	_	_
88-12	8450-8455	https	_	_
88-13	8455-8456	:	_	_
88-14	8456-8457	/	_	_
88-15	8457-8458	/	_	_
88-16	8458-8468	github.com	_	_
88-17	8468-8469	/	_	_
88-18	8469-8482	davidsandberg	_	_
88-19	8482-8483	/	_	_
88-20	8483-8490	facenet	_	_
88-21	8490-8491	/	_	_
88-22	8491-8495	blob	_	_
88-23	8495-8496	/	_	_
88-24	8496-8536	529c3b0b5fc8da4e0f48d2818906120f2e5687e6	_	_
88-25	8536-8537	/	_	_
88-26	8537-8546	README.md	_	_
88-27	8546-8547	)	_	_
88-28	8548-8555	trained	_	_
88-29	8556-8558	on	_	_
88-30	8559-8567	MS-Celeb	_	_
88-31	8567-8568	-	_	_
88-32	8568-8570	1M	_	_
88-33	8570-8571	.	_	_

#Text=Training process has been tested with this model to ensure similar results. - \[Resnet50-v1\](https://github.com/tensorflow/models/blob/master/research/slim/README.md) pre-trained on ImageNet from Tensorflow Slim.
89-1	8572-8580	Training	_	_
89-2	8581-8588	process	_	_
89-3	8589-8592	has	_	_
89-4	8593-8597	been	_	_
89-5	8598-8604	tested	_	_
89-6	8605-8609	with	_	_
89-7	8610-8614	this	_	_
89-8	8615-8620	model	_	_
89-9	8621-8623	to	_	_
89-10	8624-8630	ensure	_	_
89-11	8631-8638	similar	_	_
89-12	8639-8646	results	_	_
89-13	8646-8647	.	_	_
89-14	8648-8649	-	_	_
89-15	8650-8651	\[	_	_
89-16	8651-8659	Resnet50	_	_
89-17	8659-8660	-	_	_
89-18	8660-8662	v1	_	_
89-19	8662-8663	\]	_	_
89-20	8663-8664	(	_	_
89-21	8664-8669	https	_	_
89-22	8669-8670	:	_	_
89-23	8670-8671	/	_	_
89-24	8671-8672	/	_	_
89-25	8672-8682	github.com	_	_
89-26	8682-8683	/	_	_
89-27	8683-8693	tensorflow	*[17]	SOFTWARE[17]
89-28	8693-8694	/	*[17]	SOFTWARE[17]
89-29	8694-8700	models	_	_
89-30	8700-8701	/	_	_
89-31	8701-8705	blob	_	_
89-32	8705-8706	/	_	_
89-33	8706-8712	master	_	_
89-34	8712-8713	/	_	_
89-35	8713-8721	research	_	_
89-36	8721-8722	/	_	_
89-37	8722-8726	slim	_	_
89-38	8726-8727	/	_	_
89-39	8727-8736	README.md	_	_
89-40	8736-8737	)	_	_
89-41	8738-8749	pre-trained	_	_
89-42	8750-8752	on	_	_
89-43	8753-8761	ImageNet	*	DATASET
89-44	8762-8766	from	_	_
89-45	8767-8777	Tensorflow	*	SOFTWARE
89-46	8778-8782	Slim	_	_
89-47	8782-8783	.	_	_

#Text=We use the version resnet\_v1\_50\_2016\_08\_28.tar.gz as an initialization of the face reconstruction network. - \[68-facial-landmark detector\](https://drive.google.com/file/d/1KYFeTb963jg0F47sTiwqDdhBIvRlUkPa/view?
90-1	8784-8786	We	_	_
90-2	8787-8790	use	_	_
90-3	8791-8794	the	_	_
90-4	8795-8802	version	_	_
90-5	8803-8812	resnet\_v1	_	_
90-6	8812-8813	\_	_	_
90-7	8813-8815	50	_	_
90-8	8815-8816	\_	_	_
90-9	8816-8820	2016	_	_
90-10	8820-8821	\_	_	_
90-11	8821-8823	08	_	_
90-12	8823-8824	\_	_	_
90-13	8824-8826	28	_	_
90-14	8826-8827	.	_	_
90-15	8827-8833	tar.gz	_	_
90-16	8834-8836	as	_	_
90-17	8837-8839	an	_	_
90-18	8840-8854	initialization	_	_
90-19	8855-8857	of	_	_
90-20	8858-8861	the	_	_
90-21	8862-8866	face	_	_
90-22	8867-8881	reconstruction	_	_
90-23	8882-8889	network	_	_
90-24	8889-8890	.	_	_
90-25	8891-8892	-	_	_
90-26	8893-8894	\[	_	_
90-27	8894-8896	68	_	_
90-28	8896-8897	-	_	_
90-29	8897-8912	facial-landmark	_	_
90-30	8913-8921	detector	_	_
90-31	8921-8922	\]	_	_
90-32	8922-8923	(	_	_
90-33	8923-8928	https	_	_
90-34	8928-8929	:	_	_
90-35	8929-8930	/	_	_
90-36	8930-8931	/	_	_
90-37	8931-8947	drive.google.com	_	_
90-38	8947-8948	/	_	_
90-39	8948-8952	file	_	_
90-40	8952-8953	/	_	_
90-41	8953-8954	d	_	_
90-42	8954-8955	/	_	_
90-43	8955-8988	1KYFeTb963jg0F47sTiwqDdhBIvRlUkPa	_	_
90-44	8988-8989	/	_	_
90-45	8989-8993	view	_	_
90-46	8993-8994	?	_	_

#Text=usp=sharing).
91-1	8994-8997	usp	_	_
91-2	8997-8998	=	_	_
91-3	8998-9005	sharing	_	_
91-4	9005-9006	)	_	_
91-5	9006-9007	.	_	_

#Text=We use 68 facial landmarks for loss calculation during training.
92-1	9008-9010	We	_	_
92-2	9011-9014	use	_	_
92-3	9015-9017	68	_	_
92-4	9018-9024	facial	_	_
92-5	9025-9034	landmarks	_	_
92-6	9035-9038	for	_	_
92-7	9039-9043	loss	_	_
92-8	9044-9055	calculation	_	_
92-9	9056-9062	during	_	_
92-10	9063-9071	training	_	_
92-11	9071-9072	.	_	_

#Text=To make the training process reproducible, we provide a lightweight detector that produce comparable results to \[the method of Bulat et al.\]
93-1	9073-9075	To	_	_
93-2	9076-9080	make	_	_
93-3	9081-9084	the	_	_
93-4	9085-9093	training	_	_
93-5	9094-9101	process	_	_
93-6	9102-9114	reproducible	_	_
93-7	9114-9115	,	_	_
93-8	9116-9118	we	_	_
93-9	9119-9126	provide	_	_
93-10	9127-9128	a	_	_
93-11	9129-9140	lightweight	_	_
93-12	9141-9149	detector	_	_
93-13	9150-9154	that	_	_
93-14	9155-9162	produce	_	_
93-15	9163-9173	comparable	_	_
93-16	9174-9181	results	_	_
93-17	9182-9184	to	_	_
93-18	9185-9186	\[	_	_
93-19	9186-9189	the	_	_
93-20	9190-9196	method	_	_
93-21	9197-9199	of	_	_
93-22	9200-9205	Bulat	_	_
93-23	9206-9208	et	_	_
93-24	9209-9211	al	_	_
93-25	9211-9212	.	_	_
93-26	9212-9213	\]	_	_

#Text=(https://github.com/1adrianb/2D-and-3D-face-alignment).
94-1	9213-9214	(	_	_
94-2	9214-9219	https	_	_
94-3	9219-9220	:	_	_
94-4	9220-9221	/	_	_
94-5	9221-9222	/	_	_
94-6	9222-9232	github.com	_	_
94-7	9232-9233	/	_	_
94-8	9233-9241	1adrianb	_	_
94-9	9241-9242	/	_	_
94-10	9242-9248	2D-and	_	_
94-11	9248-9249	-	_	_
94-12	9249-9266	3D-face-alignment	_	_
94-13	9266-9267	)	_	_
94-14	9267-9268	.	_	_

#Text=The detector is trained on \[300WLP\](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm), \[LFW\](http://vis-www.cs.umass.edu/lfw/), and \[LS3D-W\](https://www.adrianbulat.com/face-alignment).  ### Training preparation ###  1.
95-1	9269-9272	The	_	_
95-2	9273-9281	detector	_	_
95-3	9282-9284	is	_	_
95-4	9285-9292	trained	_	_
95-5	9293-9295	on	_	_
95-6	9296-9297	\[	_	_
95-7	9297-9303	300WLP	_	_
95-8	9303-9304	\]	_	_
95-9	9304-9305	(	_	_
95-10	9305-9309	http	_	_
95-11	9309-9310	:	_	_
95-12	9310-9311	/	_	_
95-13	9311-9312	/	_	_
95-14	9312-9329	www.cbsr.ia.ac.cn	_	_
95-15	9329-9330	/	_	_
95-16	9330-9335	users	_	_
95-17	9335-9336	/	_	_
95-18	9336-9346	xiangyuzhu	_	_
95-19	9346-9347	/	_	_
95-20	9347-9355	projects	_	_
95-21	9355-9356	/	_	_
95-22	9356-9361	3DDFA	_	_
95-23	9361-9362	/	_	_
95-24	9362-9370	main.htm	_	_
95-25	9370-9371	)	_	_
95-26	9371-9372	,	_	_
95-27	9373-9374	\[	_	_
95-28	9374-9377	LFW	_	_
95-29	9377-9378	\]	_	_
95-30	9378-9379	(	_	_
95-31	9379-9383	http	_	_
95-32	9383-9384	:	_	_
95-33	9384-9385	/	_	_
95-34	9385-9386	/	_	_
95-35	9386-9406	vis-www.cs.umass.edu	_	_
95-36	9406-9407	/	_	_
95-37	9407-9410	lfw	_	_
95-38	9410-9411	/	_	_
95-39	9411-9412	)	_	_
95-40	9412-9413	,	_	_
95-41	9414-9417	and	_	_
95-42	9418-9419	\[	_	_
95-43	9419-9425	LS3D-W	_	_
95-44	9425-9426	\]	_	_
95-45	9426-9427	(	_	_
95-46	9427-9432	https	_	_
95-47	9432-9433	:	_	_
95-48	9433-9434	/	_	_
95-49	9434-9435	/	_	_
95-50	9435-9454	www.adrianbulat.com	_	_
95-51	9454-9455	/	_	_
95-52	9455-9469	face-alignment	_	_
95-53	9469-9470	)	_	_
95-54	9470-9471	.	_	_
95-55	9473-9474	#	_	_
95-56	9474-9475	#	_	_
95-57	9475-9476	#	_	_
95-58	9477-9485	Training	_	_
95-59	9486-9497	preparation	_	_
95-60	9498-9499	#	_	_
95-61	9499-9500	#	_	_
95-62	9500-9501	#	_	_
95-63	9503-9504	1	_	_
95-64	9504-9505	.	_	_

#Text=Download the \[pre-trained weights\](https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk/edit) of Facenet provided by Sandberg et al., unzip it and put all files in .
96-1	9506-9514	Download	_	_
96-2	9515-9518	the	_	_
96-3	9519-9520	\[	_	_
96-4	9520-9531	pre-trained	_	_
96-5	9532-9539	weights	_	_
96-6	9539-9540	\]	_	_
96-7	9540-9541	(	_	_
96-8	9541-9546	https	_	_
96-9	9546-9547	:	_	_
96-10	9547-9548	/	_	_
96-11	9548-9549	/	_	_
96-12	9549-9565	drive.google.com	_	_
96-13	9565-9566	/	_	_
96-14	9566-9570	file	_	_
96-15	9570-9571	/	_	_
96-16	9571-9572	d	_	_
96-17	9572-9573	/	_	_
96-18	9573-9601	0B5MzpY9kBtDVZ2RpVDYwWmxoSUk	_	_
96-19	9601-9602	/	_	_
96-20	9602-9606	edit	_	_
96-21	9606-9607	)	_	_
96-22	9608-9610	of	_	_
96-23	9611-9618	Facenet	_	_
96-24	9619-9627	provided	_	_
96-25	9628-9630	by	_	_
96-26	9631-9639	Sandberg	_	_
96-27	9640-9642	et	_	_
96-28	9643-9645	al	_	_
96-29	9645-9646	.	_	_
96-30	9646-9647	,	_	_
96-31	9648-9653	unzip	_	_
96-32	9654-9656	it	_	_
96-33	9657-9660	and	_	_
96-34	9661-9664	put	_	_
96-35	9665-9668	all	_	_
96-36	9669-9674	files	_	_
96-37	9675-9677	in	_	_
96-38	9678-9679	.	_	_

#Text=/weights/id\_net. 2.
97-1	9679-9680	/	_	_
97-2	9680-9687	weights	_	_
97-3	9687-9688	/	_	_
97-4	9688-9694	id\_net	_	_
97-5	9694-9695	.	_	_
97-6	9696-9697	2	_	_
97-7	9697-9698	.	_	_

#Text=Download the \[pre-trained weights\](http://download.tensorflow.org/models/resnet\_v1\_50\_2016\_08\_28.tar.gz) of Resnet\_v1\_50 provided by Tensorflow Slim, unzip it and put resnet\_v1\_50.ckpt in .
98-1	9699-9707	Download	_	_
98-2	9708-9711	the	_	_
98-3	9712-9713	\[	_	_
98-4	9713-9724	pre-trained	_	_
98-5	9725-9732	weights	_	_
98-6	9732-9733	\]	_	_
98-7	9733-9734	(	_	_
98-8	9734-9738	http	_	_
98-9	9738-9739	:	_	_
98-10	9739-9740	/	_	_
98-11	9740-9741	/	_	_
98-12	9741-9764	download.tensorflow.org	_	_
98-12	9750-9760	tensorflow	*	SOFTWARE
98-13	9764-9765	/	_	_
98-14	9765-9771	models	_	_
98-15	9771-9772	/	_	_
98-16	9772-9781	resnet\_v1	_	_
98-17	9781-9782	\_	_	_
98-18	9782-9784	50	_	_
98-19	9784-9785	\_	_	_
98-20	9785-9789	2016	_	_
98-21	9789-9790	\_	_	_
98-22	9790-9792	08	_	_
98-23	9792-9793	\_	_	_
98-24	9793-9795	28	_	_
98-25	9795-9796	.	_	_
98-26	9796-9802	tar.gz	_	_
98-27	9802-9803	)	_	_
98-28	9804-9806	of	_	_
98-29	9807-9816	Resnet\_v1	_	_
98-30	9816-9817	\_	_	_
98-31	9817-9819	50	_	_
98-32	9820-9828	provided	_	_
98-33	9829-9831	by	_	_
98-34	9832-9842	Tensorflow	*	SOFTWARE
98-35	9843-9847	Slim	_	_
98-36	9847-9848	,	_	_
98-37	9849-9854	unzip	*	SOFTWARE
98-38	9855-9857	it	_	_
98-39	9858-9861	and	_	_
98-40	9862-9865	put	_	_
98-41	9866-9875	resnet\_v1	_	_
98-42	9875-9876	\_	_	_
98-43	9876-9878	50	_	_
98-44	9878-9879	.	_	_
98-45	9879-9883	ckpt	_	_
98-46	9884-9886	in	_	_
98-47	9887-9888	.	_	_

#Text=/weights/resnet. 3.
99-1	9888-9889	/	_	_
99-2	9889-9896	weights	_	_
99-3	9896-9897	/	_	_
99-4	9897-9903	resnet	_	_
99-5	9903-9904	.	_	_
99-6	9905-9906	3	_	_
99-7	9906-9907	.	_	_

#Text=Download the \[68 landmark detector\](https://drive.google.com/file/d/1KYFeTb963jg0F47sTiwqDdhBIvRlUkPa/view?
100-1	9908-9916	Download	_	_
100-2	9917-9920	the	_	_
100-3	9921-9922	\[	_	_
100-4	9922-9924	68	_	_
100-5	9925-9933	landmark	_	_
100-6	9934-9942	detector	_	_
100-7	9942-9943	\]	_	_
100-8	9943-9944	(	_	_
100-9	9944-9949	https	_	_
100-10	9949-9950	:	_	_
100-11	9950-9951	/	_	_
100-12	9951-9952	/	_	_
100-13	9952-9968	drive.google.com	_	_
100-14	9968-9969	/	_	_
100-15	9969-9973	file	_	_
100-16	9973-9974	/	_	_
100-17	9974-9975	d	_	_
100-18	9975-9976	/	_	_
100-19	9976-10009	1KYFeTb963jg0F47sTiwqDdhBIvRlUkPa	_	_
100-20	10009-10010	/	_	_
100-21	10010-10014	view	_	_
100-22	10014-10015	?	_	_

#Text=usp=sharing), put the file in .
101-1	10015-10018	usp	_	_
101-2	10018-10019	=	_	_
101-3	10019-10026	sharing	_	_
101-4	10026-10027	)	_	_
101-5	10027-10028	,	_	_
101-6	10029-10032	put	_	_
101-7	10033-10036	the	_	_
101-8	10037-10041	file	_	_
101-9	10042-10044	in	_	_
101-10	10045-10046	.	_	_

#Text=/network.  ### Data pre-processing ### 1.
102-1	10046-10047	/	_	_
102-2	10047-10054	network	_	_
102-3	10054-10055	.	_	_
102-4	10057-10058	#	_	_
102-5	10058-10059	#	_	_
102-6	10059-10060	#	_	_
102-7	10061-10065	Data	_	_
102-8	10066-10080	pre-processing	_	_
102-9	10081-10082	#	_	_
102-10	10082-10083	#	_	_
102-11	10083-10084	#	_	_
102-12	10085-10086	1	_	_
102-13	10086-10087	.	_	_

#Text=To train our model with custom images，5 facial landmarks of each image are needed in advance for an image pre-alignment process.
103-1	10088-10090	To	_	_
103-2	10091-10096	train	_	_
103-3	10097-10100	our	_	_
103-4	10101-10106	model	_	_
103-5	10107-10111	with	_	_
103-6	10112-10118	custom	_	_
103-7	10119-10125	images	_	_
103-8	10125-10126	，	_	_
103-9	10126-10127	5	_	_
103-10	10128-10134	facial	_	_
103-11	10135-10144	landmarks	_	_
103-12	10145-10147	of	_	_
103-13	10148-10152	each	_	_
103-14	10153-10158	image	_	_
103-15	10159-10162	are	_	_
103-16	10163-10169	needed	_	_
103-17	10170-10172	in	_	_
103-18	10173-10180	advance	_	_
103-19	10181-10184	for	_	_
103-20	10185-10187	an	_	_
103-21	10188-10193	image	_	_
103-22	10194-10207	pre-alignment	_	_
103-23	10208-10215	process	_	_
103-24	10215-10216	.	_	_

#Text=We recommend using \[dlib\](http://dlib.net/) or \[MTCNN\](https://github.com/ipazc/mtcnn).
104-1	10217-10219	We	_	_
104-2	10220-10229	recommend	_	_
104-3	10230-10235	using	_	_
104-4	10236-10237	\[	_	_
104-5	10237-10241	dlib	*	SOFTWARE
104-6	10241-10242	\]	_	_
104-7	10242-10243	(	_	_
104-8	10243-10247	http	_	_
104-9	10247-10248	:	_	_
104-10	10248-10249	/	_	_
104-11	10249-10250	/	_	_
104-12	10250-10258	dlib.net	_	_
104-12	10250-10254	dlib	*	SOFTWARE
104-13	10258-10259	/	_	_
104-14	10259-10260	)	_	_
104-15	10261-10263	or	_	_
104-16	10264-10265	\[	_	_
104-17	10265-10270	MTCNN	*	SOFTWARE
104-18	10270-10271	\]	_	_
104-19	10271-10272	(	_	_
104-20	10272-10277	https	_	_
104-21	10277-10278	:	_	_
104-22	10278-10279	/	_	_
104-23	10279-10280	/	_	_
104-24	10280-10290	github.com	_	_
104-25	10290-10291	/	_	_
104-26	10291-10296	ipazc	_	_
104-27	10296-10297	/	_	_
104-28	10297-10302	mtcnn	*	SOFTWARE
104-29	10302-10303	)	_	_
104-30	10303-10304	.	_	_

#Text=Use these public face detectors to get 5 landmarks, and save all images and corresponding landmarks in <raw\_img\_path>.
105-1	10305-10308	Use	_	_
105-2	10309-10314	these	_	_
105-3	10315-10321	public	_	_
105-4	10322-10326	face	_	_
105-5	10327-10336	detectors	_	_
105-6	10337-10339	to	_	_
105-7	10340-10343	get	_	_
105-8	10344-10345	5	_	_
105-9	10346-10355	landmarks	_	_
105-10	10355-10356	,	_	_
105-11	10357-10360	and	_	_
105-12	10361-10365	save	_	_
105-13	10366-10369	all	_	_
105-14	10370-10376	images	_	_
105-15	10377-10380	and	_	_
105-16	10381-10394	corresponding	_	_
105-17	10395-10404	landmarks	_	_
105-18	10405-10407	in	_	_
105-19	10408-10409	<	_	_
105-20	10409-10421	raw\_img\_path	_	_
105-21	10421-10422	>	_	_
105-22	10422-10423	.	_	_

#Text=Note that an image and its detected landmark file should have same name. 2.
106-1	10424-10428	Note	_	_
106-2	10429-10433	that	_	_
106-3	10434-10436	an	_	_
106-4	10437-10442	image	_	_
106-5	10443-10446	and	_	_
106-6	10447-10450	its	_	_
106-7	10451-10459	detected	_	_
106-8	10460-10468	landmark	_	_
106-9	10469-10473	file	_	_
106-10	10474-10480	should	_	_
106-11	10481-10485	have	_	_
106-12	10486-10490	same	_	_
106-13	10491-10495	name	_	_
106-14	10495-10496	.	_	_
106-15	10497-10498	2	_	_
106-16	10498-10499	.	_	_

#Text=Align images and generate 68 landmarks as well as skin masks for training:   ``` # Run following command for data pre-processing.
107-1	10500-10505	Align	_	_
107-2	10506-10512	images	_	_
107-3	10513-10516	and	_	_
107-4	10517-10525	generate	_	_
107-5	10526-10528	68	_	_
107-6	10529-10538	landmarks	_	_
107-7	10539-10541	as	_	_
107-8	10542-10546	well	_	_
107-9	10547-10549	as	_	_
107-10	10550-10554	skin	_	_
107-11	10555-10560	masks	_	_
107-12	10561-10564	for	_	_
107-13	10565-10573	training	_	_
107-14	10573-10574	:	_	_
107-15	10577-10578	`	_	_
107-16	10578-10579	`	_	_
107-17	10579-10580	`	_	_
107-18	10581-10582	#	_	_
107-19	10583-10586	Run	_	_
107-20	10587-10596	following	_	_
107-21	10597-10604	command	_	_
107-22	10605-10608	for	_	_
107-23	10609-10613	data	_	_
107-24	10614-10628	pre-processing	_	_
107-25	10628-10629	.	_	_

#Text=By default, the code uses example images in .
108-1	10630-10632	By	_	_
108-2	10633-10640	default	_	_
108-3	10640-10641	,	_	_
108-4	10642-10645	the	_	_
108-5	10646-10650	code	_	_
108-6	10651-10655	uses	_	_
108-7	10656-10663	example	_	_
108-8	10664-10670	images	_	_
108-9	10671-10673	in	_	_
108-10	10674-10675	.	_	_

#Text=/input and saves the processed data in .
109-1	10675-10676	/	_	_
109-2	10676-10681	input	_	_
109-3	10682-10685	and	_	_
109-4	10686-10691	saves	_	_
109-5	10692-10695	the	_	_
109-6	10696-10705	processed	_	_
109-7	10706-10710	data	_	_
109-8	10711-10713	in	_	_
109-9	10714-10715	.	_	_

#Text=/processed\_data python preprocess\_img.py  # Alternatively, you can set your custom image path and save path python preprocess\_img.py --img\_path <raw\_img\_path> --save\_path <save\_path\_for\_processed\_data>  ```  ### Training networks ### 1.
110-1	10715-10716	/	_	_
110-2	10716-10730	processed\_data	_	_
110-3	10731-10737	python	_	_
110-4	10738-10755	preprocess\_img.py	_	_
110-5	10757-10758	#	_	_
110-6	10759-10772	Alternatively	_	_
110-7	10772-10773	,	_	_
110-8	10774-10777	you	_	_
110-9	10778-10781	can	_	_
110-10	10782-10785	set	_	_
110-11	10786-10790	your	_	_
110-12	10791-10797	custom	_	_
110-13	10798-10803	image	_	_
110-14	10804-10808	path	_	_
110-15	10809-10812	and	_	_
110-16	10813-10817	save	_	_
110-17	10818-10822	path	_	_
110-18	10823-10829	python	_	_
110-19	10830-10847	preprocess\_img.py	_	_
110-20	10848-10849	-	_	_
110-21	10849-10850	-	_	_
110-22	10850-10858	img\_path	_	_
110-23	10859-10860	<	_	_
110-24	10860-10872	raw\_img\_path	_	_
110-25	10872-10873	>	_	_
110-26	10874-10875	-	_	_
110-27	10875-10876	-	_	_
110-28	10876-10885	save\_path	_	_
110-29	10886-10887	<	_	_
110-30	10887-10915	save\_path\_for\_processed\_data	_	_
110-31	10915-10916	>	_	_
110-32	10918-10919	`	_	_
110-33	10919-10920	`	_	_
110-34	10920-10921	`	_	_
110-35	10923-10924	#	_	_
110-36	10924-10925	#	_	_
110-37	10925-10926	#	_	_
110-38	10927-10935	Training	_	_
110-39	10936-10944	networks	_	_
110-40	10945-10946	#	_	_
110-41	10946-10947	#	_	_
110-42	10947-10948	#	_	_
110-43	10949-10950	1	_	_
110-44	10950-10951	.	_	_

#Text=Train the reconstruction network with the following command: ``` # By default, the code uses the data in .
111-1	10952-10957	Train	_	_
111-2	10958-10961	the	_	_
111-3	10962-10976	reconstruction	_	_
111-4	10977-10984	network	_	_
111-5	10985-10989	with	_	_
111-6	10990-10993	the	_	_
111-7	10994-11003	following	_	_
111-8	11004-11011	command	_	_
111-9	11011-11012	:	_	_
111-10	11013-11014	`	_	_
111-11	11014-11015	`	_	_
111-12	11015-11016	`	_	_
111-13	11017-11018	#	_	_
111-14	11019-11021	By	_	_
111-15	11022-11029	default	_	_
111-16	11029-11030	,	_	_
111-17	11031-11034	the	_	_
111-18	11035-11039	code	_	_
111-19	11040-11044	uses	_	_
111-20	11045-11048	the	_	_
111-21	11049-11053	data	_	_
111-22	11054-11056	in	_	_
111-23	11057-11058	.	_	_

#Text=/processed\_data as training data as well as validation data python train.py  # Alternatively, you can set your custom data path python train.py --data\_path <custom\_data\_path> --val\_data\_path <custom\_val\_data\_path> --model\_name <custom\_model\_name>  ``` 2.
112-1	11058-11059	/	_	_
112-2	11059-11073	processed\_data	_	_
112-3	11074-11076	as	_	_
112-4	11077-11085	training	_	_
112-5	11086-11090	data	_	_
112-6	11091-11093	as	_	_
112-7	11094-11098	well	_	_
112-8	11099-11101	as	_	_
112-9	11102-11112	validation	_	_
112-10	11113-11117	data	_	_
112-11	11118-11124	python	_	_
112-12	11125-11133	train.py	_	_
112-13	11135-11136	#	_	_
112-14	11137-11150	Alternatively	_	_
112-15	11150-11151	,	_	_
112-16	11152-11155	you	_	_
112-17	11156-11159	can	_	_
112-18	11160-11163	set	_	_
112-19	11164-11168	your	_	_
112-20	11169-11175	custom	_	_
112-21	11176-11180	data	_	_
112-22	11181-11185	path	_	_
112-23	11186-11192	python	_	_
112-24	11193-11201	train.py	_	_
112-25	11202-11203	-	_	_
112-26	11203-11204	-	_	_
112-27	11204-11213	data\_path	_	_
112-28	11214-11215	<	_	_
112-29	11215-11231	custom\_data\_path	_	_
112-30	11231-11232	>	_	_
112-31	11233-11234	-	_	_
112-32	11234-11235	-	_	_
112-33	11235-11248	val\_data\_path	_	_
112-34	11249-11250	<	_	_
112-35	11250-11270	custom\_val\_data\_path	_	_
112-36	11270-11271	>	_	_
112-37	11272-11273	-	_	_
112-38	11273-11274	-	_	_
112-39	11274-11284	model\_name	_	_
112-40	11285-11286	<	_	_
112-41	11286-11303	custom\_model\_name	_	_
112-42	11303-11304	>	_	_
112-43	11306-11307	`	_	_
112-44	11307-11308	`	_	_
112-45	11308-11309	`	_	_
112-46	11310-11311	2	_	_
112-47	11311-11312	.	_	_

#Text=Monitoring the training process via tensorboard: ``` tensorboard --logdir=result/<custom\_model\_name> --port=10001 ``` 3.
113-1	11313-11323	Monitoring	_	_
113-2	11324-11327	the	_	_
113-3	11328-11336	training	_	_
113-4	11337-11344	process	_	_
113-5	11345-11348	via	_	_
113-6	11349-11360	tensorboard	*	SOFTWARE
113-7	11360-11361	:	_	_
113-8	11362-11363	`	_	_
113-9	11363-11364	`	_	_
113-10	11364-11365	`	_	_
113-11	11366-11377	tensorboard	*	SOFTWARE
113-12	11378-11379	-	_	_
113-13	11379-11380	-	_	_
113-14	11380-11386	logdir	_	_
113-15	11386-11387	=	_	_
113-16	11387-11393	result	_	_
113-17	11393-11394	/	_	_
113-18	11394-11395	<	_	_
113-19	11395-11412	custom\_model\_name	_	_
113-20	11412-11413	>	_	_
113-21	11414-11415	-	_	_
113-22	11415-11416	-	_	_
113-23	11416-11420	port	_	_
113-24	11420-11421	=	_	_
113-25	11421-11426	10001	_	_
113-26	11427-11428	`	_	_
113-27	11428-11429	`	_	_
113-28	11429-11430	`	_	_
113-29	11431-11432	3	_	_
113-30	11432-11433	.	_	_

#Text=Evaluating trained model: ``` python demo.py --use\_pb 0 --pretrain\_weights <custom\_weights>.ckpt ``` Training a model with a batchsize of 16 and 200K iterations takes 20 hours on a single Tesla M40 GPU.  ## Latest Update  ### 2020.4 ### The face reconstruction process is totally transferred to tensorflow version while the old version uses numpy.
114-1	11434-11444	Evaluating	_	_
114-2	11445-11452	trained	_	_
114-3	11453-11458	model	_	_
114-4	11458-11459	:	_	_
114-5	11460-11461	`	_	_
114-6	11461-11462	`	_	_
114-7	11462-11463	`	_	_
114-8	11464-11470	python	_	_
114-9	11471-11478	demo.py	_	_
114-10	11479-11480	-	_	_
114-11	11480-11481	-	_	_
114-12	11481-11487	use\_pb	_	_
114-13	11488-11489	0	_	_
114-14	11490-11491	-	_	_
114-15	11491-11492	-	_	_
114-16	11492-11508	pretrain\_weights	_	_
114-17	11509-11510	<	_	_
114-18	11510-11524	custom\_weights	_	_
114-19	11524-11525	>	_	_
114-20	11525-11526	.	_	_
114-21	11526-11530	ckpt	_	_
114-22	11531-11532	`	_	_
114-23	11532-11533	`	_	_
114-24	11533-11534	`	_	_
114-25	11535-11543	Training	_	_
114-26	11544-11545	a	_	_
114-27	11546-11551	model	_	_
114-28	11552-11556	with	_	_
114-29	11557-11558	a	_	_
114-30	11559-11568	batchsize	_	_
114-31	11569-11571	of	_	_
114-32	11572-11574	16	_	_
114-33	11575-11578	and	_	_
114-34	11579-11583	200K	_	_
114-35	11584-11594	iterations	_	_
114-36	11595-11600	takes	_	_
114-37	11601-11603	20	_	_
114-38	11604-11609	hours	_	_
114-39	11610-11612	on	_	_
114-40	11613-11614	a	_	_
114-41	11615-11621	single	_	_
114-42	11622-11627	Tesla	_	_
114-43	11628-11631	M40	_	_
114-44	11632-11635	GPU	_	_
114-45	11635-11636	.	_	_
114-46	11638-11639	#	_	_
114-47	11639-11640	#	_	_
114-48	11641-11647	Latest	_	_
114-49	11648-11654	Update	_	_
114-50	11656-11657	#	_	_
114-51	11657-11658	#	_	_
114-52	11658-11659	#	_	_
114-53	11660-11666	2020.4	_	_
114-54	11667-11668	#	_	_
114-55	11668-11669	#	_	_
114-56	11669-11670	#	_	_
114-57	11671-11674	The	_	_
114-58	11675-11679	face	_	_
114-59	11680-11694	reconstruction	_	_
114-60	11695-11702	process	_	_
114-61	11703-11705	is	_	_
114-62	11706-11713	totally	_	_
114-63	11714-11725	transferred	_	_
114-64	11726-11728	to	_	_
114-65	11729-11739	tensorflow	_	_
114-66	11740-11747	version	_	_
114-67	11748-11753	while	_	_
114-68	11754-11757	the	_	_
114-69	11758-11761	old	_	_
114-70	11762-11769	version	_	_
114-71	11770-11774	uses	_	_
114-72	11775-11780	numpy	_	_
114-73	11780-11781	.	_	_

#Text=We have also integrated the rendering process into the framework.
115-1	11782-11784	We	_	_
115-2	11785-11789	have	_	_
115-3	11790-11794	also	_	_
115-4	11795-11805	integrated	_	_
115-5	11806-11809	the	_	_
115-6	11810-11819	rendering	_	_
115-7	11820-11827	process	_	_
115-8	11828-11832	into	_	_
115-9	11833-11836	the	_	_
115-10	11837-11846	framework	_	_
115-11	11846-11847	.	_	_

#Text=As a result, reconstruction images aligned with the input can be easily obtained without extra efforts.
116-1	11848-11850	As	_	_
116-2	11851-11852	a	_	_
116-3	11853-11859	result	_	_
116-4	11859-11860	,	_	_
116-5	11861-11875	reconstruction	_	_
116-6	11876-11882	images	_	_
116-7	11883-11890	aligned	_	_
116-8	11891-11895	with	_	_
116-9	11896-11899	the	_	_
116-10	11900-11905	input	_	_
116-11	11906-11909	can	_	_
116-12	11910-11912	be	_	_
116-13	11913-11919	easily	_	_
116-14	11920-11928	obtained	_	_
116-15	11929-11936	without	_	_
116-16	11937-11942	extra	_	_
116-17	11943-11950	efforts	_	_
116-18	11950-11951	.	_	_

#Text=The whole process is tensorflow-based which allows gradient back-propagation for other tasks. ### 2020.6 ### Upload a \[pre-trained model\](https://drive.google.com/file/d/1fPsvLKghlCK8rknb9GPiKwIq9HIqWWwV/view?
117-1	11952-11955	The	_	_
117-2	11956-11961	whole	_	_
117-3	11962-11969	process	_	_
117-4	11970-11972	is	_	_
117-5	11973-11989	tensorflow-based	_	_
117-5	11973-11983	tensorflow	*	SOFTWARE
117-6	11990-11995	which	_	_
117-7	11996-12002	allows	_	_
117-8	12003-12011	gradient	_	_
117-9	12012-12028	back-propagation	_	_
117-10	12029-12032	for	_	_
117-11	12033-12038	other	_	_
117-12	12039-12044	tasks	_	_
117-13	12044-12045	.	_	_
117-14	12046-12047	#	_	_
117-15	12047-12048	#	_	_
117-16	12048-12049	#	_	_
117-17	12050-12056	2020.6	_	_
117-18	12057-12058	#	_	_
117-19	12058-12059	#	_	_
117-20	12059-12060	#	_	_
117-21	12061-12067	Upload	_	_
117-22	12068-12069	a	_	_
117-23	12070-12071	\[	_	_
117-24	12071-12082	pre-trained	_	_
117-25	12083-12088	model	_	_
117-26	12088-12089	\]	_	_
117-27	12089-12090	(	_	_
117-28	12090-12095	https	_	_
117-29	12095-12096	:	_	_
117-30	12096-12097	/	_	_
117-31	12097-12098	/	_	_
117-32	12098-12114	drive.google.com	_	_
117-33	12114-12115	/	_	_
117-34	12115-12119	file	_	_
117-35	12119-12120	/	_	_
117-36	12120-12121	d	_	_
117-37	12121-12122	/	_	_
117-38	12122-12155	1fPsvLKghlCK8rknb9GPiKwIq9HIqWWwV	_	_
117-39	12155-12156	/	_	_
117-40	12156-12160	view	_	_
117-41	12160-12161	?	_	_

#Text=usp=sharing) with white light assumption as described in the paper.  ### 2020.12 ### Upload the training code for single image face reconstruction.  ## Note  1.
118-1	12161-12164	usp	_	_
118-2	12164-12165	=	_	_
118-3	12165-12172	sharing	_	_
118-4	12172-12173	)	_	_
118-5	12174-12178	with	_	_
118-6	12179-12184	white	_	_
118-7	12185-12190	light	_	_
118-8	12191-12201	assumption	_	_
118-9	12202-12204	as	_	_
118-10	12205-12214	described	_	_
118-11	12215-12217	in	_	_
118-12	12218-12221	the	_	_
118-13	12222-12227	paper	_	_
118-14	12227-12228	.	_	_
118-15	12230-12231	#	_	_
118-16	12231-12232	#	_	_
118-17	12232-12233	#	_	_
118-18	12234-12241	2020.12	_	_
118-19	12242-12243	#	_	_
118-20	12243-12244	#	_	_
118-21	12244-12245	#	_	_
118-22	12246-12252	Upload	_	_
118-23	12253-12256	the	_	_
118-24	12257-12265	training	_	_
118-25	12266-12270	code	_	_
118-26	12271-12274	for	_	_
118-27	12275-12281	single	_	_
118-28	12282-12287	image	_	_
118-29	12288-12292	face	_	_
118-30	12293-12307	reconstruction	_	_
118-31	12307-12308	.	_	_
118-32	12310-12311	#	_	_
118-33	12311-12312	#	_	_
118-34	12313-12317	Note	_	_
118-35	12319-12320	1	_	_
118-36	12320-12321	.	_	_

#Text=An image pre-alignment with 5 facial landmarks is necessary before reconstruction.
119-1	12322-12324	An	_	_
119-2	12325-12330	image	_	_
119-3	12331-12344	pre-alignment	_	_
119-4	12345-12349	with	_	_
119-5	12350-12351	5	_	_
119-6	12352-12358	facial	_	_
119-7	12359-12368	landmarks	_	_
119-8	12369-12371	is	_	_
119-9	12372-12381	necessary	_	_
119-10	12382-12388	before	_	_
119-11	12389-12403	reconstruction	_	_
119-12	12403-12404	.	_	_

#Text=In our image pre-processing stage, we solve a least square problem between 5 facial landmarks on the image and 5 facial landmarks of the BFM09 average 3D face to cancel out face scales and misalignment.
120-1	12405-12407	In	_	_
120-2	12408-12411	our	_	_
120-3	12412-12417	image	_	_
120-4	12418-12432	pre-processing	_	_
120-5	12433-12438	stage	_	_
120-6	12438-12439	,	_	_
120-7	12440-12442	we	_	_
120-8	12443-12448	solve	_	_
120-9	12449-12450	a	_	_
120-10	12451-12456	least	_	_
120-11	12457-12463	square	_	_
120-12	12464-12471	problem	_	_
120-13	12472-12479	between	_	_
120-14	12480-12481	5	_	_
120-15	12482-12488	facial	_	_
120-16	12489-12498	landmarks	_	_
120-17	12499-12501	on	_	_
120-18	12502-12505	the	_	_
120-19	12506-12511	image	_	_
120-20	12512-12515	and	_	_
120-21	12516-12517	5	_	_
120-22	12518-12524	facial	_	_
120-23	12525-12534	landmarks	_	_
120-24	12535-12537	of	_	_
120-25	12538-12541	the	_	_
120-26	12542-12547	BFM09	_	_
120-27	12548-12555	average	_	_
120-28	12556-12558	3D	_	_
120-29	12559-12563	face	_	_
120-30	12564-12566	to	_	_
120-31	12567-12573	cancel	_	_
120-32	12574-12577	out	_	_
120-33	12578-12582	face	_	_
120-34	12583-12589	scales	_	_
120-35	12590-12593	and	_	_
120-36	12594-12606	misalignment	_	_
120-37	12606-12607	.	_	_

#Text=To get 5 facial landmarks, you can choose any open source face detector that returns them, such as \[dlib\](http://dlib.net/) or \[MTCNN\](https://github.com/ipazc/mtcnn).
121-1	12608-12610	To	_	_
121-2	12611-12614	get	_	_
121-3	12615-12616	5	_	_
121-4	12617-12623	facial	_	_
121-5	12624-12633	landmarks	_	_
121-6	12633-12634	,	_	_
121-7	12635-12638	you	_	_
121-8	12639-12642	can	_	_
121-9	12643-12649	choose	_	_
121-10	12650-12653	any	_	_
121-11	12654-12658	open	_	_
121-12	12659-12665	source	_	_
121-13	12666-12670	face	_	_
121-14	12671-12679	detector	_	_
121-15	12680-12684	that	_	_
121-16	12685-12692	returns	_	_
121-17	12693-12697	them	_	_
121-18	12697-12698	,	_	_
121-19	12699-12703	such	_	_
121-20	12704-12706	as	_	_
121-21	12707-12708	\[	_	_
121-22	12708-12712	dlib	*	SOFTWARE
121-23	12712-12713	\]	_	_
121-24	12713-12714	(	_	_
121-25	12714-12718	http	_	_
121-26	12718-12719	:	_	_
121-27	12719-12720	/	_	_
121-28	12720-12721	/	_	_
121-29	12721-12729	dlib.net	_	_
121-29	12721-12725	dlib	*	SOFTWARE
121-30	12729-12730	/	_	_
121-31	12730-12731	)	_	_
121-32	12732-12734	or	_	_
121-33	12735-12736	\[	_	_
121-34	12736-12741	MTCNN	*	SOFTWARE
121-35	12741-12742	\]	_	_
121-36	12742-12743	(	_	_
121-37	12743-12748	https	_	_
121-38	12748-12749	:	_	_
121-39	12749-12750	/	_	_
121-40	12750-12751	/	_	_
121-41	12751-12761	github.com	_	_
121-42	12761-12762	/	_	_
121-43	12762-12767	ipazc	_	_
121-44	12767-12768	/	_	_
121-45	12768-12773	mtcnn	*	SOFTWARE
121-46	12773-12774	)	_	_
121-47	12774-12775	.	_	_

#Text=However, these traditional 2D detectors may return wrong landmarks under large poses which could influence the alignment result.
122-1	12776-12783	However	_	_
122-2	12783-12784	,	_	_
122-3	12785-12790	these	_	_
122-4	12791-12802	traditional	_	_
122-5	12803-12805	2D	_	_
122-6	12806-12815	detectors	_	_
122-7	12816-12819	may	_	_
122-8	12820-12826	return	_	_
122-9	12827-12832	wrong	_	_
122-10	12833-12842	landmarks	_	_
122-11	12843-12848	under	_	_
122-12	12849-12854	large	_	_
122-13	12855-12860	poses	_	_
122-14	12861-12866	which	_	_
122-15	12867-12872	could	_	_
122-16	12873-12882	influence	_	_
122-17	12883-12886	the	_	_
122-18	12887-12896	alignment	_	_
122-19	12897-12903	result	_	_
122-20	12903-12904	.	_	_

#Text=Therefore, we recommend using \[the method of Bulat et al.\]
123-1	12905-12914	Therefore	_	_
123-2	12914-12915	,	_	_
123-3	12916-12918	we	_	_
123-4	12919-12928	recommend	_	_
123-5	12929-12934	using	_	_
123-6	12935-12936	\[	_	_
123-7	12936-12939	the	_	_
123-8	12940-12946	method	_	_
123-9	12947-12949	of	_	_
123-10	12950-12955	Bulat	_	_
123-11	12956-12958	et	_	_
123-12	12959-12961	al	_	_
123-13	12961-12962	.	_	_
123-14	12962-12963	\]	_	_

#Text=(https://github.com/1adrianb/2D-and-3D-face-alignment) to get facial landmarks (3D definition) with semantic consistency for large pose images.
124-1	12963-12964	(	_	_
124-2	12964-12969	https	_	_
124-3	12969-12970	:	_	_
124-4	12970-12971	/	_	_
124-5	12971-12972	/	_	_
124-6	12972-12982	github.com	_	_
124-7	12982-12983	/	_	_
124-8	12983-12991	1adrianb	_	_
124-9	12991-12992	/	_	_
124-10	12992-12998	2D-and	_	_
124-11	12998-12999	-	_	_
124-12	12999-13016	3D-face-alignment	_	_
124-13	13016-13017	)	_	_
124-14	13018-13020	to	_	_
124-15	13021-13024	get	_	_
124-16	13025-13031	facial	_	_
124-17	13032-13041	landmarks	_	_
124-18	13042-13043	(	_	_
124-19	13043-13045	3D	_	_
124-20	13046-13056	definition	_	_
124-21	13056-13057	)	_	_
124-22	13058-13062	with	_	_
124-23	13063-13071	semantic	_	_
124-24	13072-13083	consistency	_	_
124-25	13084-13087	for	_	_
124-26	13088-13093	large	_	_
124-27	13094-13098	pose	_	_
124-28	13099-13105	images	_	_
124-29	13105-13106	.	_	_

#Text=Note that our model is trained without position augmentation so that a bad alignment may lead to inaccurate reconstruction results.
125-1	13107-13111	Note	_	_
125-2	13112-13116	that	_	_
125-3	13117-13120	our	_	_
125-4	13121-13126	model	_	_
125-5	13127-13129	is	_	_
125-6	13130-13137	trained	_	_
125-7	13138-13145	without	_	_
125-8	13146-13154	position	_	_
125-9	13155-13167	augmentation	_	_
125-10	13168-13170	so	_	_
125-11	13171-13175	that	_	_
125-12	13176-13177	a	_	_
125-13	13178-13181	bad	_	_
125-14	13182-13191	alignment	_	_
125-15	13192-13195	may	_	_
125-16	13196-13200	lead	_	_
125-17	13201-13203	to	_	_
125-18	13204-13214	inaccurate	_	_
125-19	13215-13229	reconstruction	_	_
125-20	13230-13237	results	_	_
125-21	13237-13238	.	_	_

#Text=We put some examples in the .
126-1	13239-13241	We	_	_
126-2	13242-13245	put	_	_
126-3	13246-13250	some	_	_
126-4	13251-13259	examples	_	_
126-5	13260-13262	in	_	_
126-6	13263-13266	the	_	_
126-7	13267-13268	.	_	_

#Text=/input subfolder for reference.   2.
127-1	13268-13269	/	_	_
127-2	13269-13274	input	_	_
127-3	13275-13284	subfolder	_	_
127-4	13285-13288	for	_	_
127-5	13289-13298	reference	_	_
127-6	13298-13299	.	_	_
127-7	13302-13303	2	_	_
127-8	13303-13304	.	_	_

#Text=We assume a \[pinhole camera model\](https://en.wikipedia.org/wiki/Pinhole\_camera\_model) for face projection.
128-1	13305-13307	We	_	_
128-2	13308-13314	assume	_	_
128-3	13315-13316	a	_	_
128-4	13317-13318	\[	_	_
128-5	13318-13325	pinhole	_	_
128-6	13326-13332	camera	_	_
128-7	13333-13338	model	_	_
128-8	13338-13339	\]	_	_
128-9	13339-13340	(	_	_
128-10	13340-13345	https	_	_
128-11	13345-13346	:	_	_
128-12	13346-13347	/	_	_
128-13	13347-13348	/	_	_
128-14	13348-13364	en.wikipedia.org	_	_
128-15	13364-13365	/	_	_
128-16	13365-13369	wiki	_	_
128-17	13369-13370	/	_	_
128-18	13370-13390	Pinhole\_camera\_model	_	_
128-19	13390-13391	)	_	_
128-20	13392-13395	for	_	_
128-21	13396-13400	face	_	_
128-22	13401-13411	projection	_	_
128-23	13411-13412	.	_	_

#Text=The camera is positioned at (0,0,10) (dm) in the world coordinate and points to the negative z axis.
129-1	13413-13416	The	_	_
129-2	13417-13423	camera	_	_
129-3	13424-13426	is	_	_
129-4	13427-13437	positioned	_	_
129-5	13438-13440	at	_	_
129-6	13441-13442	(	_	_
129-7	13442-13448	0,0,10	_	_
129-8	13448-13449	)	_	_
129-9	13450-13451	(	_	_
129-10	13451-13453	dm	_	_
129-11	13453-13454	)	_	_
129-12	13455-13457	in	_	_
129-13	13458-13461	the	_	_
129-14	13462-13467	world	_	_
129-15	13468-13478	coordinate	_	_
129-16	13479-13482	and	_	_
129-17	13483-13489	points	_	_
129-18	13490-13492	to	_	_
129-19	13493-13496	the	_	_
129-20	13497-13505	negative	_	_
129-21	13506-13507	z	_	_
129-22	13508-13512	axis	_	_
129-23	13512-13513	.	_	_

#Text=We set the camera fov to 12.6 empirically and fix it during training and inference time.
130-1	13514-13516	We	_	_
130-2	13517-13520	set	_	_
130-3	13521-13524	the	_	_
130-4	13525-13531	camera	_	_
130-5	13532-13535	fov	_	_
130-6	13536-13538	to	_	_
130-7	13539-13543	12.6	_	_
130-8	13544-13555	empirically	_	_
130-9	13556-13559	and	_	_
130-10	13560-13563	fix	_	_
130-11	13564-13566	it	_	_
130-12	13567-13573	during	_	_
130-13	13574-13582	training	_	_
130-14	13583-13586	and	_	_
130-15	13587-13596	inference	_	_
130-16	13597-13601	time	_	_
130-17	13601-13602	.	_	_

#Text=Faces in canonical views are at the origin of the world coordinate and facing the positive z axis.
131-1	13603-13608	Faces	_	_
131-2	13609-13611	in	_	_
131-3	13612-13621	canonical	_	_
131-4	13622-13627	views	_	_
131-5	13628-13631	are	_	_
131-6	13632-13634	at	_	_
131-7	13635-13638	the	_	_
131-8	13639-13645	origin	_	_
131-9	13646-13648	of	_	_
131-10	13649-13652	the	_	_
131-11	13653-13658	world	_	_
131-12	13659-13669	coordinate	_	_
131-13	13670-13673	and	_	_
131-14	13674-13680	facing	_	_
131-15	13681-13684	the	_	_
131-16	13685-13693	positive	_	_
131-17	13694-13695	z	_	_
131-18	13696-13700	axis	_	_
131-19	13700-13701	.	_	_

#Text=Rotations and translations predicted by the R-Net are all with respect to the world coordinate.
132-1	13702-13711	Rotations	_	_
132-2	13712-13715	and	_	_
132-3	13716-13728	translations	_	_
132-4	13729-13738	predicted	_	_
132-5	13739-13741	by	_	_
132-6	13742-13745	the	_	_
132-7	13746-13751	R-Net	_	_
132-8	13752-13755	are	_	_
132-9	13756-13759	all	_	_
132-10	13760-13764	with	_	_
132-11	13765-13772	respect	_	_
132-12	13773-13775	to	_	_
132-13	13776-13779	the	_	_
132-14	13780-13785	world	_	_
132-15	13786-13796	coordinate	_	_
132-16	13796-13797	.	_	_

#Text=<p align="center">  <img src="/images/camera.png" width="300"> </p>  3.
133-1	13798-13799	<	_	_
133-2	13799-13800	p	_	_
133-3	13801-13806	align	_	_
133-4	13806-13807	=	_	_
133-5	13807-13808	"	_	_
133-6	13808-13814	center	_	_
133-7	13814-13815	"	_	_
133-8	13815-13816	>	_	_
133-9	13818-13819	<	_	_
133-10	13819-13822	img	_	_
133-11	13823-13826	src	_	_
133-12	13826-13827	=	_	_
133-13	13827-13828	"	_	_
133-14	13828-13829	/	_	_
133-15	13829-13835	images	_	_
133-16	13835-13836	/	_	_
133-17	13836-13846	camera.png	_	_
133-18	13846-13847	"	_	_
133-19	13848-13853	width	_	_
133-20	13853-13854	=	_	_
133-21	13854-13855	"	_	_
133-22	13855-13858	300	_	_
133-23	13858-13859	"	_	_
133-24	13859-13860	>	_	_
133-25	13861-13862	<	_	_
133-26	13862-13863	/	_	_
133-27	13863-13864	p	_	_
133-28	13864-13865	>	_	_
133-29	13867-13868	3	_	_
133-30	13868-13869	.	_	_

#Text=The current model is trained using 3-channel (r,g,b) scene illumination instead of white light described in the paper.
134-1	13870-13873	The	_	_
134-2	13874-13881	current	_	_
134-3	13882-13887	model	_	_
134-4	13888-13890	is	_	_
134-5	13891-13898	trained	_	_
134-6	13899-13904	using	_	_
134-7	13905-13906	3	_	_
134-8	13906-13907	-	_	_
134-9	13907-13914	channel	_	_
134-10	13915-13916	(	_	_
134-11	13916-13917	r	_	_
134-12	13917-13918	,	_	_
134-13	13918-13919	g	_	_
134-14	13919-13920	,	_	_
134-15	13920-13921	b	_	_
134-16	13921-13922	)	_	_
134-17	13923-13928	scene	_	_
134-18	13929-13941	illumination	_	_
134-19	13942-13949	instead	_	_
134-20	13950-13952	of	_	_
134-21	13953-13958	white	_	_
134-22	13959-13964	light	_	_
134-23	13965-13974	described	_	_
134-24	13975-13977	in	_	_
134-25	13978-13981	the	_	_
134-26	13982-13987	paper	_	_
134-27	13987-13988	.	_	_

#Text=As a result, the gamma coefficient that controls lighting has a dimension of 27 instead of 9.   4.
135-1	13989-13991	As	_	_
135-2	13992-13993	a	_	_
135-3	13994-14000	result	_	_
135-4	14000-14001	,	_	_
135-5	14002-14005	the	_	_
135-6	14006-14011	gamma	_	_
135-7	14012-14023	coefficient	_	_
135-8	14024-14028	that	_	_
135-9	14029-14037	controls	_	_
135-10	14038-14046	lighting	_	_
135-11	14047-14050	has	_	_
135-12	14051-14052	a	_	_
135-13	14053-14062	dimension	_	_
135-14	14063-14065	of	_	_
135-15	14066-14068	27	_	_
135-16	14069-14076	instead	_	_
135-17	14077-14079	of	_	_
135-18	14080-14081	9	_	_
135-19	14081-14082	.	_	_
135-20	14085-14086	4	_	_
135-21	14086-14087	.	_	_

#Text=We excluded ear and neck region of original BFM09 to allow the network concentrate on the face region.
136-1	14088-14090	We	_	_
136-2	14091-14099	excluded	_	_
136-3	14100-14103	ear	_	_
136-4	14104-14107	and	_	_
136-5	14108-14112	neck	_	_
136-6	14113-14119	region	_	_
136-7	14120-14122	of	_	_
136-8	14123-14131	original	_	_
136-9	14132-14137	BFM09	_	_
136-10	14138-14140	to	_	_
136-11	14141-14146	allow	_	_
136-12	14147-14150	the	_	_
136-13	14151-14158	network	_	_
136-14	14159-14170	concentrate	_	_
136-15	14171-14173	on	_	_
136-16	14174-14177	the	_	_
136-17	14178-14182	face	_	_
136-18	14183-14189	region	_	_
136-19	14189-14190	.	_	_

#Text=To see which vertices in the original model are preserved, check select\_vertex\_id.mat in the .
137-1	14191-14193	To	_	_
137-2	14194-14197	see	_	_
137-3	14198-14203	which	_	_
137-4	14204-14212	vertices	_	_
137-5	14213-14215	in	_	_
137-6	14216-14219	the	_	_
137-7	14220-14228	original	_	_
137-8	14229-14234	model	_	_
137-9	14235-14238	are	_	_
137-10	14239-14248	preserved	_	_
137-11	14248-14249	,	_	_
137-12	14250-14255	check	_	_
137-13	14256-14276	select\_vertex\_id.mat	_	_
137-14	14277-14279	in	_	_
137-15	14280-14283	the	_	_
137-16	14284-14285	.	_	_

#Text=/BFM subfolder.
138-1	14285-14286	/	_	_
138-2	14286-14289	BFM	_	_
138-3	14290-14299	subfolder	_	_
138-4	14299-14300	.	_	_

#Text=Note that index starts from 1.  5.
139-1	14301-14305	Note	_	_
139-2	14306-14310	that	_	_
139-3	14311-14316	index	_	_
139-4	14317-14323	starts	_	_
139-5	14324-14328	from	_	_
139-6	14329-14330	1	_	_
139-7	14330-14331	.	_	_
139-8	14333-14334	5	_	_
139-9	14334-14335	.	_	_

#Text=Our model may give inferior results for images with severe perspetive distortions (e.g., some selfies).
140-1	14336-14339	Our	_	_
140-2	14340-14345	model	_	_
140-3	14346-14349	may	_	_
140-4	14350-14354	give	_	_
140-5	14355-14363	inferior	_	_
140-6	14364-14371	results	_	_
140-7	14372-14375	for	_	_
140-8	14376-14382	images	_	_
140-9	14383-14387	with	_	_
140-10	14388-14394	severe	_	_
140-11	14395-14405	perspetive	_	_
140-12	14406-14417	distortions	_	_
140-13	14418-14419	(	_	_
140-14	14419-14422	e.g	_	_
140-15	14422-14423	.	_	_
140-16	14423-14424	,	_	_
140-17	14425-14429	some	_	_
140-18	14430-14437	selfies	_	_
140-19	14437-14438	)	_	_
140-20	14438-14439	.	_	_

#Text=In addition, we cannot well handle faces with eyes closed due to the lack of these kind of images in the training data.    5.
141-1	14440-14442	In	_	_
141-2	14443-14451	addition	_	_
141-3	14451-14452	,	_	_
141-4	14453-14455	we	_	_
141-5	14456-14462	cannot	_	_
141-6	14463-14467	well	_	_
141-7	14468-14474	handle	_	_
141-8	14475-14480	faces	_	_
141-9	14481-14485	with	_	_
141-10	14486-14490	eyes	_	_
141-11	14491-14497	closed	_	_
141-12	14498-14501	due	_	_
141-13	14502-14504	to	_	_
141-14	14505-14508	the	_	_
141-15	14509-14513	lack	_	_
141-16	14514-14516	of	_	_
141-17	14517-14522	these	_	_
141-18	14523-14527	kind	_	_
141-19	14528-14530	of	_	_
141-20	14531-14537	images	_	_
141-21	14538-14540	in	_	_
141-22	14541-14544	the	_	_
141-23	14545-14553	training	_	_
141-24	14554-14558	data	_	_
141-25	14558-14559	.	_	_
141-26	14563-14564	5	_	_
141-27	14564-14565	.	_	_

#Text=If you have any further questions, please contact Yu Deng (dengyu2008@hotmail.com) and Jiaolong Yang (jiaoyan@microsoft.com).   ## Citation  Please cite the following paper if this model helps your research:   @inproceedings{deng2019accurate,      title={Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set},      author={Yu Deng and Jiaolong Yang and Sicheng Xu and Dong Chen and Yunde Jia and Xin Tong},      booktitle={IEEE Computer Vision and Pattern Recognition Workshops},      year={2019}  } ## The face images on this page are from the public \[CelebA\](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset released by MMLab, CUHK.
142-1	14566-14568	If	_	_
142-2	14569-14572	you	_	_
142-3	14573-14577	have	_	_
142-4	14578-14581	any	_	_
142-5	14582-14589	further	_	_
142-6	14590-14599	questions	_	_
142-7	14599-14600	,	_	_
142-8	14601-14607	please	_	_
142-9	14608-14615	contact	_	_
142-10	14616-14618	Yu	_	_
142-11	14619-14623	Deng	_	_
142-12	14624-14625	(	_	_
142-13	14625-14635	dengyu2008	_	_
142-14	14635-14636	@	_	_
142-15	14636-14647	hotmail.com	_	_
142-16	14647-14648	)	_	_
142-17	14649-14652	and	_	_
142-18	14653-14661	Jiaolong	_	_
142-19	14662-14666	Yang	_	_
142-20	14667-14668	(	_	_
142-21	14668-14675	jiaoyan	_	_
142-22	14675-14676	@	_	_
142-23	14676-14689	microsoft.com	_	_
142-24	14689-14690	)	_	_
142-25	14690-14691	.	_	_
142-26	14694-14695	#	_	_
142-27	14695-14696	#	_	_
142-28	14697-14705	Citation	_	_
142-29	14707-14713	Please	_	_
142-30	14714-14718	cite	_	_
142-31	14719-14722	the	_	_
142-32	14723-14732	following	_	_
142-33	14733-14738	paper	_	_
142-34	14739-14741	if	_	_
142-35	14742-14746	this	_	_
142-36	14747-14752	model	_	_
142-37	14753-14758	helps	_	_
142-38	14759-14763	your	_	_
142-39	14764-14772	research	_	_
142-40	14772-14773	:	_	_
142-41	14776-14777	@	_	_
142-42	14777-14790	inproceedings	_	_
142-43	14790-14791	{	_	_
142-44	14791-14807	deng2019accurate	_	_
142-45	14807-14808	,	_	_
142-46	14814-14819	title	_	_
142-47	14819-14820	=	_	_
142-48	14820-14821	{	_	_
142-49	14821-14829	Accurate	*[18]	PUBLICATION[18]
142-50	14830-14832	3D	*[18]	PUBLICATION[18]
142-51	14833-14837	Face	*[18]	PUBLICATION[18]
142-52	14838-14852	Reconstruction	*[18]	PUBLICATION[18]
142-53	14853-14857	with	*[18]	PUBLICATION[18]
142-54	14858-14875	Weakly-Supervised	*[18]	PUBLICATION[18]
142-55	14876-14884	Learning	*[18]	PUBLICATION[18]
142-56	14884-14885	:	*[18]	PUBLICATION[18]
142-57	14886-14890	From	*[18]	PUBLICATION[18]
142-58	14891-14897	Single	*[18]	PUBLICATION[18]
142-59	14898-14903	Image	*[18]	PUBLICATION[18]
142-60	14904-14906	to	*[18]	PUBLICATION[18]
142-61	14907-14912	Image	*[18]	PUBLICATION[18]
142-62	14913-14916	Set	*[18]	PUBLICATION[18]
142-63	14916-14917	}	_	_
142-64	14917-14918	,	_	_
142-65	14924-14930	author	_	_
142-66	14930-14931	=	_	_
142-67	14931-14932	{	_	_
142-68	14932-14934	Yu	_	_
142-69	14935-14939	Deng	_	_
142-70	14940-14943	and	_	_
142-71	14944-14952	Jiaolong	_	_
142-72	14953-14957	Yang	_	_
142-73	14958-14961	and	_	_
142-74	14962-14969	Sicheng	_	_
142-75	14970-14972	Xu	_	_
142-76	14973-14976	and	_	_
142-77	14977-14981	Dong	_	_
142-78	14982-14986	Chen	_	_
142-79	14987-14990	and	_	_
142-80	14991-14996	Yunde	_	_
142-81	14997-15000	Jia	_	_
142-82	15001-15004	and	_	_
142-83	15005-15008	Xin	_	_
142-84	15009-15013	Tong	_	_
142-85	15013-15014	}	_	_
142-86	15014-15015	,	_	_
142-87	15021-15030	booktitle	_	_
142-88	15030-15031	=	_	_
142-89	15031-15032	{	_	_
142-90	15032-15036	IEEE	*[19]	PUBLICATION[19]
142-91	15037-15045	Computer	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-92	15046-15052	Vision	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-93	15053-15056	and	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-94	15057-15064	Pattern	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-95	15065-15076	Recognition	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-96	15077-15086	Workshops	*[19]|*[20]	PUBLICATION[19]|WORKSHOP[20]
142-97	15086-15087	}	_	_
142-98	15087-15088	,	_	_
142-99	15094-15098	year	_	_
142-100	15098-15099	=	_	_
142-101	15099-15100	{	_	_
142-102	15100-15104	2019	_	_
142-103	15104-15105	}	_	_
142-104	15107-15108	}	_	_
142-105	15109-15110	#	_	_
142-106	15110-15111	#	_	_
142-107	15112-15115	The	_	_
142-108	15116-15120	face	_	_
142-109	15121-15127	images	_	_
142-110	15128-15130	on	_	_
142-111	15131-15135	this	_	_
142-112	15136-15140	page	_	_
142-113	15141-15144	are	_	_
142-114	15145-15149	from	_	_
142-115	15150-15153	the	_	_
142-116	15154-15160	public	_	_
142-117	15161-15162	\[	_	_
142-118	15162-15168	CelebA	*	DATASET
142-119	15168-15169	\]	_	_
142-120	15169-15170	(	_	_
142-121	15170-15174	http	_	_
142-122	15174-15175	:	_	_
142-123	15175-15176	/	_	_
142-124	15176-15177	/	_	_
142-125	15177-15197	mmlab.ie.cuhk.edu.hk	_	_
142-126	15197-15198	/	_	_
142-127	15198-15206	projects	_	_
142-128	15206-15207	/	_	_
142-129	15207-15218	CelebA.html	_	_
142-129	15207-15213	CelebA	*	DATASET
142-130	15218-15219	)	_	_
142-131	15220-15227	dataset	_	_
142-132	15228-15236	released	_	_
142-133	15237-15239	by	_	_
142-134	15240-15245	MMLab	_	_
142-135	15245-15246	,	_	_
142-136	15247-15251	CUHK	_	_
142-137	15251-15252	.	_	_