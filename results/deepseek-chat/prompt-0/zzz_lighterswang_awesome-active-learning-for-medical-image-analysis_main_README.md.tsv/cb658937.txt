```markdown
<PUBLICATION>Video Moment Retrieval via Hierarchical Uncertainty-Based Active Learning</PUBLICATION>   üïù  **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Ji_Are_Binary_Annotations_Sufficient_Video_Moment_Retrieval_via_Hierarchical_Uncertainty-Based_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/renjie-liang/<SOFTWARE>HUAL</SOFTWARE>)**  <PUBLICATION>MHPL: Minimum Happy Points Learning for Active Source Free Domain Adaptation</PUBLICATION>   üïù  **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Wang_MHPL_Minimum_Happy_Points_Learning_for_Active_Source_Free_Domain_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)**  <PUBLICATION>Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm</PUBLICATION>   **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Xie_Active_Finetuning_Exploiting_Annotation_Budget_in_the_Pretraining-Finetuning_Paradigm_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/yichen928/<SOFTWARE>ActiveFT</SOFTWARE>)**  <PUBLICATION>Bi3D: Bi-Domain Active Learning for Cross-Domain 3D Object Detection</PUBLICATION>   **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Yuan_Bi3D_Bi-Domain_Active_Learning_for_Cross-Domain_3D_Object_Detection_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/JiakangYuan/<SOFTWARE>Bi3D</SOFTWARE>)**  <PUBLICATION>Divide and Adapt: Active Domain Adaptation via Customized Learning</PUBLICATION>   **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Huang_Divide_and_Adapt_Active_Domain_Adaptation_via_Customized_Learning_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/Duojun-Huang/<SOFTWARE>DiaNA-CVPR2023</SOFTWARE>)**  <PUBLICATION>Box-Level Active Detection</PUBLICATION>   **[<CONFERENCE>CVPR'23</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2023</CONFERENCE>/papers/Lyu_Box-Level_Active_Detection_<CONFERENCE>CVPR_2023</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/lyumengyao/<SOFTWARE>blad</SOFTWARE>)**  <PUBLICATION>Entropy-Based Active Learning for Object Detection With Progressive Diversity Constraint</PUBLICATION>   **[<CONFERENCE>CVPR'22</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2022</CONFERENCE>/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_<CONFERENCE>CVPR_2022</CONFERENCE>_paper.pdf)**  <PUBLICATION>Active Learning for Open-Set Annotation</PUBLICATION>   **[<CONFERENCE>CVPR'22</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2022</CONFERENCE>/papers/Ning_Active_Learning_for_Open-Set_Annotation_<CONFERENCE>CVPR_2022</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/PrateekMunjal/<SOFTWARE>TorchAL</SOFTWARE>)**  <PUBLICATION>Meta Agent Teaming Active Learning for Pose Estimation</PUBLICATION>   **[<CONFERENCE>CVPR'22</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2022</CONFERENCE>/papers/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_<CONFERENCE>CVPR_2022</CONFERENCE>_paper.pdf)**  <PUBLICATION>Towards Robust and Reproducible Active Learning Using Neural Networks</PUBLICATION>   **[<CONFERENCE>CVPR'22</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2022</CONFERENCE>/papers/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_<CONFERENCE>CVPR_2022</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/PrateekMunjal/<SOFTWARE>TorchAL</SOFTWARE>)**  <PUBLICATION>Active Learning by Feature Mixing</PUBLICATION>   **[<CONFERENCE>CVPR'22</CONFERENCE>]** **[[PDF]](https://openaccess.thecvf.com/content/<CONFERENCE>CVPR2022</CONFERENCE>/papers/Parvaneh_Active_Learning_by_Feature_Mixing_<CONFERENCE>CVPR_2022</CONFERENCE>_paper.pdf)** **[[Code]](https://github.com/AminParvaneh/<SOFTWARE>alpha_mix_active_learning</SOFTWARE>)**  <PUBLICATION>Which Images To Label for Few-Shot Medical Landmark Detection?</PUBLICATION>
```