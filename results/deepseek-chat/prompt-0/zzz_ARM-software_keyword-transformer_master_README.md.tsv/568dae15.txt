```markdown
There are three variants of the Keyword-Transformer model:  * **Time-domain attention**: each time-window is treated as a patch, self-attention is computed between time-windows * **Frequency-domain attention**: each frequency is treated as a patch self-attention is computed between frequencies * **Combination of both**: The signal is fed into both a time- and a frequency-domain transformer and the outputs are combined * **Patch-wise attention**: Similar to the vision transformer, it extracts rectangular patches from the spectrogram, so attention happens both in the time and frequency domain simultaneously.  ## Training a model from scratch To train <SOFTWARE>KWT-3</SOFTWARE> from scratch on <DATASET>Speech Commands V2</DATASET>, run    ```shell sh train.sh ```  Please note that the train directory (given by the argument  `--train_dir`) cannot exist prior to start script.
```