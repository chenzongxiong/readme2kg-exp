```markdown
Therefore, this survey comprises approaches that extract **partial knowledge** contained in the hidden layers and do not demand their approximation target is the input-output relationship  - ***<SOFTWARE>Extended C-Net algorithm</SOFTWARE>***   - **"<PUBLICATION>Towards Interpretable ANNs: An Exact Transformation to Multi-Class Multivariate Decision Trees</PUBLICATION>"**, <PUBLICATION>arXiv</PUBLICATION>, 2020     - Duy T Nguyen, Kathryn E Kasmarik, Hussein A Abbass *(a typical eclectic technique)*     - [[Paper]](http://arxiv-export-lb.library.cornell.edu/abs/2003.04675)  - ***Generalized eclectic techniques***   - **"<PUBLICATION>Global Model Interpretation Via Recursive Partitioning</PUBLICATION>"**, <CONFERENCE>HPCC/SmartCity/DSS</CONFERENCE>, 2018     - Chengliang Yang, Anand Rangarajan, Sanjay Ranka *(CART tree learned from the contribution matrix and applied to scene understanding tasks)*     - [[Paper]](https://ieeexplore.ieee.org/abstract/document/8622994) [[Code]](https://github.com/west-gates/<PROJECT>GIRP</PROJECT>)   - **"<PUBLICATION>Interpreting CNNs via Decision Trees</PUBLICATION>"**, <CONFERENCE>CVPR</CONFERENCE>, 2019     - Quanshi Zhang *et al.* *(encodes all potential decision modes of the CNN in a coarse-to-fine manner)*     - [[Paper]](https://openaccess.thecvf.com/content_<CONFERENCE>CVPR</CONFERENCE>_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_<CONFERENCE>CVPR</CONFERENCE>_2019_paper.html)  ##### *1.2.4 Optional: DTs for Regularizing NNs.* These approaches train NNs that resemble compact DTs through crafted regularization terms, so that they can be well-approximated by small DTs
```