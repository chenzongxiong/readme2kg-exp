```python import <PROGLANG>jury</PROGLANG>  bleu = <PROGLANG>jury</PROGLANG>.load_metric("<EVALMETRIC>bleu</EVALMETRIC>") bleu_1 = <PROGLANG>jury</PROGLANG>.load_metric("<EVALMETRIC>bleu</EVALMETRIC>", resulting_name="bleu_1", compute_kwargs={"max_order": 1}) # metrics not available in `<PROGLANG>jury</PROGLANG>` but in `<PROGLANG>evaluate</PROGLANG>` wer = <PROGLANG>jury</PROGLANG>.load_metric("<EVALMETRIC>competition_math</EVALMETRIC>") # It falls back to `<PROGLANG>evaluate</PROGLANG>` package with a warning ```  ### CLI Usage  You can specify predictions file and references file paths and get the resulting scores.
```