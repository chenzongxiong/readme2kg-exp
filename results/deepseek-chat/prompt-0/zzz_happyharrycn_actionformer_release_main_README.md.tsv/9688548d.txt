```markdown
Stay tuned.  ## Contact Yin Li (yin.li@wisc.edu)  ## References If you are using our code, please consider citing our paper. ``` @inproceedings{zhang2022actionformer,   title={<PUBLICATION>ActionFormer: Localizing Moments of Actions with Transformers</PUBLICATION>},   author={Zhang, Chen-Lin and Wu, Jianxin and Li, Yin},   booktitle={<CONFERENCE>European Conference on Computer Vision</CONFERENCE>},   series={LNCS},   volume={13664},   pages={492-510},   year={2022} } ```  If you cite our results on Ego4D, please consider citing our tech report in addition to the main paper. ``` @article{mu2022actionformerego4d,   title={<PUBLICATION>Where a Strong Backbone Meets Strong Features -- ActionFormer for Ego4D Moment Queries Challenge</PUBLICATION>},   author={Mu, Fangzhou and Mo, Sicheng and Wang, Gillian, and Li, Yin},   journal={arXiv e-prints},   year={2022} } ```  If you are using TSP features, please cite ``` @inproceedings{alwassel2021tsp,   title={<PUBLICATION>TSP: Temporally-sensitive pretraining of video encoders for localization tasks</PUBLICATION>},   author={Alwassel, Humam and Giancola, Silvio and Ghanem, Bernard},   booktitle={<CONFERENCE>Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</CONFERENCE>},   pages={3173--3183},   year={2021} } ```
```