Therefore, if you are just looking to explore the method and don't need to re-create everything from scratch, we recommend that you skip this step,   If you would like to reproduce the offline <DATASET>dataset</DATASET> with the <SOFTWARE>llama2</SOFTWARE> model, you need to follow these steps:   ```  git clone git@github.com:facebookresearch/<SOFTWARE>llama</SOFTWARE>.git  ``` and then move ```Prompt-OIRL/<SOFTWARE>llama_exps/llama_step1_gen_offline.py</SOFTWARE>``` to the ```<SOFTWARE>llama</SOFTWARE>``` folder  then run the following command   ``` torchrun --nproc_per_node 1 <SOFTWARE>llama_step1_gen_offline.py</SOFTWARE> \     --ckpt_dir <SOFTWARE>llama-2-7b-chat/</SOFTWARE> \     --tokenizer_path <SOFTWARE>tokenizer.model</SOFTWARE> \     --max_seq_len 512 --max_batch_size 8 --prompt_idx 0 --dataset_eval <DATASET>gsm8k</DATASET>  ```  #### Step 2.