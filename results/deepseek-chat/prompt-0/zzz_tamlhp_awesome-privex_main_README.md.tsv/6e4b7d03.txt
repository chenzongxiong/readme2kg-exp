```markdown
[taxonomy](taxonomy1.png)](https://arxiv.org/abs/2404.00673)  ----------  ## Approaches  | **Title** | **Year** | **Venue** | **Target Explanations** | **Attacks** | **Defenses** | **Code** | | --------------- | :----: | ---- | :----: | :----: | :----: | :----: | | [<PUBLICATION>Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack</PUBLICATION>](https://www.computer.org/csdl/proceedings-article/sp/2024/313000a120/1Ub23teQ7PG) | 2024 | _<CONFERENCE>SP</CONFERENCE>_ | Feature-based | Membership Inference | Differential Privacy, Privacy-Preserving Models, DP-SGD | - | | [<PUBLICATION>Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks</PUBLICATION>](https://arxiv.org/abs/2404.07139) | 2024 | _<CONFERENCE>arXiv</CONFERENCE>_ | Feature-based | Membership Inference | Game Theory | - | | [<PUBLICATION>On the Privacy Risks of Algorithmic Recourse</PUBLICATION>](https://proceedings.mlr.press/v206/pawelczyk23a.html) | 2023 | _<CONFERENCE>AISTATS</CONFERENCE>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks</PUBLICATION>](https://dl.acm.org/doi/full/10.1145/3608482) | 2023 | _<CONFERENCE>TIST</CONFERENCE>_ | Counterfactual | Linkage | Anonymisaion | - | | [<PUBLICATION>Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3580305.3599343) | 2023 | _<CONFERENCE>KDD</CONFERENCE>_ | Counterfactual | - | Perturbation | [[Code]](https://github.com/isVy08/<SOFTWARE>L2C</SOFTWARE>/) | | [<PUBLICATION>Private Graph Extraction via Feature Explanations</PUBLICATION>](https://petsymposium.org/popets/2023/popets-2023-0041.pdf) | 2023 | _<CONFERENCE>PETS</CONFERENCE>_ | Feature-based | Graph Extraction | Perturbation | [[Code]](https://github.com/iyempissy/<SOFTWARE>graph-stealing-attacks-with-explanation</SOFTWARE>) | | [<PUBLICATION>Privacy-Preserving Algorithmic Recourse</PUBLICATION>](https://arxiv.org/abs/2311.14137) | 2023 | _<CONFERENCE>ICAIF</CONFERENCE>_ |  Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</PUBLICATION>](https://arxiv.org/abs/2308.04341) | 2023 | _<WORKSHOP>ICML-Workshop</WORKSHOP>_ | Counterfactual | Membership Inference | Differential Privacy | - | | [<PUBLICATION>Probabilistic Dataset Reconstruction from Interpretable Models</PUBLICATION>](https://arxiv.org/abs/2308.15099) | 2023 | _<CONFERENCE>arXiv</CONFERENCE>_ | Interpretable Surrogates | Data Reconstruction | - | [[Code]](https://github.com/ferryjul/<SOFTWARE>ProbabilisticDatasetsReconstruction</SOFTWARE>) | | [<PUBLICATION>DeepFixCX: Explainable privacy-preserving image compression for medical image analysis</PUBLICATION>](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1495) | 2023 | _<CONFERENCE>WIREs-DMKD</CONFERENCE>_ | Case-based | Identity recognition | Anonymisation | [[Code]](https://github.com/adgaudio/<SOFTWARE>DeepFixCX</SOFTWARE>) | | [<PUBLICATION>XorSHAP: Privacy-Preserving Explainable AI for Decision Tree Models</PUBLICATION>](https://eprint.iacr.org/2023/1859) | 2023 | _<CONFERENCE>Preprint</CONFERENCE>_ | Shapley | - | Multi-party Computation | - | | DP-XAI | 2023 | _<SOFTWARE>Github</SOFTWARE>_ | ALE plot | - | Differential Privacy | [[Code]](https://github.com/lange-martin/<SOFTWARE>dp-global-xai</SOFTWARE>) | | [<PUBLICATION>Inferring Sensitive Attributes from Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3511808.3557362) | 2022 | _<CONFERENCE>CIKM</CONFERENCE>_ | Gradient-based, Perturbation-based | Attribute Inference | - | [[Code]](https://github.com/vasishtduddu/<SOFTWARE>AttInfExplanations</SOFTWARE>) | | [<PUBLICATION>Model explanations with differential privacy</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3531146.3533235) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Feature-based | - | Differential Privacy | - | | [<PUBLICATION>DualCF: Efficient Model Extraction Attack from Counterfactual Explanations</PUBLICATION>](https://dl.acm.org/doi/10.1145/3531146.3533188) | 2022 | _<CONFERENCE>FAccT</CONFERENCE>_ | Counterfactual | Model Extraction | - | - | | [<PUBLICATION>Feature Inference Attack on Shapley Values</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3548606.3560573) | 2022 | _<CONFERENCE>CCS</CONFERENCE>_ | Shapley | Attribute/Feature Inference | Low-dimensional | - | | [<PUBLICATION>Evaluating the privacy exposure of interpretable global explainers</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/10063510/), [<PUBLICATION>Privacy Risk of Global Explainers</PUBLICATION>](https://ebooks.iospress.nl/doi/10.3233/FAIA220206) | 2022 | _<CONFERENCE>CogMI</CONFERENCE>_ | Interpretable Surrogates | Membership Inference | - | - | | [<PUBLICATION>Privacy-Preserving Case-Based Explanations: Enabling Visual Interpretability by Protecting Privacy</PUBLICATION>](https://ieeexplore.ieee.org/document/9729808/) | 2022 | _<CONFERENCE>IEEE Access</CONFERENCE>_ | Example-based | - | Anonymisation | - | | [<PUBLICATION>On the amplification of security and privacy risks by post-hoc explanations in machine learning models</PUBLICATION>](https://arxiv.org/abs/2206.14004) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Feature-based | Membership Inference | - | - | | [<PUBLICATION>Differentially Private Counterfactuals via Functional Mechanism</PUBLICATION>](https://arxiv.org/abs/2208.02878) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Counterfactual | - | Differential Privacy | - | | [<PUBLICATION>Differentially Private Shapley Values for Data Evaluation</PUBLICATION>](https://arxiv.org/abs/2206.00511) | 2022 | _<CONFERENCE>arXiv</CONFERENCE>_ | Shapley | - | Differential Privacy | [[Code]](https://github.com/amiratag/<SOFTWARE>DataShapley</SOFTWARE>) | | [<PUBLICATION>Exploiting Explanations for Model Inversion Attacks</PUBLICATION>](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Exploiting_Explanations_for_Model_Inversion_Attacks_ICCV_2021_paper.html) | 2021 | _<CONFERENCE>ICCV</CONFERENCE>_ | Gradient-based, Interpretable Surrogates | Model Inversion | - | - | | [<PUBLICATION>On the Privacy Risks of Model Explanations</PUBLICATION>](https://dl.acm.org/doi/abs/10.1145/3461702.3462533) | 2021 | <CONFERENCE>AIES</CONFERENCE> | Feature-based, Shapley, Counterfactual | Membership Inference | - | - | | [<PUBLICATION>Adversarial XAI Methods in Cybersecurity</PUBLICATION>](https://ieeexplore.ieee.org/abstract/document/9555622) | 2021 | <CONFERENCE>TIFS</CONFERENCE> | Counterfactual | Membership Inference | - | - | | [<PUBLICATION>MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</PUBLICATION>](https://arxiv.org/abs/2107.08909) | 2021 | _<CONFERENCE>arXiv</CONFERENCE>_ | Gradient-based | Model Extraction | - | [[Code]](https://github.com/cake-lab/<SOFTWARE>datafree-model-extraction</SOFTWARE>) | | [<PUBLICATION>Robust Counterfactual Explanations for Privacy-Preserving SVM</PUBLICATION>](https://www.diva-portal.org/smash/record.jsf?
```