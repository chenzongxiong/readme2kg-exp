```markdown
Then, run the following commands to evaluate on REC and RES task: ``` # Evaluate REC performance <PROGLANG>python</PROGLANG> tools/extract_mrcn_ref_feats.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> <PROGLANG>python</PROGLANG> tools/eval_ref.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> # Evaluate RES performance <PROGLANG>python</PROGLANG> tools/run_propose_to_mask.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> <PROGLANG>python</PROGLANG> tools/eval_ref_masks.py --dataset <DATASET>refcoco</DATASET> --splitBy unc --tid <tid> --top-N 0 --m <loss_type> --save ```  ## Pretrained Models We provide pre-trained model weights as long as the corresponding **<SOFTWARE>MAttNet</SOFTWARE>-style detection file** (note the <SOFTWARE>MattNet</SOFTWARE>-style detection files can be directly used to evaluate downstream REG task performance).
```