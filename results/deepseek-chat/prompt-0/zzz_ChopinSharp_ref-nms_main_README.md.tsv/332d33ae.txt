```markdown
Run following script to setup `cache` directory: ``` sh scripts/prepare_data.sh ``` This should generate following files under `cache` directory: - vocabulary file: `std_vocab_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.txt` - selected GloVe feature: `std_glove_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.npy` - referring expression database: `std_refdb_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.json` - critical objects database: `std_ctxdb_<DATASET>refcoco</DATASET>_<DATASET>split_by</DATASET>.json`   ## Train **Train with binary XE loss:** ``` <PROGLANG>PYTHONPATH</PROGLANG>=$PWD <PROGLANG>python</PROGLANG> tools/train_att_vanilla.py --dataset <DATASET>refcoco</DATASET> --split-by <DATASET>unc</DATASET> ```  **Train with ranking loss:** ``` <PROGLANG>PYTHONPATH</PROGLANG>=$PWD <PROGLANG>python</PROGLANG> tools/train_att_rank.py --dataset <DATASET>refcoco</DATASET> --split-by <DATASET>unc</DATASET> ```  We use <SOFTWARE>tensorboard</SOFTWARE> to monitor the training process.
```